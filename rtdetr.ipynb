{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreBrusco/RTDETR/blob/main/rtdetr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estruturando Google Drive:\n"
      ],
      "metadata": {
        "id": "Z46UOYjAy2Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEFEQPaDCtlt",
        "outputId": "3b77a759-7e85-4b0f-8e41-c52ccde29022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# URL da pasta 'rgb' no repositório GitHub\n",
        "url = \"https://github.com/pedrozamboni/individual_urban_tree_crown_detection/tree/main/rgb\"\n",
        "\n",
        "# Fazer o scraping da página\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Encontrar os links dos arquivos na página\n",
        "    files = soup.find_all('a', href=True)\n",
        "\n",
        "    # Filtrar arquivos com extensão .png\n",
        "    png_files = [\n",
        "        file['href'].split('/')[-1]\n",
        "        for file in files\n",
        "        if file['href'].endswith('.png')\n",
        "    ]\n",
        "\n",
        "    print(f\"Arquivos encontrados: {png_files}\")\n",
        "\n",
        "    # Diretório de destino no Google Drive\n",
        "    dest_dir = '/content/drive/MyDrive/Imagens_Tree_Crowns/'\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # URL base para os arquivos da pasta 'rgb'\n",
        "    base_url = \"https://github.com/pedrozamboni/individual_urban_tree_crown_detection/raw/main/rgb/\"\n",
        "\n",
        "    # Baixar os arquivos\n",
        "    for file_name in png_files:\n",
        "        file_url = f\"{base_url}{file_name}\"\n",
        "        dest_file = os.path.join(dest_dir, file_name)\n",
        "        os.system(f\"wget -O {dest_file} {file_url}\")\n",
        "        print(f\"Baixado: {file_name} -> {dest_file}\")\n",
        "else:\n",
        "    print(f\"Erro ao acessar a URL: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwOjH8jaJ0ru",
        "outputId": "3da0c8b7-3be5-4345-ecf3-f4444814d227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Arquivos encontrados: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colocando Imagens no Drive**"
      ],
      "metadata": {
        "id": "Om2YOv_BplSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/RT-DETR/rtdetr_pytorch/configs/dataset/coco_detection.ymlimport os\n",
        "import shutil\n",
        "\n",
        "# Defina o caminho do Google Drive onde os arquivos serão armazenados\n",
        "drive_base_path = '/content/drive/MyDrive/Imagens_Tree_Crowns'\n",
        "\n",
        "# Repositório Git a ser clonado\n",
        "repo_url = 'https://github.com/pedrozamboni/individual_urban_tree_crown_detection.git'\n",
        "repo_clone_path = '/content/individual_urban_tree_crown_detection'\n",
        "\n",
        "# Clonar o repositório\n",
        "if not os.path.exists(repo_clone_path):\n",
        "    print(f\"Clonando o repositório {repo_url}...\")\n",
        "    os.system(f'git clone {repo_url}')\n",
        "else:\n",
        "    print(f\"Repositório já clonado em {repo_clone_path}.\")\n",
        "\n",
        "# Pastas que queremos copiar do repositório\n",
        "folders_to_copy = ['bbox_txt', 'gt', 'img_list', 'rgb']\n",
        "\n",
        "# Loop para copiar cada pasta para o Google Drive\n",
        "for folder_name in folders_to_copy:\n",
        "    src_folder = os.path.join(repo_clone_path, folder_name)\n",
        "    dest_folder = os.path.join(drive_base_path, folder_name)\n",
        "\n",
        "    if os.path.exists(src_folder):\n",
        "        # Criar a pasta de destino no Google Drive, se não existir\n",
        "        if not os.path.exists(dest_folder):\n",
        "            os.makedirs(dest_folder)\n",
        "\n",
        "        # Copiar o conteúdo da pasta para o destino\n",
        "        if not os.listdir(src_folder):\n",
        "            print(f\"Aviso: A pasta '{folder_name}' está vazia. Ignorando...\")\n",
        "        else:\n",
        "            shutil.copytree(src_folder, dest_folder, dirs_exist_ok=True)\n",
        "            print(f\"Pasta '{folder_name}' copiada para {dest_folder}.\")\n",
        "    else:\n",
        "        print(f\"Aviso: A pasta '{folder_name}' não foi encontrada no repositório.\")\n",
        "\n",
        "# Opcional: Remover o repositório clonado para liberar espaço no Colab\n",
        "if os.path.exists(repo_clone_path):\n",
        "    shutil.rmtree(repo_clone_path)\n",
        "    print(f\"Repositório clonado em {repo_clone_path} foi removido.\")\n",
        "\n",
        "print(\"Todas as pastas foram copiadas para o Google Drive com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbK2WIL4QQSG",
        "outputId": "cc8f1010-8b17-4758-9f47-8e1e90d86937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonando o repositório https://github.com/pedrozamboni/individual_urban_tree_crown_detection.git...\n",
            "Pasta 'bbox_txt' copiada para /content/drive/MyDrive/Imagens_Tree_Crowns/bbox_txt.\n",
            "Pasta 'gt' copiada para /content/drive/MyDrive/Imagens_Tree_Crowns/gt.\n",
            "Pasta 'img_list' copiada para /content/drive/MyDrive/Imagens_Tree_Crowns/img_list.\n",
            "Pasta 'rgb' copiada para /content/drive/MyDrive/Imagens_Tree_Crowns/rgb.\n",
            "Repositório clonado em /content/individual_urban_tree_crown_detection foi removido.\n",
            "Todas as pastas foram copiadas para o Google Drive com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movendo os Arquivos na Estrutura COCO para a base COCO Train:"
      ],
      "metadata": {
        "id": "JH-q_TwB56mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criação das Bases Train/Teste/Val**\n"
      ],
      "metadata": {
        "id": "jrwi12m359UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Caminhos das pastas no Google Drive\n",
        "base_dir = '/content/drive/MyDrive/Imagens_Tree_Crowns'\n",
        "images_dir = os.path.join(base_dir, 'rgb')  # Diretório das imagens\n",
        "annotations_dir = os.path.join(base_dir, 'bbox_txt')  # Diretório das anotações\n",
        "img_list_dir = os.path.join(base_dir, 'img_list')  # Diretório das listas de conjuntos (train, val, test)\n",
        "\n",
        "# Diretórios de saída\n",
        "output_dir = '/content/drive/MyDrive/dataset'  # Saída para os arquivos COCO\n",
        "output_images_dir = os.path.join(output_dir, 'images')\n",
        "output_annotations_dir = os.path.join(output_dir, 'annotations')\n",
        "\n",
        "# Limpar os diretórios de saída se já existirem\n",
        "if os.path.exists(output_images_dir):\n",
        "    shutil.rmtree(output_images_dir)\n",
        "if os.path.exists(output_annotations_dir):\n",
        "    shutil.rmtree(output_annotations_dir)\n",
        "\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_annotations_dir, exist_ok=True)\n",
        "\n",
        "# Garantir que não há duplicatas entre os conjuntos\n",
        "def split_and_remove_duplicates(images, train_ratio=0.6, val_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Divide os conjuntos em treino, validação e teste, garantindo que não haja duplicatas.\n",
        "    \"\"\"\n",
        "    random.shuffle(images)  # Embaralhar imagens\n",
        "    total_images = len(images)\n",
        "\n",
        "    # Dividir os conjuntos\n",
        "    train_split = int(total_images * train_ratio)\n",
        "    val_split = int(total_images * (train_ratio + val_ratio))\n",
        "\n",
        "    train_images = images[:train_split]\n",
        "    val_images = images[train_split:val_split]\n",
        "    test_images = images[val_split:]\n",
        "\n",
        "    # Garantir que não haja duplicatas\n",
        "    assert not set(train_images) & set(val_images), \"Duplicatas entre treino e validação!\"\n",
        "    assert not set(train_images) & set(test_images), \"Duplicatas entre treino e teste!\"\n",
        "    assert not set(val_images) & set(test_images), \"Duplicatas entre validação e teste!\"\n",
        "\n",
        "    return train_images, val_images, test_images\n",
        "\n",
        "# Processar conjuntos de dados\n",
        "def process_set(set_name, image_files, used_images, verbose=True):\n",
        "    \"\"\"\n",
        "    Processa um conjunto (train, val ou test), garantindo que não há duplicatas.\n",
        "    \"\"\"\n",
        "    # Diretório para armazenar as imagens do conjunto\n",
        "    set_images_dir = os.path.join(output_images_dir, set_name)\n",
        "    os.makedirs(set_images_dir, exist_ok=True)\n",
        "\n",
        "    images = []\n",
        "    annotations = []\n",
        "    annotation_id = 1  # ID único para cada anotação\n",
        "\n",
        "    for image_id, image_file in enumerate(image_files, 1):\n",
        "        if image_file in used_images:\n",
        "            print(f\"Aviso: Imagem duplicada encontrada '{image_file}', será ignorada.\")\n",
        "            continue\n",
        "\n",
        "        used_images.add(image_file)\n",
        "\n",
        "        # Caminhos das imagens\n",
        "        src_image_path = os.path.join(images_dir, image_file)\n",
        "        dst_image_path = os.path.join(set_images_dir, image_file)\n",
        "\n",
        "        if not os.path.exists(src_image_path):\n",
        "            print(f\"Aviso: Imagem '{src_image_path}' não encontrada, ignorando...\")\n",
        "            continue\n",
        "\n",
        "        # Copiar a imagem para o diretório correspondente\n",
        "        shutil.copyfile(src_image_path, dst_image_path)\n",
        "\n",
        "        # Obter dimensões da imagem\n",
        "        with Image.open(src_image_path) as img:\n",
        "            width, height = img.size\n",
        "\n",
        "        # Adicionar entrada para a imagem\n",
        "        images.append({\n",
        "            'id': image_id,\n",
        "            'file_name': image_file,\n",
        "            'width': width,\n",
        "            'height': height\n",
        "        })\n",
        "\n",
        "        # Ler o arquivo de anotações correspondente\n",
        "        annotation_file = os.path.splitext(image_file)[0] + '.txt'\n",
        "        annotation_path = os.path.join(annotations_dir, annotation_file)\n",
        "        if not os.path.exists(annotation_path):\n",
        "            print(f\"Aviso: Arquivo de anotação '{annotation_path}' não encontrado para a imagem '{image_file}'.\")\n",
        "            continue\n",
        "\n",
        "        # Processar cada linha do arquivo de anotações\n",
        "        with open(annotation_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            # Separar os valores e garantir formato correto\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            if len(parts) != 4:\n",
        "                print(f\"Aviso: Formato inválido na linha '{line}' do arquivo '{annotation_path}'.\")\n",
        "                continue\n",
        "\n",
        "            # Converter coordenadas para floats\n",
        "            try:\n",
        "                x_min, y_min, x_max, y_max = map(float, parts)\n",
        "            except ValueError:\n",
        "                print(f\"Aviso: Valores inválidos na linha '{line}' do arquivo '{annotation_path}'.\")\n",
        "                continue\n",
        "\n",
        "            # Ajustar coordenadas para estarem dentro dos limites da imagem\n",
        "            x_min = max(0, min(x_min, width - 1))\n",
        "            y_min = max(0, min(y_min, height - 1))\n",
        "            x_max = max(0, min(x_max, width - 1))\n",
        "            y_max = max(0, min(y_max, height - 1))\n",
        "\n",
        "            # Calcular largura e altura da bounding box\n",
        "            bbox_width = x_max - x_min\n",
        "            bbox_height = y_max - y_min\n",
        "\n",
        "            if bbox_width <= 0 or bbox_height <= 0:\n",
        "                print(f\"Aviso: BBox com largura ou altura zero para a imagem '{image_file}'.\")\n",
        "                continue\n",
        "\n",
        "            # Adicionar anotação\n",
        "            annotations.append({\n",
        "                'id': annotation_id,\n",
        "                'image_id': image_id,\n",
        "                'category_id': 0,  # ID da classe única\n",
        "                'bbox': [x_min, y_min, bbox_width, bbox_height],\n",
        "                'area': bbox_width * bbox_height,\n",
        "                'iscrowd': 0\n",
        "            })\n",
        "            annotation_id += 1\n",
        "\n",
        "    # Criar o JSON no formato COCO\n",
        "    coco_format = {\n",
        "        'images': images,\n",
        "        'annotations': annotations,\n",
        "        'categories': [\n",
        "            {\n",
        "                'id': 0,\n",
        "                'name': 'Copa de Arvore',\n",
        "                'supercategory': 'none'\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Salvar o arquivo JSON\n",
        "    json_file = os.path.join(output_annotations_dir, f'instances_{set_name}.json')\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(coco_format, f, indent=4)\n",
        "\n",
        "    print(f\"Conjunto '{set_name}' processado com sucesso! {len(images)} imagens e {len(annotations)} anotações salvas.\")\n",
        "\n",
        "# Listar todas as imagens disponíveis\n",
        "all_images = os.listdir(images_dir)\n",
        "\n",
        "# Garantir que não há duplicatas\n",
        "train_images, val_images, test_images = split_and_remove_duplicates(all_images)\n",
        "\n",
        "# Processar os conjuntos\n",
        "used_images = set()  # Rastrear imagens já usadas\n",
        "process_set('train', train_images, used_images)\n",
        "process_set('val', val_images, used_images)\n",
        "process_set('test', test_images, used_images)\n"
      ],
      "metadata": {
        "id": "6nTm4nsw3H77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5c0975b7-1a6b-4068-a237-2aafaf69fccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aviso: BBox com largura ou altura zero para a imagem '92.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '40.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '127.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '208.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '104.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '197.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '120.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '122.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '157.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '154.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '111.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '166.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '124.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '151.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '100.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '33.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '7.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '11.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '48.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '126.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '126.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '180.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '183.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '143.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '102.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '41.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '56.png'.\n",
            "Conjunto 'train' processado com sucesso! 132 imagens e 2043 anotações salvas.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '193.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '3.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '133.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '114.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '27.png'.\n",
            "Conjunto 'val' processado com sucesso! 44 imagens e 692 anotações salvas.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '66.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '172.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '17.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '73.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '121.png'.\n",
            "Aviso: BBox com largura ou altura zero para a imagem '121.png'.\n",
            "Conjunto 'test' processado com sucesso! 44 imagens e 609 anotações salvas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_images = set(os.listdir('./dataset/images/test/'))\n",
        "val_images = set(os.listdir('./dataset/images/train/'))\n",
        "val_images = set(os.listdir('./dataset/images/val/'))\n",
        "\n",
        "\n",
        "duplicates = train_images & val_images\n",
        "print(f\"Imagens duplicadas entre treino e validação: {duplicates}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20qaun48b87m",
        "outputId": "31ce9036-2139-4b89-ef18-821255520476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagens duplicadas entre treino e validação: {'191.png', '156.png', '91.png', '127.png', '79.png', '5.png', '160.png', '194.png', '176.png', '162.png', '181.png', '56.png', '164.png', '175.png', '119.png', '186.png', '202.png', '159.png', '42.png', '132.png', '94.png', '157.png', '92.png', '8.png', '106.png', '217.png', '45.png', '173.png', '166.png', '21.png', '138.png', '196.png', '169.png', '62.png', '113.png', '201.png', '77.png', '22.png', '43.png', '190.png', '152.png', '198.png', '139.png', '109.png', '178.png', '40.png', '50.png', '219.png', '84.png', '31.png', '144.png', '146.png', '66.png', '206.png', '183.png', '65.png', '161.png', '81.png', '218.png', '51.png', '143.png', '1.png', '32.png', '165.png', '215.png', '174.png', '10.png', '208.png', '149.png', '170.png', '188.png', '203.png', '116.png', '17.png', '199.png', '212.png', '41.png', '145.png', '172.png', '35.png', '214.png', '134.png', '73.png', '83.png', '137.png', '48.png', '168.png', '185.png', '216.png', '147.png', '97.png', '4.png', '189.png', '195.png', '60.png'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências necessárias\n",
        "!pip install torchvision==0.15.2 torch==2.0.1\n",
        "!pip install torch==2.0.1\n",
        "!pip install torchvision==0.15.2\n",
        "!pip install onnx==1.14.0\n",
        "!pip install onnxruntime==1.15.1\n",
        "!pip install pycocotools\n",
        "!pip install PyYAML\n",
        "!pip install scipy\n",
        "import torchvision\n",
        "print(f\"Versão do Torchvision: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hEYYMwLmurvW",
        "outputId": "a960c922-959f-4ae0-f3e6-a74c44e0be85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.15.2\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (0.45.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision==0.15.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision==0.15.2) (1.3.0)\n",
            "Collecting onnx==1.14.0\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0) (4.25.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.14.0) (4.12.2)\n",
            "Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n",
            "Collecting onnxruntime==1.15.1\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.15.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.15.1) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.15.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.15.1) (1.3.0)\n",
            "Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Versão do Torchvision: 0.15.2+cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecione o Modelo a ser Executado"
      ],
      "metadata": {
        "id": "-rWSAPysycmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/RT-DETR/rtdetrv2_pytorch/tools/train.py \\\n",
        "    -c /content/drive/MyDrive/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r50vd_m_dsp_3x_coco.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGXhTAyTN61S",
        "outputId": "d8036e90-4ab3-4ee4-f502-036dc28e11fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-03 18:20:00.754251: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-03 18:20:00.771072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-03 18:20:00.791932: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-03 18:20:00.798254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-03 18:20:00.813253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-03 18:20:01.883637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not init distributed mode.\n",
            "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': None, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': 'https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetrv2_r50vd_m_7x_coco_ema.pth', 'epoches': 150, 'last_epoch': -1, 'use_amp': False, 'use_ema': True, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.1, 'find_unused_parameters': False, 'seed': None, 'print_freq': 100, 'checkpoint_freq': 1, 'output_dir': './output/rtdetrv2_r50vd_m_dsp_3x_coco', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 1, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': './drive/MyDrive/dataset/images/train/', 'ann_file': './drive/MyDrive/dataset/annotations/instances_train.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 33, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 33}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': './drive/MyDrive/dataset/images/val/', 'ann_file': './drive/MyDrive/dataset/annotations/instances_val.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': './output/rtdetrv2_r50vd_m_dsp_3x_coco', 'checkpoint_freq': 1, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': False, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'epoches': 150, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)(?!.*norm).*$', 'lr': 1e-05}, {'params': '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0}], 'lr': 0.0001, 'betas': [0.9, 0.999], 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [1000], 'gamma': 0.1}, 'lr_warmup_scheduler': {'type': 'LinearWarmup', 'warmup_duration': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': True}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 0.5, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': 2, 'num_points': [4, 4, 4], 'cross_attn_method': 'discrete', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml', './include/optimizer.yml', './include/rtdetrv2_r50vd.yml'], 'tuning': 'https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetrv2_r50vd_m_7x_coco_ema.pth', 'config': '/content/drive/MyDrive/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r50vd_m_dsp_3x_coco.yml', 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}\n",
            "Start training\n",
            "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth\" to /root/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth\n",
            "100% 90.0M/90.0M [00:02<00:00, 32.6MB/s]\n",
            "Load PResNet50 state_dict\n",
            "tuning checkpoint from https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetrv2_r50vd_m_7x_coco_ema.pth\n",
            "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetrv2_r50vd_m_7x_coco_ema.pth\" to /root/.cache/torch/hub/checkpoints/rtdetrv2_r50vd_m_7x_coco_ema.pth\n",
            "100% 140M/140M [00:05<00:00, 26.8MB/s]\n",
            "Load model.state_dict, {'missed': [], 'unmatched': ['decoder.denoising_class_embed.weight', 'decoder.enc_score_head.weight', 'decoder.enc_score_head.bias', 'decoder.dec_score_head.0.weight', 'decoder.dec_score_head.0.bias', 'decoder.dec_score_head.1.weight', 'decoder.dec_score_head.1.bias', 'decoder.dec_score_head.2.weight', 'decoder.dec_score_head.2.bias', 'decoder.dec_score_head.3.weight', 'decoder.dec_score_head.3.bias', 'decoder.dec_score_head.4.weight', 'decoder.dec_score_head.4.bias', 'decoder.dec_score_head.5.weight', 'decoder.dec_score_head.5.bias']}\n",
            "Initial lr: [1e-05, 0.0001, 0.0001]\n",
            "building train_dataloader with batch_size=16...\n",
            "loading annotations into memory...\n",
            "Done (t=1.13s)\n",
            "creating index...\n",
            "index created!\n",
            "building val_dataloader with batch_size=32...\n",
            "loading annotations into memory...\n",
            "Done (t=0.76s)\n",
            "creating index...\n",
            "index created!\n",
            "number of trainable parameters: 36106851\n",
            "Epoch: [0]  [0/8]  eta: 0:02:57  lr: 0.000000  loss: 39.7374 (39.7374)  loss_vfl: 0.6883 (0.6883)  loss_bbox: 0.8535 (0.8535)  loss_giou: 1.8118 (1.8118)  loss_vfl_aux_0: 0.5421 (0.5421)  loss_bbox_aux_0: 0.8581 (0.8581)  loss_giou_aux_0: 1.8985 (1.8985)  loss_vfl_aux_1: 0.6417 (0.6417)  loss_bbox_aux_1: 0.8641 (0.8641)  loss_giou_aux_1: 1.8718 (1.8718)  loss_vfl_aux_2: 0.6570 (0.6570)  loss_bbox_aux_2: 0.8513 (0.8513)  loss_giou_aux_2: 1.8356 (1.8356)  loss_vfl_aux_3: 0.5709 (0.5709)  loss_bbox_aux_3: 0.8595 (0.8595)  loss_giou_aux_3: 1.8141 (1.8141)  loss_vfl_aux_4: 0.7252 (0.7252)  loss_bbox_aux_4: 0.8570 (0.8570)  loss_giou_aux_4: 1.8050 (1.8050)  loss_vfl_dn_0: 0.8958 (0.8958)  loss_bbox_dn_0: 0.4767 (0.4767)  loss_giou_dn_0: 1.2512 (1.2512)  loss_vfl_dn_1: 1.0215 (1.0215)  loss_bbox_dn_1: 0.4856 (0.4856)  loss_giou_dn_1: 1.2461 (1.2461)  loss_vfl_dn_2: 1.0011 (1.0011)  loss_bbox_dn_2: 0.4939 (0.4939)  loss_giou_dn_2: 1.2432 (1.2432)  loss_vfl_dn_3: 0.8426 (0.8426)  loss_bbox_dn_3: 0.5122 (0.5122)  loss_giou_dn_3: 1.2641 (1.2641)  loss_vfl_dn_4: 1.0479 (1.0479)  loss_bbox_dn_4: 0.5205 (0.5205)  loss_giou_dn_4: 1.2866 (1.2866)  loss_vfl_dn_5: 0.9932 (0.9932)  loss_bbox_dn_5: 0.5205 (0.5205)  loss_giou_dn_5: 1.2866 (1.2866)  loss_vfl_enc_0: 0.5504 (0.5504)  loss_bbox_enc_0: 0.8754 (0.8754)  loss_giou_enc_0: 1.9166 (1.9166)  time: 22.2465  data: 18.0319  max mem: 7580\n",
            "Epoch: [0]  [7/8]  eta: 0:00:04  lr: 0.000000  loss: 44.4677 (43.9548)  loss_vfl: 0.3957 (0.4414)  loss_bbox: 1.2136 (1.1684)  loss_giou: 2.4302 (2.3615)  loss_vfl_aux_0: 0.2995 (0.3348)  loss_bbox_aux_0: 1.2310 (1.2036)  loss_giou_aux_0: 2.4642 (2.4369)  loss_vfl_aux_1: 0.3467 (0.3891)  loss_bbox_aux_1: 1.2359 (1.1956)  loss_giou_aux_1: 2.4957 (2.4292)  loss_vfl_aux_2: 0.3678 (0.4156)  loss_bbox_aux_2: 1.2228 (1.1838)  loss_giou_aux_2: 2.4651 (2.3955)  loss_vfl_aux_3: 0.3106 (0.3504)  loss_bbox_aux_3: 1.2249 (1.1815)  loss_giou_aux_3: 2.4367 (2.3689)  loss_vfl_aux_4: 0.4212 (0.4676)  loss_bbox_aux_4: 1.2348 (1.1782)  loss_giou_aux_4: 2.3935 (2.3502)  loss_vfl_dn_0: 0.8609 (0.8418)  loss_bbox_dn_0: 0.4068 (0.4206)  loss_giou_dn_0: 1.2846 (1.3059)  loss_vfl_dn_1: 1.0059 (0.9690)  loss_bbox_dn_1: 0.4034 (0.4244)  loss_giou_dn_1: 1.2681 (1.3106)  loss_vfl_dn_2: 1.0011 (0.9642)  loss_bbox_dn_2: 0.4142 (0.4295)  loss_giou_dn_2: 1.2464 (1.3002)  loss_vfl_dn_3: 0.8426 (0.8152)  loss_bbox_dn_3: 0.4301 (0.4434)  loss_giou_dn_3: 1.2641 (1.3144)  loss_vfl_dn_4: 1.0479 (1.0324)  loss_bbox_dn_4: 0.4355 (0.4513)  loss_giou_dn_4: 1.2866 (1.3300)  loss_vfl_dn_5: 0.9932 (0.9704)  loss_bbox_dn_5: 0.4355 (0.4513)  loss_giou_dn_5: 1.2866 (1.3300)  loss_vfl_enc_0: 0.3285 (0.3465)  loss_bbox_enc_0: 1.2138 (1.1956)  loss_giou_enc_0: 2.5400 (2.4561)  time: 4.3437  data: 3.3456  max mem: 15427\n",
            "Epoch: [0] Total time: 0:00:34 (4.3501 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 44.4677 (43.9548)  loss_vfl: 0.3957 (0.4414)  loss_bbox: 1.2136 (1.1684)  loss_giou: 2.4302 (2.3615)  loss_vfl_aux_0: 0.2995 (0.3348)  loss_bbox_aux_0: 1.2310 (1.2036)  loss_giou_aux_0: 2.4642 (2.4369)  loss_vfl_aux_1: 0.3467 (0.3891)  loss_bbox_aux_1: 1.2359 (1.1956)  loss_giou_aux_1: 2.4957 (2.4292)  loss_vfl_aux_2: 0.3678 (0.4156)  loss_bbox_aux_2: 1.2228 (1.1838)  loss_giou_aux_2: 2.4651 (2.3955)  loss_vfl_aux_3: 0.3106 (0.3504)  loss_bbox_aux_3: 1.2249 (1.1815)  loss_giou_aux_3: 2.4367 (2.3689)  loss_vfl_aux_4: 0.4212 (0.4676)  loss_bbox_aux_4: 1.2348 (1.1782)  loss_giou_aux_4: 2.3935 (2.3502)  loss_vfl_dn_0: 0.8609 (0.8418)  loss_bbox_dn_0: 0.4068 (0.4206)  loss_giou_dn_0: 1.2846 (1.3059)  loss_vfl_dn_1: 1.0059 (0.9690)  loss_bbox_dn_1: 0.4034 (0.4244)  loss_giou_dn_1: 1.2681 (1.3106)  loss_vfl_dn_2: 1.0011 (0.9642)  loss_bbox_dn_2: 0.4142 (0.4295)  loss_giou_dn_2: 1.2464 (1.3002)  loss_vfl_dn_3: 0.8426 (0.8152)  loss_bbox_dn_3: 0.4301 (0.4434)  loss_giou_dn_3: 1.2641 (1.3144)  loss_vfl_dn_4: 1.0479 (1.0324)  loss_bbox_dn_4: 0.4355 (0.4513)  loss_giou_dn_4: 1.2866 (1.3300)  loss_vfl_dn_5: 0.9932 (0.9704)  loss_bbox_dn_5: 0.4355 (0.4513)  loss_giou_dn_5: 1.2866 (1.3300)  loss_vfl_enc_0: 0.3285 (0.3465)  loss_bbox_enc_0: 1.2138 (1.1956)  loss_giou_enc_0: 2.5400 (2.4561)\n",
            "Test:  [0/2]  eta: 0:01:03    time: 31.8623  data: 30.2911  max mem: 15427\n",
            "Test:  [1/2]  eta: 0:00:16    time: 16.2020  data: 15.1618  max mem: 15427\n",
            "Test: Total time: 0:00:32 (16.2290 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
            "best_stat: {'epoch': 0, 'coco_eval_bbox': 0.00023023316825713472}\n",
            "Epoch: [1]  [0/8]  eta: 0:00:17  lr: 0.000000  loss: 41.9095 (41.9095)  loss_vfl: 0.4979 (0.4979)  loss_bbox: 0.9417 (0.9417)  loss_giou: 2.3003 (2.3003)  loss_vfl_aux_0: 0.3811 (0.3811)  loss_bbox_aux_0: 0.9789 (0.9789)  loss_giou_aux_0: 2.3666 (2.3666)  loss_vfl_aux_1: 0.4529 (0.4529)  loss_bbox_aux_1: 0.9502 (0.9502)  loss_giou_aux_1: 2.3579 (2.3579)  loss_vfl_aux_2: 0.4805 (0.4805)  loss_bbox_aux_2: 0.9512 (0.9512)  loss_giou_aux_2: 2.3405 (2.3405)  loss_vfl_aux_3: 0.4027 (0.4027)  loss_bbox_aux_3: 0.9426 (0.9426)  loss_giou_aux_3: 2.3211 (2.3211)  loss_vfl_aux_4: 0.5212 (0.5212)  loss_bbox_aux_4: 0.9506 (0.9506)  loss_giou_aux_4: 2.2921 (2.2921)  loss_vfl_dn_0: 0.9008 (0.9008)  loss_bbox_dn_0: 0.3647 (0.3647)  loss_giou_dn_0: 1.2568 (1.2568)  loss_vfl_dn_1: 1.0264 (1.0264)  loss_bbox_dn_1: 0.3756 (0.3756)  loss_giou_dn_1: 1.2647 (1.2647)  loss_vfl_dn_2: 1.0115 (1.0115)  loss_bbox_dn_2: 0.3715 (0.3715)  loss_giou_dn_2: 1.2577 (1.2577)  loss_vfl_dn_3: 0.8206 (0.8206)  loss_bbox_dn_3: 0.3898 (0.3898)  loss_giou_dn_3: 1.2825 (1.2825)  loss_vfl_dn_4: 1.0312 (1.0312)  loss_bbox_dn_4: 0.3940 (0.3940)  loss_giou_dn_4: 1.2939 (1.2939)  loss_vfl_dn_5: 0.9760 (0.9760)  loss_bbox_dn_5: 0.3940 (0.3940)  loss_giou_dn_5: 1.2939 (1.2939)  loss_vfl_enc_0: 0.4225 (0.4225)  loss_bbox_enc_0: 0.9804 (0.9804)  loss_giou_enc_0: 2.3709 (2.3709)  time: 2.1986  data: 1.6533  max mem: 15427\n",
            "Epoch: [1]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 43.6099 (43.4253)  loss_vfl: 0.4054 (0.4640)  loss_bbox: 1.1898 (1.1174)  loss_giou: 2.3003 (2.3202)  loss_vfl_aux_0: 0.3177 (0.3298)  loss_bbox_aux_0: 1.2127 (1.1687)  loss_giou_aux_0: 2.3666 (2.4112)  loss_vfl_aux_1: 0.3571 (0.3790)  loss_bbox_aux_1: 1.1936 (1.1500)  loss_giou_aux_1: 2.3579 (2.4104)  loss_vfl_aux_2: 0.3947 (0.4275)  loss_bbox_aux_2: 1.2044 (1.1395)  loss_giou_aux_2: 2.3405 (2.3650)  loss_vfl_aux_3: 0.3208 (0.3643)  loss_bbox_aux_3: 1.1948 (1.1253)  loss_giou_aux_3: 2.3211 (2.3404)  loss_vfl_aux_4: 0.4288 (0.4888)  loss_bbox_aux_4: 1.1885 (1.1239)  loss_giou_aux_4: 2.2921 (2.3148)  loss_vfl_dn_0: 0.8562 (0.8519)  loss_bbox_dn_0: 0.3647 (0.4083)  loss_giou_dn_0: 1.2715 (1.2933)  loss_vfl_dn_1: 0.9926 (0.9789)  loss_bbox_dn_1: 0.3756 (0.4143)  loss_giou_dn_1: 1.2769 (1.3042)  loss_vfl_dn_2: 0.9885 (0.9679)  loss_bbox_dn_2: 0.3716 (0.4182)  loss_giou_dn_2: 1.2584 (1.3010)  loss_vfl_dn_3: 0.8325 (0.8125)  loss_bbox_dn_3: 0.3898 (0.4335)  loss_giou_dn_3: 1.2837 (1.3163)  loss_vfl_dn_4: 1.0470 (1.0277)  loss_bbox_dn_4: 0.3953 (0.4423)  loss_giou_dn_4: 1.2957 (1.3313)  loss_vfl_dn_5: 0.9883 (0.9689)  loss_bbox_dn_5: 0.3952 (0.4423)  loss_giou_dn_5: 1.2957 (1.3312)  loss_vfl_enc_0: 0.3457 (0.3515)  loss_bbox_enc_0: 1.2041 (1.1663)  loss_giou_enc_0: 2.3709 (2.4234)  time: 0.8794  data: 0.3716  max mem: 15427\n",
            "Epoch: [1] Total time: 0:00:07 (0.8866 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 43.6099 (43.4253)  loss_vfl: 0.4054 (0.4640)  loss_bbox: 1.1898 (1.1174)  loss_giou: 2.3003 (2.3202)  loss_vfl_aux_0: 0.3177 (0.3298)  loss_bbox_aux_0: 1.2127 (1.1687)  loss_giou_aux_0: 2.3666 (2.4112)  loss_vfl_aux_1: 0.3571 (0.3790)  loss_bbox_aux_1: 1.1936 (1.1500)  loss_giou_aux_1: 2.3579 (2.4104)  loss_vfl_aux_2: 0.3947 (0.4275)  loss_bbox_aux_2: 1.2044 (1.1395)  loss_giou_aux_2: 2.3405 (2.3650)  loss_vfl_aux_3: 0.3208 (0.3643)  loss_bbox_aux_3: 1.1948 (1.1253)  loss_giou_aux_3: 2.3211 (2.3404)  loss_vfl_aux_4: 0.4288 (0.4888)  loss_bbox_aux_4: 1.1885 (1.1239)  loss_giou_aux_4: 2.2921 (2.3148)  loss_vfl_dn_0: 0.8562 (0.8519)  loss_bbox_dn_0: 0.3647 (0.4083)  loss_giou_dn_0: 1.2715 (1.2933)  loss_vfl_dn_1: 0.9926 (0.9789)  loss_bbox_dn_1: 0.3756 (0.4143)  loss_giou_dn_1: 1.2769 (1.3042)  loss_vfl_dn_2: 0.9885 (0.9679)  loss_bbox_dn_2: 0.3716 (0.4182)  loss_giou_dn_2: 1.2584 (1.3010)  loss_vfl_dn_3: 0.8325 (0.8125)  loss_bbox_dn_3: 0.3898 (0.4335)  loss_giou_dn_3: 1.2837 (1.3163)  loss_vfl_dn_4: 1.0470 (1.0277)  loss_bbox_dn_4: 0.3953 (0.4423)  loss_giou_dn_4: 1.2957 (1.3313)  loss_vfl_dn_5: 0.9883 (0.9689)  loss_bbox_dn_5: 0.3952 (0.4423)  loss_giou_dn_5: 1.2957 (1.3312)  loss_vfl_enc_0: 0.3457 (0.3515)  loss_bbox_enc_0: 1.2041 (1.1663)  loss_giou_enc_0: 2.3709 (2.4234)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5386  data: 1.3007  max mem: 15427\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5187  data: 0.6665  max mem: 15427\n",
            "Test: Total time: 0:00:03 (1.9300 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
            "best_stat: {'epoch': 1, 'coco_eval_bbox': 0.00027008086755090895}\n",
            "Epoch: [2]  [0/8]  eta: 0:00:32  lr: 0.000000  loss: 47.2323 (47.2323)  loss_vfl: 0.2604 (0.2604)  loss_bbox: 1.4649 (1.4649)  loss_giou: 2.7881 (2.7881)  loss_vfl_aux_0: 0.1991 (0.1991)  loss_bbox_aux_0: 1.4644 (1.4644)  loss_giou_aux_0: 2.8559 (2.8559)  loss_vfl_aux_1: 0.2422 (0.2422)  loss_bbox_aux_1: 1.4565 (1.4565)  loss_giou_aux_1: 2.8496 (2.8496)  loss_vfl_aux_2: 0.2489 (0.2489)  loss_bbox_aux_2: 1.4350 (1.4350)  loss_giou_aux_2: 2.8336 (2.8336)  loss_vfl_aux_3: 0.2177 (0.2177)  loss_bbox_aux_3: 1.4435 (1.4435)  loss_giou_aux_3: 2.8173 (2.8173)  loss_vfl_aux_4: 0.2757 (0.2757)  loss_bbox_aux_4: 1.4739 (1.4739)  loss_giou_aux_4: 2.7782 (2.7782)  loss_vfl_dn_0: 0.8602 (0.8602)  loss_bbox_dn_0: 0.3138 (0.3138)  loss_giou_dn_0: 1.2899 (1.2899)  loss_vfl_dn_1: 1.0259 (1.0259)  loss_bbox_dn_1: 0.3196 (0.3196)  loss_giou_dn_1: 1.2866 (1.2866)  loss_vfl_dn_2: 1.0059 (1.0059)  loss_bbox_dn_2: 0.3286 (0.3286)  loss_giou_dn_2: 1.2790 (1.2790)  loss_vfl_dn_3: 0.8675 (0.8675)  loss_bbox_dn_3: 0.3426 (0.3426)  loss_giou_dn_3: 1.2840 (1.2840)  loss_vfl_dn_4: 1.0802 (1.0802)  loss_bbox_dn_4: 0.3515 (0.3515)  loss_giou_dn_4: 1.3038 (1.3038)  loss_vfl_dn_5: 1.0179 (1.0179)  loss_bbox_dn_5: 0.3515 (0.3515)  loss_giou_dn_5: 1.3038 (1.3038)  loss_vfl_enc_0: 0.2205 (0.2205)  loss_bbox_enc_0: 1.4273 (1.4273)  loss_giou_enc_0: 2.8675 (2.8675)  time: 4.0094  data: 3.4038  max mem: 15427\n",
            "Epoch: [2]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 44.8363 (44.6315)  loss_vfl: 0.3477 (0.4368)  loss_bbox: 1.2437 (1.2270)  loss_giou: 2.5746 (2.4253)  loss_vfl_aux_0: 0.2553 (0.3204)  loss_bbox_aux_0: 1.2727 (1.2635)  loss_giou_aux_0: 2.6577 (2.5142)  loss_vfl_aux_1: 0.2985 (0.3742)  loss_bbox_aux_1: 1.2506 (1.2504)  loss_giou_aux_1: 2.6471 (2.5042)  loss_vfl_aux_2: 0.3383 (0.4117)  loss_bbox_aux_2: 1.2591 (1.2393)  loss_giou_aux_2: 2.6006 (2.4667)  loss_vfl_aux_3: 0.2770 (0.3522)  loss_bbox_aux_3: 1.2344 (1.2270)  loss_giou_aux_3: 2.5954 (2.4490)  loss_vfl_aux_4: 0.3656 (0.4626)  loss_bbox_aux_4: 1.2640 (1.2306)  loss_giou_aux_4: 2.5637 (2.4206)  loss_vfl_dn_0: 0.8336 (0.8501)  loss_bbox_dn_0: 0.3496 (0.3833)  loss_giou_dn_0: 1.2980 (1.3010)  loss_vfl_dn_1: 0.9697 (0.9930)  loss_bbox_dn_1: 0.3482 (0.3907)  loss_giou_dn_1: 1.2946 (1.2955)  loss_vfl_dn_2: 0.9563 (0.9876)  loss_bbox_dn_2: 0.3418 (0.3971)  loss_giou_dn_2: 1.2790 (1.2862)  loss_vfl_dn_3: 0.8145 (0.8335)  loss_bbox_dn_3: 0.3561 (0.4135)  loss_giou_dn_3: 1.2840 (1.2978)  loss_vfl_dn_4: 1.0263 (1.0563)  loss_bbox_dn_4: 0.3665 (0.4226)  loss_giou_dn_4: 1.3038 (1.3108)  loss_vfl_dn_5: 0.9533 (0.9930)  loss_bbox_dn_5: 0.3665 (0.4225)  loss_giou_dn_5: 1.3038 (1.3108)  loss_vfl_enc_0: 0.2598 (0.3342)  loss_bbox_enc_0: 1.2644 (1.2531)  loss_giou_enc_0: 2.6330 (2.5236)  time: 0.9805  data: 0.4422  max mem: 16799\n",
            "Epoch: [2] Total time: 0:00:07 (0.9864 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 44.8363 (44.6315)  loss_vfl: 0.3477 (0.4368)  loss_bbox: 1.2437 (1.2270)  loss_giou: 2.5746 (2.4253)  loss_vfl_aux_0: 0.2553 (0.3204)  loss_bbox_aux_0: 1.2727 (1.2635)  loss_giou_aux_0: 2.6577 (2.5142)  loss_vfl_aux_1: 0.2985 (0.3742)  loss_bbox_aux_1: 1.2506 (1.2504)  loss_giou_aux_1: 2.6471 (2.5042)  loss_vfl_aux_2: 0.3383 (0.4117)  loss_bbox_aux_2: 1.2591 (1.2393)  loss_giou_aux_2: 2.6006 (2.4667)  loss_vfl_aux_3: 0.2770 (0.3522)  loss_bbox_aux_3: 1.2344 (1.2270)  loss_giou_aux_3: 2.5954 (2.4490)  loss_vfl_aux_4: 0.3656 (0.4626)  loss_bbox_aux_4: 1.2640 (1.2306)  loss_giou_aux_4: 2.5637 (2.4206)  loss_vfl_dn_0: 0.8336 (0.8501)  loss_bbox_dn_0: 0.3496 (0.3833)  loss_giou_dn_0: 1.2980 (1.3010)  loss_vfl_dn_1: 0.9697 (0.9930)  loss_bbox_dn_1: 0.3482 (0.3907)  loss_giou_dn_1: 1.2946 (1.2955)  loss_vfl_dn_2: 0.9563 (0.9876)  loss_bbox_dn_2: 0.3418 (0.3971)  loss_giou_dn_2: 1.2790 (1.2862)  loss_vfl_dn_3: 0.8145 (0.8335)  loss_bbox_dn_3: 0.3561 (0.4135)  loss_giou_dn_3: 1.2840 (1.2978)  loss_vfl_dn_4: 1.0263 (1.0563)  loss_bbox_dn_4: 0.3665 (0.4226)  loss_giou_dn_4: 1.3038 (1.3108)  loss_vfl_dn_5: 0.9533 (0.9930)  loss_bbox_dn_5: 0.3665 (0.4225)  loss_giou_dn_5: 1.3038 (1.3108)  loss_vfl_enc_0: 0.2598 (0.3342)  loss_bbox_enc_0: 1.2644 (1.2531)  loss_giou_enc_0: 2.6330 (2.5236)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.9293  data: 4.4219  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.2151  data: 2.2269  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.2464 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
            "best_stat: {'epoch': 1, 'coco_eval_bbox': 0.00027008086755090895}\n",
            "Epoch: [3]  [0/8]  eta: 0:00:16  lr: 0.000000  loss: 41.7553 (41.7553)  loss_vfl: 0.5871 (0.5871)  loss_bbox: 0.9756 (0.9756)  loss_giou: 2.0806 (2.0806)  loss_vfl_aux_0: 0.4249 (0.4249)  loss_bbox_aux_0: 1.0751 (1.0751)  loss_giou_aux_0: 2.1165 (2.1165)  loss_vfl_aux_1: 0.5055 (0.5055)  loss_bbox_aux_1: 1.0476 (1.0476)  loss_giou_aux_1: 2.1107 (2.1107)  loss_vfl_aux_2: 0.5735 (0.5735)  loss_bbox_aux_2: 1.0065 (1.0065)  loss_giou_aux_2: 2.0668 (2.0668)  loss_vfl_aux_3: 0.4915 (0.4915)  loss_bbox_aux_3: 0.9818 (0.9818)  loss_giou_aux_3: 2.0574 (2.0574)  loss_vfl_aux_4: 0.6202 (0.6202)  loss_bbox_aux_4: 0.9897 (0.9897)  loss_giou_aux_4: 2.0667 (2.0667)  loss_vfl_dn_0: 0.9090 (0.9090)  loss_bbox_dn_0: 0.4491 (0.4491)  loss_giou_dn_0: 1.2494 (1.2494)  loss_vfl_dn_1: 0.9877 (0.9877)  loss_bbox_dn_1: 0.4645 (0.4645)  loss_giou_dn_1: 1.2877 (1.2877)  loss_vfl_dn_2: 0.9764 (0.9764)  loss_bbox_dn_2: 0.4713 (0.4713)  loss_giou_dn_2: 1.2801 (1.2801)  loss_vfl_dn_3: 0.8360 (0.8360)  loss_bbox_dn_3: 0.4850 (0.4850)  loss_giou_dn_3: 1.2909 (1.2909)  loss_vfl_dn_4: 1.0429 (1.0429)  loss_bbox_dn_4: 0.4967 (0.4967)  loss_giou_dn_4: 1.3065 (1.3065)  loss_vfl_dn_5: 0.9812 (0.9812)  loss_bbox_dn_5: 0.4967 (0.4967)  loss_giou_dn_5: 1.3064 (1.3064)  loss_vfl_enc_0: 0.4395 (0.4395)  loss_bbox_enc_0: 1.0464 (1.0464)  loss_giou_enc_0: 2.1746 (2.1746)  time: 2.1012  data: 1.5795  max mem: 16799\n",
            "Epoch: [3]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 42.5902 (42.8912)  loss_vfl: 0.4376 (0.5000)  loss_bbox: 1.0129 (1.0565)  loss_giou: 2.3128 (2.2544)  loss_vfl_aux_0: 0.3512 (0.3807)  loss_bbox_aux_0: 1.0842 (1.1230)  loss_giou_aux_0: 2.3799 (2.3165)  loss_vfl_aux_1: 0.4082 (0.4333)  loss_bbox_aux_1: 1.0920 (1.1100)  loss_giou_aux_1: 2.3670 (2.3185)  loss_vfl_aux_2: 0.4280 (0.4758)  loss_bbox_aux_2: 1.0364 (1.0834)  loss_giou_aux_2: 2.3495 (2.2815)  loss_vfl_aux_3: 0.3424 (0.3980)  loss_bbox_aux_3: 1.0236 (1.0661)  loss_giou_aux_3: 2.3347 (2.2644)  loss_vfl_aux_4: 0.4605 (0.5283)  loss_bbox_aux_4: 1.0231 (1.0653)  loss_giou_aux_4: 2.3059 (2.2461)  loss_vfl_dn_0: 0.8239 (0.8616)  loss_bbox_dn_0: 0.4170 (0.4215)  loss_giou_dn_0: 1.2515 (1.2871)  loss_vfl_dn_1: 0.9593 (0.9756)  loss_bbox_dn_1: 0.4233 (0.4323)  loss_giou_dn_1: 1.2877 (1.3047)  loss_vfl_dn_2: 0.9526 (0.9731)  loss_bbox_dn_2: 0.4250 (0.4370)  loss_giou_dn_2: 1.2801 (1.2930)  loss_vfl_dn_3: 0.8060 (0.8245)  loss_bbox_dn_3: 0.4484 (0.4548)  loss_giou_dn_3: 1.2909 (1.3054)  loss_vfl_dn_4: 1.0084 (1.0353)  loss_bbox_dn_4: 0.4526 (0.4627)  loss_giou_dn_4: 1.3065 (1.3197)  loss_vfl_dn_5: 0.9446 (0.9739)  loss_bbox_dn_5: 0.4526 (0.4627)  loss_giou_dn_5: 1.3064 (1.3196)  loss_vfl_enc_0: 0.3642 (0.3897)  loss_bbox_enc_0: 1.0996 (1.1126)  loss_giou_enc_0: 2.3750 (2.3426)  time: 0.7253  data: 0.2308  max mem: 16799\n",
            "Epoch: [3] Total time: 0:00:05 (0.7329 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 42.5902 (42.8912)  loss_vfl: 0.4376 (0.5000)  loss_bbox: 1.0129 (1.0565)  loss_giou: 2.3128 (2.2544)  loss_vfl_aux_0: 0.3512 (0.3807)  loss_bbox_aux_0: 1.0842 (1.1230)  loss_giou_aux_0: 2.3799 (2.3165)  loss_vfl_aux_1: 0.4082 (0.4333)  loss_bbox_aux_1: 1.0920 (1.1100)  loss_giou_aux_1: 2.3670 (2.3185)  loss_vfl_aux_2: 0.4280 (0.4758)  loss_bbox_aux_2: 1.0364 (1.0834)  loss_giou_aux_2: 2.3495 (2.2815)  loss_vfl_aux_3: 0.3424 (0.3980)  loss_bbox_aux_3: 1.0236 (1.0661)  loss_giou_aux_3: 2.3347 (2.2644)  loss_vfl_aux_4: 0.4605 (0.5283)  loss_bbox_aux_4: 1.0231 (1.0653)  loss_giou_aux_4: 2.3059 (2.2461)  loss_vfl_dn_0: 0.8239 (0.8616)  loss_bbox_dn_0: 0.4170 (0.4215)  loss_giou_dn_0: 1.2515 (1.2871)  loss_vfl_dn_1: 0.9593 (0.9756)  loss_bbox_dn_1: 0.4233 (0.4323)  loss_giou_dn_1: 1.2877 (1.3047)  loss_vfl_dn_2: 0.9526 (0.9731)  loss_bbox_dn_2: 0.4250 (0.4370)  loss_giou_dn_2: 1.2801 (1.2930)  loss_vfl_dn_3: 0.8060 (0.8245)  loss_bbox_dn_3: 0.4484 (0.4548)  loss_giou_dn_3: 1.2909 (1.3054)  loss_vfl_dn_4: 1.0084 (1.0353)  loss_bbox_dn_4: 0.4526 (0.4627)  loss_giou_dn_4: 1.3065 (1.3197)  loss_vfl_dn_5: 0.9446 (0.9739)  loss_bbox_dn_5: 0.4526 (0.4627)  loss_giou_dn_5: 1.3064 (1.3196)  loss_vfl_enc_0: 0.3642 (0.3897)  loss_bbox_enc_0: 1.0996 (1.1126)  loss_giou_enc_0: 2.3750 (2.3426)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5677  data: 4.3694  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0365  data: 2.2020  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0637 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            "best_stat: {'epoch': 1, 'coco_eval_bbox': 0.00027008086755090895}\n",
            "Epoch: [4]  [0/8]  eta: 0:00:16  lr: 0.000000  loss: 40.6365 (40.6365)  loss_vfl: 0.6383 (0.6383)  loss_bbox: 0.8267 (0.8267)  loss_giou: 2.0728 (2.0728)  loss_vfl_aux_0: 0.4587 (0.4587)  loss_bbox_aux_0: 0.8595 (0.8595)  loss_giou_aux_0: 2.1458 (2.1458)  loss_vfl_aux_1: 0.5350 (0.5350)  loss_bbox_aux_1: 0.8498 (0.8498)  loss_giou_aux_1: 2.1414 (2.1414)  loss_vfl_aux_2: 0.5889 (0.5889)  loss_bbox_aux_2: 0.8320 (0.8320)  loss_giou_aux_2: 2.0991 (2.0991)  loss_vfl_aux_3: 0.4957 (0.4957)  loss_bbox_aux_3: 0.8436 (0.8436)  loss_giou_aux_3: 2.0905 (2.0905)  loss_vfl_aux_4: 0.6682 (0.6682)  loss_bbox_aux_4: 0.8249 (0.8249)  loss_giou_aux_4: 2.0725 (2.0725)  loss_vfl_dn_0: 0.7746 (0.7746)  loss_bbox_dn_0: 0.4298 (0.4298)  loss_giou_dn_0: 1.3505 (1.3505)  loss_vfl_dn_1: 0.8863 (0.8863)  loss_bbox_dn_1: 0.4368 (0.4368)  loss_giou_dn_1: 1.3561 (1.3561)  loss_vfl_dn_2: 0.8842 (0.8842)  loss_bbox_dn_2: 0.4448 (0.4448)  loss_giou_dn_2: 1.3591 (1.3591)  loss_vfl_dn_3: 0.7537 (0.7537)  loss_bbox_dn_3: 0.4650 (0.4650)  loss_giou_dn_3: 1.3774 (1.3774)  loss_vfl_dn_4: 0.9708 (0.9708)  loss_bbox_dn_4: 0.4735 (0.4735)  loss_giou_dn_4: 1.3902 (1.3902)  loss_vfl_dn_5: 0.9085 (0.9085)  loss_bbox_dn_5: 0.4735 (0.4735)  loss_giou_dn_5: 1.3900 (1.3900)  loss_vfl_enc_0: 0.4475 (0.4475)  loss_bbox_enc_0: 0.8572 (0.8572)  loss_giou_enc_0: 2.1637 (2.1637)  time: 2.0088  data: 1.4917  max mem: 16799\n",
            "Epoch: [4]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 41.9062 (42.7917)  loss_vfl: 0.4619 (0.5128)  loss_bbox: 1.0631 (1.0609)  loss_giou: 2.2046 (2.2342)  loss_vfl_aux_0: 0.3455 (0.3862)  loss_bbox_aux_0: 1.0776 (1.1143)  loss_giou_aux_0: 2.2611 (2.3183)  loss_vfl_aux_1: 0.3973 (0.4475)  loss_bbox_aux_1: 1.0762 (1.1095)  loss_giou_aux_1: 2.2680 (2.3078)  loss_vfl_aux_2: 0.4419 (0.4880)  loss_bbox_aux_2: 1.0711 (1.0920)  loss_giou_aux_2: 2.2587 (2.2688)  loss_vfl_aux_3: 0.3734 (0.4102)  loss_bbox_aux_3: 1.0640 (1.0696)  loss_giou_aux_3: 2.2383 (2.2493)  loss_vfl_aux_4: 0.4824 (0.5392)  loss_bbox_aux_4: 1.0741 (1.0651)  loss_giou_aux_4: 2.1936 (2.2280)  loss_vfl_dn_0: 0.8657 (0.8718)  loss_bbox_dn_0: 0.3948 (0.3923)  loss_giou_dn_0: 1.2656 (1.2788)  loss_vfl_dn_1: 1.0307 (1.0162)  loss_bbox_dn_1: 0.4038 (0.3997)  loss_giou_dn_1: 1.2726 (1.2805)  loss_vfl_dn_2: 1.0169 (1.0157)  loss_bbox_dn_2: 0.4073 (0.4059)  loss_giou_dn_2: 1.2509 (1.2694)  loss_vfl_dn_3: 0.8689 (0.8587)  loss_bbox_dn_3: 0.4144 (0.4226)  loss_giou_dn_3: 1.2622 (1.2808)  loss_vfl_dn_4: 1.0926 (1.0910)  loss_bbox_dn_4: 0.4190 (0.4310)  loss_giou_dn_4: 1.2734 (1.2931)  loss_vfl_dn_5: 1.0370 (1.0227)  loss_bbox_dn_5: 0.4189 (0.4310)  loss_giou_dn_5: 1.2732 (1.2929)  loss_vfl_enc_0: 0.3598 (0.3983)  loss_bbox_enc_0: 1.0640 (1.1012)  loss_giou_enc_0: 2.2962 (2.3367)  time: 0.7217  data: 0.2198  max mem: 16799\n",
            "Epoch: [4] Total time: 0:00:05 (0.7286 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 41.9062 (42.7917)  loss_vfl: 0.4619 (0.5128)  loss_bbox: 1.0631 (1.0609)  loss_giou: 2.2046 (2.2342)  loss_vfl_aux_0: 0.3455 (0.3862)  loss_bbox_aux_0: 1.0776 (1.1143)  loss_giou_aux_0: 2.2611 (2.3183)  loss_vfl_aux_1: 0.3973 (0.4475)  loss_bbox_aux_1: 1.0762 (1.1095)  loss_giou_aux_1: 2.2680 (2.3078)  loss_vfl_aux_2: 0.4419 (0.4880)  loss_bbox_aux_2: 1.0711 (1.0920)  loss_giou_aux_2: 2.2587 (2.2688)  loss_vfl_aux_3: 0.3734 (0.4102)  loss_bbox_aux_3: 1.0640 (1.0696)  loss_giou_aux_3: 2.2383 (2.2493)  loss_vfl_aux_4: 0.4824 (0.5392)  loss_bbox_aux_4: 1.0741 (1.0651)  loss_giou_aux_4: 2.1936 (2.2280)  loss_vfl_dn_0: 0.8657 (0.8718)  loss_bbox_dn_0: 0.3948 (0.3923)  loss_giou_dn_0: 1.2656 (1.2788)  loss_vfl_dn_1: 1.0307 (1.0162)  loss_bbox_dn_1: 0.4038 (0.3997)  loss_giou_dn_1: 1.2726 (1.2805)  loss_vfl_dn_2: 1.0169 (1.0157)  loss_bbox_dn_2: 0.4073 (0.4059)  loss_giou_dn_2: 1.2509 (1.2694)  loss_vfl_dn_3: 0.8689 (0.8587)  loss_bbox_dn_3: 0.4144 (0.4226)  loss_giou_dn_3: 1.2622 (1.2808)  loss_vfl_dn_4: 1.0926 (1.0910)  loss_bbox_dn_4: 0.4190 (0.4310)  loss_giou_dn_4: 1.2734 (1.2931)  loss_vfl_dn_5: 1.0370 (1.0227)  loss_bbox_dn_5: 0.4189 (0.4310)  loss_giou_dn_5: 1.2732 (1.2929)  loss_vfl_enc_0: 0.3598 (0.3983)  loss_bbox_enc_0: 1.0640 (1.1012)  loss_giou_enc_0: 2.2962 (2.3367)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4844  data: 1.2776  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5018  data: 0.6550  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.5191 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\n",
            "best_stat: {'epoch': 4, 'coco_eval_bbox': 0.0003078314277611373}\n",
            "Epoch: [5]  [0/8]  eta: 0:00:21  lr: 0.000000  loss: 41.3714 (41.3714)  loss_vfl: 0.3889 (0.3889)  loss_bbox: 0.9384 (0.9384)  loss_giou: 2.2718 (2.2718)  loss_vfl_aux_0: 0.3165 (0.3165)  loss_bbox_aux_0: 0.9723 (0.9723)  loss_giou_aux_0: 2.3082 (2.3082)  loss_vfl_aux_1: 0.3902 (0.3902)  loss_bbox_aux_1: 0.9553 (0.9553)  loss_giou_aux_1: 2.3127 (2.3127)  loss_vfl_aux_2: 0.3869 (0.3869)  loss_bbox_aux_2: 0.9498 (0.9498)  loss_giou_aux_2: 2.2863 (2.2863)  loss_vfl_aux_3: 0.3284 (0.3284)  loss_bbox_aux_3: 0.9255 (0.9255)  loss_giou_aux_3: 2.2763 (2.2763)  loss_vfl_aux_4: 0.4134 (0.4134)  loss_bbox_aux_4: 0.9652 (0.9652)  loss_giou_aux_4: 2.2437 (2.2437)  loss_vfl_dn_0: 0.9524 (0.9524)  loss_bbox_dn_0: 0.3982 (0.3982)  loss_giou_dn_0: 1.2115 (1.2115)  loss_vfl_dn_1: 1.1162 (1.1162)  loss_bbox_dn_1: 0.4044 (0.4044)  loss_giou_dn_1: 1.1973 (1.1973)  loss_vfl_dn_2: 1.1152 (1.1152)  loss_bbox_dn_2: 0.4019 (0.4019)  loss_giou_dn_2: 1.1823 (1.1823)  loss_vfl_dn_3: 0.9718 (0.9718)  loss_bbox_dn_3: 0.4096 (0.4096)  loss_giou_dn_3: 1.1831 (1.1831)  loss_vfl_dn_4: 1.2148 (1.2148)  loss_bbox_dn_4: 0.4159 (0.4159)  loss_giou_dn_4: 1.1940 (1.1940)  loss_vfl_dn_5: 1.1467 (1.1467)  loss_bbox_dn_5: 0.4159 (0.4159)  loss_giou_dn_5: 1.1939 (1.1939)  loss_vfl_enc_0: 0.3510 (0.3510)  loss_bbox_enc_0: 0.9574 (0.9574)  loss_giou_enc_0: 2.3084 (2.3084)  time: 2.6448  data: 2.1155  max mem: 16799\n",
            "Epoch: [5]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 41.4925 (41.5006)  loss_vfl: 0.5442 (0.5139)  loss_bbox: 0.9313 (0.9320)  loss_giou: 2.0911 (2.1576)  loss_vfl_aux_0: 0.3927 (0.3937)  loss_bbox_aux_0: 0.9809 (0.9880)  loss_giou_aux_0: 2.2009 (2.2380)  loss_vfl_aux_1: 0.4497 (0.4519)  loss_bbox_aux_1: 0.9568 (0.9697)  loss_giou_aux_1: 2.2095 (2.2400)  loss_vfl_aux_2: 0.5042 (0.4877)  loss_bbox_aux_2: 0.9482 (0.9580)  loss_giou_aux_2: 2.1597 (2.1959)  loss_vfl_aux_3: 0.4403 (0.4155)  loss_bbox_aux_3: 0.9261 (0.9368)  loss_giou_aux_3: 2.1007 (2.1738)  loss_vfl_aux_4: 0.5693 (0.5425)  loss_bbox_aux_4: 0.9271 (0.9340)  loss_giou_aux_4: 2.0946 (2.1546)  loss_vfl_dn_0: 0.9022 (0.9002)  loss_bbox_dn_0: 0.4078 (0.4184)  loss_giou_dn_0: 1.2338 (1.2529)  loss_vfl_dn_1: 1.0359 (1.0353)  loss_bbox_dn_1: 0.4234 (0.4240)  loss_giou_dn_1: 1.2345 (1.2557)  loss_vfl_dn_2: 1.0274 (1.0279)  loss_bbox_dn_2: 0.4372 (0.4310)  loss_giou_dn_2: 1.2347 (1.2517)  loss_vfl_dn_3: 0.8585 (0.8666)  loss_bbox_dn_3: 0.4531 (0.4488)  loss_giou_dn_3: 1.2528 (1.2656)  loss_vfl_dn_4: 1.0966 (1.0936)  loss_bbox_dn_4: 0.4575 (0.4572)  loss_giou_dn_4: 1.2649 (1.2770)  loss_vfl_dn_5: 1.0339 (1.0319)  loss_bbox_dn_5: 0.4574 (0.4572)  loss_giou_dn_5: 1.2646 (1.2768)  loss_vfl_enc_0: 0.3981 (0.4124)  loss_bbox_enc_0: 0.9918 (0.9842)  loss_giou_enc_0: 2.1981 (2.2485)  time: 0.7634  data: 0.2846  max mem: 16799\n",
            "Epoch: [5] Total time: 0:00:06 (0.7687 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 41.4925 (41.5006)  loss_vfl: 0.5442 (0.5139)  loss_bbox: 0.9313 (0.9320)  loss_giou: 2.0911 (2.1576)  loss_vfl_aux_0: 0.3927 (0.3937)  loss_bbox_aux_0: 0.9809 (0.9880)  loss_giou_aux_0: 2.2009 (2.2380)  loss_vfl_aux_1: 0.4497 (0.4519)  loss_bbox_aux_1: 0.9568 (0.9697)  loss_giou_aux_1: 2.2095 (2.2400)  loss_vfl_aux_2: 0.5042 (0.4877)  loss_bbox_aux_2: 0.9482 (0.9580)  loss_giou_aux_2: 2.1597 (2.1959)  loss_vfl_aux_3: 0.4403 (0.4155)  loss_bbox_aux_3: 0.9261 (0.9368)  loss_giou_aux_3: 2.1007 (2.1738)  loss_vfl_aux_4: 0.5693 (0.5425)  loss_bbox_aux_4: 0.9271 (0.9340)  loss_giou_aux_4: 2.0946 (2.1546)  loss_vfl_dn_0: 0.9022 (0.9002)  loss_bbox_dn_0: 0.4078 (0.4184)  loss_giou_dn_0: 1.2338 (1.2529)  loss_vfl_dn_1: 1.0359 (1.0353)  loss_bbox_dn_1: 0.4234 (0.4240)  loss_giou_dn_1: 1.2345 (1.2557)  loss_vfl_dn_2: 1.0274 (1.0279)  loss_bbox_dn_2: 0.4372 (0.4310)  loss_giou_dn_2: 1.2347 (1.2517)  loss_vfl_dn_3: 0.8585 (0.8666)  loss_bbox_dn_3: 0.4531 (0.4488)  loss_giou_dn_3: 1.2528 (1.2656)  loss_vfl_dn_4: 1.0966 (1.0936)  loss_bbox_dn_4: 0.4575 (0.4572)  loss_giou_dn_4: 1.2649 (1.2770)  loss_vfl_dn_5: 1.0339 (1.0319)  loss_bbox_dn_5: 0.4574 (0.4572)  loss_giou_dn_5: 1.2646 (1.2768)  loss_vfl_enc_0: 0.3981 (0.4124)  loss_bbox_enc_0: 0.9918 (0.9842)  loss_giou_enc_0: 2.1981 (2.2485)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5855  data: 4.3961  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0457  data: 2.2142  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0761 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\n",
            "best_stat: {'epoch': 5, 'coco_eval_bbox': 0.00033889667013075367}\n",
            "Epoch: [6]  [0/8]  eta: 0:00:29  lr: 0.000000  loss: 45.2944 (45.2944)  loss_vfl: 0.4762 (0.4762)  loss_bbox: 1.3235 (1.3235)  loss_giou: 2.4112 (2.4112)  loss_vfl_aux_0: 0.3704 (0.3704)  loss_bbox_aux_0: 1.3721 (1.3721)  loss_giou_aux_0: 2.4931 (2.4931)  loss_vfl_aux_1: 0.4083 (0.4083)  loss_bbox_aux_1: 1.3425 (1.3425)  loss_giou_aux_1: 2.5074 (2.5074)  loss_vfl_aux_2: 0.4449 (0.4449)  loss_bbox_aux_2: 1.3375 (1.3375)  loss_giou_aux_2: 2.4663 (2.4663)  loss_vfl_aux_3: 0.3791 (0.3791)  loss_bbox_aux_3: 1.3385 (1.3385)  loss_giou_aux_3: 2.4372 (2.4372)  loss_vfl_aux_4: 0.4968 (0.4968)  loss_bbox_aux_4: 1.3263 (1.3263)  loss_giou_aux_4: 2.4076 (2.4076)  loss_vfl_dn_0: 0.8243 (0.8243)  loss_bbox_dn_0: 0.3959 (0.3959)  loss_giou_dn_0: 1.2928 (1.2928)  loss_vfl_dn_1: 0.9593 (0.9593)  loss_bbox_dn_1: 0.3976 (0.3976)  loss_giou_dn_1: 1.2917 (1.2917)  loss_vfl_dn_2: 0.9595 (0.9595)  loss_bbox_dn_2: 0.4000 (0.4000)  loss_giou_dn_2: 1.2770 (1.2770)  loss_vfl_dn_3: 0.7963 (0.7963)  loss_bbox_dn_3: 0.4129 (0.4129)  loss_giou_dn_3: 1.2898 (1.2898)  loss_vfl_dn_4: 1.0178 (1.0178)  loss_bbox_dn_4: 0.4218 (0.4218)  loss_giou_dn_4: 1.3052 (1.3052)  loss_vfl_dn_5: 0.9581 (0.9581)  loss_bbox_dn_5: 0.4218 (0.4218)  loss_giou_dn_5: 1.3049 (1.3049)  loss_vfl_enc_0: 0.3670 (0.3670)  loss_bbox_enc_0: 1.3499 (1.3499)  loss_giou_enc_0: 2.5119 (2.5119)  time: 3.6448  data: 3.0956  max mem: 16799\n",
            "Epoch: [6]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 42.2689 (42.3076)  loss_vfl: 0.5231 (0.5334)  loss_bbox: 0.9787 (1.0254)  loss_giou: 2.1192 (2.1734)  loss_vfl_aux_0: 0.3983 (0.4097)  loss_bbox_aux_0: 1.0406 (1.0813)  loss_giou_aux_0: 2.2057 (2.2522)  loss_vfl_aux_1: 0.4706 (0.4722)  loss_bbox_aux_1: 1.0409 (1.0720)  loss_giou_aux_1: 2.1950 (2.2461)  loss_vfl_aux_2: 0.4927 (0.5112)  loss_bbox_aux_2: 1.0163 (1.0557)  loss_giou_aux_2: 2.1598 (2.2071)  loss_vfl_aux_3: 0.4158 (0.4251)  loss_bbox_aux_3: 0.9938 (1.0289)  loss_giou_aux_3: 2.1334 (2.1941)  loss_vfl_aux_4: 0.5458 (0.5654)  loss_bbox_aux_4: 0.9811 (1.0328)  loss_giou_aux_4: 2.1122 (2.1656)  loss_vfl_dn_0: 0.8820 (0.8875)  loss_bbox_dn_0: 0.4083 (0.4103)  loss_giou_dn_0: 1.2457 (1.2565)  loss_vfl_dn_1: 1.0342 (1.0396)  loss_bbox_dn_1: 0.4166 (0.4152)  loss_giou_dn_1: 1.2399 (1.2487)  loss_vfl_dn_2: 1.0508 (1.0414)  loss_bbox_dn_2: 0.4270 (0.4214)  loss_giou_dn_2: 1.2288 (1.2346)  loss_vfl_dn_3: 0.8737 (0.8712)  loss_bbox_dn_3: 0.4417 (0.4402)  loss_giou_dn_3: 1.2389 (1.2490)  loss_vfl_dn_4: 1.1128 (1.1106)  loss_bbox_dn_4: 0.4536 (0.4490)  loss_giou_dn_4: 1.2530 (1.2623)  loss_vfl_dn_5: 1.0529 (1.0429)  loss_bbox_dn_5: 0.4536 (0.4489)  loss_giou_dn_5: 1.2527 (1.2620)  loss_vfl_enc_0: 0.4021 (0.4152)  loss_bbox_enc_0: 1.0315 (1.0745)  loss_giou_enc_0: 2.2217 (2.2749)  time: 0.9344  data: 0.4106  max mem: 16799\n",
            "Epoch: [6] Total time: 0:00:07 (0.9405 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 42.2689 (42.3076)  loss_vfl: 0.5231 (0.5334)  loss_bbox: 0.9787 (1.0254)  loss_giou: 2.1192 (2.1734)  loss_vfl_aux_0: 0.3983 (0.4097)  loss_bbox_aux_0: 1.0406 (1.0813)  loss_giou_aux_0: 2.2057 (2.2522)  loss_vfl_aux_1: 0.4706 (0.4722)  loss_bbox_aux_1: 1.0409 (1.0720)  loss_giou_aux_1: 2.1950 (2.2461)  loss_vfl_aux_2: 0.4927 (0.5112)  loss_bbox_aux_2: 1.0163 (1.0557)  loss_giou_aux_2: 2.1598 (2.2071)  loss_vfl_aux_3: 0.4158 (0.4251)  loss_bbox_aux_3: 0.9938 (1.0289)  loss_giou_aux_3: 2.1334 (2.1941)  loss_vfl_aux_4: 0.5458 (0.5654)  loss_bbox_aux_4: 0.9811 (1.0328)  loss_giou_aux_4: 2.1122 (2.1656)  loss_vfl_dn_0: 0.8820 (0.8875)  loss_bbox_dn_0: 0.4083 (0.4103)  loss_giou_dn_0: 1.2457 (1.2565)  loss_vfl_dn_1: 1.0342 (1.0396)  loss_bbox_dn_1: 0.4166 (0.4152)  loss_giou_dn_1: 1.2399 (1.2487)  loss_vfl_dn_2: 1.0508 (1.0414)  loss_bbox_dn_2: 0.4270 (0.4214)  loss_giou_dn_2: 1.2288 (1.2346)  loss_vfl_dn_3: 0.8737 (0.8712)  loss_bbox_dn_3: 0.4417 (0.4402)  loss_giou_dn_3: 1.2389 (1.2490)  loss_vfl_dn_4: 1.1128 (1.1106)  loss_bbox_dn_4: 0.4536 (0.4490)  loss_giou_dn_4: 1.2530 (1.2623)  loss_vfl_dn_5: 1.0529 (1.0429)  loss_bbox_dn_5: 0.4536 (0.4489)  loss_giou_dn_5: 1.2527 (1.2620)  loss_vfl_enc_0: 0.4021 (0.4152)  loss_bbox_enc_0: 1.0315 (1.0745)  loss_giou_enc_0: 2.2217 (2.2749)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5329  data: 4.3482  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0164  data: 2.1902  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0426 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
            "best_stat: {'epoch': 6, 'coco_eval_bbox': 0.0004305199899021837}\n",
            "Epoch: [7]  [0/8]  eta: 0:00:30  lr: 0.000000  loss: 43.3867 (43.3867)  loss_vfl: 0.5176 (0.5176)  loss_bbox: 1.0818 (1.0818)  loss_giou: 2.2595 (2.2595)  loss_vfl_aux_0: 0.3505 (0.3505)  loss_bbox_aux_0: 1.1959 (1.1959)  loss_giou_aux_0: 2.3335 (2.3335)  loss_vfl_aux_1: 0.4229 (0.4229)  loss_bbox_aux_1: 1.1732 (1.1732)  loss_giou_aux_1: 2.3207 (2.3207)  loss_vfl_aux_2: 0.4596 (0.4596)  loss_bbox_aux_2: 1.1698 (1.1698)  loss_giou_aux_2: 2.2799 (2.2799)  loss_vfl_aux_3: 0.4100 (0.4100)  loss_bbox_aux_3: 1.1012 (1.1012)  loss_giou_aux_3: 2.2740 (2.2740)  loss_vfl_aux_4: 0.5540 (0.5540)  loss_bbox_aux_4: 1.0928 (1.0928)  loss_giou_aux_4: 2.2461 (2.2461)  loss_vfl_dn_0: 0.8910 (0.8910)  loss_bbox_dn_0: 0.4098 (0.4098)  loss_giou_dn_0: 1.2428 (1.2428)  loss_vfl_dn_1: 1.0499 (1.0499)  loss_bbox_dn_1: 0.4159 (0.4159)  loss_giou_dn_1: 1.2561 (1.2561)  loss_vfl_dn_2: 1.0399 (1.0399)  loss_bbox_dn_2: 0.4307 (0.4307)  loss_giou_dn_2: 1.2467 (1.2467)  loss_vfl_dn_3: 0.8772 (0.8772)  loss_bbox_dn_3: 0.4545 (0.4545)  loss_giou_dn_3: 1.2725 (1.2725)  loss_vfl_dn_4: 1.1011 (1.1011)  loss_bbox_dn_4: 0.4685 (0.4685)  loss_giou_dn_4: 1.2870 (1.2870)  loss_vfl_dn_5: 1.0394 (1.0394)  loss_bbox_dn_5: 0.4685 (0.4685)  loss_giou_dn_5: 1.2867 (1.2867)  loss_vfl_enc_0: 0.3767 (0.3767)  loss_bbox_enc_0: 1.1693 (1.1693)  loss_giou_enc_0: 2.3594 (2.3594)  time: 3.7872  data: 3.3073  max mem: 16799\n",
            "Epoch: [7]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 43.3782 (43.0916)  loss_vfl: 0.4503 (0.5226)  loss_bbox: 1.0818 (1.0816)  loss_giou: 2.2828 (2.2646)  loss_vfl_aux_0: 0.3505 (0.3957)  loss_bbox_aux_0: 1.1303 (1.1321)  loss_giou_aux_0: 2.3335 (2.3309)  loss_vfl_aux_1: 0.4227 (0.4546)  loss_bbox_aux_1: 1.1231 (1.1153)  loss_giou_aux_1: 2.3232 (2.3305)  loss_vfl_aux_2: 0.4469 (0.4955)  loss_bbox_aux_2: 1.1116 (1.1062)  loss_giou_aux_2: 2.2927 (2.2902)  loss_vfl_aux_3: 0.3684 (0.4187)  loss_bbox_aux_3: 1.0996 (1.0860)  loss_giou_aux_3: 2.2907 (2.2771)  loss_vfl_aux_4: 0.4816 (0.5558)  loss_bbox_aux_4: 1.0928 (1.0885)  loss_giou_aux_4: 2.2686 (2.2580)  loss_vfl_dn_0: 0.9095 (0.9063)  loss_bbox_dn_0: 0.3795 (0.3888)  loss_giou_dn_0: 1.2341 (1.2433)  loss_vfl_dn_1: 1.0502 (1.0500)  loss_bbox_dn_1: 0.3847 (0.3952)  loss_giou_dn_1: 1.2324 (1.2439)  loss_vfl_dn_2: 1.0399 (1.0479)  loss_bbox_dn_2: 0.3950 (0.4064)  loss_giou_dn_2: 1.2049 (1.2288)  loss_vfl_dn_3: 0.8772 (0.8844)  loss_bbox_dn_3: 0.4099 (0.4225)  loss_giou_dn_3: 1.2318 (1.2466)  loss_vfl_dn_4: 1.1256 (1.1133)  loss_bbox_dn_4: 0.4147 (0.4309)  loss_giou_dn_4: 1.2443 (1.2593)  loss_vfl_dn_5: 1.0538 (1.0442)  loss_bbox_dn_5: 0.4147 (0.4309)  loss_giou_dn_5: 1.2438 (1.2589)  loss_vfl_enc_0: 0.3666 (0.4004)  loss_bbox_enc_0: 1.1198 (1.1271)  loss_giou_enc_0: 2.3594 (2.3586)  time: 0.9503  data: 0.4413  max mem: 16799\n",
            "Epoch: [7] Total time: 0:00:07 (0.9581 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 43.3782 (43.0916)  loss_vfl: 0.4503 (0.5226)  loss_bbox: 1.0818 (1.0816)  loss_giou: 2.2828 (2.2646)  loss_vfl_aux_0: 0.3505 (0.3957)  loss_bbox_aux_0: 1.1303 (1.1321)  loss_giou_aux_0: 2.3335 (2.3309)  loss_vfl_aux_1: 0.4227 (0.4546)  loss_bbox_aux_1: 1.1231 (1.1153)  loss_giou_aux_1: 2.3232 (2.3305)  loss_vfl_aux_2: 0.4469 (0.4955)  loss_bbox_aux_2: 1.1116 (1.1062)  loss_giou_aux_2: 2.2927 (2.2902)  loss_vfl_aux_3: 0.3684 (0.4187)  loss_bbox_aux_3: 1.0996 (1.0860)  loss_giou_aux_3: 2.2907 (2.2771)  loss_vfl_aux_4: 0.4816 (0.5558)  loss_bbox_aux_4: 1.0928 (1.0885)  loss_giou_aux_4: 2.2686 (2.2580)  loss_vfl_dn_0: 0.9095 (0.9063)  loss_bbox_dn_0: 0.3795 (0.3888)  loss_giou_dn_0: 1.2341 (1.2433)  loss_vfl_dn_1: 1.0502 (1.0500)  loss_bbox_dn_1: 0.3847 (0.3952)  loss_giou_dn_1: 1.2324 (1.2439)  loss_vfl_dn_2: 1.0399 (1.0479)  loss_bbox_dn_2: 0.3950 (0.4064)  loss_giou_dn_2: 1.2049 (1.2288)  loss_vfl_dn_3: 0.8772 (0.8844)  loss_bbox_dn_3: 0.4099 (0.4225)  loss_giou_dn_3: 1.2318 (1.2466)  loss_vfl_dn_4: 1.1256 (1.1133)  loss_bbox_dn_4: 0.4147 (0.4309)  loss_giou_dn_4: 1.2443 (1.2593)  loss_vfl_dn_5: 1.0538 (1.0442)  loss_bbox_dn_5: 0.4147 (0.4309)  loss_giou_dn_5: 1.2438 (1.2589)  loss_vfl_enc_0: 0.3666 (0.4004)  loss_bbox_enc_0: 1.1198 (1.1271)  loss_giou_enc_0: 2.3594 (2.3586)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.8467  data: 1.3335  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6745  data: 0.6838  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.6947 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
            "best_stat: {'epoch': 7, 'coco_eval_bbox': 0.0005312408383194068}\n",
            "Epoch: [8]  [0/8]  eta: 0:00:29  lr: 0.000000  loss: 43.7998 (43.7998)  loss_vfl: 0.5182 (0.5182)  loss_bbox: 1.0323 (1.0323)  loss_giou: 2.3307 (2.3307)  loss_vfl_aux_0: 0.3696 (0.3696)  loss_bbox_aux_0: 1.1205 (1.1205)  loss_giou_aux_0: 2.4318 (2.4318)  loss_vfl_aux_1: 0.4359 (0.4359)  loss_bbox_aux_1: 1.1085 (1.1085)  loss_giou_aux_1: 2.4233 (2.4233)  loss_vfl_aux_2: 0.5021 (0.5021)  loss_bbox_aux_2: 1.0688 (1.0688)  loss_giou_aux_2: 2.3731 (2.3731)  loss_vfl_aux_3: 0.4140 (0.4140)  loss_bbox_aux_3: 1.0354 (1.0354)  loss_giou_aux_3: 2.3627 (2.3627)  loss_vfl_aux_4: 0.5405 (0.5405)  loss_bbox_aux_4: 1.0339 (1.0339)  loss_giou_aux_4: 2.3305 (2.3305)  loss_vfl_dn_0: 0.9363 (0.9363)  loss_bbox_dn_0: 0.4517 (0.4517)  loss_giou_dn_0: 1.2228 (1.2228)  loss_vfl_dn_1: 1.1022 (1.1022)  loss_bbox_dn_1: 0.4514 (0.4514)  loss_giou_dn_1: 1.1973 (1.1973)  loss_vfl_dn_2: 1.1031 (1.1031)  loss_bbox_dn_2: 0.4595 (0.4595)  loss_giou_dn_2: 1.1769 (1.1769)  loss_vfl_dn_3: 0.9499 (0.9499)  loss_bbox_dn_3: 0.4838 (0.4838)  loss_giou_dn_3: 1.1820 (1.1820)  loss_vfl_dn_4: 1.2071 (1.2071)  loss_bbox_dn_4: 0.4930 (0.4930)  loss_giou_dn_4: 1.1869 (1.1869)  loss_vfl_dn_5: 1.1368 (1.1368)  loss_bbox_dn_5: 0.4930 (0.4930)  loss_giou_dn_5: 1.1865 (1.1865)  loss_vfl_enc_0: 0.3857 (0.3857)  loss_bbox_enc_0: 1.1204 (1.1204)  loss_giou_enc_0: 2.4420 (2.4420)  time: 3.7168  data: 3.0920  max mem: 16799\n",
            "Epoch: [8]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 43.6223 (43.6493)  loss_vfl: 0.4546 (0.5060)  loss_bbox: 1.0323 (1.0993)  loss_giou: 2.3307 (2.3077)  loss_vfl_aux_0: 0.3190 (0.3609)  loss_bbox_aux_0: 1.1205 (1.1735)  loss_giou_aux_0: 2.4318 (2.4058)  loss_vfl_aux_1: 0.3646 (0.4312)  loss_bbox_aux_1: 1.1085 (1.1559)  loss_giou_aux_1: 2.4233 (2.3952)  loss_vfl_aux_2: 0.4364 (0.4767)  loss_bbox_aux_2: 1.0688 (1.1378)  loss_giou_aux_2: 2.3731 (2.3522)  loss_vfl_aux_3: 0.3617 (0.4005)  loss_bbox_aux_3: 1.0354 (1.1099)  loss_giou_aux_3: 2.3627 (2.3280)  loss_vfl_aux_4: 0.4789 (0.5375)  loss_bbox_aux_4: 1.0339 (1.0998)  loss_giou_aux_4: 2.3305 (2.3060)  loss_vfl_dn_0: 0.8999 (0.9056)  loss_bbox_dn_0: 0.3722 (0.4102)  loss_giou_dn_0: 1.2450 (1.2441)  loss_vfl_dn_1: 1.0569 (1.0647)  loss_bbox_dn_1: 0.3710 (0.4136)  loss_giou_dn_1: 1.2398 (1.2300)  loss_vfl_dn_2: 1.0466 (1.0714)  loss_bbox_dn_2: 0.3838 (0.4195)  loss_giou_dn_2: 1.2150 (1.2080)  loss_vfl_dn_3: 0.8831 (0.9083)  loss_bbox_dn_3: 0.3985 (0.4352)  loss_giou_dn_3: 1.2153 (1.2159)  loss_vfl_dn_4: 1.1450 (1.1592)  loss_bbox_dn_4: 0.4051 (0.4433)  loss_giou_dn_4: 1.2184 (1.2253)  loss_vfl_dn_5: 1.0764 (1.0862)  loss_bbox_dn_5: 0.4051 (0.4433)  loss_giou_dn_5: 1.2180 (1.2248)  loss_vfl_enc_0: 0.3184 (0.3686)  loss_bbox_enc_0: 1.1204 (1.1611)  loss_giou_enc_0: 2.4420 (2.4270)  time: 0.9984  data: 0.4228  max mem: 16799\n",
            "Epoch: [8] Total time: 0:00:08 (1.0054 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 43.6223 (43.6493)  loss_vfl: 0.4546 (0.5060)  loss_bbox: 1.0323 (1.0993)  loss_giou: 2.3307 (2.3077)  loss_vfl_aux_0: 0.3190 (0.3609)  loss_bbox_aux_0: 1.1205 (1.1735)  loss_giou_aux_0: 2.4318 (2.4058)  loss_vfl_aux_1: 0.3646 (0.4312)  loss_bbox_aux_1: 1.1085 (1.1559)  loss_giou_aux_1: 2.4233 (2.3952)  loss_vfl_aux_2: 0.4364 (0.4767)  loss_bbox_aux_2: 1.0688 (1.1378)  loss_giou_aux_2: 2.3731 (2.3522)  loss_vfl_aux_3: 0.3617 (0.4005)  loss_bbox_aux_3: 1.0354 (1.1099)  loss_giou_aux_3: 2.3627 (2.3280)  loss_vfl_aux_4: 0.4789 (0.5375)  loss_bbox_aux_4: 1.0339 (1.0998)  loss_giou_aux_4: 2.3305 (2.3060)  loss_vfl_dn_0: 0.8999 (0.9056)  loss_bbox_dn_0: 0.3722 (0.4102)  loss_giou_dn_0: 1.2450 (1.2441)  loss_vfl_dn_1: 1.0569 (1.0647)  loss_bbox_dn_1: 0.3710 (0.4136)  loss_giou_dn_1: 1.2398 (1.2300)  loss_vfl_dn_2: 1.0466 (1.0714)  loss_bbox_dn_2: 0.3838 (0.4195)  loss_giou_dn_2: 1.2150 (1.2080)  loss_vfl_dn_3: 0.8831 (0.9083)  loss_bbox_dn_3: 0.3985 (0.4352)  loss_giou_dn_3: 1.2153 (1.2159)  loss_vfl_dn_4: 1.1450 (1.1592)  loss_bbox_dn_4: 0.4051 (0.4433)  loss_giou_dn_4: 1.2184 (1.2253)  loss_vfl_dn_5: 1.0764 (1.0862)  loss_bbox_dn_5: 0.4051 (0.4433)  loss_giou_dn_5: 1.2180 (1.2248)  loss_vfl_enc_0: 0.3184 (0.3686)  loss_bbox_enc_0: 1.1204 (1.1611)  loss_giou_enc_0: 2.4420 (2.4270)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.0443  data: 1.8456  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.7719  data: 0.9389  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.8097 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
            "best_stat: {'epoch': 8, 'coco_eval_bbox': 0.0006026737302936158}\n",
            "Epoch: [9]  [0/8]  eta: 0:00:38  lr: 0.000000  loss: 44.0036 (44.0036)  loss_vfl: 0.3471 (0.3471)  loss_bbox: 1.1980 (1.1980)  loss_giou: 2.4962 (2.4962)  loss_vfl_aux_0: 0.2109 (0.2109)  loss_bbox_aux_0: 1.2619 (1.2619)  loss_giou_aux_0: 2.5816 (2.5816)  loss_vfl_aux_1: 0.2699 (0.2699)  loss_bbox_aux_1: 1.2187 (1.2187)  loss_giou_aux_1: 2.6067 (2.6067)  loss_vfl_aux_2: 0.3175 (0.3175)  loss_bbox_aux_2: 1.2106 (1.2106)  loss_giou_aux_2: 2.5445 (2.5445)  loss_vfl_aux_3: 0.2874 (0.2874)  loss_bbox_aux_3: 1.1786 (1.1786)  loss_giou_aux_3: 2.5337 (2.5337)  loss_vfl_aux_4: 0.3743 (0.3743)  loss_bbox_aux_4: 1.1918 (1.1918)  loss_giou_aux_4: 2.5053 (2.5053)  loss_vfl_dn_0: 0.8943 (0.8943)  loss_bbox_dn_0: 0.3283 (0.3283)  loss_giou_dn_0: 1.2681 (1.2681)  loss_vfl_dn_1: 1.0107 (1.0107)  loss_bbox_dn_1: 0.3341 (0.3341)  loss_giou_dn_1: 1.2862 (1.2862)  loss_vfl_dn_2: 0.9988 (0.9988)  loss_bbox_dn_2: 0.3357 (0.3357)  loss_giou_dn_2: 1.2822 (1.2822)  loss_vfl_dn_3: 0.8508 (0.8508)  loss_bbox_dn_3: 0.3455 (0.3455)  loss_giou_dn_3: 1.2901 (1.2901)  loss_vfl_dn_4: 1.0572 (1.0572)  loss_bbox_dn_4: 0.3513 (0.3513)  loss_giou_dn_4: 1.3047 (1.3047)  loss_vfl_dn_5: 0.9951 (0.9951)  loss_bbox_dn_5: 0.3513 (0.3513)  loss_giou_dn_5: 1.3040 (1.3040)  loss_vfl_enc_0: 0.1807 (0.1807)  loss_bbox_enc_0: 1.2332 (1.2332)  loss_giou_enc_0: 2.6666 (2.6666)  time: 4.8693  data: 4.3508  max mem: 16799\n",
            "Epoch: [9]  [7/8]  eta: 0:00:01  lr: 0.000000  loss: 41.7358 (42.3907)  loss_vfl: 0.6757 (0.6245)  loss_bbox: 0.9641 (1.0148)  loss_giou: 2.0977 (2.1344)  loss_vfl_aux_0: 0.5049 (0.4626)  loss_bbox_aux_0: 0.9986 (1.0620)  loss_giou_aux_0: 2.1842 (2.2285)  loss_vfl_aux_1: 0.5747 (0.5293)  loss_bbox_aux_1: 0.9927 (1.0506)  loss_giou_aux_1: 2.1539 (2.2195)  loss_vfl_aux_2: 0.6453 (0.5803)  loss_bbox_aux_2: 0.9862 (1.0378)  loss_giou_aux_2: 2.1009 (2.1683)  loss_vfl_aux_3: 0.5460 (0.4940)  loss_bbox_aux_3: 0.9730 (1.0160)  loss_giou_aux_3: 2.1021 (2.1528)  loss_vfl_aux_4: 0.7236 (0.6654)  loss_bbox_aux_4: 0.9711 (1.0177)  loss_giou_aux_4: 2.0932 (2.1307)  loss_vfl_dn_0: 0.8943 (0.8977)  loss_bbox_dn_0: 0.3921 (0.4081)  loss_giou_dn_0: 1.2507 (1.2458)  loss_vfl_dn_1: 1.0107 (1.0432)  loss_bbox_dn_1: 0.3962 (0.4121)  loss_giou_dn_1: 1.2366 (1.2372)  loss_vfl_dn_2: 1.0328 (1.0407)  loss_bbox_dn_2: 0.4038 (0.4213)  loss_giou_dn_2: 1.2238 (1.2263)  loss_vfl_dn_3: 0.8536 (0.8750)  loss_bbox_dn_3: 0.4235 (0.4380)  loss_giou_dn_3: 1.2239 (1.2380)  loss_vfl_dn_4: 1.0729 (1.1088)  loss_bbox_dn_4: 0.4293 (0.4467)  loss_giou_dn_4: 1.2367 (1.2508)  loss_vfl_dn_5: 1.0045 (1.0353)  loss_bbox_dn_5: 0.4293 (0.4466)  loss_giou_dn_5: 1.2361 (1.2502)  loss_vfl_enc_0: 0.5010 (0.4614)  loss_bbox_enc_0: 1.0021 (1.0579)  loss_giou_enc_0: 2.2081 (2.2606)  time: 1.0789  data: 0.5608  max mem: 16799\n",
            "Epoch: [9] Total time: 0:00:08 (1.0846 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 41.7358 (42.3907)  loss_vfl: 0.6757 (0.6245)  loss_bbox: 0.9641 (1.0148)  loss_giou: 2.0977 (2.1344)  loss_vfl_aux_0: 0.5049 (0.4626)  loss_bbox_aux_0: 0.9986 (1.0620)  loss_giou_aux_0: 2.1842 (2.2285)  loss_vfl_aux_1: 0.5747 (0.5293)  loss_bbox_aux_1: 0.9927 (1.0506)  loss_giou_aux_1: 2.1539 (2.2195)  loss_vfl_aux_2: 0.6453 (0.5803)  loss_bbox_aux_2: 0.9862 (1.0378)  loss_giou_aux_2: 2.1009 (2.1683)  loss_vfl_aux_3: 0.5460 (0.4940)  loss_bbox_aux_3: 0.9730 (1.0160)  loss_giou_aux_3: 2.1021 (2.1528)  loss_vfl_aux_4: 0.7236 (0.6654)  loss_bbox_aux_4: 0.9711 (1.0177)  loss_giou_aux_4: 2.0932 (2.1307)  loss_vfl_dn_0: 0.8943 (0.8977)  loss_bbox_dn_0: 0.3921 (0.4081)  loss_giou_dn_0: 1.2507 (1.2458)  loss_vfl_dn_1: 1.0107 (1.0432)  loss_bbox_dn_1: 0.3962 (0.4121)  loss_giou_dn_1: 1.2366 (1.2372)  loss_vfl_dn_2: 1.0328 (1.0407)  loss_bbox_dn_2: 0.4038 (0.4213)  loss_giou_dn_2: 1.2238 (1.2263)  loss_vfl_dn_3: 0.8536 (0.8750)  loss_bbox_dn_3: 0.4235 (0.4380)  loss_giou_dn_3: 1.2239 (1.2380)  loss_vfl_dn_4: 1.0729 (1.1088)  loss_bbox_dn_4: 0.4293 (0.4467)  loss_giou_dn_4: 1.2367 (1.2508)  loss_vfl_dn_5: 1.0045 (1.0353)  loss_bbox_dn_5: 0.4293 (0.4466)  loss_giou_dn_5: 1.2361 (1.2502)  loss_vfl_enc_0: 0.5010 (0.4614)  loss_bbox_enc_0: 1.0021 (1.0579)  loss_giou_enc_0: 2.2081 (2.2606)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5371  data: 4.3558  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0192  data: 2.1939  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0368 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.125\n",
            "best_stat: {'epoch': 9, 'coco_eval_bbox': 0.0007886370749166238}\n",
            "Epoch: [10]  [0/8]  eta: 0:00:29  lr: 0.000000  loss: 45.2292 (45.2292)  loss_vfl: 0.4306 (0.4306)  loss_bbox: 1.2209 (1.2209)  loss_giou: 2.6288 (2.6288)  loss_vfl_aux_0: 0.2964 (0.2964)  loss_bbox_aux_0: 1.2384 (1.2384)  loss_giou_aux_0: 2.7148 (2.7148)  loss_vfl_aux_1: 0.3523 (0.3523)  loss_bbox_aux_1: 1.2370 (1.2370)  loss_giou_aux_1: 2.7066 (2.7066)  loss_vfl_aux_2: 0.3830 (0.3830)  loss_bbox_aux_2: 1.2270 (1.2270)  loss_giou_aux_2: 2.6730 (2.6730)  loss_vfl_aux_3: 0.3385 (0.3385)  loss_bbox_aux_3: 1.2088 (1.2088)  loss_giou_aux_3: 2.6461 (2.6461)  loss_vfl_aux_4: 0.4572 (0.4572)  loss_bbox_aux_4: 1.2181 (1.2181)  loss_giou_aux_4: 2.6284 (2.6284)  loss_vfl_dn_0: 0.8045 (0.8045)  loss_bbox_dn_0: 0.3458 (0.3458)  loss_giou_dn_0: 1.3185 (1.3185)  loss_vfl_dn_1: 0.9286 (0.9286)  loss_bbox_dn_1: 0.3531 (0.3531)  loss_giou_dn_1: 1.3112 (1.3112)  loss_vfl_dn_2: 0.9250 (0.9250)  loss_bbox_dn_2: 0.3523 (0.3523)  loss_giou_dn_2: 1.2915 (1.2915)  loss_vfl_dn_3: 0.7862 (0.7862)  loss_bbox_dn_3: 0.3604 (0.3604)  loss_giou_dn_3: 1.3009 (1.3009)  loss_vfl_dn_4: 0.9995 (0.9995)  loss_bbox_dn_4: 0.3675 (0.3675)  loss_giou_dn_4: 1.3092 (1.3092)  loss_vfl_dn_5: 0.9189 (0.9189)  loss_bbox_dn_5: 0.3674 (0.3674)  loss_giou_dn_5: 1.3081 (1.3081)  loss_vfl_enc_0: 0.3262 (0.3262)  loss_bbox_enc_0: 1.2226 (1.2226)  loss_giou_enc_0: 2.7258 (2.7258)  time: 3.7419  data: 3.1332  max mem: 16799\n",
            "Epoch: [10]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 41.8768 (42.6550)  loss_vfl: 0.5778 (0.5696)  loss_bbox: 0.9288 (1.0380)  loss_giou: 2.0800 (2.2012)  loss_vfl_aux_0: 0.4664 (0.4221)  loss_bbox_aux_0: 1.0376 (1.1072)  loss_giou_aux_0: 2.2055 (2.3061)  loss_vfl_aux_1: 0.5221 (0.4863)  loss_bbox_aux_1: 1.0172 (1.0934)  loss_giou_aux_1: 2.1887 (2.3037)  loss_vfl_aux_2: 0.5704 (0.5313)  loss_bbox_aux_2: 0.9894 (1.0841)  loss_giou_aux_2: 2.1393 (2.2540)  loss_vfl_aux_3: 0.4637 (0.4533)  loss_bbox_aux_3: 0.9467 (1.0524)  loss_giou_aux_3: 2.1008 (2.2188)  loss_vfl_aux_4: 0.6205 (0.6041)  loss_bbox_aux_4: 0.9291 (1.0363)  loss_giou_aux_4: 2.0779 (2.2021)  loss_vfl_dn_0: 0.9245 (0.9193)  loss_bbox_dn_0: 0.3529 (0.3703)  loss_giou_dn_0: 1.2136 (1.2305)  loss_vfl_dn_1: 1.1004 (1.0837)  loss_bbox_dn_1: 0.3551 (0.3724)  loss_giou_dn_1: 1.1948 (1.2129)  loss_vfl_dn_2: 1.0873 (1.0742)  loss_bbox_dn_2: 0.3580 (0.3769)  loss_giou_dn_2: 1.1830 (1.1997)  loss_vfl_dn_3: 0.9146 (0.9087)  loss_bbox_dn_3: 0.3705 (0.3897)  loss_giou_dn_3: 1.1948 (1.2102)  loss_vfl_dn_4: 1.1823 (1.1563)  loss_bbox_dn_4: 0.3783 (0.3979)  loss_giou_dn_4: 1.2063 (1.2197)  loss_vfl_dn_5: 1.1037 (1.0820)  loss_bbox_dn_5: 0.3782 (0.3979)  loss_giou_dn_5: 1.2056 (1.2189)  loss_vfl_enc_0: 0.4606 (0.4368)  loss_bbox_enc_0: 1.0333 (1.1050)  loss_giou_enc_0: 2.2184 (2.3281)  time: 0.9648  data: 0.4179  max mem: 16799\n",
            "Epoch: [10] Total time: 0:00:07 (0.9709 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 41.8768 (42.6550)  loss_vfl: 0.5778 (0.5696)  loss_bbox: 0.9288 (1.0380)  loss_giou: 2.0800 (2.2012)  loss_vfl_aux_0: 0.4664 (0.4221)  loss_bbox_aux_0: 1.0376 (1.1072)  loss_giou_aux_0: 2.2055 (2.3061)  loss_vfl_aux_1: 0.5221 (0.4863)  loss_bbox_aux_1: 1.0172 (1.0934)  loss_giou_aux_1: 2.1887 (2.3037)  loss_vfl_aux_2: 0.5704 (0.5313)  loss_bbox_aux_2: 0.9894 (1.0841)  loss_giou_aux_2: 2.1393 (2.2540)  loss_vfl_aux_3: 0.4637 (0.4533)  loss_bbox_aux_3: 0.9467 (1.0524)  loss_giou_aux_3: 2.1008 (2.2188)  loss_vfl_aux_4: 0.6205 (0.6041)  loss_bbox_aux_4: 0.9291 (1.0363)  loss_giou_aux_4: 2.0779 (2.2021)  loss_vfl_dn_0: 0.9245 (0.9193)  loss_bbox_dn_0: 0.3529 (0.3703)  loss_giou_dn_0: 1.2136 (1.2305)  loss_vfl_dn_1: 1.1004 (1.0837)  loss_bbox_dn_1: 0.3551 (0.3724)  loss_giou_dn_1: 1.1948 (1.2129)  loss_vfl_dn_2: 1.0873 (1.0742)  loss_bbox_dn_2: 0.3580 (0.3769)  loss_giou_dn_2: 1.1830 (1.1997)  loss_vfl_dn_3: 0.9146 (0.9087)  loss_bbox_dn_3: 0.3705 (0.3897)  loss_giou_dn_3: 1.1948 (1.2102)  loss_vfl_dn_4: 1.1823 (1.1563)  loss_bbox_dn_4: 0.3783 (0.3979)  loss_giou_dn_4: 1.2063 (1.2197)  loss_vfl_dn_5: 1.1037 (1.0820)  loss_bbox_dn_5: 0.3782 (0.3979)  loss_giou_dn_5: 1.2056 (1.2189)  loss_vfl_enc_0: 0.4606 (0.4368)  loss_bbox_enc_0: 1.0333 (1.1050)  loss_giou_enc_0: 2.2184 (2.3281)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8448  data: 4.3401  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1735  data: 2.1862  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.2023 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
            "best_stat: {'epoch': 10, 'coco_eval_bbox': 0.0010419113970688246}\n",
            "Epoch: [11]  [0/8]  eta: 0:00:30  lr: 0.000000  loss: 43.6003 (43.6003)  loss_vfl: 0.2852 (0.2852)  loss_bbox: 1.1602 (1.1602)  loss_giou: 2.5626 (2.5626)  loss_vfl_aux_0: 0.1936 (0.1936)  loss_bbox_aux_0: 1.2348 (1.2348)  loss_giou_aux_0: 2.6353 (2.6353)  loss_vfl_aux_1: 0.2314 (0.2314)  loss_bbox_aux_1: 1.2331 (1.2331)  loss_giou_aux_1: 2.6267 (2.6267)  loss_vfl_aux_2: 0.2594 (0.2594)  loss_bbox_aux_2: 1.2198 (1.2198)  loss_giou_aux_2: 2.5744 (2.5744)  loss_vfl_aux_3: 0.2252 (0.2252)  loss_bbox_aux_3: 1.1464 (1.1464)  loss_giou_aux_3: 2.5817 (2.5817)  loss_vfl_aux_4: 0.3037 (0.3037)  loss_bbox_aux_4: 1.1579 (1.1579)  loss_giou_aux_4: 2.5685 (2.5685)  loss_vfl_dn_0: 0.8460 (0.8460)  loss_bbox_dn_0: 0.3169 (0.3169)  loss_giou_dn_0: 1.2937 (1.2937)  loss_vfl_dn_1: 0.9955 (0.9955)  loss_bbox_dn_1: 0.3186 (0.3186)  loss_giou_dn_1: 1.2811 (1.2811)  loss_vfl_dn_2: 0.9922 (0.9922)  loss_bbox_dn_2: 0.3109 (0.3109)  loss_giou_dn_2: 1.2579 (1.2579)  loss_vfl_dn_3: 0.8696 (0.8696)  loss_bbox_dn_3: 0.3175 (0.3175)  loss_giou_dn_3: 1.2638 (1.2638)  loss_vfl_dn_4: 1.0720 (1.0720)  loss_bbox_dn_4: 0.3203 (0.3203)  loss_giou_dn_4: 1.2729 (1.2729)  loss_vfl_dn_5: 0.9918 (0.9918)  loss_bbox_dn_5: 0.3203 (0.3203)  loss_giou_dn_5: 1.2715 (1.2715)  loss_vfl_enc_0: 0.2109 (0.2109)  loss_bbox_enc_0: 1.2018 (1.2018)  loss_giou_enc_0: 2.6749 (2.6749)  time: 3.7682  data: 3.2440  max mem: 16799\n",
            "Epoch: [11]  [7/8]  eta: 0:00:00  lr: 0.000000  loss: 40.7871 (42.6678)  loss_vfl: 0.5504 (0.5883)  loss_bbox: 0.8706 (1.0183)  loss_giou: 2.1139 (2.2086)  loss_vfl_aux_0: 0.4704 (0.4650)  loss_bbox_aux_0: 0.8933 (1.0785)  loss_giou_aux_0: 2.1784 (2.2940)  loss_vfl_aux_1: 0.5386 (0.5211)  loss_bbox_aux_1: 0.8848 (1.0683)  loss_giou_aux_1: 2.1856 (2.2963)  loss_vfl_aux_2: 0.5438 (0.5545)  loss_bbox_aux_2: 0.8857 (1.0641)  loss_giou_aux_2: 2.1366 (2.2506)  loss_vfl_aux_3: 0.4533 (0.4685)  loss_bbox_aux_3: 0.8674 (1.0207)  loss_giou_aux_3: 2.1275 (2.2289)  loss_vfl_aux_4: 0.5845 (0.6255)  loss_bbox_aux_4: 0.8689 (1.0182)  loss_giou_aux_4: 2.1157 (2.2093)  loss_vfl_dn_0: 0.8904 (0.9058)  loss_bbox_dn_0: 0.3467 (0.3756)  loss_giou_dn_0: 1.2392 (1.2332)  loss_vfl_dn_1: 1.0413 (1.0659)  loss_bbox_dn_1: 0.3480 (0.3805)  loss_giou_dn_1: 1.2009 (1.2181)  loss_vfl_dn_2: 1.0576 (1.0648)  loss_bbox_dn_2: 0.3639 (0.3903)  loss_giou_dn_2: 1.1791 (1.2047)  loss_vfl_dn_3: 0.8854 (0.8961)  loss_bbox_dn_3: 0.3710 (0.4039)  loss_giou_dn_3: 1.1880 (1.2201)  loss_vfl_dn_4: 1.1463 (1.1286)  loss_bbox_dn_4: 0.3835 (0.4136)  loss_giou_dn_4: 1.2036 (1.2335)  loss_vfl_dn_5: 1.0570 (1.0494)  loss_bbox_dn_5: 0.3834 (0.4136)  loss_giou_dn_5: 1.2031 (1.2327)  loss_vfl_enc_0: 0.4656 (0.4622)  loss_bbox_enc_0: 0.9072 (1.0739)  loss_giou_enc_0: 2.2077 (2.3226)  time: 0.9317  data: 0.4211  max mem: 16799\n",
            "Epoch: [11] Total time: 0:00:07 (0.9385 s / it)\n",
            "Averaged stats: lr: 0.000000  loss: 40.7871 (42.6678)  loss_vfl: 0.5504 (0.5883)  loss_bbox: 0.8706 (1.0183)  loss_giou: 2.1139 (2.2086)  loss_vfl_aux_0: 0.4704 (0.4650)  loss_bbox_aux_0: 0.8933 (1.0785)  loss_giou_aux_0: 2.1784 (2.2940)  loss_vfl_aux_1: 0.5386 (0.5211)  loss_bbox_aux_1: 0.8848 (1.0683)  loss_giou_aux_1: 2.1856 (2.2963)  loss_vfl_aux_2: 0.5438 (0.5545)  loss_bbox_aux_2: 0.8857 (1.0641)  loss_giou_aux_2: 2.1366 (2.2506)  loss_vfl_aux_3: 0.4533 (0.4685)  loss_bbox_aux_3: 0.8674 (1.0207)  loss_giou_aux_3: 2.1275 (2.2289)  loss_vfl_aux_4: 0.5845 (0.6255)  loss_bbox_aux_4: 0.8689 (1.0182)  loss_giou_aux_4: 2.1157 (2.2093)  loss_vfl_dn_0: 0.8904 (0.9058)  loss_bbox_dn_0: 0.3467 (0.3756)  loss_giou_dn_0: 1.2392 (1.2332)  loss_vfl_dn_1: 1.0413 (1.0659)  loss_bbox_dn_1: 0.3480 (0.3805)  loss_giou_dn_1: 1.2009 (1.2181)  loss_vfl_dn_2: 1.0576 (1.0648)  loss_bbox_dn_2: 0.3639 (0.3903)  loss_giou_dn_2: 1.1791 (1.2047)  loss_vfl_dn_3: 0.8854 (0.8961)  loss_bbox_dn_3: 0.3710 (0.4039)  loss_giou_dn_3: 1.1880 (1.2201)  loss_vfl_dn_4: 1.1463 (1.1286)  loss_bbox_dn_4: 0.3835 (0.4136)  loss_giou_dn_4: 1.2036 (1.2335)  loss_vfl_dn_5: 1.0570 (1.0494)  loss_bbox_dn_5: 0.3834 (0.4136)  loss_giou_dn_5: 1.2031 (1.2327)  loss_vfl_enc_0: 0.4656 (0.4622)  loss_bbox_enc_0: 0.9072 (1.0739)  loss_giou_enc_0: 2.2077 (2.3226)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5271  data: 1.3551  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5128  data: 0.6938  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.5424 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
            "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.0010707181377065294}\n",
            "Epoch: [12]  [0/8]  eta: 0:00:41  lr: 0.000000  loss: 40.8380 (40.8380)  loss_vfl: 0.6416 (0.6416)  loss_bbox: 0.8877 (0.8877)  loss_giou: 2.0025 (2.0025)  loss_vfl_aux_0: 0.4854 (0.4854)  loss_bbox_aux_0: 0.9977 (0.9977)  loss_giou_aux_0: 2.0420 (2.0420)  loss_vfl_aux_1: 0.5643 (0.5643)  loss_bbox_aux_1: 0.9466 (0.9466)  loss_giou_aux_1: 2.0576 (2.0576)  loss_vfl_aux_2: 0.6246 (0.6246)  loss_bbox_aux_2: 0.9331 (0.9331)  loss_giou_aux_2: 1.9887 (1.9887)  loss_vfl_aux_3: 0.5282 (0.5282)  loss_bbox_aux_3: 0.9110 (0.9110)  loss_giou_aux_3: 1.9955 (1.9955)  loss_vfl_aux_4: 0.6796 (0.6796)  loss_bbox_aux_4: 0.8883 (0.8883)  loss_giou_aux_4: 2.0035 (2.0035)  loss_vfl_dn_0: 0.9074 (0.9074)  loss_bbox_dn_0: 0.4110 (0.4110)  loss_giou_dn_0: 1.2199 (1.2199)  loss_vfl_dn_1: 1.1083 (1.1083)  loss_bbox_dn_1: 0.4102 (0.4102)  loss_giou_dn_1: 1.1909 (1.1909)  loss_vfl_dn_2: 1.1039 (1.1039)  loss_bbox_dn_2: 0.4263 (0.4263)  loss_giou_dn_2: 1.1805 (1.1805)  loss_vfl_dn_3: 0.9224 (0.9224)  loss_bbox_dn_3: 0.4465 (0.4465)  loss_giou_dn_3: 1.1962 (1.1962)  loss_vfl_dn_4: 1.1570 (1.1570)  loss_bbox_dn_4: 0.4626 (0.4626)  loss_giou_dn_4: 1.2145 (1.2145)  loss_vfl_dn_5: 1.0706 (1.0706)  loss_bbox_dn_5: 0.4625 (0.4625)  loss_giou_dn_5: 1.2136 (1.2136)  loss_vfl_enc_0: 0.4827 (0.4827)  loss_bbox_enc_0: 0.9617 (0.9617)  loss_giou_enc_0: 2.1116 (2.1116)  time: 5.1588  data: 4.6718  max mem: 16799\n",
            "Epoch: [12]  [7/8]  eta: 0:00:01  lr: 0.000001  loss: 40.8380 (41.1444)  loss_vfl: 0.6416 (0.7111)  loss_bbox: 0.8199 (0.8629)  loss_giou: 1.7878 (1.9671)  loss_vfl_aux_0: 0.5260 (0.5681)  loss_bbox_aux_0: 0.8663 (0.9633)  loss_giou_aux_0: 1.9048 (2.0497)  loss_vfl_aux_1: 0.5813 (0.6523)  loss_bbox_aux_1: 0.8442 (0.9358)  loss_giou_aux_1: 1.8943 (2.0497)  loss_vfl_aux_2: 0.6246 (0.6922)  loss_bbox_aux_2: 0.8376 (0.9270)  loss_giou_aux_2: 1.8608 (2.0059)  loss_vfl_aux_3: 0.5282 (0.5767)  loss_bbox_aux_3: 0.8169 (0.8683)  loss_giou_aux_3: 1.8314 (1.9916)  loss_vfl_aux_4: 0.6796 (0.7596)  loss_bbox_aux_4: 0.8199 (0.8650)  loss_giou_aux_4: 1.7870 (1.9649)  loss_vfl_dn_0: 0.9422 (0.9460)  loss_bbox_dn_0: 0.3901 (0.4083)  loss_giou_dn_0: 1.1943 (1.2030)  loss_vfl_dn_1: 1.1091 (1.1181)  loss_bbox_dn_1: 0.3853 (0.4121)  loss_giou_dn_1: 1.1754 (1.1843)  loss_vfl_dn_2: 1.1297 (1.1126)  loss_bbox_dn_2: 0.3968 (0.4271)  loss_giou_dn_2: 1.1546 (1.1701)  loss_vfl_dn_3: 0.9602 (0.9343)  loss_bbox_dn_3: 0.4159 (0.4431)  loss_giou_dn_3: 1.1667 (1.1848)  loss_vfl_dn_4: 1.2056 (1.1829)  loss_bbox_dn_4: 0.4270 (0.4536)  loss_giou_dn_4: 1.1787 (1.1950)  loss_vfl_dn_5: 1.1221 (1.1022)  loss_bbox_dn_5: 0.4270 (0.4536)  loss_giou_dn_5: 1.1776 (1.1942)  loss_vfl_enc_0: 0.5233 (0.5582)  loss_bbox_enc_0: 0.8936 (0.9599)  loss_giou_enc_0: 1.9591 (2.0901)  time: 1.1336  data: 0.6068  max mem: 16799\n",
            "Epoch: [12] Total time: 0:00:09 (1.1399 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 40.8380 (41.1444)  loss_vfl: 0.6416 (0.7111)  loss_bbox: 0.8199 (0.8629)  loss_giou: 1.7878 (1.9671)  loss_vfl_aux_0: 0.5260 (0.5681)  loss_bbox_aux_0: 0.8663 (0.9633)  loss_giou_aux_0: 1.9048 (2.0497)  loss_vfl_aux_1: 0.5813 (0.6523)  loss_bbox_aux_1: 0.8442 (0.9358)  loss_giou_aux_1: 1.8943 (2.0497)  loss_vfl_aux_2: 0.6246 (0.6922)  loss_bbox_aux_2: 0.8376 (0.9270)  loss_giou_aux_2: 1.8608 (2.0059)  loss_vfl_aux_3: 0.5282 (0.5767)  loss_bbox_aux_3: 0.8169 (0.8683)  loss_giou_aux_3: 1.8314 (1.9916)  loss_vfl_aux_4: 0.6796 (0.7596)  loss_bbox_aux_4: 0.8199 (0.8650)  loss_giou_aux_4: 1.7870 (1.9649)  loss_vfl_dn_0: 0.9422 (0.9460)  loss_bbox_dn_0: 0.3901 (0.4083)  loss_giou_dn_0: 1.1943 (1.2030)  loss_vfl_dn_1: 1.1091 (1.1181)  loss_bbox_dn_1: 0.3853 (0.4121)  loss_giou_dn_1: 1.1754 (1.1843)  loss_vfl_dn_2: 1.1297 (1.1126)  loss_bbox_dn_2: 0.3968 (0.4271)  loss_giou_dn_2: 1.1546 (1.1701)  loss_vfl_dn_3: 0.9602 (0.9343)  loss_bbox_dn_3: 0.4159 (0.4431)  loss_giou_dn_3: 1.1667 (1.1848)  loss_vfl_dn_4: 1.2056 (1.1829)  loss_bbox_dn_4: 0.4270 (0.4536)  loss_giou_dn_4: 1.1787 (1.1950)  loss_vfl_dn_5: 1.1221 (1.1022)  loss_bbox_dn_5: 0.4270 (0.4536)  loss_giou_dn_5: 1.1776 (1.1942)  loss_vfl_enc_0: 0.5233 (0.5582)  loss_bbox_enc_0: 0.8936 (0.9599)  loss_giou_enc_0: 1.9591 (2.0901)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.6454  data: 4.4642  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0719  data: 2.2481  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0973 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
            "best_stat: {'epoch': 12, 'coco_eval_bbox': 0.0017179096222241306}\n",
            "Epoch: [13]  [0/8]  eta: 0:00:26  lr: 0.000001  loss: 39.4619 (39.4619)  loss_vfl: 0.6885 (0.6885)  loss_bbox: 0.7736 (0.7736)  loss_giou: 1.9484 (1.9484)  loss_vfl_aux_0: 0.6422 (0.6422)  loss_bbox_aux_0: 0.7775 (0.7775)  loss_giou_aux_0: 1.9806 (1.9806)  loss_vfl_aux_1: 0.6861 (0.6861)  loss_bbox_aux_1: 0.7717 (0.7717)  loss_giou_aux_1: 1.9878 (1.9878)  loss_vfl_aux_2: 0.6835 (0.6835)  loss_bbox_aux_2: 0.7989 (0.7989)  loss_giou_aux_2: 1.9548 (1.9548)  loss_vfl_aux_3: 0.5700 (0.5700)  loss_bbox_aux_3: 0.7582 (0.7582)  loss_giou_aux_3: 1.9732 (1.9732)  loss_vfl_aux_4: 0.7412 (0.7412)  loss_bbox_aux_4: 0.7745 (0.7745)  loss_giou_aux_4: 1.9494 (1.9494)  loss_vfl_dn_0: 0.9320 (0.9320)  loss_bbox_dn_0: 0.3516 (0.3516)  loss_giou_dn_0: 1.2144 (1.2144)  loss_vfl_dn_1: 1.0448 (1.0448)  loss_bbox_dn_1: 0.3644 (0.3644)  loss_giou_dn_1: 1.2083 (1.2083)  loss_vfl_dn_2: 0.9759 (0.9759)  loss_bbox_dn_2: 0.3973 (0.3973)  loss_giou_dn_2: 1.2320 (1.2320)  loss_vfl_dn_3: 0.8255 (0.8255)  loss_bbox_dn_3: 0.4189 (0.4189)  loss_giou_dn_3: 1.2547 (1.2547)  loss_vfl_dn_4: 1.0142 (1.0142)  loss_bbox_dn_4: 0.4303 (0.4303)  loss_giou_dn_4: 1.2733 (1.2733)  loss_vfl_dn_5: 0.9416 (0.9416)  loss_bbox_dn_5: 0.4302 (0.4302)  loss_giou_dn_5: 1.2721 (1.2721)  loss_vfl_enc_0: 0.6169 (0.6169)  loss_bbox_enc_0: 0.7634 (0.7634)  loss_giou_enc_0: 2.0400 (2.0400)  time: 3.2928  data: 2.8056  max mem: 16799\n",
            "Epoch: [13]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 41.6543 (41.6617)  loss_vfl: 0.7012 (0.7085)  loss_bbox: 0.8661 (0.9126)  loss_giou: 1.9484 (2.0672)  loss_vfl_aux_0: 0.5633 (0.5795)  loss_bbox_aux_0: 0.9430 (0.9556)  loss_giou_aux_0: 2.0547 (2.1385)  loss_vfl_aux_1: 0.6569 (0.6544)  loss_bbox_aux_1: 0.9140 (0.9400)  loss_giou_aux_1: 2.0548 (2.1411)  loss_vfl_aux_2: 0.6835 (0.6869)  loss_bbox_aux_2: 0.8960 (0.9418)  loss_giou_aux_2: 2.0057 (2.0969)  loss_vfl_aux_3: 0.5700 (0.5756)  loss_bbox_aux_3: 0.8672 (0.9073)  loss_giou_aux_3: 1.9732 (2.0876)  loss_vfl_aux_4: 0.7451 (0.7542)  loss_bbox_aux_4: 0.8651 (0.9165)  loss_giou_aux_4: 1.9494 (2.0629)  loss_vfl_dn_0: 0.9320 (0.9367)  loss_bbox_dn_0: 0.3584 (0.3822)  loss_giou_dn_0: 1.2040 (1.2044)  loss_vfl_dn_1: 1.0842 (1.0920)  loss_bbox_dn_1: 0.3644 (0.3871)  loss_giou_dn_1: 1.1918 (1.1874)  loss_vfl_dn_2: 1.0808 (1.0798)  loss_bbox_dn_2: 0.3744 (0.4027)  loss_giou_dn_2: 1.1834 (1.1790)  loss_vfl_dn_3: 0.9017 (0.8969)  loss_bbox_dn_3: 0.3888 (0.4201)  loss_giou_dn_3: 1.2016 (1.1987)  loss_vfl_dn_4: 1.1356 (1.1340)  loss_bbox_dn_4: 0.4016 (0.4306)  loss_giou_dn_4: 1.2152 (1.2106)  loss_vfl_dn_5: 1.0611 (1.0517)  loss_bbox_dn_5: 0.4016 (0.4305)  loss_giou_dn_5: 1.2140 (1.2096)  loss_vfl_enc_0: 0.5527 (0.5705)  loss_bbox_enc_0: 0.9492 (0.9487)  loss_giou_enc_0: 2.0847 (2.1814)  time: 0.8527  data: 0.3666  max mem: 16799\n",
            "Epoch: [13] Total time: 0:00:06 (0.8601 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 41.6543 (41.6617)  loss_vfl: 0.7012 (0.7085)  loss_bbox: 0.8661 (0.9126)  loss_giou: 1.9484 (2.0672)  loss_vfl_aux_0: 0.5633 (0.5795)  loss_bbox_aux_0: 0.9430 (0.9556)  loss_giou_aux_0: 2.0547 (2.1385)  loss_vfl_aux_1: 0.6569 (0.6544)  loss_bbox_aux_1: 0.9140 (0.9400)  loss_giou_aux_1: 2.0548 (2.1411)  loss_vfl_aux_2: 0.6835 (0.6869)  loss_bbox_aux_2: 0.8960 (0.9418)  loss_giou_aux_2: 2.0057 (2.0969)  loss_vfl_aux_3: 0.5700 (0.5756)  loss_bbox_aux_3: 0.8672 (0.9073)  loss_giou_aux_3: 1.9732 (2.0876)  loss_vfl_aux_4: 0.7451 (0.7542)  loss_bbox_aux_4: 0.8651 (0.9165)  loss_giou_aux_4: 1.9494 (2.0629)  loss_vfl_dn_0: 0.9320 (0.9367)  loss_bbox_dn_0: 0.3584 (0.3822)  loss_giou_dn_0: 1.2040 (1.2044)  loss_vfl_dn_1: 1.0842 (1.0920)  loss_bbox_dn_1: 0.3644 (0.3871)  loss_giou_dn_1: 1.1918 (1.1874)  loss_vfl_dn_2: 1.0808 (1.0798)  loss_bbox_dn_2: 0.3744 (0.4027)  loss_giou_dn_2: 1.1834 (1.1790)  loss_vfl_dn_3: 0.9017 (0.8969)  loss_bbox_dn_3: 0.3888 (0.4201)  loss_giou_dn_3: 1.2016 (1.1987)  loss_vfl_dn_4: 1.1356 (1.1340)  loss_bbox_dn_4: 0.4016 (0.4306)  loss_giou_dn_4: 1.2152 (1.2106)  loss_vfl_dn_5: 1.0611 (1.0517)  loss_bbox_dn_5: 0.4016 (0.4305)  loss_giou_dn_5: 1.2140 (1.2096)  loss_vfl_enc_0: 0.5527 (0.5705)  loss_bbox_enc_0: 0.9492 (0.9487)  loss_giou_enc_0: 2.0847 (2.1814)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5122  data: 1.3504  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5064  data: 0.6912  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.5392 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181\n",
            "best_stat: {'epoch': 13, 'coco_eval_bbox': 0.002248899428110565}\n",
            "Epoch: [14]  [0/8]  eta: 0:00:36  lr: 0.000001  loss: 41.3201 (41.3201)  loss_vfl: 0.8630 (0.8630)  loss_bbox: 0.8351 (0.8351)  loss_giou: 1.8649 (1.8649)  loss_vfl_aux_0: 0.6429 (0.6429)  loss_bbox_aux_0: 0.9846 (0.9846)  loss_giou_aux_0: 1.9974 (1.9974)  loss_vfl_aux_1: 0.7333 (0.7333)  loss_bbox_aux_1: 0.9658 (0.9658)  loss_giou_aux_1: 1.9931 (1.9931)  loss_vfl_aux_2: 0.7825 (0.7825)  loss_bbox_aux_2: 0.9562 (0.9562)  loss_giou_aux_2: 1.9316 (1.9316)  loss_vfl_aux_3: 0.6704 (0.6704)  loss_bbox_aux_3: 0.8601 (0.8601)  loss_giou_aux_3: 1.8814 (1.8814)  loss_vfl_aux_4: 0.9207 (0.9207)  loss_bbox_aux_4: 0.8352 (0.8352)  loss_giou_aux_4: 1.8682 (1.8682)  loss_vfl_dn_0: 0.8923 (0.8923)  loss_bbox_dn_0: 0.4584 (0.4584)  loss_giou_dn_0: 1.2160 (1.2160)  loss_vfl_dn_1: 1.0486 (1.0486)  loss_bbox_dn_1: 0.4491 (0.4491)  loss_giou_dn_1: 1.1926 (1.1926)  loss_vfl_dn_2: 1.0275 (1.0275)  loss_bbox_dn_2: 0.4783 (0.4783)  loss_giou_dn_2: 1.1912 (1.1912)  loss_vfl_dn_3: 0.8152 (0.8152)  loss_bbox_dn_3: 0.5062 (0.5062)  loss_giou_dn_3: 1.2236 (1.2236)  loss_vfl_dn_4: 1.0516 (1.0516)  loss_bbox_dn_4: 0.5212 (0.5212)  loss_giou_dn_4: 1.2397 (1.2397)  loss_vfl_dn_5: 0.9801 (0.9801)  loss_bbox_dn_5: 0.5212 (0.5212)  loss_giou_dn_5: 1.2393 (1.2393)  loss_vfl_enc_0: 0.6651 (0.6651)  loss_bbox_enc_0: 0.9714 (0.9714)  loss_giou_enc_0: 2.0452 (2.0452)  time: 4.5935  data: 4.0621  max mem: 16799\n",
            "Epoch: [14]  [7/8]  eta: 0:00:01  lr: 0.000001  loss: 41.3201 (41.2307)  loss_vfl: 0.6575 (0.7304)  loss_bbox: 0.8351 (0.8629)  loss_giou: 1.9681 (2.0034)  loss_vfl_aux_0: 0.5565 (0.5861)  loss_bbox_aux_0: 0.9587 (0.9562)  loss_giou_aux_0: 2.0879 (2.0967)  loss_vfl_aux_1: 0.6358 (0.6734)  loss_bbox_aux_1: 0.9419 (0.9446)  loss_giou_aux_1: 2.0743 (2.0914)  loss_vfl_aux_2: 0.6741 (0.7250)  loss_bbox_aux_2: 0.9343 (0.9304)  loss_giou_aux_2: 2.0076 (2.0458)  loss_vfl_aux_3: 0.5462 (0.5890)  loss_bbox_aux_3: 0.8601 (0.8660)  loss_giou_aux_3: 1.9745 (2.0216)  loss_vfl_aux_4: 0.7146 (0.7859)  loss_bbox_aux_4: 0.8352 (0.8643)  loss_giou_aux_4: 1.9679 (2.0027)  loss_vfl_dn_0: 0.9131 (0.9306)  loss_bbox_dn_0: 0.3573 (0.3824)  loss_giou_dn_0: 1.1904 (1.2008)  loss_vfl_dn_1: 1.0839 (1.1030)  loss_bbox_dn_1: 0.3623 (0.3835)  loss_giou_dn_1: 1.1725 (1.1739)  loss_vfl_dn_2: 1.0737 (1.0886)  loss_bbox_dn_2: 0.3785 (0.3975)  loss_giou_dn_2: 1.1745 (1.1634)  loss_vfl_dn_3: 0.9001 (0.9125)  loss_bbox_dn_3: 0.3829 (0.4117)  loss_giou_dn_3: 1.1971 (1.1825)  loss_vfl_dn_4: 1.1391 (1.1531)  loss_bbox_dn_4: 0.3873 (0.4199)  loss_giou_dn_4: 1.2046 (1.1937)  loss_vfl_dn_5: 1.0658 (1.0708)  loss_bbox_dn_5: 0.3873 (0.4198)  loss_giou_dn_5: 1.2028 (1.1925)  loss_vfl_enc_0: 0.5929 (0.6022)  loss_bbox_enc_0: 0.9443 (0.9512)  loss_giou_enc_0: 2.0856 (2.1213)  time: 1.0590  data: 0.5363  max mem: 16799\n",
            "Epoch: [14] Total time: 0:00:08 (1.0647 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 41.3201 (41.2307)  loss_vfl: 0.6575 (0.7304)  loss_bbox: 0.8351 (0.8629)  loss_giou: 1.9681 (2.0034)  loss_vfl_aux_0: 0.5565 (0.5861)  loss_bbox_aux_0: 0.9587 (0.9562)  loss_giou_aux_0: 2.0879 (2.0967)  loss_vfl_aux_1: 0.6358 (0.6734)  loss_bbox_aux_1: 0.9419 (0.9446)  loss_giou_aux_1: 2.0743 (2.0914)  loss_vfl_aux_2: 0.6741 (0.7250)  loss_bbox_aux_2: 0.9343 (0.9304)  loss_giou_aux_2: 2.0076 (2.0458)  loss_vfl_aux_3: 0.5462 (0.5890)  loss_bbox_aux_3: 0.8601 (0.8660)  loss_giou_aux_3: 1.9745 (2.0216)  loss_vfl_aux_4: 0.7146 (0.7859)  loss_bbox_aux_4: 0.8352 (0.8643)  loss_giou_aux_4: 1.9679 (2.0027)  loss_vfl_dn_0: 0.9131 (0.9306)  loss_bbox_dn_0: 0.3573 (0.3824)  loss_giou_dn_0: 1.1904 (1.2008)  loss_vfl_dn_1: 1.0839 (1.1030)  loss_bbox_dn_1: 0.3623 (0.3835)  loss_giou_dn_1: 1.1725 (1.1739)  loss_vfl_dn_2: 1.0737 (1.0886)  loss_bbox_dn_2: 0.3785 (0.3975)  loss_giou_dn_2: 1.1745 (1.1634)  loss_vfl_dn_3: 0.9001 (0.9125)  loss_bbox_dn_3: 0.3829 (0.4117)  loss_giou_dn_3: 1.1971 (1.1825)  loss_vfl_dn_4: 1.1391 (1.1531)  loss_bbox_dn_4: 0.3873 (0.4199)  loss_giou_dn_4: 1.2046 (1.1937)  loss_vfl_dn_5: 1.0658 (1.0708)  loss_bbox_dn_5: 0.3873 (0.4198)  loss_giou_dn_5: 1.2028 (1.1925)  loss_vfl_enc_0: 0.5929 (0.6022)  loss_bbox_enc_0: 0.9443 (0.9512)  loss_giou_enc_0: 2.0856 (2.1213)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5383  data: 1.3586  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5201  data: 0.6956  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.5605 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
            "best_stat: {'epoch': 14, 'coco_eval_bbox': 0.0030780004689151407}\n",
            "Epoch: [15]  [0/8]  eta: 0:00:29  lr: 0.000001  loss: 39.2050 (39.2050)  loss_vfl: 0.8592 (0.8592)  loss_bbox: 0.7428 (0.7428)  loss_giou: 1.7062 (1.7062)  loss_vfl_aux_0: 0.7755 (0.7755)  loss_bbox_aux_0: 0.7713 (0.7713)  loss_giou_aux_0: 1.7829 (1.7829)  loss_vfl_aux_1: 0.8612 (0.8612)  loss_bbox_aux_1: 0.7463 (0.7463)  loss_giou_aux_1: 1.7817 (1.7817)  loss_vfl_aux_2: 0.8963 (0.8963)  loss_bbox_aux_2: 0.7412 (0.7412)  loss_giou_aux_2: 1.7584 (1.7584)  loss_vfl_aux_3: 0.6886 (0.6886)  loss_bbox_aux_3: 0.7035 (0.7035)  loss_giou_aux_3: 1.7709 (1.7709)  loss_vfl_aux_4: 0.9280 (0.9280)  loss_bbox_aux_4: 0.7415 (0.7415)  loss_giou_aux_4: 1.7144 (1.7144)  loss_vfl_dn_0: 0.9545 (0.9545)  loss_bbox_dn_0: 0.3977 (0.3977)  loss_giou_dn_0: 1.1864 (1.1864)  loss_vfl_dn_1: 1.1181 (1.1181)  loss_bbox_dn_1: 0.3939 (0.3939)  loss_giou_dn_1: 1.1499 (1.1499)  loss_vfl_dn_2: 1.1165 (1.1165)  loss_bbox_dn_2: 0.4096 (0.4096)  loss_giou_dn_2: 1.1371 (1.1371)  loss_vfl_dn_3: 0.9381 (0.9381)  loss_bbox_dn_3: 0.4227 (0.4227)  loss_giou_dn_3: 1.1537 (1.1537)  loss_vfl_dn_4: 1.1906 (1.1906)  loss_bbox_dn_4: 0.4324 (0.4324)  loss_giou_dn_4: 1.1665 (1.1665)  loss_vfl_dn_5: 1.0884 (1.0884)  loss_bbox_dn_5: 0.4323 (0.4323)  loss_giou_dn_5: 1.1656 (1.1656)  loss_vfl_enc_0: 0.7927 (0.7927)  loss_bbox_enc_0: 0.7585 (0.7585)  loss_giou_enc_0: 1.8299 (1.8299)  time: 3.6907  data: 3.2285  max mem: 16799\n",
            "Epoch: [15]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 41.4660 (41.3909)  loss_vfl: 0.6351 (0.6742)  loss_bbox: 0.7866 (0.8437)  loss_giou: 1.9702 (2.0672)  loss_vfl_aux_0: 0.5446 (0.5750)  loss_bbox_aux_0: 0.9621 (0.9925)  loss_giou_aux_0: 2.0818 (2.1601)  loss_vfl_aux_1: 0.6345 (0.6605)  loss_bbox_aux_1: 0.9265 (0.9673)  loss_giou_aux_1: 2.0635 (2.1596)  loss_vfl_aux_2: 0.6161 (0.6685)  loss_bbox_aux_2: 0.9301 (0.9702)  loss_giou_aux_2: 2.0341 (2.1320)  loss_vfl_aux_3: 0.5077 (0.5472)  loss_bbox_aux_3: 0.7972 (0.8406)  loss_giou_aux_3: 2.0036 (2.1002)  loss_vfl_aux_4: 0.6700 (0.7236)  loss_bbox_aux_4: 0.7835 (0.8452)  loss_giou_aux_4: 1.9738 (2.0672)  loss_vfl_dn_0: 0.9637 (0.9687)  loss_bbox_dn_0: 0.3692 (0.3525)  loss_giou_dn_0: 1.1791 (1.1781)  loss_vfl_dn_1: 1.1372 (1.1529)  loss_bbox_dn_1: 0.3623 (0.3507)  loss_giou_dn_1: 1.1449 (1.1414)  loss_vfl_dn_2: 1.1273 (1.1432)  loss_bbox_dn_2: 0.3774 (0.3644)  loss_giou_dn_2: 1.1313 (1.1250)  loss_vfl_dn_3: 0.9381 (0.9572)  loss_bbox_dn_3: 0.3799 (0.3785)  loss_giou_dn_3: 1.1463 (1.1391)  loss_vfl_dn_4: 1.1816 (1.1996)  loss_bbox_dn_4: 0.3901 (0.3895)  loss_giou_dn_4: 1.1635 (1.1525)  loss_vfl_dn_5: 1.0896 (1.1036)  loss_bbox_dn_5: 0.3900 (0.3895)  loss_giou_dn_5: 1.1616 (1.1511)  loss_vfl_enc_0: 0.5837 (0.5878)  loss_bbox_enc_0: 0.9520 (0.9818)  loss_giou_enc_0: 2.1041 (2.1891)  time: 0.9530  data: 0.4332  max mem: 16799\n",
            "Epoch: [15] Total time: 0:00:07 (0.9612 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 41.4660 (41.3909)  loss_vfl: 0.6351 (0.6742)  loss_bbox: 0.7866 (0.8437)  loss_giou: 1.9702 (2.0672)  loss_vfl_aux_0: 0.5446 (0.5750)  loss_bbox_aux_0: 0.9621 (0.9925)  loss_giou_aux_0: 2.0818 (2.1601)  loss_vfl_aux_1: 0.6345 (0.6605)  loss_bbox_aux_1: 0.9265 (0.9673)  loss_giou_aux_1: 2.0635 (2.1596)  loss_vfl_aux_2: 0.6161 (0.6685)  loss_bbox_aux_2: 0.9301 (0.9702)  loss_giou_aux_2: 2.0341 (2.1320)  loss_vfl_aux_3: 0.5077 (0.5472)  loss_bbox_aux_3: 0.7972 (0.8406)  loss_giou_aux_3: 2.0036 (2.1002)  loss_vfl_aux_4: 0.6700 (0.7236)  loss_bbox_aux_4: 0.7835 (0.8452)  loss_giou_aux_4: 1.9738 (2.0672)  loss_vfl_dn_0: 0.9637 (0.9687)  loss_bbox_dn_0: 0.3692 (0.3525)  loss_giou_dn_0: 1.1791 (1.1781)  loss_vfl_dn_1: 1.1372 (1.1529)  loss_bbox_dn_1: 0.3623 (0.3507)  loss_giou_dn_1: 1.1449 (1.1414)  loss_vfl_dn_2: 1.1273 (1.1432)  loss_bbox_dn_2: 0.3774 (0.3644)  loss_giou_dn_2: 1.1313 (1.1250)  loss_vfl_dn_3: 0.9381 (0.9572)  loss_bbox_dn_3: 0.3799 (0.3785)  loss_giou_dn_3: 1.1463 (1.1391)  loss_vfl_dn_4: 1.1816 (1.1996)  loss_bbox_dn_4: 0.3901 (0.3895)  loss_giou_dn_4: 1.1635 (1.1525)  loss_vfl_dn_5: 1.0896 (1.1036)  loss_bbox_dn_5: 0.3900 (0.3895)  loss_giou_dn_5: 1.1616 (1.1511)  loss_vfl_enc_0: 0.5837 (0.5878)  loss_bbox_enc_0: 0.9520 (0.9818)  loss_giou_enc_0: 2.1041 (2.1891)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8923  data: 4.3953  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1954  data: 2.2139  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.2289 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.103\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
            "best_stat: {'epoch': 15, 'coco_eval_bbox': 0.0036295493021730567}\n",
            "Epoch: [16]  [0/8]  eta: 0:00:30  lr: 0.000001  loss: 41.3064 (41.3064)  loss_vfl: 0.6582 (0.6582)  loss_bbox: 0.8736 (0.8736)  loss_giou: 2.0104 (2.0104)  loss_vfl_aux_0: 0.4768 (0.4768)  loss_bbox_aux_0: 1.0355 (1.0355)  loss_giou_aux_0: 2.1369 (2.1369)  loss_vfl_aux_1: 0.5714 (0.5714)  loss_bbox_aux_1: 1.0253 (1.0253)  loss_giou_aux_1: 2.0999 (2.0999)  loss_vfl_aux_2: 0.6247 (0.6247)  loss_bbox_aux_2: 0.9895 (0.9895)  loss_giou_aux_2: 2.0661 (2.0661)  loss_vfl_aux_3: 0.5042 (0.5042)  loss_bbox_aux_3: 0.8610 (0.8610)  loss_giou_aux_3: 2.0727 (2.0727)  loss_vfl_aux_4: 0.7077 (0.7077)  loss_bbox_aux_4: 0.8811 (0.8811)  loss_giou_aux_4: 2.0083 (2.0083)  loss_vfl_dn_0: 0.9326 (0.9326)  loss_bbox_dn_0: 0.4559 (0.4559)  loss_giou_dn_0: 1.1829 (1.1829)  loss_vfl_dn_1: 1.1017 (1.1017)  loss_bbox_dn_1: 0.4520 (0.4520)  loss_giou_dn_1: 1.1568 (1.1568)  loss_vfl_dn_2: 1.0760 (1.0760)  loss_bbox_dn_2: 0.4693 (0.4693)  loss_giou_dn_2: 1.1422 (1.1422)  loss_vfl_dn_3: 0.9166 (0.9166)  loss_bbox_dn_3: 0.4806 (0.4806)  loss_giou_dn_3: 1.1518 (1.1518)  loss_vfl_dn_4: 1.1863 (1.1863)  loss_bbox_dn_4: 0.4850 (0.4850)  loss_giou_dn_4: 1.1507 (1.1507)  loss_vfl_dn_5: 1.0842 (1.0842)  loss_bbox_dn_5: 0.4850 (0.4850)  loss_giou_dn_5: 1.1494 (1.1494)  loss_vfl_enc_0: 0.4468 (0.4468)  loss_bbox_enc_0: 1.0499 (1.0499)  loss_giou_enc_0: 2.1474 (2.1474)  time: 3.7704  data: 3.1096  max mem: 16799\n",
            "Epoch: [16]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 41.3064 (41.2723)  loss_vfl: 0.7227 (0.7120)  loss_bbox: 0.8548 (0.8538)  loss_giou: 2.0104 (2.0170)  loss_vfl_aux_0: 0.5987 (0.5947)  loss_bbox_aux_0: 1.0343 (1.0224)  loss_giou_aux_0: 2.1496 (2.1184)  loss_vfl_aux_1: 0.6816 (0.6863)  loss_bbox_aux_1: 1.0253 (1.0061)  loss_giou_aux_1: 2.1324 (2.1115)  loss_vfl_aux_2: 0.6998 (0.7065)  loss_bbox_aux_2: 0.9895 (1.0051)  loss_giou_aux_2: 2.1180 (2.0805)  loss_vfl_aux_3: 0.5837 (0.5797)  loss_bbox_aux_3: 0.8414 (0.8450)  loss_giou_aux_3: 2.0727 (2.0556)  loss_vfl_aux_4: 0.7808 (0.7686)  loss_bbox_aux_4: 0.8544 (0.8545)  loss_giou_aux_4: 2.0083 (2.0174)  loss_vfl_dn_0: 0.9326 (0.9468)  loss_bbox_dn_0: 0.3339 (0.3522)  loss_giou_dn_0: 1.1829 (1.1820)  loss_vfl_dn_1: 1.0860 (1.1138)  loss_bbox_dn_1: 0.3385 (0.3502)  loss_giou_dn_1: 1.1568 (1.1605)  loss_vfl_dn_2: 1.0693 (1.0962)  loss_bbox_dn_2: 0.3591 (0.3638)  loss_giou_dn_2: 1.1422 (1.1471)  loss_vfl_dn_3: 0.8778 (0.9157)  loss_bbox_dn_3: 0.3734 (0.3744)  loss_giou_dn_3: 1.1518 (1.1626)  loss_vfl_dn_4: 1.1357 (1.1589)  loss_bbox_dn_4: 0.3832 (0.3830)  loss_giou_dn_4: 1.1507 (1.1697)  loss_vfl_dn_5: 1.0317 (1.0608)  loss_bbox_dn_5: 0.3832 (0.3829)  loss_giou_dn_5: 1.1494 (1.1685)  loss_vfl_enc_0: 0.6040 (0.5832)  loss_bbox_enc_0: 1.0423 (1.0117)  loss_giou_enc_0: 2.1866 (2.1535)  time: 0.9733  data: 0.4200  max mem: 16799\n",
            "Epoch: [16] Total time: 0:00:07 (0.9821 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 41.3064 (41.2723)  loss_vfl: 0.7227 (0.7120)  loss_bbox: 0.8548 (0.8538)  loss_giou: 2.0104 (2.0170)  loss_vfl_aux_0: 0.5987 (0.5947)  loss_bbox_aux_0: 1.0343 (1.0224)  loss_giou_aux_0: 2.1496 (2.1184)  loss_vfl_aux_1: 0.6816 (0.6863)  loss_bbox_aux_1: 1.0253 (1.0061)  loss_giou_aux_1: 2.1324 (2.1115)  loss_vfl_aux_2: 0.6998 (0.7065)  loss_bbox_aux_2: 0.9895 (1.0051)  loss_giou_aux_2: 2.1180 (2.0805)  loss_vfl_aux_3: 0.5837 (0.5797)  loss_bbox_aux_3: 0.8414 (0.8450)  loss_giou_aux_3: 2.0727 (2.0556)  loss_vfl_aux_4: 0.7808 (0.7686)  loss_bbox_aux_4: 0.8544 (0.8545)  loss_giou_aux_4: 2.0083 (2.0174)  loss_vfl_dn_0: 0.9326 (0.9468)  loss_bbox_dn_0: 0.3339 (0.3522)  loss_giou_dn_0: 1.1829 (1.1820)  loss_vfl_dn_1: 1.0860 (1.1138)  loss_bbox_dn_1: 0.3385 (0.3502)  loss_giou_dn_1: 1.1568 (1.1605)  loss_vfl_dn_2: 1.0693 (1.0962)  loss_bbox_dn_2: 0.3591 (0.3638)  loss_giou_dn_2: 1.1422 (1.1471)  loss_vfl_dn_3: 0.8778 (0.9157)  loss_bbox_dn_3: 0.3734 (0.3744)  loss_giou_dn_3: 1.1518 (1.1626)  loss_vfl_dn_4: 1.1357 (1.1589)  loss_bbox_dn_4: 0.3832 (0.3830)  loss_giou_dn_4: 1.1507 (1.1697)  loss_vfl_dn_5: 1.0317 (1.0608)  loss_bbox_dn_5: 0.3832 (0.3829)  loss_giou_dn_5: 1.1494 (1.1685)  loss_vfl_enc_0: 0.6040 (0.5832)  loss_bbox_enc_0: 1.0423 (1.0117)  loss_giou_enc_0: 2.1866 (2.1535)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4309  data: 4.2702  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9641  data: 2.1515  max mem: 16799\n",
            "Test: Total time: 0:00:05 (2.9866 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
            "best_stat: {'epoch': 16, 'coco_eval_bbox': 0.004102441398982335}\n",
            "Epoch: [17]  [0/8]  eta: 0:00:32  lr: 0.000001  loss: 42.8888 (42.8888)  loss_vfl: 0.6800 (0.6800)  loss_bbox: 0.9906 (0.9906)  loss_giou: 2.0360 (2.0360)  loss_vfl_aux_0: 0.5196 (0.5196)  loss_bbox_aux_0: 1.1620 (1.1620)  loss_giou_aux_0: 2.2287 (2.2287)  loss_vfl_aux_1: 0.5882 (0.5882)  loss_bbox_aux_1: 1.1778 (1.1778)  loss_giou_aux_1: 2.2079 (2.2079)  loss_vfl_aux_2: 0.6432 (0.6432)  loss_bbox_aux_2: 1.1644 (1.1644)  loss_giou_aux_2: 2.1671 (2.1671)  loss_vfl_aux_3: 0.5473 (0.5473)  loss_bbox_aux_3: 0.9983 (0.9983)  loss_giou_aux_3: 2.0908 (2.0908)  loss_vfl_aux_4: 0.7506 (0.7506)  loss_bbox_aux_4: 0.9931 (0.9931)  loss_giou_aux_4: 2.0320 (2.0320)  loss_vfl_dn_0: 0.9788 (0.9788)  loss_bbox_dn_0: 0.4219 (0.4219)  loss_giou_dn_0: 1.1694 (1.1694)  loss_vfl_dn_1: 1.1685 (1.1685)  loss_bbox_dn_1: 0.4178 (0.4178)  loss_giou_dn_1: 1.1250 (1.1250)  loss_vfl_dn_2: 1.1703 (1.1703)  loss_bbox_dn_2: 0.4083 (0.4083)  loss_giou_dn_2: 1.1065 (1.1065)  loss_vfl_dn_3: 1.0172 (1.0172)  loss_bbox_dn_3: 0.4160 (0.4160)  loss_giou_dn_3: 1.1130 (1.1130)  loss_vfl_dn_4: 1.2715 (1.2715)  loss_bbox_dn_4: 0.4195 (0.4195)  loss_giou_dn_4: 1.1108 (1.1108)  loss_vfl_dn_5: 1.1547 (1.1547)  loss_bbox_dn_5: 0.4193 (0.4193)  loss_giou_dn_5: 1.1089 (1.1089)  loss_vfl_enc_0: 0.4992 (0.4992)  loss_bbox_enc_0: 1.1555 (1.1555)  loss_giou_enc_0: 2.2594 (2.2594)  time: 4.0708  data: 3.4094  max mem: 16799\n",
            "Epoch: [17]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 39.8048 (40.3852)  loss_vfl: 0.6800 (0.7950)  loss_bbox: 0.6645 (0.7754)  loss_giou: 1.7296 (1.8301)  loss_vfl_aux_0: 0.5252 (0.6669)  loss_bbox_aux_0: 0.8976 (0.9340)  loss_giou_aux_0: 1.9315 (1.9871)  loss_vfl_aux_1: 0.5882 (0.7451)  loss_bbox_aux_1: 0.8915 (0.9233)  loss_giou_aux_1: 1.9321 (1.9857)  loss_vfl_aux_2: 0.6432 (0.7769)  loss_bbox_aux_2: 0.8870 (0.9193)  loss_giou_aux_2: 1.9144 (1.9503)  loss_vfl_aux_3: 0.5473 (0.6458)  loss_bbox_aux_3: 0.6918 (0.7789)  loss_giou_aux_3: 1.7810 (1.8709)  loss_vfl_aux_4: 0.7506 (0.8614)  loss_bbox_aux_4: 0.6841 (0.7763)  loss_giou_aux_4: 1.7418 (1.8314)  loss_vfl_dn_0: 0.9587 (0.9660)  loss_bbox_dn_0: 0.3299 (0.3845)  loss_giou_dn_0: 1.1694 (1.1633)  loss_vfl_dn_1: 1.1511 (1.1474)  loss_bbox_dn_1: 0.3241 (0.3821)  loss_giou_dn_1: 1.1250 (1.1250)  loss_vfl_dn_2: 1.1364 (1.1539)  loss_bbox_dn_2: 0.3358 (0.3915)  loss_giou_dn_2: 1.1058 (1.1039)  loss_vfl_dn_3: 0.9569 (0.9576)  loss_bbox_dn_3: 0.3387 (0.4037)  loss_giou_dn_3: 1.1130 (1.1244)  loss_vfl_dn_4: 1.2004 (1.2214)  loss_bbox_dn_4: 0.3474 (0.4106)  loss_giou_dn_4: 1.1234 (1.1307)  loss_vfl_dn_5: 1.0937 (1.1159)  loss_bbox_dn_5: 0.3472 (0.4105)  loss_giou_dn_5: 1.1211 (1.1291)  loss_vfl_enc_0: 0.5509 (0.6502)  loss_bbox_enc_0: 0.8745 (0.9285)  loss_giou_enc_0: 1.9732 (2.0310)  time: 0.9964  data: 0.4422  max mem: 16799\n",
            "Epoch: [17] Total time: 0:00:08 (1.0025 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 39.8048 (40.3852)  loss_vfl: 0.6800 (0.7950)  loss_bbox: 0.6645 (0.7754)  loss_giou: 1.7296 (1.8301)  loss_vfl_aux_0: 0.5252 (0.6669)  loss_bbox_aux_0: 0.8976 (0.9340)  loss_giou_aux_0: 1.9315 (1.9871)  loss_vfl_aux_1: 0.5882 (0.7451)  loss_bbox_aux_1: 0.8915 (0.9233)  loss_giou_aux_1: 1.9321 (1.9857)  loss_vfl_aux_2: 0.6432 (0.7769)  loss_bbox_aux_2: 0.8870 (0.9193)  loss_giou_aux_2: 1.9144 (1.9503)  loss_vfl_aux_3: 0.5473 (0.6458)  loss_bbox_aux_3: 0.6918 (0.7789)  loss_giou_aux_3: 1.7810 (1.8709)  loss_vfl_aux_4: 0.7506 (0.8614)  loss_bbox_aux_4: 0.6841 (0.7763)  loss_giou_aux_4: 1.7418 (1.8314)  loss_vfl_dn_0: 0.9587 (0.9660)  loss_bbox_dn_0: 0.3299 (0.3845)  loss_giou_dn_0: 1.1694 (1.1633)  loss_vfl_dn_1: 1.1511 (1.1474)  loss_bbox_dn_1: 0.3241 (0.3821)  loss_giou_dn_1: 1.1250 (1.1250)  loss_vfl_dn_2: 1.1364 (1.1539)  loss_bbox_dn_2: 0.3358 (0.3915)  loss_giou_dn_2: 1.1058 (1.1039)  loss_vfl_dn_3: 0.9569 (0.9576)  loss_bbox_dn_3: 0.3387 (0.4037)  loss_giou_dn_3: 1.1130 (1.1244)  loss_vfl_dn_4: 1.2004 (1.2214)  loss_bbox_dn_4: 0.3474 (0.4106)  loss_giou_dn_4: 1.1234 (1.1307)  loss_vfl_dn_5: 1.0937 (1.1159)  loss_bbox_dn_5: 0.3472 (0.4105)  loss_giou_dn_5: 1.1211 (1.1291)  loss_vfl_enc_0: 0.5509 (0.6502)  loss_bbox_enc_0: 0.8745 (0.9285)  loss_giou_enc_0: 1.9732 (2.0310)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5662  data: 4.4090  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0302  data: 2.2207  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0576 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
            "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.004486955129078847}\n",
            "Epoch: [18]  [0/8]  eta: 0:00:27  lr: 0.000001  loss: 37.8678 (37.8678)  loss_vfl: 1.1482 (1.1482)  loss_bbox: 0.5392 (0.5392)  loss_giou: 1.4033 (1.4033)  loss_vfl_aux_0: 0.9600 (0.9600)  loss_bbox_aux_0: 0.6195 (0.6195)  loss_giou_aux_0: 1.4891 (1.4891)  loss_vfl_aux_1: 1.0647 (1.0647)  loss_bbox_aux_1: 0.5999 (0.5999)  loss_giou_aux_1: 1.4806 (1.4806)  loss_vfl_aux_2: 1.1370 (1.1370)  loss_bbox_aux_2: 0.5724 (0.5724)  loss_giou_aux_2: 1.4483 (1.4483)  loss_vfl_aux_3: 0.9328 (0.9328)  loss_bbox_aux_3: 0.5366 (0.5366)  loss_giou_aux_3: 1.4314 (1.4314)  loss_vfl_aux_4: 1.2411 (1.2411)  loss_bbox_aux_4: 0.5395 (0.5395)  loss_giou_aux_4: 1.4067 (1.4067)  loss_vfl_dn_0: 0.9741 (0.9741)  loss_bbox_dn_0: 0.4770 (0.4770)  loss_giou_dn_0: 1.1570 (1.1570)  loss_vfl_dn_1: 1.1198 (1.1198)  loss_bbox_dn_1: 0.4821 (0.4821)  loss_giou_dn_1: 1.1316 (1.1316)  loss_vfl_dn_2: 1.1333 (1.1333)  loss_bbox_dn_2: 0.4922 (0.4922)  loss_giou_dn_2: 1.1066 (1.1066)  loss_vfl_dn_3: 0.8968 (0.8968)  loss_bbox_dn_3: 0.5223 (0.5223)  loss_giou_dn_3: 1.1473 (1.1473)  loss_vfl_dn_4: 1.1616 (1.1616)  loss_bbox_dn_4: 0.5295 (0.5295)  loss_giou_dn_4: 1.1509 (1.1509)  loss_vfl_dn_5: 1.0503 (1.0503)  loss_bbox_dn_5: 0.5294 (0.5294)  loss_giou_dn_5: 1.1498 (1.1498)  loss_vfl_enc_0: 0.8979 (0.8979)  loss_bbox_enc_0: 0.6435 (0.6435)  loss_giou_enc_0: 1.5646 (1.5646)  time: 3.3946  data: 2.8390  max mem: 16799\n",
            "Epoch: [18]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 39.8970 (40.2670)  loss_vfl: 0.6865 (0.7468)  loss_bbox: 0.8622 (0.7933)  loss_giou: 1.9706 (1.8579)  loss_vfl_aux_0: 0.6301 (0.6535)  loss_bbox_aux_0: 0.8564 (0.9605)  loss_giou_aux_0: 2.0565 (2.0423)  loss_vfl_aux_1: 0.6886 (0.7264)  loss_bbox_aux_1: 0.8484 (0.9402)  loss_giou_aux_1: 2.0583 (2.0481)  loss_vfl_aux_2: 0.6848 (0.7453)  loss_bbox_aux_2: 0.8574 (0.9436)  loss_giou_aux_2: 2.0321 (2.0132)  loss_vfl_aux_3: 0.5580 (0.6165)  loss_bbox_aux_3: 0.8389 (0.7744)  loss_giou_aux_3: 1.9969 (1.9122)  loss_vfl_aux_4: 0.7401 (0.8113)  loss_bbox_aux_4: 0.8586 (0.7941)  loss_giou_aux_4: 1.9733 (1.8599)  loss_vfl_dn_0: 0.9741 (0.9750)  loss_bbox_dn_0: 0.3190 (0.3444)  loss_giou_dn_0: 1.1528 (1.1578)  loss_vfl_dn_1: 1.1612 (1.1547)  loss_bbox_dn_1: 0.3085 (0.3395)  loss_giou_dn_1: 1.1132 (1.1182)  loss_vfl_dn_2: 1.1309 (1.1354)  loss_bbox_dn_2: 0.3147 (0.3477)  loss_giou_dn_2: 1.0930 (1.1024)  loss_vfl_dn_3: 0.9346 (0.9460)  loss_bbox_dn_3: 0.3162 (0.3590)  loss_giou_dn_3: 1.1097 (1.1190)  loss_vfl_dn_4: 1.1616 (1.1985)  loss_bbox_dn_4: 0.3201 (0.3644)  loss_giou_dn_4: 1.1242 (1.1218)  loss_vfl_dn_5: 1.0503 (1.0878)  loss_bbox_dn_5: 0.3200 (0.3643)  loss_giou_dn_5: 1.1221 (1.1201)  loss_vfl_enc_0: 0.6228 (0.6239)  loss_bbox_enc_0: 0.8786 (0.9614)  loss_giou_enc_0: 2.0737 (2.0859)  time: 0.9691  data: 0.3805  max mem: 16799\n",
            "Epoch: [18] Total time: 0:00:07 (0.9759 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 39.8970 (40.2670)  loss_vfl: 0.6865 (0.7468)  loss_bbox: 0.8622 (0.7933)  loss_giou: 1.9706 (1.8579)  loss_vfl_aux_0: 0.6301 (0.6535)  loss_bbox_aux_0: 0.8564 (0.9605)  loss_giou_aux_0: 2.0565 (2.0423)  loss_vfl_aux_1: 0.6886 (0.7264)  loss_bbox_aux_1: 0.8484 (0.9402)  loss_giou_aux_1: 2.0583 (2.0481)  loss_vfl_aux_2: 0.6848 (0.7453)  loss_bbox_aux_2: 0.8574 (0.9436)  loss_giou_aux_2: 2.0321 (2.0132)  loss_vfl_aux_3: 0.5580 (0.6165)  loss_bbox_aux_3: 0.8389 (0.7744)  loss_giou_aux_3: 1.9969 (1.9122)  loss_vfl_aux_4: 0.7401 (0.8113)  loss_bbox_aux_4: 0.8586 (0.7941)  loss_giou_aux_4: 1.9733 (1.8599)  loss_vfl_dn_0: 0.9741 (0.9750)  loss_bbox_dn_0: 0.3190 (0.3444)  loss_giou_dn_0: 1.1528 (1.1578)  loss_vfl_dn_1: 1.1612 (1.1547)  loss_bbox_dn_1: 0.3085 (0.3395)  loss_giou_dn_1: 1.1132 (1.1182)  loss_vfl_dn_2: 1.1309 (1.1354)  loss_bbox_dn_2: 0.3147 (0.3477)  loss_giou_dn_2: 1.0930 (1.1024)  loss_vfl_dn_3: 0.9346 (0.9460)  loss_bbox_dn_3: 0.3162 (0.3590)  loss_giou_dn_3: 1.1097 (1.1190)  loss_vfl_dn_4: 1.1616 (1.1985)  loss_bbox_dn_4: 0.3201 (0.3644)  loss_giou_dn_4: 1.1242 (1.1218)  loss_vfl_dn_5: 1.0503 (1.0878)  loss_bbox_dn_5: 0.3200 (0.3643)  loss_giou_dn_5: 1.1221 (1.1201)  loss_vfl_enc_0: 0.6228 (0.6239)  loss_bbox_enc_0: 0.8786 (0.9614)  loss_giou_enc_0: 2.0737 (2.0859)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5374  data: 1.3622  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6836  data: 0.6971  max mem: 16799\n",
            "Test: Total time: 0:00:03 (1.7208 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
            "best_stat: {'epoch': 18, 'coco_eval_bbox': 0.005360849455305455}\n",
            "Epoch: [19]  [0/8]  eta: 0:00:29  lr: 0.000001  loss: 38.6637 (38.6637)  loss_vfl: 1.1459 (1.1459)  loss_bbox: 0.5279 (0.5279)  loss_giou: 1.4465 (1.4465)  loss_vfl_aux_0: 1.0366 (1.0366)  loss_bbox_aux_0: 0.6653 (0.6653)  loss_giou_aux_0: 1.5873 (1.5873)  loss_vfl_aux_1: 1.1340 (1.1340)  loss_bbox_aux_1: 0.6524 (0.6524)  loss_giou_aux_1: 1.5851 (1.5851)  loss_vfl_aux_2: 1.1687 (1.1687)  loss_bbox_aux_2: 0.6455 (0.6455)  loss_giou_aux_2: 1.5645 (1.5645)  loss_vfl_aux_3: 0.9558 (0.9558)  loss_bbox_aux_3: 0.5350 (0.5350)  loss_giou_aux_3: 1.4803 (1.4803)  loss_vfl_aux_4: 1.2522 (1.2522)  loss_bbox_aux_4: 0.5387 (0.5387)  loss_giou_aux_4: 1.4496 (1.4496)  loss_vfl_dn_0: 1.0272 (1.0272)  loss_bbox_dn_0: 0.4325 (0.4325)  loss_giou_dn_0: 1.1114 (1.1114)  loss_vfl_dn_1: 1.1837 (1.1837)  loss_bbox_dn_1: 0.4288 (0.4288)  loss_giou_dn_1: 1.0826 (1.0826)  loss_vfl_dn_2: 1.1742 (1.1742)  loss_bbox_dn_2: 0.4439 (0.4439)  loss_giou_dn_2: 1.0717 (1.0717)  loss_vfl_dn_3: 0.9666 (0.9666)  loss_bbox_dn_3: 0.4602 (0.4602)  loss_giou_dn_3: 1.1010 (1.1010)  loss_vfl_dn_4: 1.2403 (1.2403)  loss_bbox_dn_4: 0.4719 (0.4719)  loss_giou_dn_4: 1.1051 (1.1051)  loss_vfl_dn_5: 1.1242 (1.1242)  loss_bbox_dn_5: 0.4717 (0.4717)  loss_giou_dn_5: 1.1038 (1.1038)  loss_vfl_enc_0: 0.9519 (0.9519)  loss_bbox_enc_0: 0.6837 (0.6837)  loss_giou_enc_0: 1.6560 (1.6560)  time: 3.7461  data: 3.2324  max mem: 16799\n",
            "Epoch: [19]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 38.6637 (39.1334)  loss_vfl: 0.7830 (0.8840)  loss_bbox: 0.5872 (0.6495)  loss_giou: 1.5168 (1.6286)  loss_vfl_aux_0: 0.7268 (0.8107)  loss_bbox_aux_0: 0.7291 (0.8445)  loss_giou_aux_0: 1.6928 (1.8287)  loss_vfl_aux_1: 0.8256 (0.8955)  loss_bbox_aux_1: 0.7272 (0.8276)  loss_giou_aux_1: 1.6859 (1.8341)  loss_vfl_aux_2: 0.7995 (0.9026)  loss_bbox_aux_2: 0.7199 (0.8357)  loss_giou_aux_2: 1.6593 (1.8028)  loss_vfl_aux_3: 0.6455 (0.7392)  loss_bbox_aux_3: 0.5967 (0.6515)  loss_giou_aux_3: 1.5450 (1.6755)  loss_vfl_aux_4: 0.8601 (0.9700)  loss_bbox_aux_4: 0.5888 (0.6511)  loss_giou_aux_4: 1.5149 (1.6293)  loss_vfl_dn_0: 0.9853 (1.0034)  loss_bbox_dn_0: 0.3852 (0.3795)  loss_giou_dn_0: 1.1289 (1.1293)  loss_vfl_dn_1: 1.1435 (1.1656)  loss_bbox_dn_1: 0.3909 (0.3755)  loss_giou_dn_1: 1.1048 (1.0994)  loss_vfl_dn_2: 1.1363 (1.1538)  loss_bbox_dn_2: 0.4013 (0.3931)  loss_giou_dn_2: 1.0791 (1.0843)  loss_vfl_dn_3: 0.9488 (0.9497)  loss_bbox_dn_3: 0.4118 (0.4033)  loss_giou_dn_3: 1.1071 (1.1054)  loss_vfl_dn_4: 1.2130 (1.2045)  loss_bbox_dn_4: 0.4220 (0.4122)  loss_giou_dn_4: 1.1084 (1.1082)  loss_vfl_dn_5: 1.0948 (1.0787)  loss_bbox_dn_5: 0.4219 (0.4121)  loss_giou_dn_5: 1.1051 (1.1065)  loss_vfl_enc_0: 0.7056 (0.7839)  loss_bbox_enc_0: 0.7557 (0.8487)  loss_giou_enc_0: 1.7378 (1.8754)  time: 0.9589  data: 0.4267  max mem: 16799\n",
            "Epoch: [19] Total time: 0:00:07 (0.9656 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 38.6637 (39.1334)  loss_vfl: 0.7830 (0.8840)  loss_bbox: 0.5872 (0.6495)  loss_giou: 1.5168 (1.6286)  loss_vfl_aux_0: 0.7268 (0.8107)  loss_bbox_aux_0: 0.7291 (0.8445)  loss_giou_aux_0: 1.6928 (1.8287)  loss_vfl_aux_1: 0.8256 (0.8955)  loss_bbox_aux_1: 0.7272 (0.8276)  loss_giou_aux_1: 1.6859 (1.8341)  loss_vfl_aux_2: 0.7995 (0.9026)  loss_bbox_aux_2: 0.7199 (0.8357)  loss_giou_aux_2: 1.6593 (1.8028)  loss_vfl_aux_3: 0.6455 (0.7392)  loss_bbox_aux_3: 0.5967 (0.6515)  loss_giou_aux_3: 1.5450 (1.6755)  loss_vfl_aux_4: 0.8601 (0.9700)  loss_bbox_aux_4: 0.5888 (0.6511)  loss_giou_aux_4: 1.5149 (1.6293)  loss_vfl_dn_0: 0.9853 (1.0034)  loss_bbox_dn_0: 0.3852 (0.3795)  loss_giou_dn_0: 1.1289 (1.1293)  loss_vfl_dn_1: 1.1435 (1.1656)  loss_bbox_dn_1: 0.3909 (0.3755)  loss_giou_dn_1: 1.1048 (1.0994)  loss_vfl_dn_2: 1.1363 (1.1538)  loss_bbox_dn_2: 0.4013 (0.3931)  loss_giou_dn_2: 1.0791 (1.0843)  loss_vfl_dn_3: 0.9488 (0.9497)  loss_bbox_dn_3: 0.4118 (0.4033)  loss_giou_dn_3: 1.1071 (1.1054)  loss_vfl_dn_4: 1.2130 (1.2045)  loss_bbox_dn_4: 0.4220 (0.4122)  loss_giou_dn_4: 1.1084 (1.1082)  loss_vfl_dn_5: 1.0948 (1.0787)  loss_bbox_dn_5: 0.4219 (0.4121)  loss_giou_dn_5: 1.1051 (1.1065)  loss_vfl_enc_0: 0.7056 (0.7839)  loss_bbox_enc_0: 0.7557 (0.8487)  loss_giou_enc_0: 1.7378 (1.8754)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5823  data: 4.4128  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0386  data: 2.2224  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.0652 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "best_stat: {'epoch': 19, 'coco_eval_bbox': 0.005531501358333408}\n",
            "Epoch: [20]  [0/8]  eta: 0:00:30  lr: 0.000001  loss: 41.5534 (41.5534)  loss_vfl: 0.5940 (0.5940)  loss_bbox: 0.9440 (0.9440)  loss_giou: 2.1034 (2.1034)  loss_vfl_aux_0: 0.5495 (0.5495)  loss_bbox_aux_0: 1.0914 (1.0914)  loss_giou_aux_0: 2.2562 (2.2562)  loss_vfl_aux_1: 0.6049 (0.6049)  loss_bbox_aux_1: 1.0699 (1.0699)  loss_giou_aux_1: 2.2606 (2.2606)  loss_vfl_aux_2: 0.6169 (0.6169)  loss_bbox_aux_2: 1.0669 (1.0669)  loss_giou_aux_2: 2.2381 (2.2381)  loss_vfl_aux_3: 0.5005 (0.5005)  loss_bbox_aux_3: 0.8923 (0.8923)  loss_giou_aux_3: 2.1667 (2.1667)  loss_vfl_aux_4: 0.6561 (0.6561)  loss_bbox_aux_4: 0.9454 (0.9454)  loss_giou_aux_4: 2.1016 (2.1016)  loss_vfl_dn_0: 0.9587 (0.9587)  loss_bbox_dn_0: 0.3134 (0.3134)  loss_giou_dn_0: 1.1592 (1.1592)  loss_vfl_dn_1: 1.1169 (1.1169)  loss_bbox_dn_1: 0.3113 (0.3113)  loss_giou_dn_1: 1.1172 (1.1172)  loss_vfl_dn_2: 1.0763 (1.0763)  loss_bbox_dn_2: 0.3374 (0.3374)  loss_giou_dn_2: 1.1129 (1.1129)  loss_vfl_dn_3: 0.9012 (0.9012)  loss_bbox_dn_3: 0.3371 (0.3371)  loss_giou_dn_3: 1.1335 (1.1335)  loss_vfl_dn_4: 1.1500 (1.1500)  loss_bbox_dn_4: 0.3464 (0.3464)  loss_giou_dn_4: 1.1386 (1.1386)  loss_vfl_dn_5: 1.0203 (1.0203)  loss_bbox_dn_5: 0.3463 (0.3463)  loss_giou_dn_5: 1.1367 (1.1367)  loss_vfl_enc_0: 0.5207 (0.5207)  loss_bbox_enc_0: 1.0664 (1.0664)  loss_giou_enc_0: 2.2947 (2.2947)  time: 3.8462  data: 3.2068  max mem: 16799\n",
            "Epoch: [20]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 41.0108 (40.9344)  loss_vfl: 0.7517 (0.7709)  loss_bbox: 0.8087 (0.8313)  loss_giou: 1.8060 (1.8795)  loss_vfl_aux_0: 0.7448 (0.7202)  loss_bbox_aux_0: 1.0914 (1.0355)  loss_giou_aux_0: 2.0810 (2.0559)  loss_vfl_aux_1: 0.8211 (0.7958)  loss_bbox_aux_1: 1.0641 (1.0125)  loss_giou_aux_1: 2.0822 (2.0569)  loss_vfl_aux_2: 0.8463 (0.8064)  loss_bbox_aux_2: 1.0669 (1.0248)  loss_giou_aux_2: 2.0457 (2.0280)  loss_vfl_aux_3: 0.6629 (0.6512)  loss_bbox_aux_3: 0.8049 (0.8126)  loss_giou_aux_3: 1.8722 (1.9443)  loss_vfl_aux_4: 0.8365 (0.8495)  loss_bbox_aux_4: 0.8031 (0.8340)  loss_giou_aux_4: 1.8139 (1.8794)  loss_vfl_dn_0: 0.9879 (0.9800)  loss_bbox_dn_0: 0.3287 (0.3380)  loss_giou_dn_0: 1.1379 (1.1438)  loss_vfl_dn_1: 1.1590 (1.1354)  loss_bbox_dn_1: 0.3238 (0.3345)  loss_giou_dn_1: 1.0982 (1.1111)  loss_vfl_dn_2: 1.1422 (1.1048)  loss_bbox_dn_2: 0.3374 (0.3512)  loss_giou_dn_2: 1.0797 (1.1024)  loss_vfl_dn_3: 0.9384 (0.9106)  loss_bbox_dn_3: 0.3533 (0.3626)  loss_giou_dn_3: 1.1084 (1.1252)  loss_vfl_dn_4: 1.1530 (1.1326)  loss_bbox_dn_4: 0.3581 (0.3692)  loss_giou_dn_4: 1.1095 (1.1289)  loss_vfl_dn_5: 1.0304 (0.9987)  loss_bbox_dn_5: 0.3579 (0.3691)  loss_giou_dn_5: 1.1087 (1.1272)  loss_vfl_enc_0: 0.7029 (0.6884)  loss_bbox_enc_0: 1.0664 (1.0244)  loss_giou_enc_0: 2.1322 (2.1076)  time: 0.9699  data: 0.4353  max mem: 16799\n",
            "Epoch: [20] Total time: 0:00:07 (0.9797 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 41.0108 (40.9344)  loss_vfl: 0.7517 (0.7709)  loss_bbox: 0.8087 (0.8313)  loss_giou: 1.8060 (1.8795)  loss_vfl_aux_0: 0.7448 (0.7202)  loss_bbox_aux_0: 1.0914 (1.0355)  loss_giou_aux_0: 2.0810 (2.0559)  loss_vfl_aux_1: 0.8211 (0.7958)  loss_bbox_aux_1: 1.0641 (1.0125)  loss_giou_aux_1: 2.0822 (2.0569)  loss_vfl_aux_2: 0.8463 (0.8064)  loss_bbox_aux_2: 1.0669 (1.0248)  loss_giou_aux_2: 2.0457 (2.0280)  loss_vfl_aux_3: 0.6629 (0.6512)  loss_bbox_aux_3: 0.8049 (0.8126)  loss_giou_aux_3: 1.8722 (1.9443)  loss_vfl_aux_4: 0.8365 (0.8495)  loss_bbox_aux_4: 0.8031 (0.8340)  loss_giou_aux_4: 1.8139 (1.8794)  loss_vfl_dn_0: 0.9879 (0.9800)  loss_bbox_dn_0: 0.3287 (0.3380)  loss_giou_dn_0: 1.1379 (1.1438)  loss_vfl_dn_1: 1.1590 (1.1354)  loss_bbox_dn_1: 0.3238 (0.3345)  loss_giou_dn_1: 1.0982 (1.1111)  loss_vfl_dn_2: 1.1422 (1.1048)  loss_bbox_dn_2: 0.3374 (0.3512)  loss_giou_dn_2: 1.0797 (1.1024)  loss_vfl_dn_3: 0.9384 (0.9106)  loss_bbox_dn_3: 0.3533 (0.3626)  loss_giou_dn_3: 1.1084 (1.1252)  loss_vfl_dn_4: 1.1530 (1.1326)  loss_bbox_dn_4: 0.3581 (0.3692)  loss_giou_dn_4: 1.1095 (1.1289)  loss_vfl_dn_5: 1.0304 (0.9987)  loss_bbox_dn_5: 0.3579 (0.3691)  loss_giou_dn_5: 1.1087 (1.1272)  loss_vfl_enc_0: 0.7029 (0.6884)  loss_bbox_enc_0: 1.0664 (1.0244)  loss_giou_enc_0: 2.1322 (2.1076)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8857  data: 4.3918  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1924  data: 2.2122  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.2255 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.021\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
            "best_stat: {'epoch': 20, 'coco_eval_bbox': 0.0063351446419907895}\n",
            "Epoch: [21]  [0/8]  eta: 0:00:26  lr: 0.000001  loss: 37.8703 (37.8703)  loss_vfl: 0.8792 (0.8792)  loss_bbox: 0.5710 (0.5710)  loss_giou: 1.5144 (1.5144)  loss_vfl_aux_0: 0.7978 (0.7978)  loss_bbox_aux_0: 0.8487 (0.8487)  loss_giou_aux_0: 1.8273 (1.8273)  loss_vfl_aux_1: 0.8641 (0.8641)  loss_bbox_aux_1: 0.8306 (0.8306)  loss_giou_aux_1: 1.8298 (1.8298)  loss_vfl_aux_2: 0.8817 (0.8817)  loss_bbox_aux_2: 0.8580 (0.8580)  loss_giou_aux_2: 1.7961 (1.7961)  loss_vfl_aux_3: 0.7367 (0.7367)  loss_bbox_aux_3: 0.5295 (0.5295)  loss_giou_aux_3: 1.5942 (1.5942)  loss_vfl_aux_4: 0.9845 (0.9845)  loss_bbox_aux_4: 0.5649 (0.5649)  loss_giou_aux_4: 1.5196 (1.5196)  loss_vfl_dn_0: 0.9340 (0.9340)  loss_bbox_dn_0: 0.3439 (0.3439)  loss_giou_dn_0: 1.1542 (1.1542)  loss_vfl_dn_1: 1.0678 (1.0678)  loss_bbox_dn_1: 0.3416 (0.3416)  loss_giou_dn_1: 1.1197 (1.1197)  loss_vfl_dn_2: 1.0458 (1.0458)  loss_bbox_dn_2: 0.3817 (0.3817)  loss_giou_dn_2: 1.1152 (1.1152)  loss_vfl_dn_3: 0.8713 (0.8713)  loss_bbox_dn_3: 0.3718 (0.3718)  loss_giou_dn_3: 1.1259 (1.1259)  loss_vfl_dn_4: 1.0978 (1.0978)  loss_bbox_dn_4: 0.3813 (0.3813)  loss_giou_dn_4: 1.1292 (1.1292)  loss_vfl_dn_5: 0.9649 (0.9649)  loss_bbox_dn_5: 0.3811 (0.3811)  loss_giou_dn_5: 1.1276 (1.1276)  loss_vfl_enc_0: 0.7837 (0.7837)  loss_bbox_enc_0: 0.8313 (0.8313)  loss_giou_enc_0: 1.8721 (1.8721)  time: 3.2717  data: 2.7629  max mem: 16799\n",
            "Epoch: [21]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 38.2430 (39.0713)  loss_vfl: 0.8792 (0.8437)  loss_bbox: 0.6172 (0.6560)  loss_giou: 1.5928 (1.6622)  loss_vfl_aux_0: 0.7978 (0.8109)  loss_bbox_aux_0: 0.8487 (0.9047)  loss_giou_aux_0: 1.8227 (1.8662)  loss_vfl_aux_1: 0.8641 (0.8881)  loss_bbox_aux_1: 0.8306 (0.8821)  loss_giou_aux_1: 1.8298 (1.8697)  loss_vfl_aux_2: 0.8817 (0.9015)  loss_bbox_aux_2: 0.8579 (0.8944)  loss_giou_aux_2: 1.7961 (1.8420)  loss_vfl_aux_3: 0.7367 (0.7186)  loss_bbox_aux_3: 0.6109 (0.6455)  loss_giou_aux_3: 1.6370 (1.7334)  loss_vfl_aux_4: 0.9845 (0.9439)  loss_bbox_aux_4: 0.6120 (0.6552)  loss_giou_aux_4: 1.6014 (1.6666)  loss_vfl_dn_0: 0.9898 (0.9953)  loss_bbox_dn_0: 0.3439 (0.3513)  loss_giou_dn_0: 1.1154 (1.1226)  loss_vfl_dn_1: 1.1569 (1.1433)  loss_bbox_dn_1: 0.3416 (0.3448)  loss_giou_dn_1: 1.0836 (1.0881)  loss_vfl_dn_2: 1.1468 (1.1318)  loss_bbox_dn_2: 0.3707 (0.3599)  loss_giou_dn_2: 1.0592 (1.0736)  loss_vfl_dn_3: 0.9255 (0.9179)  loss_bbox_dn_3: 0.3718 (0.3666)  loss_giou_dn_3: 1.0915 (1.0971)  loss_vfl_dn_4: 1.1569 (1.1510)  loss_bbox_dn_4: 0.3812 (0.3734)  loss_giou_dn_4: 1.0899 (1.0986)  loss_vfl_dn_5: 1.0010 (0.9974)  loss_bbox_dn_5: 0.3811 (0.3733)  loss_giou_dn_5: 1.0883 (1.0972)  loss_vfl_enc_0: 0.7837 (0.7901)  loss_bbox_enc_0: 0.8228 (0.8989)  loss_giou_enc_0: 1.8721 (1.9141)  time: 0.8938  data: 0.3614  max mem: 16799\n",
            "Epoch: [21] Total time: 0:00:07 (0.9007 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 38.2430 (39.0713)  loss_vfl: 0.8792 (0.8437)  loss_bbox: 0.6172 (0.6560)  loss_giou: 1.5928 (1.6622)  loss_vfl_aux_0: 0.7978 (0.8109)  loss_bbox_aux_0: 0.8487 (0.9047)  loss_giou_aux_0: 1.8227 (1.8662)  loss_vfl_aux_1: 0.8641 (0.8881)  loss_bbox_aux_1: 0.8306 (0.8821)  loss_giou_aux_1: 1.8298 (1.8697)  loss_vfl_aux_2: 0.8817 (0.9015)  loss_bbox_aux_2: 0.8579 (0.8944)  loss_giou_aux_2: 1.7961 (1.8420)  loss_vfl_aux_3: 0.7367 (0.7186)  loss_bbox_aux_3: 0.6109 (0.6455)  loss_giou_aux_3: 1.6370 (1.7334)  loss_vfl_aux_4: 0.9845 (0.9439)  loss_bbox_aux_4: 0.6120 (0.6552)  loss_giou_aux_4: 1.6014 (1.6666)  loss_vfl_dn_0: 0.9898 (0.9953)  loss_bbox_dn_0: 0.3439 (0.3513)  loss_giou_dn_0: 1.1154 (1.1226)  loss_vfl_dn_1: 1.1569 (1.1433)  loss_bbox_dn_1: 0.3416 (0.3448)  loss_giou_dn_1: 1.0836 (1.0881)  loss_vfl_dn_2: 1.1468 (1.1318)  loss_bbox_dn_2: 0.3707 (0.3599)  loss_giou_dn_2: 1.0592 (1.0736)  loss_vfl_dn_3: 0.9255 (0.9179)  loss_bbox_dn_3: 0.3718 (0.3666)  loss_giou_dn_3: 1.0915 (1.0971)  loss_vfl_dn_4: 1.1569 (1.1510)  loss_bbox_dn_4: 0.3812 (0.3734)  loss_giou_dn_4: 1.0899 (1.0986)  loss_vfl_dn_5: 1.0010 (0.9974)  loss_bbox_dn_5: 0.3811 (0.3733)  loss_giou_dn_5: 1.0883 (1.0972)  loss_vfl_enc_0: 0.7837 (0.7901)  loss_bbox_enc_0: 0.8228 (0.8989)  loss_giou_enc_0: 1.8721 (1.9141)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.1258  data: 2.9629  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3092  data: 1.4977  max mem: 16799\n",
            "Test: Total time: 0:00:04 (2.3316 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
            "best_stat: {'epoch': 21, 'coco_eval_bbox': 0.0069904492373647166}\n",
            "Epoch: [22]  [0/8]  eta: 0:00:25  lr: 0.000001  loss: 37.3754 (37.3754)  loss_vfl: 0.9276 (0.9276)  loss_bbox: 0.5345 (0.5345)  loss_giou: 1.3960 (1.3960)  loss_vfl_aux_0: 0.9437 (0.9437)  loss_bbox_aux_0: 0.7612 (0.7612)  loss_giou_aux_0: 1.6794 (1.6794)  loss_vfl_aux_1: 1.0023 (1.0023)  loss_bbox_aux_1: 0.7599 (0.7599)  loss_giou_aux_1: 1.6663 (1.6663)  loss_vfl_aux_2: 0.9981 (0.9981)  loss_bbox_aux_2: 0.7753 (0.7753)  loss_giou_aux_2: 1.6311 (1.6311)  loss_vfl_aux_3: 0.8248 (0.8248)  loss_bbox_aux_3: 0.5202 (0.5202)  loss_giou_aux_3: 1.4833 (1.4833)  loss_vfl_aux_4: 1.0415 (1.0415)  loss_bbox_aux_4: 0.5334 (0.5334)  loss_giou_aux_4: 1.4037 (1.4037)  loss_vfl_dn_0: 0.9996 (0.9996)  loss_bbox_dn_0: 0.3866 (0.3866)  loss_giou_dn_0: 1.1197 (1.1197)  loss_vfl_dn_1: 1.0957 (1.0957)  loss_bbox_dn_1: 0.3820 (0.3820)  loss_giou_dn_1: 1.0904 (1.0904)  loss_vfl_dn_2: 1.0601 (1.0601)  loss_bbox_dn_2: 0.4025 (0.4025)  loss_giou_dn_2: 1.0888 (1.0888)  loss_vfl_dn_3: 0.8870 (0.8870)  loss_bbox_dn_3: 0.3996 (0.3996)  loss_giou_dn_3: 1.1062 (1.1062)  loss_vfl_dn_4: 1.0940 (1.0940)  loss_bbox_dn_4: 0.4111 (0.4111)  loss_giou_dn_4: 1.1091 (1.1091)  loss_vfl_dn_5: 0.9355 (0.9355)  loss_bbox_dn_5: 0.4108 (0.4108)  loss_giou_dn_5: 1.1071 (1.1071)  loss_vfl_enc_0: 0.9350 (0.9350)  loss_bbox_enc_0: 0.7757 (0.7757)  loss_giou_enc_0: 1.6966 (1.6966)  time: 3.1485  data: 2.6977  max mem: 16799\n",
            "Epoch: [22]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 38.2779 (40.1961)  loss_vfl: 0.7217 (0.7156)  loss_bbox: 0.6258 (0.8261)  loss_giou: 1.7380 (1.8129)  loss_vfl_aux_0: 0.7329 (0.7316)  loss_bbox_aux_0: 0.9446 (1.0517)  loss_giou_aux_0: 1.9968 (2.0338)  loss_vfl_aux_1: 0.8017 (0.7784)  loss_bbox_aux_1: 0.9108 (1.0160)  loss_giou_aux_1: 1.9805 (2.0452)  loss_vfl_aux_2: 0.8265 (0.7924)  loss_bbox_aux_2: 0.9418 (1.0343)  loss_giou_aux_2: 1.9282 (2.0107)  loss_vfl_aux_3: 0.6416 (0.6413)  loss_bbox_aux_3: 0.6102 (0.7987)  loss_giou_aux_3: 1.7930 (1.8857)  loss_vfl_aux_4: 0.8167 (0.8238)  loss_bbox_aux_4: 0.6268 (0.8288)  loss_giou_aux_4: 1.7366 (1.8118)  loss_vfl_dn_0: 0.9577 (0.9682)  loss_bbox_dn_0: 0.2921 (0.3348)  loss_giou_dn_0: 1.1280 (1.1376)  loss_vfl_dn_1: 1.0957 (1.0977)  loss_bbox_dn_1: 0.2904 (0.3268)  loss_giou_dn_1: 1.0904 (1.1038)  loss_vfl_dn_2: 1.0747 (1.0622)  loss_bbox_dn_2: 0.3048 (0.3411)  loss_giou_dn_2: 1.0879 (1.0997)  loss_vfl_dn_3: 0.8870 (0.8817)  loss_bbox_dn_3: 0.3100 (0.3479)  loss_giou_dn_3: 1.1101 (1.1169)  loss_vfl_dn_4: 1.0903 (1.0742)  loss_bbox_dn_4: 0.3127 (0.3530)  loss_giou_dn_4: 1.1067 (1.1180)  loss_vfl_dn_5: 0.9130 (0.8931)  loss_bbox_dn_5: 0.3125 (0.3528)  loss_giou_dn_5: 1.1047 (1.1156)  loss_vfl_enc_0: 0.6629 (0.7011)  loss_bbox_enc_0: 0.9096 (1.0520)  loss_giou_enc_0: 2.0622 (2.0789)  time: 0.9167  data: 0.3759  max mem: 16799\n",
            "Epoch: [22] Total time: 0:00:07 (0.9228 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 38.2779 (40.1961)  loss_vfl: 0.7217 (0.7156)  loss_bbox: 0.6258 (0.8261)  loss_giou: 1.7380 (1.8129)  loss_vfl_aux_0: 0.7329 (0.7316)  loss_bbox_aux_0: 0.9446 (1.0517)  loss_giou_aux_0: 1.9968 (2.0338)  loss_vfl_aux_1: 0.8017 (0.7784)  loss_bbox_aux_1: 0.9108 (1.0160)  loss_giou_aux_1: 1.9805 (2.0452)  loss_vfl_aux_2: 0.8265 (0.7924)  loss_bbox_aux_2: 0.9418 (1.0343)  loss_giou_aux_2: 1.9282 (2.0107)  loss_vfl_aux_3: 0.6416 (0.6413)  loss_bbox_aux_3: 0.6102 (0.7987)  loss_giou_aux_3: 1.7930 (1.8857)  loss_vfl_aux_4: 0.8167 (0.8238)  loss_bbox_aux_4: 0.6268 (0.8288)  loss_giou_aux_4: 1.7366 (1.8118)  loss_vfl_dn_0: 0.9577 (0.9682)  loss_bbox_dn_0: 0.2921 (0.3348)  loss_giou_dn_0: 1.1280 (1.1376)  loss_vfl_dn_1: 1.0957 (1.0977)  loss_bbox_dn_1: 0.2904 (0.3268)  loss_giou_dn_1: 1.0904 (1.1038)  loss_vfl_dn_2: 1.0747 (1.0622)  loss_bbox_dn_2: 0.3048 (0.3411)  loss_giou_dn_2: 1.0879 (1.0997)  loss_vfl_dn_3: 0.8870 (0.8817)  loss_bbox_dn_3: 0.3100 (0.3479)  loss_giou_dn_3: 1.1101 (1.1169)  loss_vfl_dn_4: 1.0903 (1.0742)  loss_bbox_dn_4: 0.3127 (0.3530)  loss_giou_dn_4: 1.1067 (1.1180)  loss_vfl_dn_5: 0.9130 (0.8931)  loss_bbox_dn_5: 0.3125 (0.3528)  loss_giou_dn_5: 1.1047 (1.1156)  loss_vfl_enc_0: 0.6629 (0.7011)  loss_bbox_enc_0: 0.9096 (1.0520)  loss_giou_enc_0: 2.0622 (2.0789)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4556  data: 1.2992  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4732  data: 0.6657  max mem: 16799\n",
            "Test: Total time: 0:00:04 (2.1642 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
            "best_stat: {'epoch': 22, 'coco_eval_bbox': 0.009150432717036007}\n",
            "Epoch: [23]  [0/8]  eta: 0:00:29  lr: 0.000001  loss: 37.3568 (37.3568)  loss_vfl: 1.0612 (1.0612)  loss_bbox: 0.4701 (0.4701)  loss_giou: 1.2236 (1.2236)  loss_vfl_aux_0: 1.1550 (1.1550)  loss_bbox_aux_0: 0.7422 (0.7422)  loss_giou_aux_0: 1.5061 (1.5061)  loss_vfl_aux_1: 1.2011 (1.2011)  loss_bbox_aux_1: 0.7283 (0.7283)  loss_giou_aux_1: 1.5306 (1.5306)  loss_vfl_aux_2: 1.1904 (1.1904)  loss_bbox_aux_2: 0.7358 (0.7358)  loss_giou_aux_2: 1.5155 (1.5155)  loss_vfl_aux_3: 0.9430 (0.9430)  loss_bbox_aux_3: 0.4542 (0.4542)  loss_giou_aux_3: 1.2701 (1.2701)  loss_vfl_aux_4: 1.2325 (1.2325)  loss_bbox_aux_4: 0.4706 (0.4706)  loss_giou_aux_4: 1.2284 (1.2284)  loss_vfl_dn_0: 1.0616 (1.0616)  loss_bbox_dn_0: 0.3871 (0.3871)  loss_giou_dn_0: 1.0639 (1.0639)  loss_vfl_dn_1: 1.2011 (1.2011)  loss_bbox_dn_1: 0.3817 (0.3817)  loss_giou_dn_1: 1.0264 (1.0264)  loss_vfl_dn_2: 1.1757 (1.1757)  loss_bbox_dn_2: 0.4074 (0.4074)  loss_giou_dn_2: 1.0219 (1.0219)  loss_vfl_dn_3: 0.9346 (0.9346)  loss_bbox_dn_3: 0.4318 (0.4318)  loss_giou_dn_3: 1.0598 (1.0598)  loss_vfl_dn_4: 1.1711 (1.1711)  loss_bbox_dn_4: 0.4333 (0.4333)  loss_giou_dn_4: 1.0519 (1.0519)  loss_vfl_dn_5: 0.9658 (0.9658)  loss_bbox_dn_5: 0.4331 (0.4331)  loss_giou_dn_5: 1.0492 (1.0492)  loss_vfl_enc_0: 1.1283 (1.1283)  loss_bbox_enc_0: 0.7347 (0.7347)  loss_giou_enc_0: 1.5778 (1.5778)  time: 3.6432  data: 3.0999  max mem: 16799\n",
            "Epoch: [23]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 37.4536 (37.8729)  loss_vfl: 0.7686 (0.7659)  loss_bbox: 0.6325 (0.6206)  loss_giou: 1.5444 (1.5834)  loss_vfl_aux_0: 0.8326 (0.8499)  loss_bbox_aux_0: 0.8041 (0.8740)  loss_giou_aux_0: 1.7956 (1.8010)  loss_vfl_aux_1: 0.8621 (0.8908)  loss_bbox_aux_1: 0.7903 (0.8467)  loss_giou_aux_1: 1.7903 (1.8141)  loss_vfl_aux_2: 0.8955 (0.9028)  loss_bbox_aux_2: 0.8084 (0.8616)  loss_giou_aux_2: 1.7580 (1.7851)  loss_vfl_aux_3: 0.7214 (0.7147)  loss_bbox_aux_3: 0.6291 (0.6130)  loss_giou_aux_3: 1.5944 (1.6419)  loss_vfl_aux_4: 0.8992 (0.9062)  loss_bbox_aux_4: 0.6365 (0.6218)  loss_giou_aux_4: 1.5474 (1.5871)  loss_vfl_dn_0: 0.9795 (0.9890)  loss_bbox_dn_0: 0.3244 (0.3379)  loss_giou_dn_0: 1.0985 (1.1187)  loss_vfl_dn_1: 1.0979 (1.1182)  loss_bbox_dn_1: 0.3173 (0.3305)  loss_giou_dn_1: 1.0501 (1.0826)  loss_vfl_dn_2: 1.1128 (1.0990)  loss_bbox_dn_2: 0.3350 (0.3435)  loss_giou_dn_2: 1.0219 (1.0682)  loss_vfl_dn_3: 0.9071 (0.8883)  loss_bbox_dn_3: 0.3351 (0.3527)  loss_giou_dn_3: 1.0598 (1.0899)  loss_vfl_dn_4: 1.1238 (1.0901)  loss_bbox_dn_4: 0.3409 (0.3539)  loss_giou_dn_4: 1.0519 (1.0856)  loss_vfl_dn_5: 0.8948 (0.8731)  loss_bbox_dn_5: 0.3407 (0.3538)  loss_giou_dn_5: 1.0492 (1.0843)  loss_vfl_enc_0: 0.8087 (0.8150)  loss_bbox_enc_0: 0.8087 (0.8730)  loss_giou_enc_0: 1.8336 (1.8450)  time: 0.9563  data: 0.4259  max mem: 16799\n",
            "Epoch: [23] Total time: 0:00:07 (0.9624 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 37.4536 (37.8729)  loss_vfl: 0.7686 (0.7659)  loss_bbox: 0.6325 (0.6206)  loss_giou: 1.5444 (1.5834)  loss_vfl_aux_0: 0.8326 (0.8499)  loss_bbox_aux_0: 0.8041 (0.8740)  loss_giou_aux_0: 1.7956 (1.8010)  loss_vfl_aux_1: 0.8621 (0.8908)  loss_bbox_aux_1: 0.7903 (0.8467)  loss_giou_aux_1: 1.7903 (1.8141)  loss_vfl_aux_2: 0.8955 (0.9028)  loss_bbox_aux_2: 0.8084 (0.8616)  loss_giou_aux_2: 1.7580 (1.7851)  loss_vfl_aux_3: 0.7214 (0.7147)  loss_bbox_aux_3: 0.6291 (0.6130)  loss_giou_aux_3: 1.5944 (1.6419)  loss_vfl_aux_4: 0.8992 (0.9062)  loss_bbox_aux_4: 0.6365 (0.6218)  loss_giou_aux_4: 1.5474 (1.5871)  loss_vfl_dn_0: 0.9795 (0.9890)  loss_bbox_dn_0: 0.3244 (0.3379)  loss_giou_dn_0: 1.0985 (1.1187)  loss_vfl_dn_1: 1.0979 (1.1182)  loss_bbox_dn_1: 0.3173 (0.3305)  loss_giou_dn_1: 1.0501 (1.0826)  loss_vfl_dn_2: 1.1128 (1.0990)  loss_bbox_dn_2: 0.3350 (0.3435)  loss_giou_dn_2: 1.0219 (1.0682)  loss_vfl_dn_3: 0.9071 (0.8883)  loss_bbox_dn_3: 0.3351 (0.3527)  loss_giou_dn_3: 1.0598 (1.0899)  loss_vfl_dn_4: 1.1238 (1.0901)  loss_bbox_dn_4: 0.3409 (0.3539)  loss_giou_dn_4: 1.0519 (1.0856)  loss_vfl_dn_5: 0.8948 (0.8731)  loss_bbox_dn_5: 0.3407 (0.3538)  loss_giou_dn_5: 1.0492 (1.0843)  loss_vfl_enc_0: 0.8087 (0.8150)  loss_bbox_enc_0: 0.8087 (0.8730)  loss_giou_enc_0: 1.8336 (1.8450)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.9064  data: 4.4178  max mem: 16799\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1982  data: 2.2248  max mem: 16799\n",
            "Test: Total time: 0:00:06 (3.2231 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
            "best_stat: {'epoch': 23, 'coco_eval_bbox': 0.010519433025680378}\n",
            "Epoch: [24]  [0/8]  eta: 0:00:29  lr: 0.000001  loss: 39.9521 (39.9521)  loss_vfl: 0.5658 (0.5658)  loss_bbox: 0.8541 (0.8541)  loss_giou: 1.9084 (1.9084)  loss_vfl_aux_0: 0.7062 (0.7062)  loss_bbox_aux_0: 1.0606 (1.0606)  loss_giou_aux_0: 2.1056 (2.1056)  loss_vfl_aux_1: 0.7579 (0.7579)  loss_bbox_aux_1: 1.0321 (1.0321)  loss_giou_aux_1: 2.0913 (2.0913)  loss_vfl_aux_2: 0.7287 (0.7287)  loss_bbox_aux_2: 1.0693 (1.0693)  loss_giou_aux_2: 2.0745 (2.0745)  loss_vfl_aux_3: 0.5903 (0.5903)  loss_bbox_aux_3: 0.8310 (0.8310)  loss_giou_aux_3: 1.9968 (1.9968)  loss_vfl_aux_4: 0.6961 (0.6961)  loss_bbox_aux_4: 0.8461 (0.8461)  loss_giou_aux_4: 1.9173 (1.9173)  loss_vfl_dn_0: 1.0649 (1.0649)  loss_bbox_dn_0: 0.2886 (0.2886)  loss_giou_dn_0: 1.0726 (1.0726)  loss_vfl_dn_1: 1.2078 (1.2078)  loss_bbox_dn_1: 0.2744 (0.2744)  loss_giou_dn_1: 1.0212 (1.0212)  loss_vfl_dn_2: 1.1750 (1.1750)  loss_bbox_dn_2: 0.2810 (0.2810)  loss_giou_dn_2: 1.0045 (1.0045)  loss_vfl_dn_3: 0.9658 (0.9658)  loss_bbox_dn_3: 0.2880 (0.2880)  loss_giou_dn_3: 1.0183 (1.0183)  loss_vfl_dn_4: 1.1317 (1.1317)  loss_bbox_dn_4: 0.2869 (0.2869)  loss_giou_dn_4: 1.0171 (1.0171)  loss_vfl_dn_5: 0.8589 (0.8589)  loss_bbox_dn_5: 0.2869 (0.2869)  loss_giou_dn_5: 1.0142 (1.0142)  loss_vfl_enc_0: 0.6369 (0.6369)  loss_bbox_enc_0: 1.0697 (1.0697)  loss_giou_enc_0: 2.1553 (2.1553)  time: 3.7429  data: 3.0940  max mem: 16811\n",
            "Epoch: [24]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 37.6196 (38.1520)  loss_vfl: 0.6617 (0.6999)  loss_bbox: 0.5937 (0.6812)  loss_giou: 1.6180 (1.6290)  loss_vfl_aux_0: 0.8576 (0.8610)  loss_bbox_aux_0: 0.8754 (0.9212)  loss_giou_aux_0: 1.8011 (1.8448)  loss_vfl_aux_1: 0.8843 (0.8997)  loss_bbox_aux_1: 0.8552 (0.8922)  loss_giou_aux_1: 1.8071 (1.8458)  loss_vfl_aux_2: 0.8425 (0.8969)  loss_bbox_aux_2: 0.8646 (0.9145)  loss_giou_aux_2: 1.7986 (1.8236)  loss_vfl_aux_3: 0.6869 (0.7048)  loss_bbox_aux_3: 0.5897 (0.6695)  loss_giou_aux_3: 1.6721 (1.6927)  loss_vfl_aux_4: 0.8437 (0.8674)  loss_bbox_aux_4: 0.5997 (0.6817)  loss_giou_aux_4: 1.6169 (1.6334)  loss_vfl_dn_0: 0.9859 (1.0103)  loss_bbox_dn_0: 0.3263 (0.3319)  loss_giou_dn_0: 1.0888 (1.0957)  loss_vfl_dn_1: 1.1076 (1.1301)  loss_bbox_dn_1: 0.3179 (0.3228)  loss_giou_dn_1: 1.0644 (1.0595)  loss_vfl_dn_2: 1.0557 (1.1052)  loss_bbox_dn_2: 0.3287 (0.3359)  loss_giou_dn_2: 1.0346 (1.0446)  loss_vfl_dn_3: 0.8659 (0.8902)  loss_bbox_dn_3: 0.3332 (0.3359)  loss_giou_dn_3: 1.0493 (1.0576)  loss_vfl_dn_4: 1.0344 (1.0599)  loss_bbox_dn_4: 0.3367 (0.3370)  loss_giou_dn_4: 1.0405 (1.0521)  loss_vfl_dn_5: 0.7628 (0.7996)  loss_bbox_dn_5: 0.3366 (0.3369)  loss_giou_dn_5: 1.0380 (1.0505)  loss_vfl_enc_0: 0.8508 (0.8181)  loss_bbox_enc_0: 0.8839 (0.9241)  loss_giou_enc_0: 1.8633 (1.8949)  time: 0.9761  data: 0.4072  max mem: 16811\n",
            "Epoch: [24] Total time: 0:00:07 (0.9826 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 37.6196 (38.1520)  loss_vfl: 0.6617 (0.6999)  loss_bbox: 0.5937 (0.6812)  loss_giou: 1.6180 (1.6290)  loss_vfl_aux_0: 0.8576 (0.8610)  loss_bbox_aux_0: 0.8754 (0.9212)  loss_giou_aux_0: 1.8011 (1.8448)  loss_vfl_aux_1: 0.8843 (0.8997)  loss_bbox_aux_1: 0.8552 (0.8922)  loss_giou_aux_1: 1.8071 (1.8458)  loss_vfl_aux_2: 0.8425 (0.8969)  loss_bbox_aux_2: 0.8646 (0.9145)  loss_giou_aux_2: 1.7986 (1.8236)  loss_vfl_aux_3: 0.6869 (0.7048)  loss_bbox_aux_3: 0.5897 (0.6695)  loss_giou_aux_3: 1.6721 (1.6927)  loss_vfl_aux_4: 0.8437 (0.8674)  loss_bbox_aux_4: 0.5997 (0.6817)  loss_giou_aux_4: 1.6169 (1.6334)  loss_vfl_dn_0: 0.9859 (1.0103)  loss_bbox_dn_0: 0.3263 (0.3319)  loss_giou_dn_0: 1.0888 (1.0957)  loss_vfl_dn_1: 1.1076 (1.1301)  loss_bbox_dn_1: 0.3179 (0.3228)  loss_giou_dn_1: 1.0644 (1.0595)  loss_vfl_dn_2: 1.0557 (1.1052)  loss_bbox_dn_2: 0.3287 (0.3359)  loss_giou_dn_2: 1.0346 (1.0446)  loss_vfl_dn_3: 0.8659 (0.8902)  loss_bbox_dn_3: 0.3332 (0.3359)  loss_giou_dn_3: 1.0493 (1.0576)  loss_vfl_dn_4: 1.0344 (1.0599)  loss_bbox_dn_4: 0.3367 (0.3370)  loss_giou_dn_4: 1.0405 (1.0521)  loss_vfl_dn_5: 0.7628 (0.7996)  loss_bbox_dn_5: 0.3366 (0.3369)  loss_giou_dn_5: 1.0380 (1.0505)  loss_vfl_enc_0: 0.8508 (0.8181)  loss_bbox_enc_0: 0.8839 (0.9241)  loss_giou_enc_0: 1.8633 (1.8949)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4760  data: 4.3199  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9813  data: 2.1760  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0022 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            "best_stat: {'epoch': 24, 'coco_eval_bbox': 0.011102939255274478}\n",
            "Epoch: [25]  [0/8]  eta: 0:00:24  lr: 0.000001  loss: 38.2208 (38.2208)  loss_vfl: 0.5680 (0.5680)  loss_bbox: 0.6351 (0.6351)  loss_giou: 1.7486 (1.7486)  loss_vfl_aux_0: 0.7652 (0.7652)  loss_bbox_aux_0: 0.9749 (0.9749)  loss_giou_aux_0: 1.9975 (1.9975)  loss_vfl_aux_1: 0.7853 (0.7853)  loss_bbox_aux_1: 0.9459 (0.9459)  loss_giou_aux_1: 2.0116 (2.0116)  loss_vfl_aux_2: 0.8171 (0.8171)  loss_bbox_aux_2: 0.9763 (0.9763)  loss_giou_aux_2: 1.9700 (1.9700)  loss_vfl_aux_3: 0.6135 (0.6135)  loss_bbox_aux_3: 0.6438 (0.6438)  loss_giou_aux_3: 1.7990 (1.7990)  loss_vfl_aux_4: 0.7573 (0.7573)  loss_bbox_aux_4: 0.6465 (0.6465)  loss_giou_aux_4: 1.7402 (1.7402)  loss_vfl_dn_0: 1.0082 (1.0082)  loss_bbox_dn_0: 0.3233 (0.3233)  loss_giou_dn_0: 1.0842 (1.0842)  loss_vfl_dn_1: 1.0832 (1.0832)  loss_bbox_dn_1: 0.3153 (0.3153)  loss_giou_dn_1: 1.0674 (1.0674)  loss_vfl_dn_2: 1.0553 (1.0553)  loss_bbox_dn_2: 0.3342 (0.3342)  loss_giou_dn_2: 1.0619 (1.0619)  loss_vfl_dn_3: 0.8411 (0.8411)  loss_bbox_dn_3: 0.3335 (0.3335)  loss_giou_dn_3: 1.0827 (1.0827)  loss_vfl_dn_4: 0.9872 (0.9872)  loss_bbox_dn_4: 0.3310 (0.3310)  loss_giou_dn_4: 1.0752 (1.0752)  loss_vfl_dn_5: 0.7076 (0.7076)  loss_bbox_dn_5: 0.3310 (0.3310)  loss_giou_dn_5: 1.0739 (1.0739)  loss_vfl_enc_0: 0.7065 (0.7065)  loss_bbox_enc_0: 0.9632 (0.9632)  loss_giou_enc_0: 2.0590 (2.0590)  time: 3.1118  data: 2.5541  max mem: 16811\n",
            "Epoch: [25]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 34.9686 (35.5607)  loss_vfl: 0.6212 (0.6629)  loss_bbox: 0.5687 (0.5320)  loss_giou: 1.4108 (1.4198)  loss_vfl_aux_0: 0.9600 (0.9821)  loss_bbox_aux_0: 0.6858 (0.7265)  loss_giou_aux_0: 1.5572 (1.6002)  loss_vfl_aux_1: 0.9647 (0.9932)  loss_bbox_aux_1: 0.6729 (0.7071)  loss_giou_aux_1: 1.5747 (1.6103)  loss_vfl_aux_2: 0.9434 (0.9901)  loss_bbox_aux_2: 0.6911 (0.7286)  loss_giou_aux_2: 1.5594 (1.5905)  loss_vfl_aux_3: 0.7323 (0.7557)  loss_bbox_aux_3: 0.5675 (0.5333)  loss_giou_aux_3: 1.4612 (1.4653)  loss_vfl_aux_4: 0.8717 (0.8981)  loss_bbox_aux_4: 0.5650 (0.5325)  loss_giou_aux_4: 1.4179 (1.4244)  loss_vfl_dn_0: 1.0303 (1.0318)  loss_bbox_dn_0: 0.3265 (0.3360)  loss_giou_dn_0: 1.0584 (1.0676)  loss_vfl_dn_1: 1.1241 (1.1228)  loss_bbox_dn_1: 0.3192 (0.3275)  loss_giou_dn_1: 1.0167 (1.0339)  loss_vfl_dn_2: 1.0786 (1.0877)  loss_bbox_dn_2: 0.3410 (0.3481)  loss_giou_dn_2: 1.0097 (1.0299)  loss_vfl_dn_3: 0.8752 (0.8654)  loss_bbox_dn_3: 0.3359 (0.3440)  loss_giou_dn_3: 1.0167 (1.0459)  loss_vfl_dn_4: 0.9913 (1.0006)  loss_bbox_dn_4: 0.3359 (0.3432)  loss_giou_dn_4: 1.0044 (1.0363)  loss_vfl_dn_5: 0.6955 (0.6984)  loss_bbox_dn_5: 0.3358 (0.3431)  loss_giou_dn_5: 1.0025 (1.0350)  loss_vfl_enc_0: 0.8782 (0.9321)  loss_bbox_enc_0: 0.6823 (0.7303)  loss_giou_enc_0: 1.6018 (1.6483)  time: 0.8766  data: 0.3351  max mem: 16811\n",
            "Epoch: [25] Total time: 0:00:07 (0.8838 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 34.9686 (35.5607)  loss_vfl: 0.6212 (0.6629)  loss_bbox: 0.5687 (0.5320)  loss_giou: 1.4108 (1.4198)  loss_vfl_aux_0: 0.9600 (0.9821)  loss_bbox_aux_0: 0.6858 (0.7265)  loss_giou_aux_0: 1.5572 (1.6002)  loss_vfl_aux_1: 0.9647 (0.9932)  loss_bbox_aux_1: 0.6729 (0.7071)  loss_giou_aux_1: 1.5747 (1.6103)  loss_vfl_aux_2: 0.9434 (0.9901)  loss_bbox_aux_2: 0.6911 (0.7286)  loss_giou_aux_2: 1.5594 (1.5905)  loss_vfl_aux_3: 0.7323 (0.7557)  loss_bbox_aux_3: 0.5675 (0.5333)  loss_giou_aux_3: 1.4612 (1.4653)  loss_vfl_aux_4: 0.8717 (0.8981)  loss_bbox_aux_4: 0.5650 (0.5325)  loss_giou_aux_4: 1.4179 (1.4244)  loss_vfl_dn_0: 1.0303 (1.0318)  loss_bbox_dn_0: 0.3265 (0.3360)  loss_giou_dn_0: 1.0584 (1.0676)  loss_vfl_dn_1: 1.1241 (1.1228)  loss_bbox_dn_1: 0.3192 (0.3275)  loss_giou_dn_1: 1.0167 (1.0339)  loss_vfl_dn_2: 1.0786 (1.0877)  loss_bbox_dn_2: 0.3410 (0.3481)  loss_giou_dn_2: 1.0097 (1.0299)  loss_vfl_dn_3: 0.8752 (0.8654)  loss_bbox_dn_3: 0.3359 (0.3440)  loss_giou_dn_3: 1.0167 (1.0459)  loss_vfl_dn_4: 0.9913 (1.0006)  loss_bbox_dn_4: 0.3359 (0.3432)  loss_giou_dn_4: 1.0044 (1.0363)  loss_vfl_dn_5: 0.6955 (0.6984)  loss_bbox_dn_5: 0.3358 (0.3431)  loss_giou_dn_5: 1.0025 (1.0350)  loss_vfl_enc_0: 0.8782 (0.9321)  loss_bbox_enc_0: 0.6823 (0.7303)  loss_giou_enc_0: 1.6018 (1.6483)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4304  data: 1.2778  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4591  data: 0.6550  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4841 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.056\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            "best_stat: {'epoch': 25, 'coco_eval_bbox': 0.013206893680786537}\n",
            "Epoch: [26]  [0/8]  eta: 0:00:42  lr: 0.000001  loss: 34.0333 (34.0333)  loss_vfl: 0.6969 (0.6969)  loss_bbox: 0.5280 (0.5280)  loss_giou: 1.2445 (1.2445)  loss_vfl_aux_0: 1.1344 (1.1344)  loss_bbox_aux_0: 0.5530 (0.5530)  loss_giou_aux_0: 1.2738 (1.2738)  loss_vfl_aux_1: 1.1242 (1.1242)  loss_bbox_aux_1: 0.5393 (0.5393)  loss_giou_aux_1: 1.2813 (1.2813)  loss_vfl_aux_2: 1.1153 (1.1153)  loss_bbox_aux_2: 0.5476 (0.5476)  loss_giou_aux_2: 1.2778 (1.2778)  loss_vfl_aux_3: 0.8493 (0.8493)  loss_bbox_aux_3: 0.5284 (0.5284)  loss_giou_aux_3: 1.2612 (1.2612)  loss_vfl_aux_4: 0.9643 (0.9643)  loss_bbox_aux_4: 0.5255 (0.5255)  loss_giou_aux_4: 1.2537 (1.2537)  loss_vfl_dn_0: 1.0606 (1.0606)  loss_bbox_dn_0: 0.4050 (0.4050)  loss_giou_dn_0: 1.0459 (1.0459)  loss_vfl_dn_1: 1.1662 (1.1662)  loss_bbox_dn_1: 0.3953 (0.3953)  loss_giou_dn_1: 0.9900 (0.9900)  loss_vfl_dn_2: 1.1622 (1.1622)  loss_bbox_dn_2: 0.4136 (0.4136)  loss_giou_dn_2: 0.9690 (0.9690)  loss_vfl_dn_3: 0.9400 (0.9400)  loss_bbox_dn_3: 0.3928 (0.3928)  loss_giou_dn_3: 0.9704 (0.9704)  loss_vfl_dn_4: 1.0391 (1.0391)  loss_bbox_dn_4: 0.3911 (0.3911)  loss_giou_dn_4: 0.9648 (0.9648)  loss_vfl_dn_5: 0.6849 (0.6849)  loss_bbox_dn_5: 0.3908 (0.3908)  loss_giou_dn_5: 0.9631 (0.9631)  loss_vfl_enc_0: 1.1156 (1.1156)  loss_bbox_enc_0: 0.5562 (0.5562)  loss_giou_enc_0: 1.3181 (1.3181)  time: 5.3009  data: 4.8101  max mem: 16811\n",
            "Epoch: [26]  [7/8]  eta: 0:00:01  lr: 0.000001  loss: 35.8026 (36.1968)  loss_vfl: 0.4889 (0.5362)  loss_bbox: 0.5568 (0.5982)  loss_giou: 1.4671 (1.5310)  loss_vfl_aux_0: 0.8222 (0.8963)  loss_bbox_aux_0: 0.7766 (0.8989)  loss_giou_aux_0: 1.6260 (1.7656)  loss_vfl_aux_1: 0.8078 (0.8931)  loss_bbox_aux_1: 0.7260 (0.8581)  loss_giou_aux_1: 1.6392 (1.7725)  loss_vfl_aux_2: 0.7908 (0.8710)  loss_bbox_aux_2: 0.7531 (0.8929)  loss_giou_aux_2: 1.6369 (1.7606)  loss_vfl_aux_3: 0.6075 (0.6631)  loss_bbox_aux_3: 0.5596 (0.5887)  loss_giou_aux_3: 1.5129 (1.5818)  loss_vfl_aux_4: 0.6833 (0.7445)  loss_bbox_aux_4: 0.5506 (0.5993)  loss_giou_aux_4: 1.4880 (1.5378)  loss_vfl_dn_0: 1.0160 (1.0086)  loss_bbox_dn_0: 0.3217 (0.3325)  loss_giou_dn_0: 1.0674 (1.0742)  loss_vfl_dn_1: 1.0773 (1.0761)  loss_bbox_dn_1: 0.3051 (0.3196)  loss_giou_dn_1: 1.0132 (1.0354)  loss_vfl_dn_2: 1.0388 (1.0430)  loss_bbox_dn_2: 0.3234 (0.3378)  loss_giou_dn_2: 1.0117 (1.0249)  loss_vfl_dn_3: 0.8347 (0.8478)  loss_bbox_dn_3: 0.3097 (0.3239)  loss_giou_dn_3: 1.0044 (1.0267)  loss_vfl_dn_4: 0.8856 (0.9165)  loss_bbox_dn_4: 0.3071 (0.3235)  loss_giou_dn_4: 0.9985 (1.0231)  loss_vfl_dn_5: 0.5602 (0.5935)  loss_bbox_dn_5: 0.3070 (0.3233)  loss_giou_dn_5: 0.9974 (1.0214)  loss_vfl_enc_0: 0.7881 (0.8537)  loss_bbox_enc_0: 0.7845 (0.8902)  loss_giou_enc_0: 1.6858 (1.8116)  time: 1.1294  data: 0.6358  max mem: 16811\n",
            "Epoch: [26] Total time: 0:00:09 (1.1356 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 35.8026 (36.1968)  loss_vfl: 0.4889 (0.5362)  loss_bbox: 0.5568 (0.5982)  loss_giou: 1.4671 (1.5310)  loss_vfl_aux_0: 0.8222 (0.8963)  loss_bbox_aux_0: 0.7766 (0.8989)  loss_giou_aux_0: 1.6260 (1.7656)  loss_vfl_aux_1: 0.8078 (0.8931)  loss_bbox_aux_1: 0.7260 (0.8581)  loss_giou_aux_1: 1.6392 (1.7725)  loss_vfl_aux_2: 0.7908 (0.8710)  loss_bbox_aux_2: 0.7531 (0.8929)  loss_giou_aux_2: 1.6369 (1.7606)  loss_vfl_aux_3: 0.6075 (0.6631)  loss_bbox_aux_3: 0.5596 (0.5887)  loss_giou_aux_3: 1.5129 (1.5818)  loss_vfl_aux_4: 0.6833 (0.7445)  loss_bbox_aux_4: 0.5506 (0.5993)  loss_giou_aux_4: 1.4880 (1.5378)  loss_vfl_dn_0: 1.0160 (1.0086)  loss_bbox_dn_0: 0.3217 (0.3325)  loss_giou_dn_0: 1.0674 (1.0742)  loss_vfl_dn_1: 1.0773 (1.0761)  loss_bbox_dn_1: 0.3051 (0.3196)  loss_giou_dn_1: 1.0132 (1.0354)  loss_vfl_dn_2: 1.0388 (1.0430)  loss_bbox_dn_2: 0.3234 (0.3378)  loss_giou_dn_2: 1.0117 (1.0249)  loss_vfl_dn_3: 0.8347 (0.8478)  loss_bbox_dn_3: 0.3097 (0.3239)  loss_giou_dn_3: 1.0044 (1.0267)  loss_vfl_dn_4: 0.8856 (0.9165)  loss_bbox_dn_4: 0.3071 (0.3235)  loss_giou_dn_4: 0.9985 (1.0231)  loss_vfl_dn_5: 0.5602 (0.5935)  loss_bbox_dn_5: 0.3070 (0.3233)  loss_giou_dn_5: 0.9974 (1.0214)  loss_vfl_enc_0: 0.7881 (0.8537)  loss_bbox_enc_0: 0.7845 (0.8902)  loss_giou_enc_0: 1.6858 (1.8116)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4630  data: 4.2924  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9769  data: 2.1625  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9943 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.046\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.071\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
            "best_stat: {'epoch': 26, 'coco_eval_bbox': 0.015746212398849754}\n",
            "Epoch: [27]  [0/8]  eta: 0:00:27  lr: 0.000001  loss: 36.9517 (36.9517)  loss_vfl: 0.3602 (0.3602)  loss_bbox: 0.7261 (0.7261)  loss_giou: 1.8145 (1.8145)  loss_vfl_aux_0: 0.6198 (0.6198)  loss_bbox_aux_0: 1.1240 (1.1240)  loss_giou_aux_0: 2.0944 (2.0944)  loss_vfl_aux_1: 0.5943 (0.5943)  loss_bbox_aux_1: 1.0500 (1.0500)  loss_giou_aux_1: 2.1056 (2.1056)  loss_vfl_aux_2: 0.5516 (0.5516)  loss_bbox_aux_2: 1.1040 (1.1040)  loss_giou_aux_2: 2.0674 (2.0674)  loss_vfl_aux_3: 0.4382 (0.4382)  loss_bbox_aux_3: 0.7169 (0.7169)  loss_giou_aux_3: 1.8913 (1.8913)  loss_vfl_aux_4: 0.4870 (0.4870)  loss_bbox_aux_4: 0.7348 (0.7348)  loss_giou_aux_4: 1.8128 (1.8128)  loss_vfl_dn_0: 0.9383 (0.9383)  loss_bbox_dn_0: 0.2332 (0.2332)  loss_giou_dn_0: 1.1167 (1.1167)  loss_vfl_dn_1: 0.9450 (0.9450)  loss_bbox_dn_1: 0.2261 (0.2261)  loss_giou_dn_1: 1.0980 (1.0980)  loss_vfl_dn_2: 0.8572 (0.8572)  loss_bbox_dn_2: 0.2580 (0.2580)  loss_giou_dn_2: 1.1064 (1.1064)  loss_vfl_dn_3: 0.7630 (0.7630)  loss_bbox_dn_3: 0.2405 (0.2405)  loss_giou_dn_3: 1.0959 (1.0959)  loss_vfl_dn_4: 0.7701 (0.7701)  loss_bbox_dn_4: 0.2427 (0.2427)  loss_giou_dn_4: 1.1014 (1.1014)  loss_vfl_dn_5: 0.4995 (0.4995)  loss_bbox_dn_5: 0.2425 (0.2425)  loss_giou_dn_5: 1.1008 (1.1008)  loss_vfl_enc_0: 0.6067 (0.6067)  loss_bbox_enc_0: 1.0640 (1.0640)  loss_giou_enc_0: 2.1527 (2.1527)  time: 3.4296  data: 2.9632  max mem: 16811\n",
            "Epoch: [27]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 34.0585 (34.6216)  loss_vfl: 0.6020 (0.6066)  loss_bbox: 0.5235 (0.5863)  loss_giou: 1.3249 (1.4434)  loss_vfl_aux_0: 1.0226 (1.0019)  loss_bbox_aux_0: 0.6575 (0.7214)  loss_giou_aux_0: 1.4587 (1.5758)  loss_vfl_aux_1: 0.9693 (0.9423)  loss_bbox_aux_1: 0.6491 (0.6946)  loss_giou_aux_1: 1.4659 (1.5856)  loss_vfl_aux_2: 0.9453 (0.9322)  loss_bbox_aux_2: 0.6713 (0.7215)  loss_giou_aux_2: 1.4459 (1.5628)  loss_vfl_aux_3: 0.6925 (0.6775)  loss_bbox_aux_3: 0.5234 (0.5823)  loss_giou_aux_3: 1.3535 (1.4884)  loss_vfl_aux_4: 0.7428 (0.7364)  loss_bbox_aux_4: 0.5238 (0.5917)  loss_giou_aux_4: 1.3335 (1.4466)  loss_vfl_dn_0: 1.0229 (1.0363)  loss_bbox_dn_0: 0.3580 (0.3480)  loss_giou_dn_0: 1.0375 (1.0478)  loss_vfl_dn_1: 1.0612 (1.0707)  loss_bbox_dn_1: 0.3315 (0.3317)  loss_giou_dn_1: 1.0008 (1.0133)  loss_vfl_dn_2: 1.0327 (1.0277)  loss_bbox_dn_2: 0.3461 (0.3469)  loss_giou_dn_2: 0.9807 (1.0005)  loss_vfl_dn_3: 0.8232 (0.8280)  loss_bbox_dn_3: 0.3312 (0.3332)  loss_giou_dn_3: 0.9796 (1.0066)  loss_vfl_dn_4: 0.8226 (0.8444)  loss_bbox_dn_4: 0.3271 (0.3319)  loss_giou_dn_4: 0.9788 (0.9987)  loss_vfl_dn_5: 0.5276 (0.5261)  loss_bbox_dn_5: 0.3270 (0.3318)  loss_giou_dn_5: 0.9776 (0.9977)  loss_vfl_enc_0: 0.9411 (0.9551)  loss_bbox_enc_0: 0.6545 (0.7274)  loss_giou_enc_0: 1.5005 (1.6206)  time: 0.9146  data: 0.3977  max mem: 16811\n",
            "Epoch: [27] Total time: 0:00:07 (0.9202 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 34.0585 (34.6216)  loss_vfl: 0.6020 (0.6066)  loss_bbox: 0.5235 (0.5863)  loss_giou: 1.3249 (1.4434)  loss_vfl_aux_0: 1.0226 (1.0019)  loss_bbox_aux_0: 0.6575 (0.7214)  loss_giou_aux_0: 1.4587 (1.5758)  loss_vfl_aux_1: 0.9693 (0.9423)  loss_bbox_aux_1: 0.6491 (0.6946)  loss_giou_aux_1: 1.4659 (1.5856)  loss_vfl_aux_2: 0.9453 (0.9322)  loss_bbox_aux_2: 0.6713 (0.7215)  loss_giou_aux_2: 1.4459 (1.5628)  loss_vfl_aux_3: 0.6925 (0.6775)  loss_bbox_aux_3: 0.5234 (0.5823)  loss_giou_aux_3: 1.3535 (1.4884)  loss_vfl_aux_4: 0.7428 (0.7364)  loss_bbox_aux_4: 0.5238 (0.5917)  loss_giou_aux_4: 1.3335 (1.4466)  loss_vfl_dn_0: 1.0229 (1.0363)  loss_bbox_dn_0: 0.3580 (0.3480)  loss_giou_dn_0: 1.0375 (1.0478)  loss_vfl_dn_1: 1.0612 (1.0707)  loss_bbox_dn_1: 0.3315 (0.3317)  loss_giou_dn_1: 1.0008 (1.0133)  loss_vfl_dn_2: 1.0327 (1.0277)  loss_bbox_dn_2: 0.3461 (0.3469)  loss_giou_dn_2: 0.9807 (1.0005)  loss_vfl_dn_3: 0.8232 (0.8280)  loss_bbox_dn_3: 0.3312 (0.3332)  loss_giou_dn_3: 0.9796 (1.0066)  loss_vfl_dn_4: 0.8226 (0.8444)  loss_bbox_dn_4: 0.3271 (0.3319)  loss_giou_dn_4: 0.9788 (0.9987)  loss_vfl_dn_5: 0.5276 (0.5261)  loss_bbox_dn_5: 0.3270 (0.3318)  loss_giou_dn_5: 0.9776 (0.9977)  loss_vfl_enc_0: 0.9411 (0.9551)  loss_bbox_enc_0: 0.6545 (0.7274)  loss_giou_enc_0: 1.5005 (1.6206)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.1889  data: 4.0491  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.8358  data: 2.0406  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8742 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.082\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            "best_stat: {'epoch': 27, 'coco_eval_bbox': 0.02411745237707996}\n",
            "Epoch: [28]  [0/8]  eta: 0:00:29  lr: 0.000001  loss: 33.6001 (33.6001)  loss_vfl: 0.6406 (0.6406)  loss_bbox: 0.5994 (0.5994)  loss_giou: 1.5103 (1.5103)  loss_vfl_aux_0: 0.9589 (0.9589)  loss_bbox_aux_0: 0.6214 (0.6214)  loss_giou_aux_0: 1.5440 (1.5440)  loss_vfl_aux_1: 0.8730 (0.8730)  loss_bbox_aux_1: 0.6158 (0.6158)  loss_giou_aux_1: 1.5643 (1.5643)  loss_vfl_aux_2: 0.8384 (0.8384)  loss_bbox_aux_2: 0.6454 (0.6454)  loss_giou_aux_2: 1.5454 (1.5454)  loss_vfl_aux_3: 0.5727 (0.5727)  loss_bbox_aux_3: 0.5985 (0.5985)  loss_giou_aux_3: 1.5385 (1.5385)  loss_vfl_aux_4: 0.6023 (0.6023)  loss_bbox_aux_4: 0.6086 (0.6086)  loss_giou_aux_4: 1.5258 (1.5258)  loss_vfl_dn_0: 0.9914 (0.9914)  loss_bbox_dn_0: 0.3179 (0.3179)  loss_giou_dn_0: 1.0838 (1.0838)  loss_vfl_dn_1: 0.9825 (0.9825)  loss_bbox_dn_1: 0.2979 (0.2979)  loss_giou_dn_1: 1.0497 (1.0497)  loss_vfl_dn_2: 0.9197 (0.9197)  loss_bbox_dn_2: 0.3148 (0.3148)  loss_giou_dn_2: 1.0618 (1.0618)  loss_vfl_dn_3: 0.7602 (0.7602)  loss_bbox_dn_3: 0.3032 (0.3032)  loss_giou_dn_3: 1.0608 (1.0608)  loss_vfl_dn_4: 0.7363 (0.7363)  loss_bbox_dn_4: 0.3009 (0.3009)  loss_giou_dn_4: 1.0580 (1.0580)  loss_vfl_dn_5: 0.4604 (0.4604)  loss_bbox_dn_5: 0.3009 (0.3009)  loss_giou_dn_5: 1.0570 (1.0570)  loss_vfl_enc_0: 0.9502 (0.9502)  loss_bbox_enc_0: 0.6338 (0.6338)  loss_giou_enc_0: 1.5559 (1.5559)  time: 3.6667  data: 3.0529  max mem: 16811\n",
            "Epoch: [28]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 33.7410 (34.2268)  loss_vfl: 0.7193 (0.7232)  loss_bbox: 0.5650 (0.5791)  loss_giou: 1.4972 (1.5128)  loss_vfl_aux_0: 0.9127 (0.9187)  loss_bbox_aux_0: 0.6867 (0.7687)  loss_giou_aux_0: 1.6461 (1.6662)  loss_vfl_aux_1: 0.8323 (0.8287)  loss_bbox_aux_1: 0.6705 (0.7392)  loss_giou_aux_1: 1.6762 (1.6812)  loss_vfl_aux_2: 0.7879 (0.7854)  loss_bbox_aux_2: 0.6963 (0.7733)  loss_giou_aux_2: 1.6613 (1.6649)  loss_vfl_aux_3: 0.5727 (0.5930)  loss_bbox_aux_3: 0.5755 (0.5825)  loss_giou_aux_3: 1.5654 (1.5722)  loss_vfl_aux_4: 0.5848 (0.5930)  loss_bbox_aux_4: 0.5688 (0.5877)  loss_giou_aux_4: 1.5003 (1.5207)  loss_vfl_dn_0: 1.0269 (1.0193)  loss_bbox_dn_0: 0.3043 (0.3095)  loss_giou_dn_0: 1.0318 (1.0476)  loss_vfl_dn_1: 1.0227 (1.0221)  loss_bbox_dn_1: 0.2792 (0.2895)  loss_giou_dn_1: 0.9818 (0.9980)  loss_vfl_dn_2: 0.9240 (0.9427)  loss_bbox_dn_2: 0.2916 (0.3035)  loss_giou_dn_2: 0.9619 (0.9939)  loss_vfl_dn_3: 0.8117 (0.8145)  loss_bbox_dn_3: 0.2768 (0.2880)  loss_giou_dn_3: 0.9633 (0.9878)  loss_vfl_dn_4: 0.7363 (0.7501)  loss_bbox_dn_4: 0.2744 (0.2858)  loss_giou_dn_4: 0.9502 (0.9821)  loss_vfl_dn_5: 0.4815 (0.4810)  loss_bbox_dn_5: 0.2742 (0.2857)  loss_giou_dn_5: 0.9497 (0.9809)  loss_vfl_enc_0: 0.8496 (0.8677)  loss_bbox_enc_0: 0.7123 (0.7769)  loss_giou_enc_0: 1.7321 (1.7098)  time: 0.9261  data: 0.4124  max mem: 16811\n",
            "Epoch: [28] Total time: 0:00:07 (0.9415 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 33.7410 (34.2268)  loss_vfl: 0.7193 (0.7232)  loss_bbox: 0.5650 (0.5791)  loss_giou: 1.4972 (1.5128)  loss_vfl_aux_0: 0.9127 (0.9187)  loss_bbox_aux_0: 0.6867 (0.7687)  loss_giou_aux_0: 1.6461 (1.6662)  loss_vfl_aux_1: 0.8323 (0.8287)  loss_bbox_aux_1: 0.6705 (0.7392)  loss_giou_aux_1: 1.6762 (1.6812)  loss_vfl_aux_2: 0.7879 (0.7854)  loss_bbox_aux_2: 0.6963 (0.7733)  loss_giou_aux_2: 1.6613 (1.6649)  loss_vfl_aux_3: 0.5727 (0.5930)  loss_bbox_aux_3: 0.5755 (0.5825)  loss_giou_aux_3: 1.5654 (1.5722)  loss_vfl_aux_4: 0.5848 (0.5930)  loss_bbox_aux_4: 0.5688 (0.5877)  loss_giou_aux_4: 1.5003 (1.5207)  loss_vfl_dn_0: 1.0269 (1.0193)  loss_bbox_dn_0: 0.3043 (0.3095)  loss_giou_dn_0: 1.0318 (1.0476)  loss_vfl_dn_1: 1.0227 (1.0221)  loss_bbox_dn_1: 0.2792 (0.2895)  loss_giou_dn_1: 0.9818 (0.9980)  loss_vfl_dn_2: 0.9240 (0.9427)  loss_bbox_dn_2: 0.2916 (0.3035)  loss_giou_dn_2: 0.9619 (0.9939)  loss_vfl_dn_3: 0.8117 (0.8145)  loss_bbox_dn_3: 0.2768 (0.2880)  loss_giou_dn_3: 0.9633 (0.9878)  loss_vfl_dn_4: 0.7363 (0.7501)  loss_bbox_dn_4: 0.2744 (0.2858)  loss_giou_dn_4: 0.9502 (0.9821)  loss_vfl_dn_5: 0.4815 (0.4810)  loss_bbox_dn_5: 0.2742 (0.2857)  loss_giou_dn_5: 0.9497 (0.9809)  loss_vfl_enc_0: 0.8496 (0.8677)  loss_bbox_enc_0: 0.7123 (0.7769)  loss_giou_enc_0: 1.7321 (1.7098)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8086  data: 4.3465  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1473  data: 2.1896  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1672 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
            "best_stat: {'epoch': 28, 'coco_eval_bbox': 0.027575559703939056}\n",
            "Epoch: [29]  [0/8]  eta: 0:00:28  lr: 0.000001  loss: 35.2021 (35.2021)  loss_vfl: 0.7601 (0.7601)  loss_bbox: 0.5854 (0.5854)  loss_giou: 1.6474 (1.6474)  loss_vfl_aux_0: 0.9089 (0.9089)  loss_bbox_aux_0: 0.8401 (0.8401)  loss_giou_aux_0: 1.8257 (1.8257)  loss_vfl_aux_1: 0.7962 (0.7962)  loss_bbox_aux_1: 0.8103 (0.8103)  loss_giou_aux_1: 1.8667 (1.8667)  loss_vfl_aux_2: 0.7289 (0.7289)  loss_bbox_aux_2: 0.8431 (0.8431)  loss_giou_aux_2: 1.8486 (1.8486)  loss_vfl_aux_3: 0.5432 (0.5432)  loss_bbox_aux_3: 0.5792 (0.5792)  loss_giou_aux_3: 1.7093 (1.7093)  loss_vfl_aux_4: 0.5346 (0.5346)  loss_bbox_aux_4: 0.5886 (0.5886)  loss_giou_aux_4: 1.6491 (1.6491)  loss_vfl_dn_0: 1.0590 (1.0590)  loss_bbox_dn_0: 0.2800 (0.2800)  loss_giou_dn_0: 1.0159 (1.0159)  loss_vfl_dn_1: 1.0805 (1.0805)  loss_bbox_dn_1: 0.2559 (0.2559)  loss_giou_dn_1: 0.9699 (0.9699)  loss_vfl_dn_2: 0.9815 (0.9815)  loss_bbox_dn_2: 0.2637 (0.2637)  loss_giou_dn_2: 0.9608 (0.9608)  loss_vfl_dn_3: 0.8591 (0.8591)  loss_bbox_dn_3: 0.2524 (0.2524)  loss_giou_dn_3: 0.9630 (0.9630)  loss_vfl_dn_4: 0.7452 (0.7452)  loss_bbox_dn_4: 0.2486 (0.2486)  loss_giou_dn_4: 0.9563 (0.9563)  loss_vfl_dn_5: 0.4932 (0.4932)  loss_bbox_dn_5: 0.2487 (0.2487)  loss_giou_dn_5: 0.9559 (0.9559)  loss_vfl_enc_0: 0.8433 (0.8433)  loss_bbox_enc_0: 0.8406 (0.8406)  loss_giou_enc_0: 1.8631 (1.8631)  time: 3.5735  data: 2.9459  max mem: 16811\n",
            "Epoch: [29]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 32.2557 (32.9223)  loss_vfl: 0.7601 (0.8002)  loss_bbox: 0.5854 (0.5566)  loss_giou: 1.4413 (1.4250)  loss_vfl_aux_0: 0.9503 (0.9890)  loss_bbox_aux_0: 0.6015 (0.6855)  loss_giou_aux_0: 1.4427 (1.5172)  loss_vfl_aux_1: 0.8487 (0.8577)  loss_bbox_aux_1: 0.5954 (0.6643)  loss_giou_aux_1: 1.4567 (1.5348)  loss_vfl_aux_2: 0.7357 (0.7833)  loss_bbox_aux_2: 0.6219 (0.6925)  loss_giou_aux_2: 1.4643 (1.5299)  loss_vfl_aux_3: 0.5720 (0.5925)  loss_bbox_aux_3: 0.5792 (0.5579)  loss_giou_aux_3: 1.4533 (1.4701)  loss_vfl_aux_4: 0.5637 (0.5784)  loss_bbox_aux_4: 0.5886 (0.5610)  loss_giou_aux_4: 1.4492 (1.4327)  loss_vfl_dn_0: 0.9982 (1.0220)  loss_bbox_dn_0: 0.3240 (0.3316)  loss_giou_dn_0: 1.0159 (1.0223)  loss_vfl_dn_1: 0.9665 (0.9861)  loss_bbox_dn_1: 0.3051 (0.3039)  loss_giou_dn_1: 0.9570 (0.9707)  loss_vfl_dn_2: 0.8869 (0.8857)  loss_bbox_dn_2: 0.3176 (0.3135)  loss_giou_dn_2: 0.9526 (0.9682)  loss_vfl_dn_3: 0.7612 (0.7675)  loss_bbox_dn_3: 0.2964 (0.3006)  loss_giou_dn_3: 0.9579 (0.9654)  loss_vfl_dn_4: 0.6732 (0.6765)  loss_bbox_dn_4: 0.2917 (0.2980)  loss_giou_dn_4: 0.9494 (0.9576)  loss_vfl_dn_5: 0.4775 (0.4743)  loss_bbox_dn_5: 0.2917 (0.2980)  loss_giou_dn_5: 0.9477 (0.9569)  loss_vfl_enc_0: 0.8905 (0.9493)  loss_bbox_enc_0: 0.6141 (0.6968)  loss_giou_enc_0: 1.4768 (1.5488)  time: 0.9054  data: 0.3884  max mem: 16811\n",
            "Epoch: [29] Total time: 0:00:07 (0.9117 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 32.2557 (32.9223)  loss_vfl: 0.7601 (0.8002)  loss_bbox: 0.5854 (0.5566)  loss_giou: 1.4413 (1.4250)  loss_vfl_aux_0: 0.9503 (0.9890)  loss_bbox_aux_0: 0.6015 (0.6855)  loss_giou_aux_0: 1.4427 (1.5172)  loss_vfl_aux_1: 0.8487 (0.8577)  loss_bbox_aux_1: 0.5954 (0.6643)  loss_giou_aux_1: 1.4567 (1.5348)  loss_vfl_aux_2: 0.7357 (0.7833)  loss_bbox_aux_2: 0.6219 (0.6925)  loss_giou_aux_2: 1.4643 (1.5299)  loss_vfl_aux_3: 0.5720 (0.5925)  loss_bbox_aux_3: 0.5792 (0.5579)  loss_giou_aux_3: 1.4533 (1.4701)  loss_vfl_aux_4: 0.5637 (0.5784)  loss_bbox_aux_4: 0.5886 (0.5610)  loss_giou_aux_4: 1.4492 (1.4327)  loss_vfl_dn_0: 0.9982 (1.0220)  loss_bbox_dn_0: 0.3240 (0.3316)  loss_giou_dn_0: 1.0159 (1.0223)  loss_vfl_dn_1: 0.9665 (0.9861)  loss_bbox_dn_1: 0.3051 (0.3039)  loss_giou_dn_1: 0.9570 (0.9707)  loss_vfl_dn_2: 0.8869 (0.8857)  loss_bbox_dn_2: 0.3176 (0.3135)  loss_giou_dn_2: 0.9526 (0.9682)  loss_vfl_dn_3: 0.7612 (0.7675)  loss_bbox_dn_3: 0.2964 (0.3006)  loss_giou_dn_3: 0.9579 (0.9654)  loss_vfl_dn_4: 0.6732 (0.6765)  loss_bbox_dn_4: 0.2917 (0.2980)  loss_giou_dn_4: 0.9494 (0.9576)  loss_vfl_dn_5: 0.4775 (0.4743)  loss_bbox_dn_5: 0.2917 (0.2980)  loss_giou_dn_5: 0.9477 (0.9569)  loss_vfl_enc_0: 0.8905 (0.9493)  loss_bbox_enc_0: 0.6141 (0.6968)  loss_giou_enc_0: 1.4768 (1.5488)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.2284  data: 4.0792  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.8607  data: 2.0559  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8807 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
            "best_stat: {'epoch': 29, 'coco_eval_bbox': 0.030535355836898034}\n",
            "Epoch: [30]  [0/8]  eta: 0:00:32  lr: 0.000001  loss: 33.0632 (33.0632)  loss_vfl: 0.6332 (0.6332)  loss_bbox: 0.6516 (0.6516)  loss_giou: 1.5449 (1.5449)  loss_vfl_aux_0: 0.9722 (0.9722)  loss_bbox_aux_0: 0.7105 (0.7105)  loss_giou_aux_0: 1.5552 (1.5552)  loss_vfl_aux_1: 0.8223 (0.8223)  loss_bbox_aux_1: 0.6735 (0.6735)  loss_giou_aux_1: 1.5750 (1.5750)  loss_vfl_aux_2: 0.7099 (0.7099)  loss_bbox_aux_2: 0.7157 (0.7157)  loss_giou_aux_2: 1.5771 (1.5771)  loss_vfl_aux_3: 0.5364 (0.5364)  loss_bbox_aux_3: 0.6378 (0.6378)  loss_giou_aux_3: 1.5714 (1.5714)  loss_vfl_aux_4: 0.5387 (0.5387)  loss_bbox_aux_4: 0.6530 (0.6530)  loss_giou_aux_4: 1.5482 (1.5482)  loss_vfl_dn_0: 1.0515 (1.0515)  loss_bbox_dn_0: 0.3212 (0.3212)  loss_giou_dn_0: 1.0031 (1.0031)  loss_vfl_dn_1: 0.9688 (0.9688)  loss_bbox_dn_1: 0.2903 (0.2903)  loss_giou_dn_1: 0.9495 (0.9495)  loss_vfl_dn_2: 0.8588 (0.8588)  loss_bbox_dn_2: 0.3049 (0.3049)  loss_giou_dn_2: 0.9344 (0.9344)  loss_vfl_dn_3: 0.7516 (0.7516)  loss_bbox_dn_3: 0.2918 (0.2918)  loss_giou_dn_3: 0.9361 (0.9361)  loss_vfl_dn_4: 0.6570 (0.6570)  loss_bbox_dn_4: 0.2900 (0.2900)  loss_giou_dn_4: 0.9221 (0.9221)  loss_vfl_dn_5: 0.4848 (0.4848)  loss_bbox_dn_5: 0.2902 (0.2902)  loss_giou_dn_5: 0.9226 (0.9226)  loss_vfl_enc_0: 0.9069 (0.9069)  loss_bbox_enc_0: 0.7158 (0.7158)  loss_giou_enc_0: 1.5852 (1.5852)  time: 4.0113  data: 3.3448  max mem: 16811\n",
            "Epoch: [30]  [7/8]  eta: 0:00:01  lr: 0.000001  loss: 31.3803 (31.8605)  loss_vfl: 0.6660 (0.7274)  loss_bbox: 0.5258 (0.5641)  loss_giou: 1.3607 (1.4104)  loss_vfl_aux_0: 1.0051 (1.0094)  loss_bbox_aux_0: 0.5921 (0.6383)  loss_giou_aux_0: 1.4269 (1.4784)  loss_vfl_aux_1: 0.8223 (0.8161)  loss_bbox_aux_1: 0.5760 (0.6182)  loss_giou_aux_1: 1.4453 (1.4943)  loss_vfl_aux_2: 0.7099 (0.7204)  loss_bbox_aux_2: 0.5920 (0.6390)  loss_giou_aux_2: 1.4379 (1.4927)  loss_vfl_aux_3: 0.5518 (0.5787)  loss_bbox_aux_3: 0.5209 (0.5584)  loss_giou_aux_3: 1.3882 (1.4495)  loss_vfl_aux_4: 0.5797 (0.5946)  loss_bbox_aux_4: 0.5226 (0.5658)  loss_giou_aux_4: 1.3622 (1.4155)  loss_vfl_dn_0: 1.0148 (1.0231)  loss_bbox_dn_0: 0.2939 (0.3084)  loss_giou_dn_0: 1.0121 (1.0108)  loss_vfl_dn_1: 0.9010 (0.9250)  loss_bbox_dn_1: 0.2799 (0.2849)  loss_giou_dn_1: 0.9495 (0.9548)  loss_vfl_dn_2: 0.8031 (0.8189)  loss_bbox_dn_2: 0.2807 (0.2864)  loss_giou_dn_2: 0.9344 (0.9368)  loss_vfl_dn_3: 0.6809 (0.7095)  loss_bbox_dn_3: 0.2768 (0.2803)  loss_giou_dn_3: 0.9361 (0.9380)  loss_vfl_dn_4: 0.5991 (0.6202)  loss_bbox_dn_4: 0.2742 (0.2762)  loss_giou_dn_4: 0.9251 (0.9277)  loss_vfl_dn_5: 0.4710 (0.4804)  loss_bbox_dn_5: 0.2742 (0.2762)  loss_giou_dn_5: 0.9246 (0.9276)  loss_vfl_enc_0: 0.9118 (0.9290)  loss_bbox_enc_0: 0.6014 (0.6552)  loss_giou_enc_0: 1.4656 (1.5200)  time: 1.0097  data: 0.4343  max mem: 16811\n",
            "Epoch: [30] Total time: 0:00:08 (1.0158 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 31.3803 (31.8605)  loss_vfl: 0.6660 (0.7274)  loss_bbox: 0.5258 (0.5641)  loss_giou: 1.3607 (1.4104)  loss_vfl_aux_0: 1.0051 (1.0094)  loss_bbox_aux_0: 0.5921 (0.6383)  loss_giou_aux_0: 1.4269 (1.4784)  loss_vfl_aux_1: 0.8223 (0.8161)  loss_bbox_aux_1: 0.5760 (0.6182)  loss_giou_aux_1: 1.4453 (1.4943)  loss_vfl_aux_2: 0.7099 (0.7204)  loss_bbox_aux_2: 0.5920 (0.6390)  loss_giou_aux_2: 1.4379 (1.4927)  loss_vfl_aux_3: 0.5518 (0.5787)  loss_bbox_aux_3: 0.5209 (0.5584)  loss_giou_aux_3: 1.3882 (1.4495)  loss_vfl_aux_4: 0.5797 (0.5946)  loss_bbox_aux_4: 0.5226 (0.5658)  loss_giou_aux_4: 1.3622 (1.4155)  loss_vfl_dn_0: 1.0148 (1.0231)  loss_bbox_dn_0: 0.2939 (0.3084)  loss_giou_dn_0: 1.0121 (1.0108)  loss_vfl_dn_1: 0.9010 (0.9250)  loss_bbox_dn_1: 0.2799 (0.2849)  loss_giou_dn_1: 0.9495 (0.9548)  loss_vfl_dn_2: 0.8031 (0.8189)  loss_bbox_dn_2: 0.2807 (0.2864)  loss_giou_dn_2: 0.9344 (0.9368)  loss_vfl_dn_3: 0.6809 (0.7095)  loss_bbox_dn_3: 0.2768 (0.2803)  loss_giou_dn_3: 0.9361 (0.9380)  loss_vfl_dn_4: 0.5991 (0.6202)  loss_bbox_dn_4: 0.2742 (0.2762)  loss_giou_dn_4: 0.9251 (0.9277)  loss_vfl_dn_5: 0.4710 (0.4804)  loss_bbox_dn_5: 0.2742 (0.2762)  loss_giou_dn_5: 0.9246 (0.9276)  loss_vfl_enc_0: 0.9118 (0.9290)  loss_bbox_enc_0: 0.6014 (0.6552)  loss_giou_enc_0: 1.4656 (1.5200)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4315  data: 4.3012  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9553  data: 2.1669  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9749 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467\n",
            "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.033388313023256344}\n",
            "Epoch: [31]  [0/8]  eta: 0:00:30  lr: 0.000001  loss: 32.7415 (32.7415)  loss_vfl: 0.6909 (0.6909)  loss_bbox: 0.6165 (0.6165)  loss_giou: 1.4789 (1.4789)  loss_vfl_aux_0: 1.0542 (1.0542)  loss_bbox_aux_0: 0.7786 (0.7786)  loss_giou_aux_0: 1.5306 (1.5306)  loss_vfl_aux_1: 0.8525 (0.8525)  loss_bbox_aux_1: 0.7520 (0.7520)  loss_giou_aux_1: 1.5250 (1.5250)  loss_vfl_aux_2: 0.7286 (0.7286)  loss_bbox_aux_2: 0.7791 (0.7791)  loss_giou_aux_2: 1.5357 (1.5357)  loss_vfl_aux_3: 0.6058 (0.6058)  loss_bbox_aux_3: 0.6003 (0.6003)  loss_giou_aux_3: 1.5103 (1.5103)  loss_vfl_aux_4: 0.6324 (0.6324)  loss_bbox_aux_4: 0.6133 (0.6133)  loss_giou_aux_4: 1.4799 (1.4799)  loss_vfl_dn_0: 1.0463 (1.0463)  loss_bbox_dn_0: 0.3015 (0.3015)  loss_giou_dn_0: 0.9789 (0.9789)  loss_vfl_dn_1: 0.9245 (0.9245)  loss_bbox_dn_1: 0.2784 (0.2784)  loss_giou_dn_1: 0.9070 (0.9070)  loss_vfl_dn_2: 0.7894 (0.7894)  loss_bbox_dn_2: 0.2761 (0.2761)  loss_giou_dn_2: 0.8865 (0.8865)  loss_vfl_dn_3: 0.6770 (0.6770)  loss_bbox_dn_3: 0.2795 (0.2795)  loss_giou_dn_3: 0.9035 (0.9035)  loss_vfl_dn_4: 0.6004 (0.6004)  loss_bbox_dn_4: 0.2755 (0.2755)  loss_giou_dn_4: 0.8879 (0.8879)  loss_vfl_dn_5: 0.4816 (0.4816)  loss_bbox_dn_5: 0.2757 (0.2757)  loss_giou_dn_5: 0.8884 (0.8884)  loss_vfl_enc_0: 0.9531 (0.9531)  loss_bbox_enc_0: 0.8010 (0.8010)  loss_giou_enc_0: 1.5648 (1.5648)  time: 3.7565  data: 3.0757  max mem: 16811\n",
            "Epoch: [31]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 30.9625 (30.9090)  loss_vfl: 0.6897 (0.6830)  loss_bbox: 0.5315 (0.5288)  loss_giou: 1.3798 (1.3676)  loss_vfl_aux_0: 1.0359 (1.0321)  loss_bbox_aux_0: 0.6622 (0.6299)  loss_giou_aux_0: 1.4910 (1.4435)  loss_vfl_aux_1: 0.7405 (0.7587)  loss_bbox_aux_1: 0.6334 (0.6088)  loss_giou_aux_1: 1.4917 (1.4560)  loss_vfl_aux_2: 0.6456 (0.6689)  loss_bbox_aux_2: 0.6623 (0.6284)  loss_giou_aux_2: 1.4891 (1.4553)  loss_vfl_aux_3: 0.6011 (0.6032)  loss_bbox_aux_3: 0.5295 (0.5210)  loss_giou_aux_3: 1.4094 (1.4055)  loss_vfl_aux_4: 0.6324 (0.6586)  loss_bbox_aux_4: 0.5353 (0.5293)  loss_giou_aux_4: 1.3815 (1.3683)  loss_vfl_dn_0: 0.9997 (1.0200)  loss_bbox_dn_0: 0.3015 (0.3059)  loss_giou_dn_0: 0.9823 (0.9865)  loss_vfl_dn_1: 0.8050 (0.8331)  loss_bbox_dn_1: 0.2784 (0.2779)  loss_giou_dn_1: 0.9313 (0.9324)  loss_vfl_dn_2: 0.6981 (0.7209)  loss_bbox_dn_2: 0.2761 (0.2779)  loss_giou_dn_2: 0.9103 (0.9126)  loss_vfl_dn_3: 0.6340 (0.6431)  loss_bbox_dn_3: 0.2780 (0.2710)  loss_giou_dn_3: 0.9118 (0.9147)  loss_vfl_dn_4: 0.5529 (0.5625)  loss_bbox_dn_4: 0.2755 (0.2690)  loss_giou_dn_4: 0.9042 (0.9066)  loss_vfl_dn_5: 0.4737 (0.4791)  loss_bbox_dn_5: 0.2757 (0.2690)  loss_giou_dn_5: 0.9032 (0.9057)  loss_vfl_enc_0: 0.9370 (0.9392)  loss_bbox_enc_0: 0.6825 (0.6474)  loss_giou_enc_0: 1.5477 (1.4876)  time: 0.9745  data: 0.4183  max mem: 16811\n",
            "Epoch: [31] Total time: 0:00:07 (0.9819 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 30.9625 (30.9090)  loss_vfl: 0.6897 (0.6830)  loss_bbox: 0.5315 (0.5288)  loss_giou: 1.3798 (1.3676)  loss_vfl_aux_0: 1.0359 (1.0321)  loss_bbox_aux_0: 0.6622 (0.6299)  loss_giou_aux_0: 1.4910 (1.4435)  loss_vfl_aux_1: 0.7405 (0.7587)  loss_bbox_aux_1: 0.6334 (0.6088)  loss_giou_aux_1: 1.4917 (1.4560)  loss_vfl_aux_2: 0.6456 (0.6689)  loss_bbox_aux_2: 0.6623 (0.6284)  loss_giou_aux_2: 1.4891 (1.4553)  loss_vfl_aux_3: 0.6011 (0.6032)  loss_bbox_aux_3: 0.5295 (0.5210)  loss_giou_aux_3: 1.4094 (1.4055)  loss_vfl_aux_4: 0.6324 (0.6586)  loss_bbox_aux_4: 0.5353 (0.5293)  loss_giou_aux_4: 1.3815 (1.3683)  loss_vfl_dn_0: 0.9997 (1.0200)  loss_bbox_dn_0: 0.3015 (0.3059)  loss_giou_dn_0: 0.9823 (0.9865)  loss_vfl_dn_1: 0.8050 (0.8331)  loss_bbox_dn_1: 0.2784 (0.2779)  loss_giou_dn_1: 0.9313 (0.9324)  loss_vfl_dn_2: 0.6981 (0.7209)  loss_bbox_dn_2: 0.2761 (0.2779)  loss_giou_dn_2: 0.9103 (0.9126)  loss_vfl_dn_3: 0.6340 (0.6431)  loss_bbox_dn_3: 0.2780 (0.2710)  loss_giou_dn_3: 0.9118 (0.9147)  loss_vfl_dn_4: 0.5529 (0.5625)  loss_bbox_dn_4: 0.2755 (0.2690)  loss_giou_dn_4: 0.9042 (0.9066)  loss_vfl_dn_5: 0.4737 (0.4791)  loss_bbox_dn_5: 0.2757 (0.2690)  loss_giou_dn_5: 0.9032 (0.9057)  loss_vfl_enc_0: 0.9370 (0.9392)  loss_bbox_enc_0: 0.6825 (0.6474)  loss_giou_enc_0: 1.5477 (1.4876)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8386  data: 4.3358  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1592  data: 2.1842  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1798 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
            "best_stat: {'epoch': 31, 'coco_eval_bbox': 0.03407319579034258}\n",
            "Epoch: [32]  [0/8]  eta: 0:00:28  lr: 0.000001  loss: 30.0717 (30.0717)  loss_vfl: 0.8685 (0.8685)  loss_bbox: 0.5136 (0.5136)  loss_giou: 1.1065 (1.1065)  loss_vfl_aux_0: 1.2084 (1.2084)  loss_bbox_aux_0: 0.5086 (0.5086)  loss_giou_aux_0: 1.0959 (1.0959)  loss_vfl_aux_1: 0.8299 (0.8299)  loss_bbox_aux_1: 0.5077 (0.5077)  loss_giou_aux_1: 1.1286 (1.1286)  loss_vfl_aux_2: 0.8051 (0.8051)  loss_bbox_aux_2: 0.5157 (0.5157)  loss_giou_aux_2: 1.0870 (1.0870)  loss_vfl_aux_3: 0.7905 (0.7905)  loss_bbox_aux_3: 0.5355 (0.5355)  loss_giou_aux_3: 1.1263 (1.1263)  loss_vfl_aux_4: 0.9076 (0.9076)  loss_bbox_aux_4: 0.5145 (0.5145)  loss_giou_aux_4: 1.1068 (1.1068)  loss_vfl_dn_0: 1.0430 (1.0430)  loss_bbox_dn_0: 0.4341 (0.4341)  loss_giou_dn_0: 0.9664 (0.9664)  loss_vfl_dn_1: 0.7797 (0.7797)  loss_bbox_dn_1: 0.4228 (0.4228)  loss_giou_dn_1: 0.9381 (0.9381)  loss_vfl_dn_2: 0.7261 (0.7261)  loss_bbox_dn_2: 0.3986 (0.3986)  loss_giou_dn_2: 0.8879 (0.8879)  loss_vfl_dn_3: 0.6217 (0.6217)  loss_bbox_dn_3: 0.4083 (0.4083)  loss_giou_dn_3: 0.9171 (0.9171)  loss_vfl_dn_4: 0.5518 (0.5518)  loss_bbox_dn_4: 0.3947 (0.3947)  loss_giou_dn_4: 0.8914 (0.8914)  loss_vfl_dn_5: 0.4702 (0.4702)  loss_bbox_dn_5: 0.3948 (0.3948)  loss_giou_dn_5: 0.8910 (0.8910)  loss_vfl_enc_0: 1.0520 (1.0520)  loss_bbox_enc_0: 0.5422 (0.5422)  loss_giou_enc_0: 1.1832 (1.1832)  time: 3.5790  data: 2.9865  max mem: 16811\n",
            "Epoch: [32]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 30.1503 (31.0532)  loss_vfl: 0.6163 (0.6726)  loss_bbox: 0.5649 (0.5988)  loss_giou: 1.3494 (1.3959)  loss_vfl_aux_0: 0.9406 (0.9776)  loss_bbox_aux_0: 0.5881 (0.6598)  loss_giou_aux_0: 1.4825 (1.4602)  loss_vfl_aux_1: 0.6144 (0.6787)  loss_bbox_aux_1: 0.5740 (0.6432)  loss_giou_aux_1: 1.5020 (1.4781)  loss_vfl_aux_2: 0.5534 (0.6145)  loss_bbox_aux_2: 0.5938 (0.6621)  loss_giou_aux_2: 1.4991 (1.4672)  loss_vfl_aux_3: 0.5877 (0.6391)  loss_bbox_aux_3: 0.5633 (0.5899)  loss_giou_aux_3: 1.4207 (1.4271)  loss_vfl_aux_4: 0.6224 (0.7006)  loss_bbox_aux_4: 0.5729 (0.6004)  loss_giou_aux_4: 1.3606 (1.3976)  loss_vfl_dn_0: 0.9600 (0.9796)  loss_bbox_dn_0: 0.2879 (0.3255)  loss_giou_dn_0: 0.9859 (0.9937)  loss_vfl_dn_1: 0.7041 (0.7217)  loss_bbox_dn_1: 0.2527 (0.2979)  loss_giou_dn_1: 0.9381 (0.9461)  loss_vfl_dn_2: 0.5967 (0.6145)  loss_bbox_dn_2: 0.2534 (0.2964)  loss_giou_dn_2: 0.9276 (0.9291)  loss_vfl_dn_3: 0.5703 (0.5851)  loss_bbox_dn_3: 0.2441 (0.2913)  loss_giou_dn_3: 0.9226 (0.9318)  loss_vfl_dn_4: 0.5135 (0.5181)  loss_bbox_dn_4: 0.2429 (0.2888)  loss_giou_dn_4: 0.9170 (0.9240)  loss_vfl_dn_5: 0.4525 (0.4569)  loss_bbox_dn_5: 0.2428 (0.2887)  loss_giou_dn_5: 0.9159 (0.9233)  loss_vfl_enc_0: 0.8719 (0.8967)  loss_bbox_enc_0: 0.6015 (0.6701)  loss_giou_enc_0: 1.5094 (1.5107)  time: 0.9052  data: 0.3987  max mem: 16811\n",
            "Epoch: [32] Total time: 0:00:07 (0.9117 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 30.1503 (31.0532)  loss_vfl: 0.6163 (0.6726)  loss_bbox: 0.5649 (0.5988)  loss_giou: 1.3494 (1.3959)  loss_vfl_aux_0: 0.9406 (0.9776)  loss_bbox_aux_0: 0.5881 (0.6598)  loss_giou_aux_0: 1.4825 (1.4602)  loss_vfl_aux_1: 0.6144 (0.6787)  loss_bbox_aux_1: 0.5740 (0.6432)  loss_giou_aux_1: 1.5020 (1.4781)  loss_vfl_aux_2: 0.5534 (0.6145)  loss_bbox_aux_2: 0.5938 (0.6621)  loss_giou_aux_2: 1.4991 (1.4672)  loss_vfl_aux_3: 0.5877 (0.6391)  loss_bbox_aux_3: 0.5633 (0.5899)  loss_giou_aux_3: 1.4207 (1.4271)  loss_vfl_aux_4: 0.6224 (0.7006)  loss_bbox_aux_4: 0.5729 (0.6004)  loss_giou_aux_4: 1.3606 (1.3976)  loss_vfl_dn_0: 0.9600 (0.9796)  loss_bbox_dn_0: 0.2879 (0.3255)  loss_giou_dn_0: 0.9859 (0.9937)  loss_vfl_dn_1: 0.7041 (0.7217)  loss_bbox_dn_1: 0.2527 (0.2979)  loss_giou_dn_1: 0.9381 (0.9461)  loss_vfl_dn_2: 0.5967 (0.6145)  loss_bbox_dn_2: 0.2534 (0.2964)  loss_giou_dn_2: 0.9276 (0.9291)  loss_vfl_dn_3: 0.5703 (0.5851)  loss_bbox_dn_3: 0.2441 (0.2913)  loss_giou_dn_3: 0.9226 (0.9318)  loss_vfl_dn_4: 0.5135 (0.5181)  loss_bbox_dn_4: 0.2429 (0.2888)  loss_giou_dn_4: 0.9170 (0.9240)  loss_vfl_dn_5: 0.4525 (0.4569)  loss_bbox_dn_5: 0.2428 (0.2887)  loss_giou_dn_5: 0.9159 (0.9233)  loss_vfl_enc_0: 0.8719 (0.8967)  loss_bbox_enc_0: 0.6015 (0.6701)  loss_giou_enc_0: 1.5094 (1.5107)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5968  data: 4.4737  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0375  data: 2.2530  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0679 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
            "best_stat: {'epoch': 32, 'coco_eval_bbox': 0.040825308686259755}\n",
            "Epoch: [33]  [0/8]  eta: 0:00:16  lr: 0.000001  loss: 30.1877 (30.1877)  loss_vfl: 0.7031 (0.7031)  loss_bbox: 0.5770 (0.5770)  loss_giou: 1.2516 (1.2516)  loss_vfl_aux_0: 1.1966 (1.1966)  loss_bbox_aux_0: 0.5679 (0.5679)  loss_giou_aux_0: 1.2474 (1.2474)  loss_vfl_aux_1: 0.7995 (0.7995)  loss_bbox_aux_1: 0.5601 (0.5601)  loss_giou_aux_1: 1.2619 (1.2619)  loss_vfl_aux_2: 0.6883 (0.6883)  loss_bbox_aux_2: 0.5783 (0.5783)  loss_giou_aux_2: 1.2651 (1.2651)  loss_vfl_aux_3: 0.6850 (0.6850)  loss_bbox_aux_3: 0.5524 (0.5524)  loss_giou_aux_3: 1.2621 (1.2621)  loss_vfl_aux_4: 0.7113 (0.7113)  loss_bbox_aux_4: 0.5664 (0.5664)  loss_giou_aux_4: 1.2523 (1.2523)  loss_vfl_dn_0: 1.0364 (1.0364)  loss_bbox_dn_0: 0.3763 (0.3763)  loss_giou_dn_0: 0.9475 (0.9475)  loss_vfl_dn_1: 0.7733 (0.7733)  loss_bbox_dn_1: 0.3296 (0.3296)  loss_giou_dn_1: 0.8990 (0.8990)  loss_vfl_dn_2: 0.6363 (0.6363)  loss_bbox_dn_2: 0.3369 (0.3369)  loss_giou_dn_2: 0.8882 (0.8882)  loss_vfl_dn_3: 0.6271 (0.6271)  loss_bbox_dn_3: 0.3258 (0.3258)  loss_giou_dn_3: 0.8977 (0.8977)  loss_vfl_dn_4: 0.5792 (0.5792)  loss_bbox_dn_4: 0.3263 (0.3263)  loss_giou_dn_4: 0.8866 (0.8866)  loss_vfl_dn_5: 0.4852 (0.4852)  loss_bbox_dn_5: 0.3262 (0.3262)  loss_giou_dn_5: 0.8864 (0.8864)  loss_vfl_enc_0: 0.9732 (0.9732)  loss_bbox_enc_0: 0.6018 (0.6018)  loss_giou_enc_0: 1.3223 (1.3223)  time: 2.0524  data: 1.5024  max mem: 16811\n",
            "Epoch: [33]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 29.3665 (29.3961)  loss_vfl: 0.7436 (0.7398)  loss_bbox: 0.5441 (0.5379)  loss_giou: 1.1657 (1.1873)  loss_vfl_aux_0: 1.1250 (1.1480)  loss_bbox_aux_0: 0.5413 (0.5328)  loss_giou_aux_0: 1.1583 (1.1859)  loss_vfl_aux_1: 0.7350 (0.7602)  loss_bbox_aux_1: 0.5278 (0.5216)  loss_giou_aux_1: 1.1634 (1.1979)  loss_vfl_aux_2: 0.6953 (0.7037)  loss_bbox_aux_2: 0.5453 (0.5369)  loss_giou_aux_2: 1.1594 (1.1901)  loss_vfl_aux_3: 0.7172 (0.7171)  loss_bbox_aux_3: 0.5177 (0.5240)  loss_giou_aux_3: 1.1607 (1.1928)  loss_vfl_aux_4: 0.7454 (0.7452)  loss_bbox_aux_4: 0.5383 (0.5331)  loss_giou_aux_4: 1.1642 (1.1919)  loss_vfl_dn_0: 0.9944 (1.0036)  loss_bbox_dn_0: 0.3763 (0.3775)  loss_giou_dn_0: 0.9616 (0.9652)  loss_vfl_dn_1: 0.6863 (0.7052)  loss_bbox_dn_1: 0.3386 (0.3366)  loss_giou_dn_1: 0.9082 (0.9166)  loss_vfl_dn_2: 0.5892 (0.5959)  loss_bbox_dn_2: 0.3431 (0.3442)  loss_giou_dn_2: 0.8914 (0.8982)  loss_vfl_dn_3: 0.5838 (0.5972)  loss_bbox_dn_3: 0.3341 (0.3332)  loss_giou_dn_3: 0.8989 (0.9109)  loss_vfl_dn_4: 0.5447 (0.5529)  loss_bbox_dn_4: 0.3366 (0.3344)  loss_giou_dn_4: 0.8946 (0.9009)  loss_vfl_dn_5: 0.4601 (0.4629)  loss_bbox_dn_5: 0.3366 (0.3344)  loss_giou_dn_5: 0.8938 (0.9010)  loss_vfl_enc_0: 0.9732 (0.9745)  loss_bbox_enc_0: 0.5485 (0.5475)  loss_giou_enc_0: 1.2296 (1.2573)  time: 0.7275  data: 0.2166  max mem: 16811\n",
            "Epoch: [33] Total time: 0:00:05 (0.7326 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 29.3665 (29.3961)  loss_vfl: 0.7436 (0.7398)  loss_bbox: 0.5441 (0.5379)  loss_giou: 1.1657 (1.1873)  loss_vfl_aux_0: 1.1250 (1.1480)  loss_bbox_aux_0: 0.5413 (0.5328)  loss_giou_aux_0: 1.1583 (1.1859)  loss_vfl_aux_1: 0.7350 (0.7602)  loss_bbox_aux_1: 0.5278 (0.5216)  loss_giou_aux_1: 1.1634 (1.1979)  loss_vfl_aux_2: 0.6953 (0.7037)  loss_bbox_aux_2: 0.5453 (0.5369)  loss_giou_aux_2: 1.1594 (1.1901)  loss_vfl_aux_3: 0.7172 (0.7171)  loss_bbox_aux_3: 0.5177 (0.5240)  loss_giou_aux_3: 1.1607 (1.1928)  loss_vfl_aux_4: 0.7454 (0.7452)  loss_bbox_aux_4: 0.5383 (0.5331)  loss_giou_aux_4: 1.1642 (1.1919)  loss_vfl_dn_0: 0.9944 (1.0036)  loss_bbox_dn_0: 0.3763 (0.3775)  loss_giou_dn_0: 0.9616 (0.9652)  loss_vfl_dn_1: 0.6863 (0.7052)  loss_bbox_dn_1: 0.3386 (0.3366)  loss_giou_dn_1: 0.9082 (0.9166)  loss_vfl_dn_2: 0.5892 (0.5959)  loss_bbox_dn_2: 0.3431 (0.3442)  loss_giou_dn_2: 0.8914 (0.8982)  loss_vfl_dn_3: 0.5838 (0.5972)  loss_bbox_dn_3: 0.3341 (0.3332)  loss_giou_dn_3: 0.8989 (0.9109)  loss_vfl_dn_4: 0.5447 (0.5529)  loss_bbox_dn_4: 0.3366 (0.3344)  loss_giou_dn_4: 0.8946 (0.9009)  loss_vfl_dn_5: 0.4601 (0.4629)  loss_bbox_dn_5: 0.3366 (0.3344)  loss_giou_dn_5: 0.8938 (0.9010)  loss_vfl_enc_0: 0.9732 (0.9745)  loss_bbox_enc_0: 0.5485 (0.5475)  loss_giou_enc_0: 1.2296 (1.2573)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4435  data: 1.3251  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4618  data: 0.6789  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4838 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
            "best_stat: {'epoch': 32, 'coco_eval_bbox': 0.040825308686259755}\n",
            "Epoch: [34]  [0/8]  eta: 0:00:20  lr: 0.000001  loss: 30.0881 (30.0881)  loss_vfl: 0.7189 (0.7189)  loss_bbox: 0.6124 (0.6124)  loss_giou: 1.3225 (1.3225)  loss_vfl_aux_0: 1.0347 (1.0347)  loss_bbox_aux_0: 0.5916 (0.5916)  loss_giou_aux_0: 1.3413 (1.3413)  loss_vfl_aux_1: 0.6559 (0.6559)  loss_bbox_aux_1: 0.5935 (0.5935)  loss_giou_aux_1: 1.3313 (1.3313)  loss_vfl_aux_2: 0.6359 (0.6359)  loss_bbox_aux_2: 0.6089 (0.6089)  loss_giou_aux_2: 1.3254 (1.3254)  loss_vfl_aux_3: 0.6638 (0.6638)  loss_bbox_aux_3: 0.5985 (0.5985)  loss_giou_aux_3: 1.3247 (1.3247)  loss_vfl_aux_4: 0.7058 (0.7058)  loss_bbox_aux_4: 0.6140 (0.6140)  loss_giou_aux_4: 1.3239 (1.3239)  loss_vfl_dn_0: 0.9878 (0.9878)  loss_bbox_dn_0: 0.3706 (0.3706)  loss_giou_dn_0: 0.9522 (0.9522)  loss_vfl_dn_1: 0.6473 (0.6473)  loss_bbox_dn_1: 0.3301 (0.3301)  loss_giou_dn_1: 0.9103 (0.9103)  loss_vfl_dn_2: 0.5573 (0.5573)  loss_bbox_dn_2: 0.3341 (0.3341)  loss_giou_dn_2: 0.8937 (0.8937)  loss_vfl_dn_3: 0.5725 (0.5725)  loss_bbox_dn_3: 0.3256 (0.3256)  loss_giou_dn_3: 0.9024 (0.9024)  loss_vfl_dn_4: 0.5338 (0.5338)  loss_bbox_dn_4: 0.3263 (0.3263)  loss_giou_dn_4: 0.8997 (0.8997)  loss_vfl_dn_5: 0.4450 (0.4450)  loss_bbox_dn_5: 0.3262 (0.3262)  loss_giou_dn_5: 0.8993 (0.8993)  loss_vfl_enc_0: 0.8619 (0.8619)  loss_bbox_enc_0: 0.6154 (0.6154)  loss_giou_enc_0: 1.3937 (1.3937)  time: 2.6103  data: 2.0371  max mem: 16811\n",
            "Epoch: [34]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 28.9971 (29.2284)  loss_vfl: 0.8229 (0.8394)  loss_bbox: 0.5328 (0.5407)  loss_giou: 1.1651 (1.1938)  loss_vfl_aux_0: 1.1165 (1.1301)  loss_bbox_aux_0: 0.5152 (0.5296)  loss_giou_aux_0: 1.1603 (1.1850)  loss_vfl_aux_1: 0.7459 (0.7533)  loss_bbox_aux_1: 0.5063 (0.5198)  loss_giou_aux_1: 1.1628 (1.1905)  loss_vfl_aux_2: 0.7574 (0.7658)  loss_bbox_aux_2: 0.5255 (0.5362)  loss_giou_aux_2: 1.1571 (1.1894)  loss_vfl_aux_3: 0.8192 (0.8282)  loss_bbox_aux_3: 0.5160 (0.5247)  loss_giou_aux_3: 1.1701 (1.1956)  loss_vfl_aux_4: 0.8306 (0.8181)  loss_bbox_aux_4: 0.5241 (0.5358)  loss_giou_aux_4: 1.1632 (1.1935)  loss_vfl_dn_0: 1.0079 (1.0105)  loss_bbox_dn_0: 0.3450 (0.3479)  loss_giou_dn_0: 0.9321 (0.9341)  loss_vfl_dn_1: 0.6263 (0.6282)  loss_bbox_dn_1: 0.3129 (0.3182)  loss_giou_dn_1: 0.8909 (0.8958)  loss_vfl_dn_2: 0.5548 (0.5499)  loss_bbox_dn_2: 0.3143 (0.3195)  loss_giou_dn_2: 0.8701 (0.8736)  loss_vfl_dn_3: 0.5466 (0.5531)  loss_bbox_dn_3: 0.3071 (0.3162)  loss_giou_dn_3: 0.9024 (0.8894)  loss_vfl_dn_4: 0.5250 (0.5285)  loss_bbox_dn_4: 0.3094 (0.3159)  loss_giou_dn_4: 0.8880 (0.8783)  loss_vfl_dn_5: 0.4505 (0.4499)  loss_bbox_dn_5: 0.3093 (0.3159)  loss_giou_dn_5: 0.8882 (0.8784)  loss_vfl_enc_0: 0.9484 (0.9587)  loss_bbox_enc_0: 0.5286 (0.5459)  loss_giou_enc_0: 1.2369 (1.2510)  time: 0.8035  data: 0.2881  max mem: 16811\n",
            "Epoch: [34] Total time: 0:00:06 (0.8088 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 28.9971 (29.2284)  loss_vfl: 0.8229 (0.8394)  loss_bbox: 0.5328 (0.5407)  loss_giou: 1.1651 (1.1938)  loss_vfl_aux_0: 1.1165 (1.1301)  loss_bbox_aux_0: 0.5152 (0.5296)  loss_giou_aux_0: 1.1603 (1.1850)  loss_vfl_aux_1: 0.7459 (0.7533)  loss_bbox_aux_1: 0.5063 (0.5198)  loss_giou_aux_1: 1.1628 (1.1905)  loss_vfl_aux_2: 0.7574 (0.7658)  loss_bbox_aux_2: 0.5255 (0.5362)  loss_giou_aux_2: 1.1571 (1.1894)  loss_vfl_aux_3: 0.8192 (0.8282)  loss_bbox_aux_3: 0.5160 (0.5247)  loss_giou_aux_3: 1.1701 (1.1956)  loss_vfl_aux_4: 0.8306 (0.8181)  loss_bbox_aux_4: 0.5241 (0.5358)  loss_giou_aux_4: 1.1632 (1.1935)  loss_vfl_dn_0: 1.0079 (1.0105)  loss_bbox_dn_0: 0.3450 (0.3479)  loss_giou_dn_0: 0.9321 (0.9341)  loss_vfl_dn_1: 0.6263 (0.6282)  loss_bbox_dn_1: 0.3129 (0.3182)  loss_giou_dn_1: 0.8909 (0.8958)  loss_vfl_dn_2: 0.5548 (0.5499)  loss_bbox_dn_2: 0.3143 (0.3195)  loss_giou_dn_2: 0.8701 (0.8736)  loss_vfl_dn_3: 0.5466 (0.5531)  loss_bbox_dn_3: 0.3071 (0.3162)  loss_giou_dn_3: 0.9024 (0.8894)  loss_vfl_dn_4: 0.5250 (0.5285)  loss_bbox_dn_4: 0.3094 (0.3159)  loss_giou_dn_4: 0.8880 (0.8783)  loss_vfl_dn_5: 0.4505 (0.4499)  loss_bbox_dn_5: 0.3093 (0.3159)  loss_giou_dn_5: 0.8882 (0.8784)  loss_vfl_enc_0: 0.9484 (0.9587)  loss_bbox_enc_0: 0.5286 (0.5459)  loss_giou_enc_0: 1.2369 (1.2510)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5175  data: 4.4020  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9957  data: 2.2172  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0229 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
            "best_stat: {'epoch': 34, 'coco_eval_bbox': 0.04293191760398069}\n",
            "Epoch: [35]  [0/8]  eta: 0:00:23  lr: 0.000001  loss: 29.5554 (29.5554)  loss_vfl: 0.7695 (0.7695)  loss_bbox: 0.5434 (0.5434)  loss_giou: 1.1970 (1.1970)  loss_vfl_aux_0: 1.0611 (1.0611)  loss_bbox_aux_0: 0.5414 (0.5414)  loss_giou_aux_0: 1.2023 (1.2023)  loss_vfl_aux_1: 0.7651 (0.7651)  loss_bbox_aux_1: 0.5327 (0.5327)  loss_giou_aux_1: 1.2039 (1.2039)  loss_vfl_aux_2: 0.8178 (0.8178)  loss_bbox_aux_2: 0.5501 (0.5501)  loss_giou_aux_2: 1.1988 (1.1988)  loss_vfl_aux_3: 0.9047 (0.9047)  loss_bbox_aux_3: 0.5357 (0.5357)  loss_giou_aux_3: 1.2076 (1.2076)  loss_vfl_aux_4: 0.8306 (0.8306)  loss_bbox_aux_4: 0.5450 (0.5450)  loss_giou_aux_4: 1.1945 (1.1945)  loss_vfl_dn_0: 0.9478 (0.9478)  loss_bbox_dn_0: 0.3840 (0.3840)  loss_giou_dn_0: 0.9590 (0.9590)  loss_vfl_dn_1: 0.5718 (0.5718)  loss_bbox_dn_1: 0.3533 (0.3533)  loss_giou_dn_1: 0.9266 (0.9266)  loss_vfl_dn_2: 0.5080 (0.5080)  loss_bbox_dn_2: 0.3567 (0.3567)  loss_giou_dn_2: 0.9156 (0.9156)  loss_vfl_dn_3: 0.5058 (0.5058)  loss_bbox_dn_3: 0.3579 (0.3579)  loss_giou_dn_3: 0.9358 (0.9358)  loss_vfl_dn_4: 0.4913 (0.4913)  loss_bbox_dn_4: 0.3581 (0.3581)  loss_giou_dn_4: 0.9272 (0.9272)  loss_vfl_dn_5: 0.4335 (0.4335)  loss_bbox_dn_5: 0.3580 (0.3580)  loss_giou_dn_5: 0.9269 (0.9269)  loss_vfl_enc_0: 0.9079 (0.9079)  loss_bbox_enc_0: 0.5569 (0.5569)  loss_giou_enc_0: 1.2722 (1.2722)  time: 2.9243  data: 2.3482  max mem: 16811\n",
            "Epoch: [35]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 28.6264 (28.7203)  loss_vfl: 0.7695 (0.7851)  loss_bbox: 0.5152 (0.5169)  loss_giou: 1.1775 (1.1615)  loss_vfl_aux_0: 1.1149 (1.1233)  loss_bbox_aux_0: 0.5008 (0.5087)  loss_giou_aux_0: 1.1498 (1.1506)  loss_vfl_aux_1: 0.8359 (0.8498)  loss_bbox_aux_1: 0.5012 (0.4978)  loss_giou_aux_1: 1.1669 (1.1628)  loss_vfl_aux_2: 0.8549 (0.8597)  loss_bbox_aux_2: 0.5094 (0.5100)  loss_giou_aux_2: 1.1765 (1.1637)  loss_vfl_aux_3: 0.9377 (0.9399)  loss_bbox_aux_3: 0.5041 (0.5079)  loss_giou_aux_3: 1.1759 (1.1650)  loss_vfl_aux_4: 0.8554 (0.8624)  loss_bbox_aux_4: 0.5104 (0.5147)  loss_giou_aux_4: 1.1758 (1.1595)  loss_vfl_dn_0: 0.9998 (1.0014)  loss_bbox_dn_0: 0.3284 (0.3289)  loss_giou_dn_0: 0.9060 (0.9043)  loss_vfl_dn_1: 0.5718 (0.5730)  loss_bbox_dn_1: 0.2996 (0.3034)  loss_giou_dn_1: 0.8612 (0.8662)  loss_vfl_dn_2: 0.5248 (0.5281)  loss_bbox_dn_2: 0.2972 (0.2998)  loss_giou_dn_2: 0.8392 (0.8440)  loss_vfl_dn_3: 0.5361 (0.5380)  loss_bbox_dn_3: 0.2942 (0.2981)  loss_giou_dn_3: 0.8497 (0.8542)  loss_vfl_dn_4: 0.5121 (0.5134)  loss_bbox_dn_4: 0.2929 (0.2971)  loss_giou_dn_4: 0.8388 (0.8444)  loss_vfl_dn_5: 0.4522 (0.4533)  loss_bbox_dn_5: 0.2928 (0.2970)  loss_giou_dn_5: 0.8390 (0.8443)  loss_vfl_enc_0: 0.9544 (0.9533)  loss_bbox_enc_0: 0.5130 (0.5218)  loss_giou_enc_0: 1.2122 (1.2167)  time: 0.8381  data: 0.3242  max mem: 16811\n",
            "Epoch: [35] Total time: 0:00:06 (0.8453 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 28.6264 (28.7203)  loss_vfl: 0.7695 (0.7851)  loss_bbox: 0.5152 (0.5169)  loss_giou: 1.1775 (1.1615)  loss_vfl_aux_0: 1.1149 (1.1233)  loss_bbox_aux_0: 0.5008 (0.5087)  loss_giou_aux_0: 1.1498 (1.1506)  loss_vfl_aux_1: 0.8359 (0.8498)  loss_bbox_aux_1: 0.5012 (0.4978)  loss_giou_aux_1: 1.1669 (1.1628)  loss_vfl_aux_2: 0.8549 (0.8597)  loss_bbox_aux_2: 0.5094 (0.5100)  loss_giou_aux_2: 1.1765 (1.1637)  loss_vfl_aux_3: 0.9377 (0.9399)  loss_bbox_aux_3: 0.5041 (0.5079)  loss_giou_aux_3: 1.1759 (1.1650)  loss_vfl_aux_4: 0.8554 (0.8624)  loss_bbox_aux_4: 0.5104 (0.5147)  loss_giou_aux_4: 1.1758 (1.1595)  loss_vfl_dn_0: 0.9998 (1.0014)  loss_bbox_dn_0: 0.3284 (0.3289)  loss_giou_dn_0: 0.9060 (0.9043)  loss_vfl_dn_1: 0.5718 (0.5730)  loss_bbox_dn_1: 0.2996 (0.3034)  loss_giou_dn_1: 0.8612 (0.8662)  loss_vfl_dn_2: 0.5248 (0.5281)  loss_bbox_dn_2: 0.2972 (0.2998)  loss_giou_dn_2: 0.8392 (0.8440)  loss_vfl_dn_3: 0.5361 (0.5380)  loss_bbox_dn_3: 0.2942 (0.2981)  loss_giou_dn_3: 0.8497 (0.8542)  loss_vfl_dn_4: 0.5121 (0.5134)  loss_bbox_dn_4: 0.2929 (0.2971)  loss_giou_dn_4: 0.8388 (0.8444)  loss_vfl_dn_5: 0.4522 (0.4533)  loss_bbox_dn_5: 0.2928 (0.2970)  loss_giou_dn_5: 0.8390 (0.8443)  loss_vfl_enc_0: 0.9544 (0.9533)  loss_bbox_enc_0: 0.5130 (0.5218)  loss_giou_enc_0: 1.2122 (1.2167)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.2916  data: 4.1784  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.8825  data: 2.1054  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9039 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            "best_stat: {'epoch': 35, 'coco_eval_bbox': 0.04953272500753873}\n",
            "Epoch: [36]  [0/8]  eta: 0:00:20  lr: 0.000001  loss: 28.8603 (28.8603)  loss_vfl: 0.7542 (0.7542)  loss_bbox: 0.5298 (0.5298)  loss_giou: 1.1830 (1.1830)  loss_vfl_aux_0: 1.0873 (1.0873)  loss_bbox_aux_0: 0.5194 (0.5194)  loss_giou_aux_0: 1.1785 (1.1785)  loss_vfl_aux_1: 0.9125 (0.9125)  loss_bbox_aux_1: 0.5129 (0.5129)  loss_giou_aux_1: 1.1800 (1.1800)  loss_vfl_aux_2: 0.8764 (0.8764)  loss_bbox_aux_2: 0.5230 (0.5230)  loss_giou_aux_2: 1.1768 (1.1768)  loss_vfl_aux_3: 0.9221 (0.9221)  loss_bbox_aux_3: 0.5121 (0.5121)  loss_giou_aux_3: 1.1869 (1.1869)  loss_vfl_aux_4: 0.8440 (0.8440)  loss_bbox_aux_4: 0.5291 (0.5291)  loss_giou_aux_4: 1.1798 (1.1798)  loss_vfl_dn_0: 0.9837 (0.9837)  loss_bbox_dn_0: 0.3441 (0.3441)  loss_giou_dn_0: 0.9050 (0.9050)  loss_vfl_dn_1: 0.5577 (0.5577)  loss_bbox_dn_1: 0.3040 (0.3040)  loss_giou_dn_1: 0.8545 (0.8545)  loss_vfl_dn_2: 0.5238 (0.5238)  loss_bbox_dn_2: 0.3108 (0.3108)  loss_giou_dn_2: 0.8408 (0.8408)  loss_vfl_dn_3: 0.5427 (0.5427)  loss_bbox_dn_3: 0.3031 (0.3031)  loss_giou_dn_3: 0.8480 (0.8480)  loss_vfl_dn_4: 0.5131 (0.5131)  loss_bbox_dn_4: 0.3030 (0.3030)  loss_giou_dn_4: 0.8385 (0.8385)  loss_vfl_dn_5: 0.4523 (0.4523)  loss_bbox_dn_5: 0.3028 (0.3028)  loss_giou_dn_5: 0.8376 (0.8376)  loss_vfl_enc_0: 0.8911 (0.8911)  loss_bbox_enc_0: 0.5454 (0.5454)  loss_giou_enc_0: 1.2505 (1.2505)  time: 2.5047  data: 1.9310  max mem: 16811\n",
            "Epoch: [36]  [7/8]  eta: 0:00:00  lr: 0.000001  loss: 28.4141 (28.4878)  loss_vfl: 0.7807 (0.7888)  loss_bbox: 0.5298 (0.5205)  loss_giou: 1.1803 (1.1575)  loss_vfl_aux_0: 1.0872 (1.0890)  loss_bbox_aux_0: 0.5105 (0.5077)  loss_giou_aux_0: 1.1584 (1.1480)  loss_vfl_aux_1: 0.9295 (0.9729)  loss_bbox_aux_1: 0.5102 (0.5016)  loss_giou_aux_1: 1.1703 (1.1580)  loss_vfl_aux_2: 0.8749 (0.9069)  loss_bbox_aux_2: 0.5205 (0.5123)  loss_giou_aux_2: 1.1768 (1.1561)  loss_vfl_aux_3: 0.9130 (0.9108)  loss_bbox_aux_3: 0.5173 (0.5093)  loss_giou_aux_3: 1.1834 (1.1626)  loss_vfl_aux_4: 0.8925 (0.9109)  loss_bbox_aux_4: 0.5241 (0.5180)  loss_giou_aux_4: 1.1755 (1.1522)  loss_vfl_dn_0: 0.9551 (0.9641)  loss_bbox_dn_0: 0.3302 (0.3258)  loss_giou_dn_0: 0.8744 (0.8813)  loss_vfl_dn_1: 0.5439 (0.5485)  loss_bbox_dn_1: 0.2917 (0.2931)  loss_giou_dn_1: 0.8254 (0.8307)  loss_vfl_dn_2: 0.5123 (0.5160)  loss_bbox_dn_2: 0.2904 (0.2903)  loss_giou_dn_2: 0.8068 (0.8114)  loss_vfl_dn_3: 0.5317 (0.5385)  loss_bbox_dn_3: 0.2862 (0.2869)  loss_giou_dn_3: 0.8110 (0.8167)  loss_vfl_dn_4: 0.4984 (0.5006)  loss_bbox_dn_4: 0.2860 (0.2865)  loss_giou_dn_4: 0.8034 (0.8101)  loss_vfl_dn_5: 0.4550 (0.4568)  loss_bbox_dn_5: 0.2859 (0.2864)  loss_giou_dn_5: 0.8032 (0.8095)  loss_vfl_enc_0: 0.8920 (0.9189)  loss_bbox_enc_0: 0.5287 (0.5267)  loss_giou_enc_0: 1.2048 (1.2058)  time: 0.7847  data: 0.2701  max mem: 16811\n",
            "Epoch: [36] Total time: 0:00:06 (0.7906 s / it)\n",
            "Averaged stats: lr: 0.000001  loss: 28.4141 (28.4878)  loss_vfl: 0.7807 (0.7888)  loss_bbox: 0.5298 (0.5205)  loss_giou: 1.1803 (1.1575)  loss_vfl_aux_0: 1.0872 (1.0890)  loss_bbox_aux_0: 0.5105 (0.5077)  loss_giou_aux_0: 1.1584 (1.1480)  loss_vfl_aux_1: 0.9295 (0.9729)  loss_bbox_aux_1: 0.5102 (0.5016)  loss_giou_aux_1: 1.1703 (1.1580)  loss_vfl_aux_2: 0.8749 (0.9069)  loss_bbox_aux_2: 0.5205 (0.5123)  loss_giou_aux_2: 1.1768 (1.1561)  loss_vfl_aux_3: 0.9130 (0.9108)  loss_bbox_aux_3: 0.5173 (0.5093)  loss_giou_aux_3: 1.1834 (1.1626)  loss_vfl_aux_4: 0.8925 (0.9109)  loss_bbox_aux_4: 0.5241 (0.5180)  loss_giou_aux_4: 1.1755 (1.1522)  loss_vfl_dn_0: 0.9551 (0.9641)  loss_bbox_dn_0: 0.3302 (0.3258)  loss_giou_dn_0: 0.8744 (0.8813)  loss_vfl_dn_1: 0.5439 (0.5485)  loss_bbox_dn_1: 0.2917 (0.2931)  loss_giou_dn_1: 0.8254 (0.8307)  loss_vfl_dn_2: 0.5123 (0.5160)  loss_bbox_dn_2: 0.2904 (0.2903)  loss_giou_dn_2: 0.8068 (0.8114)  loss_vfl_dn_3: 0.5317 (0.5385)  loss_bbox_dn_3: 0.2862 (0.2869)  loss_giou_dn_3: 0.8110 (0.8167)  loss_vfl_dn_4: 0.4984 (0.5006)  loss_bbox_dn_4: 0.2860 (0.2865)  loss_giou_dn_4: 0.8034 (0.8101)  loss_vfl_dn_5: 0.4550 (0.4568)  loss_bbox_dn_5: 0.2859 (0.2864)  loss_giou_dn_5: 0.8032 (0.8095)  loss_vfl_enc_0: 0.8920 (0.9189)  loss_bbox_enc_0: 0.5287 (0.5267)  loss_giou_enc_0: 1.2048 (1.2058)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.8431  data: 3.7259  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.8279  data: 1.8789  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8570 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n",
            "best_stat: {'epoch': 36, 'coco_eval_bbox': 0.0538973200939786}\n",
            "Epoch: [37]  [0/8]  eta: 0:00:23  lr: 0.000001  loss: 29.1755 (29.1755)  loss_vfl: 0.7642 (0.7642)  loss_bbox: 0.5940 (0.5940)  loss_giou: 1.2736 (1.2736)  loss_vfl_aux_0: 1.0181 (1.0181)  loss_bbox_aux_0: 0.5690 (0.5690)  loss_giou_aux_0: 1.2770 (1.2770)  loss_vfl_aux_1: 0.9763 (0.9763)  loss_bbox_aux_1: 0.5660 (0.5660)  loss_giou_aux_1: 1.2890 (1.2890)  loss_vfl_aux_2: 0.8659 (0.8659)  loss_bbox_aux_2: 0.5773 (0.5773)  loss_giou_aux_2: 1.2820 (1.2820)  loss_vfl_aux_3: 0.8042 (0.8042)  loss_bbox_aux_3: 0.5737 (0.5737)  loss_giou_aux_3: 1.2874 (1.2874)  loss_vfl_aux_4: 0.9036 (0.9036)  loss_bbox_aux_4: 0.5838 (0.5838)  loss_giou_aux_4: 1.2743 (1.2743)  loss_vfl_dn_0: 0.9574 (0.9574)  loss_bbox_dn_0: 0.2892 (0.2892)  loss_giou_dn_0: 0.8634 (0.8634)  loss_vfl_dn_1: 0.5544 (0.5544)  loss_bbox_dn_1: 0.2548 (0.2548)  loss_giou_dn_1: 0.8031 (0.8031)  loss_vfl_dn_2: 0.5252 (0.5252)  loss_bbox_dn_2: 0.2515 (0.2515)  loss_giou_dn_2: 0.7862 (0.7862)  loss_vfl_dn_3: 0.5693 (0.5693)  loss_bbox_dn_3: 0.2501 (0.2501)  loss_giou_dn_3: 0.7891 (0.7891)  loss_vfl_dn_4: 0.5139 (0.5139)  loss_bbox_dn_4: 0.2486 (0.2486)  loss_giou_dn_4: 0.7837 (0.7837)  loss_vfl_dn_5: 0.4655 (0.4655)  loss_bbox_dn_5: 0.2484 (0.2484)  loss_giou_dn_5: 0.7820 (0.7820)  loss_vfl_enc_0: 0.8434 (0.8434)  loss_bbox_enc_0: 0.5780 (0.5780)  loss_giou_enc_0: 1.3388 (1.3388)  time: 2.9707  data: 2.4251  max mem: 16811\n",
            "Epoch: [37]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 27.2689 (27.5372)  loss_vfl: 0.7861 (0.7802)  loss_bbox: 0.4815 (0.5032)  loss_giou: 1.0895 (1.1303)  loss_vfl_aux_0: 1.0315 (1.0517)  loss_bbox_aux_0: 0.4668 (0.4872)  loss_giou_aux_0: 1.0729 (1.1211)  loss_vfl_aux_1: 0.9750 (0.9456)  loss_bbox_aux_1: 0.4607 (0.4827)  loss_giou_aux_1: 1.0839 (1.1314)  loss_vfl_aux_2: 0.8659 (0.8624)  loss_bbox_aux_2: 0.4769 (0.4946)  loss_giou_aux_2: 1.0851 (1.1264)  loss_vfl_aux_3: 0.8056 (0.8156)  loss_bbox_aux_3: 0.4748 (0.4948)  loss_giou_aux_3: 1.0928 (1.1327)  loss_vfl_aux_4: 0.9036 (0.8773)  loss_bbox_aux_4: 0.4729 (0.4989)  loss_giou_aux_4: 1.0927 (1.1275)  loss_vfl_dn_0: 0.9367 (0.9340)  loss_bbox_dn_0: 0.3085 (0.3069)  loss_giou_dn_0: 0.8452 (0.8478)  loss_vfl_dn_1: 0.5512 (0.5513)  loss_bbox_dn_1: 0.2765 (0.2724)  loss_giou_dn_1: 0.7887 (0.7924)  loss_vfl_dn_2: 0.5171 (0.5173)  loss_bbox_dn_2: 0.2745 (0.2708)  loss_giou_dn_2: 0.7724 (0.7770)  loss_vfl_dn_3: 0.5420 (0.5458)  loss_bbox_dn_3: 0.2680 (0.2668)  loss_giou_dn_3: 0.7722 (0.7795)  loss_vfl_dn_4: 0.4977 (0.5029)  loss_bbox_dn_4: 0.2656 (0.2657)  loss_giou_dn_4: 0.7697 (0.7747)  loss_vfl_dn_5: 0.4655 (0.4649)  loss_bbox_dn_5: 0.2656 (0.2656)  loss_giou_dn_5: 0.7683 (0.7740)  loss_vfl_enc_0: 0.8846 (0.8810)  loss_bbox_enc_0: 0.4835 (0.5064)  loss_giou_enc_0: 1.1216 (1.1767)  time: 0.8441  data: 0.3322  max mem: 16811\n",
            "Epoch: [37] Total time: 0:00:06 (0.8520 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 27.2689 (27.5372)  loss_vfl: 0.7861 (0.7802)  loss_bbox: 0.4815 (0.5032)  loss_giou: 1.0895 (1.1303)  loss_vfl_aux_0: 1.0315 (1.0517)  loss_bbox_aux_0: 0.4668 (0.4872)  loss_giou_aux_0: 1.0729 (1.1211)  loss_vfl_aux_1: 0.9750 (0.9456)  loss_bbox_aux_1: 0.4607 (0.4827)  loss_giou_aux_1: 1.0839 (1.1314)  loss_vfl_aux_2: 0.8659 (0.8624)  loss_bbox_aux_2: 0.4769 (0.4946)  loss_giou_aux_2: 1.0851 (1.1264)  loss_vfl_aux_3: 0.8056 (0.8156)  loss_bbox_aux_3: 0.4748 (0.4948)  loss_giou_aux_3: 1.0928 (1.1327)  loss_vfl_aux_4: 0.9036 (0.8773)  loss_bbox_aux_4: 0.4729 (0.4989)  loss_giou_aux_4: 1.0927 (1.1275)  loss_vfl_dn_0: 0.9367 (0.9340)  loss_bbox_dn_0: 0.3085 (0.3069)  loss_giou_dn_0: 0.8452 (0.8478)  loss_vfl_dn_1: 0.5512 (0.5513)  loss_bbox_dn_1: 0.2765 (0.2724)  loss_giou_dn_1: 0.7887 (0.7924)  loss_vfl_dn_2: 0.5171 (0.5173)  loss_bbox_dn_2: 0.2745 (0.2708)  loss_giou_dn_2: 0.7724 (0.7770)  loss_vfl_dn_3: 0.5420 (0.5458)  loss_bbox_dn_3: 0.2680 (0.2668)  loss_giou_dn_3: 0.7722 (0.7795)  loss_vfl_dn_4: 0.4977 (0.5029)  loss_bbox_dn_4: 0.2656 (0.2657)  loss_giou_dn_4: 0.7697 (0.7747)  loss_vfl_dn_5: 0.4655 (0.4649)  loss_bbox_dn_5: 0.2656 (0.2656)  loss_giou_dn_5: 0.7683 (0.7740)  loss_vfl_enc_0: 0.8846 (0.8810)  loss_bbox_enc_0: 0.4835 (0.5064)  loss_giou_enc_0: 1.1216 (1.1767)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5192  data: 1.3996  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4965  data: 0.7158  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.5230 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.139\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
            "best_stat: {'epoch': 37, 'coco_eval_bbox': 0.06834710015079842}\n",
            "Epoch: [38]  [0/8]  eta: 0:00:18  lr: 0.000002  loss: 27.2980 (27.2980)  loss_vfl: 0.8339 (0.8339)  loss_bbox: 0.4978 (0.4978)  loss_giou: 1.1183 (1.1183)  loss_vfl_aux_0: 1.0861 (1.0861)  loss_bbox_aux_0: 0.4789 (0.4789)  loss_giou_aux_0: 1.0956 (1.0956)  loss_vfl_aux_1: 0.9498 (0.9498)  loss_bbox_aux_1: 0.4796 (0.4796)  loss_giou_aux_1: 1.1192 (1.1192)  loss_vfl_aux_2: 0.8819 (0.8819)  loss_bbox_aux_2: 0.4915 (0.4915)  loss_giou_aux_2: 1.1245 (1.1245)  loss_vfl_aux_3: 0.8253 (0.8253)  loss_bbox_aux_3: 0.4963 (0.4963)  loss_giou_aux_3: 1.1227 (1.1227)  loss_vfl_aux_4: 0.9049 (0.9049)  loss_bbox_aux_4: 0.5045 (0.5045)  loss_giou_aux_4: 1.1078 (1.1078)  loss_vfl_dn_0: 0.9405 (0.9405)  loss_bbox_dn_0: 0.2765 (0.2765)  loss_giou_dn_0: 0.8186 (0.8186)  loss_vfl_dn_1: 0.5666 (0.5666)  loss_bbox_dn_1: 0.2461 (0.2461)  loss_giou_dn_1: 0.7638 (0.7638)  loss_vfl_dn_2: 0.5196 (0.5196)  loss_bbox_dn_2: 0.2444 (0.2444)  loss_giou_dn_2: 0.7512 (0.7512)  loss_vfl_dn_3: 0.5416 (0.5416)  loss_bbox_dn_3: 0.2402 (0.2402)  loss_giou_dn_3: 0.7561 (0.7561)  loss_vfl_dn_4: 0.5059 (0.5059)  loss_bbox_dn_4: 0.2388 (0.2388)  loss_giou_dn_4: 0.7516 (0.7516)  loss_vfl_dn_5: 0.4745 (0.4745)  loss_bbox_dn_5: 0.2388 (0.2388)  loss_giou_dn_5: 0.7503 (0.7503)  loss_vfl_enc_0: 0.9039 (0.9039)  loss_bbox_enc_0: 0.5062 (0.5062)  loss_giou_enc_0: 1.1442 (1.1442)  time: 2.3285  data: 1.7863  max mem: 16811\n",
            "Epoch: [38]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 26.6600 (26.7324)  loss_vfl: 0.7793 (0.7728)  loss_bbox: 0.4731 (0.4945)  loss_giou: 1.0779 (1.1016)  loss_vfl_aux_0: 1.0289 (1.0262)  loss_bbox_aux_0: 0.4552 (0.4777)  loss_giou_aux_0: 1.0677 (1.0897)  loss_vfl_aux_1: 0.8996 (0.8977)  loss_bbox_aux_1: 0.4491 (0.4761)  loss_giou_aux_1: 1.0735 (1.1005)  loss_vfl_aux_2: 0.8406 (0.8376)  loss_bbox_aux_2: 0.4584 (0.4821)  loss_giou_aux_2: 1.0733 (1.0975)  loss_vfl_aux_3: 0.7873 (0.7843)  loss_bbox_aux_3: 0.4681 (0.4904)  loss_giou_aux_3: 1.0823 (1.1084)  loss_vfl_aux_4: 0.8416 (0.8404)  loss_bbox_aux_4: 0.4689 (0.4918)  loss_giou_aux_4: 1.0808 (1.0956)  loss_vfl_dn_0: 0.8806 (0.8884)  loss_bbox_dn_0: 0.2892 (0.2953)  loss_giou_dn_0: 0.8186 (0.8231)  loss_vfl_dn_1: 0.5563 (0.5560)  loss_bbox_dn_1: 0.2461 (0.2581)  loss_giou_dn_1: 0.7547 (0.7567)  loss_vfl_dn_2: 0.5167 (0.5131)  loss_bbox_dn_2: 0.2482 (0.2568)  loss_giou_dn_2: 0.7383 (0.7428)  loss_vfl_dn_3: 0.5293 (0.5286)  loss_bbox_dn_3: 0.2426 (0.2533)  loss_giou_dn_3: 0.7400 (0.7464)  loss_vfl_dn_4: 0.5059 (0.5021)  loss_bbox_dn_4: 0.2409 (0.2522)  loss_giou_dn_4: 0.7332 (0.7414)  loss_vfl_dn_5: 0.4719 (0.4693)  loss_bbox_dn_5: 0.2406 (0.2522)  loss_giou_dn_5: 0.7325 (0.7412)  loss_vfl_enc_0: 0.8535 (0.8488)  loss_bbox_enc_0: 0.4843 (0.4998)  loss_giou_enc_0: 1.1169 (1.1417)  time: 0.7574  data: 0.2437  max mem: 16811\n",
            "Epoch: [38] Total time: 0:00:06 (0.7646 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 26.6600 (26.7324)  loss_vfl: 0.7793 (0.7728)  loss_bbox: 0.4731 (0.4945)  loss_giou: 1.0779 (1.1016)  loss_vfl_aux_0: 1.0289 (1.0262)  loss_bbox_aux_0: 0.4552 (0.4777)  loss_giou_aux_0: 1.0677 (1.0897)  loss_vfl_aux_1: 0.8996 (0.8977)  loss_bbox_aux_1: 0.4491 (0.4761)  loss_giou_aux_1: 1.0735 (1.1005)  loss_vfl_aux_2: 0.8406 (0.8376)  loss_bbox_aux_2: 0.4584 (0.4821)  loss_giou_aux_2: 1.0733 (1.0975)  loss_vfl_aux_3: 0.7873 (0.7843)  loss_bbox_aux_3: 0.4681 (0.4904)  loss_giou_aux_3: 1.0823 (1.1084)  loss_vfl_aux_4: 0.8416 (0.8404)  loss_bbox_aux_4: 0.4689 (0.4918)  loss_giou_aux_4: 1.0808 (1.0956)  loss_vfl_dn_0: 0.8806 (0.8884)  loss_bbox_dn_0: 0.2892 (0.2953)  loss_giou_dn_0: 0.8186 (0.8231)  loss_vfl_dn_1: 0.5563 (0.5560)  loss_bbox_dn_1: 0.2461 (0.2581)  loss_giou_dn_1: 0.7547 (0.7567)  loss_vfl_dn_2: 0.5167 (0.5131)  loss_bbox_dn_2: 0.2482 (0.2568)  loss_giou_dn_2: 0.7383 (0.7428)  loss_vfl_dn_3: 0.5293 (0.5286)  loss_bbox_dn_3: 0.2426 (0.2533)  loss_giou_dn_3: 0.7400 (0.7464)  loss_vfl_dn_4: 0.5059 (0.5021)  loss_bbox_dn_4: 0.2409 (0.2522)  loss_giou_dn_4: 0.7332 (0.7414)  loss_vfl_dn_5: 0.4719 (0.4693)  loss_bbox_dn_5: 0.2406 (0.2522)  loss_giou_dn_5: 0.7325 (0.7412)  loss_vfl_enc_0: 0.8535 (0.8488)  loss_bbox_enc_0: 0.4843 (0.4998)  loss_giou_enc_0: 1.1169 (1.1417)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8845  data: 4.4397  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1775  data: 2.2361  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.2102 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
            "best_stat: {'epoch': 38, 'coco_eval_bbox': 0.07570889991508672}\n",
            "Epoch: [39]  [0/8]  eta: 0:00:20  lr: 0.000002  loss: 26.7209 (26.7209)  loss_vfl: 0.7039 (0.7039)  loss_bbox: 0.5459 (0.5459)  loss_giou: 1.1633 (1.1633)  loss_vfl_aux_0: 0.9808 (0.9808)  loss_bbox_aux_0: 0.5191 (0.5191)  loss_giou_aux_0: 1.1412 (1.1412)  loss_vfl_aux_1: 0.8342 (0.8342)  loss_bbox_aux_1: 0.5190 (0.5190)  loss_giou_aux_1: 1.1631 (1.1631)  loss_vfl_aux_2: 0.7833 (0.7833)  loss_bbox_aux_2: 0.5297 (0.5297)  loss_giou_aux_2: 1.1601 (1.1601)  loss_vfl_aux_3: 0.7231 (0.7231)  loss_bbox_aux_3: 0.5368 (0.5368)  loss_giou_aux_3: 1.1704 (1.1704)  loss_vfl_aux_4: 0.7558 (0.7558)  loss_bbox_aux_4: 0.5421 (0.5421)  loss_giou_aux_4: 1.1581 (1.1581)  loss_vfl_dn_0: 0.8621 (0.8621)  loss_bbox_dn_0: 0.2829 (0.2829)  loss_giou_dn_0: 0.7986 (0.7986)  loss_vfl_dn_1: 0.5579 (0.5579)  loss_bbox_dn_1: 0.2400 (0.2400)  loss_giou_dn_1: 0.7293 (0.7293)  loss_vfl_dn_2: 0.5066 (0.5066)  loss_bbox_dn_2: 0.2371 (0.2371)  loss_giou_dn_2: 0.7143 (0.7143)  loss_vfl_dn_3: 0.5171 (0.5171)  loss_bbox_dn_3: 0.2336 (0.2336)  loss_giou_dn_3: 0.7132 (0.7132)  loss_vfl_dn_4: 0.5040 (0.5040)  loss_bbox_dn_4: 0.2308 (0.2308)  loss_giou_dn_4: 0.7046 (0.7046)  loss_vfl_dn_5: 0.4740 (0.4740)  loss_bbox_dn_5: 0.2312 (0.2312)  loss_giou_dn_5: 0.7059 (0.7059)  loss_vfl_enc_0: 0.8181 (0.8181)  loss_bbox_enc_0: 0.5391 (0.5391)  loss_giou_enc_0: 1.1904 (1.1904)  time: 2.5801  data: 1.9877  max mem: 16811\n",
            "Epoch: [39]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 26.0165 (26.2167)  loss_vfl: 0.7129 (0.7316)  loss_bbox: 0.4830 (0.4951)  loss_giou: 1.1061 (1.0977)  loss_vfl_aux_0: 0.9766 (0.9757)  loss_bbox_aux_0: 0.4711 (0.4750)  loss_giou_aux_0: 1.0743 (1.0759)  loss_vfl_aux_1: 0.8674 (0.8777)  loss_bbox_aux_1: 0.4728 (0.4744)  loss_giou_aux_1: 1.0865 (1.0857)  loss_vfl_aux_2: 0.8593 (0.8584)  loss_bbox_aux_2: 0.4773 (0.4832)  loss_giou_aux_2: 1.0864 (1.0829)  loss_vfl_aux_3: 0.7671 (0.7718)  loss_bbox_aux_3: 0.4836 (0.4927)  loss_giou_aux_3: 1.1100 (1.1003)  loss_vfl_aux_4: 0.7915 (0.8059)  loss_bbox_aux_4: 0.4805 (0.4892)  loss_giou_aux_4: 1.0990 (1.0883)  loss_vfl_dn_0: 0.8341 (0.8254)  loss_bbox_dn_0: 0.2829 (0.2866)  loss_giou_dn_0: 0.7986 (0.8050)  loss_vfl_dn_1: 0.5378 (0.5400)  loss_bbox_dn_1: 0.2503 (0.2534)  loss_giou_dn_1: 0.7359 (0.7459)  loss_vfl_dn_2: 0.4882 (0.4914)  loss_bbox_dn_2: 0.2480 (0.2512)  loss_giou_dn_2: 0.7188 (0.7315)  loss_vfl_dn_3: 0.5002 (0.4978)  loss_bbox_dn_3: 0.2438 (0.2483)  loss_giou_dn_3: 0.7220 (0.7336)  loss_vfl_dn_4: 0.4886 (0.4885)  loss_bbox_dn_4: 0.2454 (0.2484)  loss_giou_dn_4: 0.7196 (0.7320)  loss_vfl_dn_5: 0.4601 (0.4649)  loss_bbox_dn_5: 0.2452 (0.2484)  loss_giou_dn_5: 0.7202 (0.7316)  loss_vfl_enc_0: 0.8014 (0.8082)  loss_bbox_enc_0: 0.4902 (0.4985)  loss_giou_enc_0: 1.1033 (1.1244)  time: 0.8006  data: 0.2805  max mem: 16811\n",
            "Epoch: [39] Total time: 0:00:06 (0.8085 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 26.0165 (26.2167)  loss_vfl: 0.7129 (0.7316)  loss_bbox: 0.4830 (0.4951)  loss_giou: 1.1061 (1.0977)  loss_vfl_aux_0: 0.9766 (0.9757)  loss_bbox_aux_0: 0.4711 (0.4750)  loss_giou_aux_0: 1.0743 (1.0759)  loss_vfl_aux_1: 0.8674 (0.8777)  loss_bbox_aux_1: 0.4728 (0.4744)  loss_giou_aux_1: 1.0865 (1.0857)  loss_vfl_aux_2: 0.8593 (0.8584)  loss_bbox_aux_2: 0.4773 (0.4832)  loss_giou_aux_2: 1.0864 (1.0829)  loss_vfl_aux_3: 0.7671 (0.7718)  loss_bbox_aux_3: 0.4836 (0.4927)  loss_giou_aux_3: 1.1100 (1.1003)  loss_vfl_aux_4: 0.7915 (0.8059)  loss_bbox_aux_4: 0.4805 (0.4892)  loss_giou_aux_4: 1.0990 (1.0883)  loss_vfl_dn_0: 0.8341 (0.8254)  loss_bbox_dn_0: 0.2829 (0.2866)  loss_giou_dn_0: 0.7986 (0.8050)  loss_vfl_dn_1: 0.5378 (0.5400)  loss_bbox_dn_1: 0.2503 (0.2534)  loss_giou_dn_1: 0.7359 (0.7459)  loss_vfl_dn_2: 0.4882 (0.4914)  loss_bbox_dn_2: 0.2480 (0.2512)  loss_giou_dn_2: 0.7188 (0.7315)  loss_vfl_dn_3: 0.5002 (0.4978)  loss_bbox_dn_3: 0.2438 (0.2483)  loss_giou_dn_3: 0.7220 (0.7336)  loss_vfl_dn_4: 0.4886 (0.4885)  loss_bbox_dn_4: 0.2454 (0.2484)  loss_giou_dn_4: 0.7196 (0.7320)  loss_vfl_dn_5: 0.4601 (0.4649)  loss_bbox_dn_5: 0.2452 (0.2484)  loss_giou_dn_5: 0.7202 (0.7316)  loss_vfl_enc_0: 0.8014 (0.8082)  loss_bbox_enc_0: 0.4902 (0.4985)  loss_giou_enc_0: 1.1033 (1.1244)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.2858  data: 4.1799  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.8779  data: 2.1067  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8957 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.117\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            "best_stat: {'epoch': 39, 'coco_eval_bbox': 0.07812336778972978}\n",
            "Epoch: [40]  [0/8]  eta: 0:00:23  lr: 0.000002  loss: 25.2930 (25.2930)  loss_vfl: 0.7281 (0.7281)  loss_bbox: 0.4292 (0.4292)  loss_giou: 1.0574 (1.0574)  loss_vfl_aux_0: 0.9350 (0.9350)  loss_bbox_aux_0: 0.4201 (0.4201)  loss_giou_aux_0: 1.0348 (1.0348)  loss_vfl_aux_1: 0.8565 (0.8565)  loss_bbox_aux_1: 0.4133 (0.4133)  loss_giou_aux_1: 1.0417 (1.0417)  loss_vfl_aux_2: 0.8599 (0.8599)  loss_bbox_aux_2: 0.4242 (0.4242)  loss_giou_aux_2: 1.0354 (1.0354)  loss_vfl_aux_3: 0.7640 (0.7640)  loss_bbox_aux_3: 0.4189 (0.4189)  loss_giou_aux_3: 1.0598 (1.0598)  loss_vfl_aux_4: 0.8040 (0.8040)  loss_bbox_aux_4: 0.4268 (0.4268)  loss_giou_aux_4: 1.0453 (1.0453)  loss_vfl_dn_0: 0.7722 (0.7722)  loss_bbox_dn_0: 0.2697 (0.2697)  loss_giou_dn_0: 0.8191 (0.8191)  loss_vfl_dn_1: 0.5278 (0.5278)  loss_bbox_dn_1: 0.2359 (0.2359)  loss_giou_dn_1: 0.7639 (0.7639)  loss_vfl_dn_2: 0.4867 (0.4867)  loss_bbox_dn_2: 0.2365 (0.2365)  loss_giou_dn_2: 0.7481 (0.7481)  loss_vfl_dn_3: 0.4858 (0.4858)  loss_bbox_dn_3: 0.2330 (0.2330)  loss_giou_dn_3: 0.7487 (0.7487)  loss_vfl_dn_4: 0.4871 (0.4871)  loss_bbox_dn_4: 0.2329 (0.2329)  loss_giou_dn_4: 0.7430 (0.7430)  loss_vfl_dn_5: 0.4682 (0.4682)  loss_bbox_dn_5: 0.2331 (0.2331)  loss_giou_dn_5: 0.7420 (0.7420)  loss_vfl_enc_0: 0.7934 (0.7934)  loss_bbox_enc_0: 0.4349 (0.4349)  loss_giou_enc_0: 1.0764 (1.0764)  time: 2.9930  data: 2.4087  max mem: 16811\n",
            "Epoch: [40]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 25.2930 (25.4682)  loss_vfl: 0.7103 (0.7044)  loss_bbox: 0.4575 (0.4759)  loss_giou: 1.0574 (1.0690)  loss_vfl_aux_0: 0.9260 (0.9370)  loss_bbox_aux_0: 0.4387 (0.4545)  loss_giou_aux_0: 1.0328 (1.0501)  loss_vfl_aux_1: 0.8886 (0.8676)  loss_bbox_aux_1: 0.4429 (0.4556)  loss_giou_aux_1: 1.0417 (1.0597)  loss_vfl_aux_2: 0.8599 (0.8514)  loss_bbox_aux_2: 0.4424 (0.4617)  loss_giou_aux_2: 1.0354 (1.0540)  loss_vfl_aux_3: 0.7471 (0.7278)  loss_bbox_aux_3: 0.4561 (0.4695)  loss_giou_aux_3: 1.0598 (1.0747)  loss_vfl_aux_4: 0.7855 (0.7837)  loss_bbox_aux_4: 0.4513 (0.4679)  loss_giou_aux_4: 1.0453 (1.0571)  loss_vfl_dn_0: 0.7492 (0.7596)  loss_bbox_dn_0: 0.2722 (0.2778)  loss_giou_dn_0: 0.8097 (0.7930)  loss_vfl_dn_1: 0.5231 (0.5247)  loss_bbox_dn_1: 0.2493 (0.2505)  loss_giou_dn_1: 0.7447 (0.7360)  loss_vfl_dn_2: 0.4724 (0.4786)  loss_bbox_dn_2: 0.2477 (0.2462)  loss_giou_dn_2: 0.7196 (0.7192)  loss_vfl_dn_3: 0.4709 (0.4781)  loss_bbox_dn_3: 0.2431 (0.2433)  loss_giou_dn_3: 0.7198 (0.7207)  loss_vfl_dn_4: 0.4723 (0.4773)  loss_bbox_dn_4: 0.2415 (0.2433)  loss_giou_dn_4: 0.7176 (0.7192)  loss_vfl_dn_5: 0.4521 (0.4576)  loss_bbox_dn_5: 0.2412 (0.2431)  loss_giou_dn_5: 0.7171 (0.7182)  loss_vfl_enc_0: 0.7934 (0.7919)  loss_bbox_enc_0: 0.4554 (0.4737)  loss_giou_enc_0: 1.0677 (1.0947)  time: 0.8497  data: 0.3280  max mem: 16811\n",
            "Epoch: [40] Total time: 0:00:06 (0.8559 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 25.2930 (25.4682)  loss_vfl: 0.7103 (0.7044)  loss_bbox: 0.4575 (0.4759)  loss_giou: 1.0574 (1.0690)  loss_vfl_aux_0: 0.9260 (0.9370)  loss_bbox_aux_0: 0.4387 (0.4545)  loss_giou_aux_0: 1.0328 (1.0501)  loss_vfl_aux_1: 0.8886 (0.8676)  loss_bbox_aux_1: 0.4429 (0.4556)  loss_giou_aux_1: 1.0417 (1.0597)  loss_vfl_aux_2: 0.8599 (0.8514)  loss_bbox_aux_2: 0.4424 (0.4617)  loss_giou_aux_2: 1.0354 (1.0540)  loss_vfl_aux_3: 0.7471 (0.7278)  loss_bbox_aux_3: 0.4561 (0.4695)  loss_giou_aux_3: 1.0598 (1.0747)  loss_vfl_aux_4: 0.7855 (0.7837)  loss_bbox_aux_4: 0.4513 (0.4679)  loss_giou_aux_4: 1.0453 (1.0571)  loss_vfl_dn_0: 0.7492 (0.7596)  loss_bbox_dn_0: 0.2722 (0.2778)  loss_giou_dn_0: 0.8097 (0.7930)  loss_vfl_dn_1: 0.5231 (0.5247)  loss_bbox_dn_1: 0.2493 (0.2505)  loss_giou_dn_1: 0.7447 (0.7360)  loss_vfl_dn_2: 0.4724 (0.4786)  loss_bbox_dn_2: 0.2477 (0.2462)  loss_giou_dn_2: 0.7196 (0.7192)  loss_vfl_dn_3: 0.4709 (0.4781)  loss_bbox_dn_3: 0.2431 (0.2433)  loss_giou_dn_3: 0.7198 (0.7207)  loss_vfl_dn_4: 0.4723 (0.4773)  loss_bbox_dn_4: 0.2415 (0.2433)  loss_giou_dn_4: 0.7176 (0.7192)  loss_vfl_dn_5: 0.4521 (0.4576)  loss_bbox_dn_5: 0.2412 (0.2431)  loss_giou_dn_5: 0.7171 (0.7182)  loss_vfl_enc_0: 0.7934 (0.7919)  loss_bbox_enc_0: 0.4554 (0.4737)  loss_giou_enc_0: 1.0677 (1.0947)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4479  data: 1.3473  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4559  data: 0.6896  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.9713 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.129\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
            "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.0890253743794248}\n",
            "Epoch: [41]  [0/8]  eta: 0:00:23  lr: 0.000002  loss: 26.3533 (26.3533)  loss_vfl: 0.6269 (0.6269)  loss_bbox: 0.5220 (0.5220)  loss_giou: 1.1714 (1.1714)  loss_vfl_aux_0: 0.8130 (0.8130)  loss_bbox_aux_0: 0.5110 (0.5110)  loss_giou_aux_0: 1.1671 (1.1671)  loss_vfl_aux_1: 0.8288 (0.8288)  loss_bbox_aux_1: 0.5106 (0.5106)  loss_giou_aux_1: 1.1764 (1.1764)  loss_vfl_aux_2: 0.8038 (0.8038)  loss_bbox_aux_2: 0.5085 (0.5085)  loss_giou_aux_2: 1.1633 (1.1633)  loss_vfl_aux_3: 0.6483 (0.6483)  loss_bbox_aux_3: 0.5211 (0.5211)  loss_giou_aux_3: 1.1753 (1.1753)  loss_vfl_aux_4: 0.7126 (0.7126)  loss_bbox_aux_4: 0.5168 (0.5168)  loss_giou_aux_4: 1.1637 (1.1637)  loss_vfl_dn_0: 0.6903 (0.6903)  loss_bbox_dn_0: 0.2955 (0.2955)  loss_giou_dn_0: 0.8307 (0.8307)  loss_vfl_dn_1: 0.5132 (0.5132)  loss_bbox_dn_1: 0.2693 (0.2693)  loss_giou_dn_1: 0.7803 (0.7803)  loss_vfl_dn_2: 0.4682 (0.4682)  loss_bbox_dn_2: 0.2680 (0.2680)  loss_giou_dn_2: 0.7651 (0.7651)  loss_vfl_dn_3: 0.4668 (0.4668)  loss_bbox_dn_3: 0.2652 (0.2652)  loss_giou_dn_3: 0.7643 (0.7643)  loss_vfl_dn_4: 0.4665 (0.4665)  loss_bbox_dn_4: 0.2659 (0.2659)  loss_giou_dn_4: 0.7671 (0.7671)  loss_vfl_dn_5: 0.4543 (0.4543)  loss_bbox_dn_5: 0.2655 (0.2655)  loss_giou_dn_5: 0.7658 (0.7658)  loss_vfl_enc_0: 0.7078 (0.7078)  loss_bbox_enc_0: 0.5306 (0.5306)  loss_giou_enc_0: 1.2123 (1.2123)  time: 2.9503  data: 2.3740  max mem: 16811\n",
            "Epoch: [41]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 24.6352 (24.7313)  loss_vfl: 0.6404 (0.6510)  loss_bbox: 0.4398 (0.4470)  loss_giou: 1.0218 (1.0491)  loss_vfl_aux_0: 0.8775 (0.8940)  loss_bbox_aux_0: 0.4326 (0.4351)  loss_giou_aux_0: 1.0069 (1.0212)  loss_vfl_aux_1: 0.8568 (0.8610)  loss_bbox_aux_1: 0.4252 (0.4353)  loss_giou_aux_1: 1.0120 (1.0370)  loss_vfl_aux_2: 0.8241 (0.8274)  loss_bbox_aux_2: 0.4402 (0.4437)  loss_giou_aux_2: 1.0082 (1.0327)  loss_vfl_aux_3: 0.6584 (0.6829)  loss_bbox_aux_3: 0.4400 (0.4440)  loss_giou_aux_3: 1.0333 (1.0495)  loss_vfl_aux_4: 0.7138 (0.7268)  loss_bbox_aux_4: 0.4382 (0.4430)  loss_giou_aux_4: 1.0159 (1.0414)  loss_vfl_dn_0: 0.6967 (0.6990)  loss_bbox_dn_0: 0.2753 (0.2767)  loss_giou_dn_0: 0.7818 (0.7798)  loss_vfl_dn_1: 0.5179 (0.5196)  loss_bbox_dn_1: 0.2428 (0.2464)  loss_giou_dn_1: 0.7189 (0.7181)  loss_vfl_dn_2: 0.4699 (0.4716)  loss_bbox_dn_2: 0.2445 (0.2457)  loss_giou_dn_2: 0.7119 (0.7076)  loss_vfl_dn_3: 0.4661 (0.4654)  loss_bbox_dn_3: 0.2411 (0.2419)  loss_giou_dn_3: 0.7087 (0.7081)  loss_vfl_dn_4: 0.4715 (0.4719)  loss_bbox_dn_4: 0.2403 (0.2408)  loss_giou_dn_4: 0.7070 (0.7056)  loss_vfl_dn_5: 0.4543 (0.4559)  loss_bbox_dn_5: 0.2401 (0.2407)  loss_giou_dn_5: 0.7051 (0.7049)  loss_vfl_enc_0: 0.7873 (0.7892)  loss_bbox_enc_0: 0.4424 (0.4545)  loss_giou_enc_0: 1.0474 (1.0660)  time: 0.8464  data: 0.3289  max mem: 16811\n",
            "Epoch: [41] Total time: 0:00:06 (0.8552 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 24.6352 (24.7313)  loss_vfl: 0.6404 (0.6510)  loss_bbox: 0.4398 (0.4470)  loss_giou: 1.0218 (1.0491)  loss_vfl_aux_0: 0.8775 (0.8940)  loss_bbox_aux_0: 0.4326 (0.4351)  loss_giou_aux_0: 1.0069 (1.0212)  loss_vfl_aux_1: 0.8568 (0.8610)  loss_bbox_aux_1: 0.4252 (0.4353)  loss_giou_aux_1: 1.0120 (1.0370)  loss_vfl_aux_2: 0.8241 (0.8274)  loss_bbox_aux_2: 0.4402 (0.4437)  loss_giou_aux_2: 1.0082 (1.0327)  loss_vfl_aux_3: 0.6584 (0.6829)  loss_bbox_aux_3: 0.4400 (0.4440)  loss_giou_aux_3: 1.0333 (1.0495)  loss_vfl_aux_4: 0.7138 (0.7268)  loss_bbox_aux_4: 0.4382 (0.4430)  loss_giou_aux_4: 1.0159 (1.0414)  loss_vfl_dn_0: 0.6967 (0.6990)  loss_bbox_dn_0: 0.2753 (0.2767)  loss_giou_dn_0: 0.7818 (0.7798)  loss_vfl_dn_1: 0.5179 (0.5196)  loss_bbox_dn_1: 0.2428 (0.2464)  loss_giou_dn_1: 0.7189 (0.7181)  loss_vfl_dn_2: 0.4699 (0.4716)  loss_bbox_dn_2: 0.2445 (0.2457)  loss_giou_dn_2: 0.7119 (0.7076)  loss_vfl_dn_3: 0.4661 (0.4654)  loss_bbox_dn_3: 0.2411 (0.2419)  loss_giou_dn_3: 0.7087 (0.7081)  loss_vfl_dn_4: 0.4715 (0.4719)  loss_bbox_dn_4: 0.2403 (0.2408)  loss_giou_dn_4: 0.7070 (0.7056)  loss_vfl_dn_5: 0.4543 (0.4559)  loss_bbox_dn_5: 0.2401 (0.2407)  loss_giou_dn_5: 0.7051 (0.7049)  loss_vfl_enc_0: 0.7873 (0.7892)  loss_bbox_enc_0: 0.4424 (0.4545)  loss_giou_enc_0: 1.0474 (1.0660)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4520  data: 4.3483  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9609  data: 2.1904  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9794 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
            "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.10262710982959906}\n",
            "Epoch: [42]  [0/8]  eta: 0:00:23  lr: 0.000002  loss: 26.6950 (26.6950)  loss_vfl: 0.5421 (0.5421)  loss_bbox: 0.6122 (0.6122)  loss_giou: 1.2022 (1.2022)  loss_vfl_aux_0: 0.7853 (0.7853)  loss_bbox_aux_0: 0.6014 (0.6014)  loss_giou_aux_0: 1.1991 (1.1991)  loss_vfl_aux_1: 0.7625 (0.7625)  loss_bbox_aux_1: 0.5982 (0.5982)  loss_giou_aux_1: 1.2138 (1.2138)  loss_vfl_aux_2: 0.7087 (0.7087)  loss_bbox_aux_2: 0.6168 (0.6168)  loss_giou_aux_2: 1.2117 (1.2117)  loss_vfl_aux_3: 0.6105 (0.6105)  loss_bbox_aux_3: 0.6035 (0.6035)  loss_giou_aux_3: 1.2064 (1.2064)  loss_vfl_aux_4: 0.5877 (0.5877)  loss_bbox_aux_4: 0.6118 (0.6118)  loss_giou_aux_4: 1.1986 (1.1986)  loss_vfl_dn_0: 0.6405 (0.6405)  loss_bbox_dn_0: 0.3207 (0.3207)  loss_giou_dn_0: 0.8106 (0.8106)  loss_vfl_dn_1: 0.5104 (0.5104)  loss_bbox_dn_1: 0.2776 (0.2776)  loss_giou_dn_1: 0.7494 (0.7494)  loss_vfl_dn_2: 0.4665 (0.4665)  loss_bbox_dn_2: 0.2788 (0.2788)  loss_giou_dn_2: 0.7411 (0.7411)  loss_vfl_dn_3: 0.4573 (0.4573)  loss_bbox_dn_3: 0.2753 (0.2753)  loss_giou_dn_3: 0.7457 (0.7457)  loss_vfl_dn_4: 0.4605 (0.4605)  loss_bbox_dn_4: 0.2762 (0.2762)  loss_giou_dn_4: 0.7457 (0.7457)  loss_vfl_dn_5: 0.4480 (0.4480)  loss_bbox_dn_5: 0.2762 (0.2762)  loss_giou_dn_5: 0.7458 (0.7458)  loss_vfl_enc_0: 0.7030 (0.7030)  loss_bbox_enc_0: 0.6304 (0.6304)  loss_giou_enc_0: 1.2627 (1.2627)  time: 2.9694  data: 2.3943  max mem: 16811\n",
            "Epoch: [42]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 23.9792 (24.3723)  loss_vfl: 0.5949 (0.6005)  loss_bbox: 0.4117 (0.4478)  loss_giou: 0.9979 (1.0465)  loss_vfl_aux_0: 0.8363 (0.8659)  loss_bbox_aux_0: 0.4047 (0.4416)  loss_giou_aux_0: 0.9849 (1.0223)  loss_vfl_aux_1: 0.8435 (0.8570)  loss_bbox_aux_1: 0.4086 (0.4439)  loss_giou_aux_1: 0.9924 (1.0392)  loss_vfl_aux_2: 0.7705 (0.7872)  loss_bbox_aux_2: 0.4097 (0.4485)  loss_giou_aux_2: 0.9964 (1.0418)  loss_vfl_aux_3: 0.6586 (0.6728)  loss_bbox_aux_3: 0.4032 (0.4433)  loss_giou_aux_3: 0.9973 (1.0506)  loss_vfl_aux_4: 0.6401 (0.6567)  loss_bbox_aux_4: 0.4099 (0.4470)  loss_giou_aux_4: 0.9966 (1.0438)  loss_vfl_dn_0: 0.6405 (0.6536)  loss_bbox_dn_0: 0.2584 (0.2675)  loss_giou_dn_0: 0.7624 (0.7643)  loss_vfl_dn_1: 0.5141 (0.5157)  loss_bbox_dn_1: 0.2334 (0.2379)  loss_giou_dn_1: 0.7146 (0.7038)  loss_vfl_dn_2: 0.4665 (0.4653)  loss_bbox_dn_2: 0.2311 (0.2351)  loss_giou_dn_2: 0.7009 (0.6908)  loss_vfl_dn_3: 0.4573 (0.4562)  loss_bbox_dn_3: 0.2285 (0.2324)  loss_giou_dn_3: 0.7051 (0.6937)  loss_vfl_dn_4: 0.4605 (0.4640)  loss_bbox_dn_4: 0.2273 (0.2326)  loss_giou_dn_4: 0.7057 (0.6934)  loss_vfl_dn_5: 0.4480 (0.4479)  loss_bbox_dn_5: 0.2271 (0.2325)  loss_giou_dn_5: 0.7051 (0.6931)  loss_vfl_enc_0: 0.7980 (0.7969)  loss_bbox_enc_0: 0.4225 (0.4634)  loss_giou_enc_0: 1.0306 (1.0758)  time: 0.8459  data: 0.3251  max mem: 16811\n",
            "Epoch: [42] Total time: 0:00:06 (0.8510 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 23.9792 (24.3723)  loss_vfl: 0.5949 (0.6005)  loss_bbox: 0.4117 (0.4478)  loss_giou: 0.9979 (1.0465)  loss_vfl_aux_0: 0.8363 (0.8659)  loss_bbox_aux_0: 0.4047 (0.4416)  loss_giou_aux_0: 0.9849 (1.0223)  loss_vfl_aux_1: 0.8435 (0.8570)  loss_bbox_aux_1: 0.4086 (0.4439)  loss_giou_aux_1: 0.9924 (1.0392)  loss_vfl_aux_2: 0.7705 (0.7872)  loss_bbox_aux_2: 0.4097 (0.4485)  loss_giou_aux_2: 0.9964 (1.0418)  loss_vfl_aux_3: 0.6586 (0.6728)  loss_bbox_aux_3: 0.4032 (0.4433)  loss_giou_aux_3: 0.9973 (1.0506)  loss_vfl_aux_4: 0.6401 (0.6567)  loss_bbox_aux_4: 0.4099 (0.4470)  loss_giou_aux_4: 0.9966 (1.0438)  loss_vfl_dn_0: 0.6405 (0.6536)  loss_bbox_dn_0: 0.2584 (0.2675)  loss_giou_dn_0: 0.7624 (0.7643)  loss_vfl_dn_1: 0.5141 (0.5157)  loss_bbox_dn_1: 0.2334 (0.2379)  loss_giou_dn_1: 0.7146 (0.7038)  loss_vfl_dn_2: 0.4665 (0.4653)  loss_bbox_dn_2: 0.2311 (0.2351)  loss_giou_dn_2: 0.7009 (0.6908)  loss_vfl_dn_3: 0.4573 (0.4562)  loss_bbox_dn_3: 0.2285 (0.2324)  loss_giou_dn_3: 0.7051 (0.6937)  loss_vfl_dn_4: 0.4605 (0.4640)  loss_bbox_dn_4: 0.2273 (0.2326)  loss_giou_dn_4: 0.7057 (0.6934)  loss_vfl_dn_5: 0.4480 (0.4479)  loss_bbox_dn_5: 0.2271 (0.2325)  loss_giou_dn_5: 0.7051 (0.6931)  loss_vfl_enc_0: 0.7980 (0.7969)  loss_bbox_enc_0: 0.4225 (0.4634)  loss_giou_enc_0: 1.0306 (1.0758)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7815  data: 1.6800  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6228  data: 0.8562  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6513 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.162\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
            "best_stat: {'epoch': 42, 'coco_eval_bbox': 0.12798616910320185}\n",
            "Epoch: [43]  [0/8]  eta: 0:00:35  lr: 0.000002  loss: 22.6968 (22.6968)  loss_vfl: 0.5984 (0.5984)  loss_bbox: 0.3660 (0.3660)  loss_giou: 0.9300 (0.9300)  loss_vfl_aux_0: 0.8986 (0.8986)  loss_bbox_aux_0: 0.3303 (0.3303)  loss_giou_aux_0: 0.8678 (0.8678)  loss_vfl_aux_1: 0.8903 (0.8903)  loss_bbox_aux_1: 0.3446 (0.3446)  loss_giou_aux_1: 0.8962 (0.8962)  loss_vfl_aux_2: 0.8091 (0.8091)  loss_bbox_aux_2: 0.3512 (0.3512)  loss_giou_aux_2: 0.8990 (0.8990)  loss_vfl_aux_3: 0.6989 (0.6989)  loss_bbox_aux_3: 0.3661 (0.3661)  loss_giou_aux_3: 0.9259 (0.9259)  loss_vfl_aux_4: 0.6555 (0.6555)  loss_bbox_aux_4: 0.3579 (0.3579)  loss_giou_aux_4: 0.9222 (0.9222)  loss_vfl_dn_0: 0.6285 (0.6285)  loss_bbox_dn_0: 0.2536 (0.2536)  loss_giou_dn_0: 0.7508 (0.7508)  loss_vfl_dn_1: 0.5213 (0.5213)  loss_bbox_dn_1: 0.2183 (0.2183)  loss_giou_dn_1: 0.6801 (0.6801)  loss_vfl_dn_2: 0.4653 (0.4653)  loss_bbox_dn_2: 0.2148 (0.2148)  loss_giou_dn_2: 0.6689 (0.6689)  loss_vfl_dn_3: 0.4607 (0.4607)  loss_bbox_dn_3: 0.2138 (0.2138)  loss_giou_dn_3: 0.6687 (0.6687)  loss_vfl_dn_4: 0.4706 (0.4706)  loss_bbox_dn_4: 0.2133 (0.2133)  loss_giou_dn_4: 0.6688 (0.6688)  loss_vfl_dn_5: 0.4587 (0.4587)  loss_bbox_dn_5: 0.2131 (0.2131)  loss_giou_dn_5: 0.6676 (0.6676)  loss_vfl_enc_0: 0.8890 (0.8890)  loss_bbox_enc_0: 0.3483 (0.3483)  loss_giou_enc_0: 0.9143 (0.9143)  time: 4.4479  data: 3.9073  max mem: 16811\n",
            "Epoch: [43]  [7/8]  eta: 0:00:01  lr: 0.000002  loss: 23.8573 (23.7232)  loss_vfl: 0.5763 (0.5907)  loss_bbox: 0.4076 (0.4135)  loss_giou: 0.9914 (1.0020)  loss_vfl_aux_0: 0.8588 (0.8634)  loss_bbox_aux_0: 0.4243 (0.4201)  loss_giou_aux_0: 0.9630 (0.9864)  loss_vfl_aux_1: 0.8400 (0.8530)  loss_bbox_aux_1: 0.4253 (0.4215)  loss_giou_aux_1: 0.9902 (1.0035)  loss_vfl_aux_2: 0.7758 (0.7860)  loss_bbox_aux_2: 0.4326 (0.4321)  loss_giou_aux_2: 0.9933 (1.0046)  loss_vfl_aux_3: 0.6164 (0.6416)  loss_bbox_aux_3: 0.4058 (0.4115)  loss_giou_aux_3: 0.9913 (1.0029)  loss_vfl_aux_4: 0.6087 (0.6262)  loss_bbox_aux_4: 0.4114 (0.4147)  loss_giou_aux_4: 0.9778 (0.9963)  loss_vfl_dn_0: 0.6041 (0.6093)  loss_bbox_dn_0: 0.2605 (0.2629)  loss_giou_dn_0: 0.7508 (0.7635)  loss_vfl_dn_1: 0.5100 (0.5113)  loss_bbox_dn_1: 0.2213 (0.2310)  loss_giou_dn_1: 0.6866 (0.6962)  loss_vfl_dn_2: 0.4617 (0.4627)  loss_bbox_dn_2: 0.2175 (0.2266)  loss_giou_dn_2: 0.6744 (0.6825)  loss_vfl_dn_3: 0.4572 (0.4584)  loss_bbox_dn_3: 0.2146 (0.2242)  loss_giou_dn_3: 0.6707 (0.6831)  loss_vfl_dn_4: 0.4612 (0.4630)  loss_bbox_dn_4: 0.2155 (0.2237)  loss_giou_dn_4: 0.6719 (0.6813)  loss_vfl_dn_5: 0.4513 (0.4517)  loss_bbox_dn_5: 0.2152 (0.2236)  loss_giou_dn_5: 0.6706 (0.6808)  loss_vfl_enc_0: 0.8360 (0.8386)  loss_bbox_enc_0: 0.4426 (0.4440)  loss_giou_enc_0: 1.0071 (1.0349)  time: 1.0281  data: 0.5168  max mem: 16811\n",
            "Epoch: [43] Total time: 0:00:08 (1.0350 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 23.8573 (23.7232)  loss_vfl: 0.5763 (0.5907)  loss_bbox: 0.4076 (0.4135)  loss_giou: 0.9914 (1.0020)  loss_vfl_aux_0: 0.8588 (0.8634)  loss_bbox_aux_0: 0.4243 (0.4201)  loss_giou_aux_0: 0.9630 (0.9864)  loss_vfl_aux_1: 0.8400 (0.8530)  loss_bbox_aux_1: 0.4253 (0.4215)  loss_giou_aux_1: 0.9902 (1.0035)  loss_vfl_aux_2: 0.7758 (0.7860)  loss_bbox_aux_2: 0.4326 (0.4321)  loss_giou_aux_2: 0.9933 (1.0046)  loss_vfl_aux_3: 0.6164 (0.6416)  loss_bbox_aux_3: 0.4058 (0.4115)  loss_giou_aux_3: 0.9913 (1.0029)  loss_vfl_aux_4: 0.6087 (0.6262)  loss_bbox_aux_4: 0.4114 (0.4147)  loss_giou_aux_4: 0.9778 (0.9963)  loss_vfl_dn_0: 0.6041 (0.6093)  loss_bbox_dn_0: 0.2605 (0.2629)  loss_giou_dn_0: 0.7508 (0.7635)  loss_vfl_dn_1: 0.5100 (0.5113)  loss_bbox_dn_1: 0.2213 (0.2310)  loss_giou_dn_1: 0.6866 (0.6962)  loss_vfl_dn_2: 0.4617 (0.4627)  loss_bbox_dn_2: 0.2175 (0.2266)  loss_giou_dn_2: 0.6744 (0.6825)  loss_vfl_dn_3: 0.4572 (0.4584)  loss_bbox_dn_3: 0.2146 (0.2242)  loss_giou_dn_3: 0.6707 (0.6831)  loss_vfl_dn_4: 0.4612 (0.4630)  loss_bbox_dn_4: 0.2155 (0.2237)  loss_giou_dn_4: 0.6719 (0.6813)  loss_vfl_dn_5: 0.4513 (0.4517)  loss_bbox_dn_5: 0.2152 (0.2236)  loss_giou_dn_5: 0.6706 (0.6808)  loss_vfl_enc_0: 0.8360 (0.8386)  loss_bbox_enc_0: 0.4426 (0.4440)  loss_giou_enc_0: 1.0071 (1.0349)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.2515  data: 1.8096  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.8566  data: 0.9208  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.8835 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.174\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
            "best_stat: {'epoch': 43, 'coco_eval_bbox': 0.14021279177405088}\n",
            "Epoch: [44]  [0/8]  eta: 0:00:26  lr: 0.000002  loss: 24.9776 (24.9776)  loss_vfl: 0.5560 (0.5560)  loss_bbox: 0.4868 (0.4868)  loss_giou: 1.1049 (1.1049)  loss_vfl_aux_0: 0.8135 (0.8135)  loss_bbox_aux_0: 0.5242 (0.5242)  loss_giou_aux_0: 1.1174 (1.1174)  loss_vfl_aux_1: 0.8314 (0.8314)  loss_bbox_aux_1: 0.5266 (0.5266)  loss_giou_aux_1: 1.1366 (1.1366)  loss_vfl_aux_2: 0.7616 (0.7616)  loss_bbox_aux_2: 0.5429 (0.5429)  loss_giou_aux_2: 1.1368 (1.1368)  loss_vfl_aux_3: 0.5797 (0.5797)  loss_bbox_aux_3: 0.4908 (0.4908)  loss_giou_aux_3: 1.1271 (1.1271)  loss_vfl_aux_4: 0.5970 (0.5970)  loss_bbox_aux_4: 0.4925 (0.4925)  loss_giou_aux_4: 1.0979 (1.0979)  loss_vfl_dn_0: 0.6000 (0.6000)  loss_bbox_dn_0: 0.2596 (0.2596)  loss_giou_dn_0: 0.7448 (0.7448)  loss_vfl_dn_1: 0.5217 (0.5217)  loss_bbox_dn_1: 0.2363 (0.2363)  loss_giou_dn_1: 0.6884 (0.6884)  loss_vfl_dn_2: 0.4648 (0.4648)  loss_bbox_dn_2: 0.2290 (0.2290)  loss_giou_dn_2: 0.6737 (0.6737)  loss_vfl_dn_3: 0.4586 (0.4586)  loss_bbox_dn_3: 0.2272 (0.2272)  loss_giou_dn_3: 0.6746 (0.6746)  loss_vfl_dn_4: 0.4627 (0.4627)  loss_bbox_dn_4: 0.2268 (0.2268)  loss_giou_dn_4: 0.6732 (0.6732)  loss_vfl_dn_5: 0.4552 (0.4552)  loss_bbox_dn_5: 0.2267 (0.2267)  loss_giou_dn_5: 0.6722 (0.6722)  loss_vfl_enc_0: 0.8491 (0.8491)  loss_bbox_enc_0: 0.5418 (0.5418)  loss_giou_enc_0: 1.1674 (1.1674)  time: 3.3015  data: 2.7673  max mem: 16811\n",
            "Epoch: [44]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 23.0482 (23.3868)  loss_vfl: 0.5541 (0.5483)  loss_bbox: 0.3794 (0.3955)  loss_giou: 0.9789 (0.9884)  loss_vfl_aux_0: 0.8389 (0.8588)  loss_bbox_aux_0: 0.4045 (0.4226)  loss_giou_aux_0: 0.9914 (0.9966)  loss_vfl_aux_1: 0.8201 (0.8241)  loss_bbox_aux_1: 0.4148 (0.4239)  loss_giou_aux_1: 1.0067 (1.0149)  loss_vfl_aux_2: 0.7616 (0.7582)  loss_bbox_aux_2: 0.4149 (0.4345)  loss_giou_aux_2: 1.0164 (1.0216)  loss_vfl_aux_3: 0.5779 (0.5808)  loss_bbox_aux_3: 0.3750 (0.3956)  loss_giou_aux_3: 0.9953 (1.0057)  loss_vfl_aux_4: 0.5907 (0.5841)  loss_bbox_aux_4: 0.3797 (0.3974)  loss_giou_aux_4: 0.9763 (0.9851)  loss_vfl_dn_0: 0.5880 (0.5925)  loss_bbox_dn_0: 0.2596 (0.2560)  loss_giou_dn_0: 0.7358 (0.7429)  loss_vfl_dn_1: 0.5066 (0.5076)  loss_bbox_dn_1: 0.2299 (0.2279)  loss_giou_dn_1: 0.6809 (0.6816)  loss_vfl_dn_2: 0.4597 (0.4578)  loss_bbox_dn_2: 0.2282 (0.2264)  loss_giou_dn_2: 0.6700 (0.6729)  loss_vfl_dn_3: 0.4543 (0.4513)  loss_bbox_dn_3: 0.2242 (0.2230)  loss_giou_dn_3: 0.6726 (0.6738)  loss_vfl_dn_4: 0.4577 (0.4572)  loss_bbox_dn_4: 0.2223 (0.2227)  loss_giou_dn_4: 0.6714 (0.6718)  loss_vfl_dn_5: 0.4424 (0.4433)  loss_bbox_dn_5: 0.2222 (0.2225)  loss_giou_dn_5: 0.6713 (0.6715)  loss_vfl_enc_0: 0.8491 (0.8568)  loss_bbox_enc_0: 0.4381 (0.4449)  loss_giou_enc_0: 1.0372 (1.0461)  time: 0.8814  data: 0.3661  max mem: 16811\n",
            "Epoch: [44] Total time: 0:00:07 (0.8871 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 23.0482 (23.3868)  loss_vfl: 0.5541 (0.5483)  loss_bbox: 0.3794 (0.3955)  loss_giou: 0.9789 (0.9884)  loss_vfl_aux_0: 0.8389 (0.8588)  loss_bbox_aux_0: 0.4045 (0.4226)  loss_giou_aux_0: 0.9914 (0.9966)  loss_vfl_aux_1: 0.8201 (0.8241)  loss_bbox_aux_1: 0.4148 (0.4239)  loss_giou_aux_1: 1.0067 (1.0149)  loss_vfl_aux_2: 0.7616 (0.7582)  loss_bbox_aux_2: 0.4149 (0.4345)  loss_giou_aux_2: 1.0164 (1.0216)  loss_vfl_aux_3: 0.5779 (0.5808)  loss_bbox_aux_3: 0.3750 (0.3956)  loss_giou_aux_3: 0.9953 (1.0057)  loss_vfl_aux_4: 0.5907 (0.5841)  loss_bbox_aux_4: 0.3797 (0.3974)  loss_giou_aux_4: 0.9763 (0.9851)  loss_vfl_dn_0: 0.5880 (0.5925)  loss_bbox_dn_0: 0.2596 (0.2560)  loss_giou_dn_0: 0.7358 (0.7429)  loss_vfl_dn_1: 0.5066 (0.5076)  loss_bbox_dn_1: 0.2299 (0.2279)  loss_giou_dn_1: 0.6809 (0.6816)  loss_vfl_dn_2: 0.4597 (0.4578)  loss_bbox_dn_2: 0.2282 (0.2264)  loss_giou_dn_2: 0.6700 (0.6729)  loss_vfl_dn_3: 0.4543 (0.4513)  loss_bbox_dn_3: 0.2242 (0.2230)  loss_giou_dn_3: 0.6726 (0.6738)  loss_vfl_dn_4: 0.4577 (0.4572)  loss_bbox_dn_4: 0.2223 (0.2227)  loss_giou_dn_4: 0.6714 (0.6718)  loss_vfl_dn_5: 0.4424 (0.4433)  loss_bbox_dn_5: 0.2222 (0.2225)  loss_giou_dn_5: 0.6713 (0.6715)  loss_vfl_enc_0: 0.8491 (0.8568)  loss_bbox_enc_0: 0.4381 (0.4449)  loss_giou_enc_0: 1.0372 (1.0461)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4219  data: 1.3304  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4406  data: 0.6812  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4665 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
            "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.15186758112894408}\n",
            "Epoch: [45]  [0/8]  eta: 0:00:29  lr: 0.000002  loss: 23.9316 (23.9316)  loss_vfl: 0.5141 (0.5141)  loss_bbox: 0.4452 (0.4452)  loss_giou: 1.0237 (1.0237)  loss_vfl_aux_0: 0.8022 (0.8022)  loss_bbox_aux_0: 0.4903 (0.4903)  loss_giou_aux_0: 1.0669 (1.0669)  loss_vfl_aux_1: 0.7450 (0.7450)  loss_bbox_aux_1: 0.4898 (0.4898)  loss_giou_aux_1: 1.0782 (1.0782)  loss_vfl_aux_2: 0.6735 (0.6735)  loss_bbox_aux_2: 0.5042 (0.5042)  loss_giou_aux_2: 1.0796 (1.0796)  loss_vfl_aux_3: 0.5307 (0.5307)  loss_bbox_aux_3: 0.4580 (0.4580)  loss_giou_aux_3: 1.0593 (1.0593)  loss_vfl_aux_4: 0.5280 (0.5280)  loss_bbox_aux_4: 0.4502 (0.4502)  loss_giou_aux_4: 1.0186 (1.0186)  loss_vfl_dn_0: 0.5691 (0.5691)  loss_bbox_dn_0: 0.2753 (0.2753)  loss_giou_dn_0: 0.7538 (0.7538)  loss_vfl_dn_1: 0.5083 (0.5083)  loss_bbox_dn_1: 0.2458 (0.2458)  loss_giou_dn_1: 0.6804 (0.6804)  loss_vfl_dn_2: 0.4665 (0.4665)  loss_bbox_dn_2: 0.2448 (0.2448)  loss_giou_dn_2: 0.6779 (0.6779)  loss_vfl_dn_3: 0.4590 (0.4590)  loss_bbox_dn_3: 0.2400 (0.2400)  loss_giou_dn_3: 0.6763 (0.6763)  loss_vfl_dn_4: 0.4602 (0.4602)  loss_bbox_dn_4: 0.2415 (0.2415)  loss_giou_dn_4: 0.6794 (0.6794)  loss_vfl_dn_5: 0.4469 (0.4469)  loss_bbox_dn_5: 0.2414 (0.2414)  loss_giou_dn_5: 0.6795 (0.6795)  loss_vfl_enc_0: 0.7950 (0.7950)  loss_bbox_enc_0: 0.5181 (0.5181)  loss_giou_enc_0: 1.1149 (1.1149)  time: 3.7344  data: 3.1608  max mem: 16811\n",
            "Epoch: [45]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 22.6042 (22.9147)  loss_vfl: 0.5338 (0.5480)  loss_bbox: 0.3687 (0.3826)  loss_giou: 0.9282 (0.9533)  loss_vfl_aux_0: 0.8632 (0.8874)  loss_bbox_aux_0: 0.3907 (0.4032)  loss_giou_aux_0: 0.9208 (0.9561)  loss_vfl_aux_1: 0.7881 (0.8325)  loss_bbox_aux_1: 0.3903 (0.4022)  loss_giou_aux_1: 0.9464 (0.9731)  loss_vfl_aux_2: 0.7261 (0.7407)  loss_bbox_aux_2: 0.3976 (0.4113)  loss_giou_aux_2: 0.9518 (0.9794)  loss_vfl_aux_3: 0.5538 (0.5645)  loss_bbox_aux_3: 0.3629 (0.3818)  loss_giou_aux_3: 0.9364 (0.9771)  loss_vfl_aux_4: 0.5563 (0.5697)  loss_bbox_aux_4: 0.3619 (0.3824)  loss_giou_aux_4: 0.9242 (0.9555)  loss_vfl_dn_0: 0.5741 (0.5764)  loss_bbox_dn_0: 0.2535 (0.2527)  loss_giou_dn_0: 0.7369 (0.7370)  loss_vfl_dn_1: 0.5042 (0.5040)  loss_bbox_dn_1: 0.2241 (0.2254)  loss_giou_dn_1: 0.6701 (0.6736)  loss_vfl_dn_2: 0.4571 (0.4573)  loss_bbox_dn_2: 0.2185 (0.2217)  loss_giou_dn_2: 0.6576 (0.6642)  loss_vfl_dn_3: 0.4500 (0.4507)  loss_bbox_dn_3: 0.2186 (0.2187)  loss_giou_dn_3: 0.6588 (0.6631)  loss_vfl_dn_4: 0.4555 (0.4560)  loss_bbox_dn_4: 0.2180 (0.2191)  loss_giou_dn_4: 0.6571 (0.6621)  loss_vfl_dn_5: 0.4413 (0.4424)  loss_bbox_dn_5: 0.2177 (0.2188)  loss_giou_dn_5: 0.6572 (0.6616)  loss_vfl_enc_0: 0.8600 (0.8790)  loss_bbox_enc_0: 0.4058 (0.4210)  loss_giou_enc_0: 0.9690 (1.0091)  time: 0.9473  data: 0.4287  max mem: 16811\n",
            "Epoch: [45] Total time: 0:00:07 (0.9548 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 22.6042 (22.9147)  loss_vfl: 0.5338 (0.5480)  loss_bbox: 0.3687 (0.3826)  loss_giou: 0.9282 (0.9533)  loss_vfl_aux_0: 0.8632 (0.8874)  loss_bbox_aux_0: 0.3907 (0.4032)  loss_giou_aux_0: 0.9208 (0.9561)  loss_vfl_aux_1: 0.7881 (0.8325)  loss_bbox_aux_1: 0.3903 (0.4022)  loss_giou_aux_1: 0.9464 (0.9731)  loss_vfl_aux_2: 0.7261 (0.7407)  loss_bbox_aux_2: 0.3976 (0.4113)  loss_giou_aux_2: 0.9518 (0.9794)  loss_vfl_aux_3: 0.5538 (0.5645)  loss_bbox_aux_3: 0.3629 (0.3818)  loss_giou_aux_3: 0.9364 (0.9771)  loss_vfl_aux_4: 0.5563 (0.5697)  loss_bbox_aux_4: 0.3619 (0.3824)  loss_giou_aux_4: 0.9242 (0.9555)  loss_vfl_dn_0: 0.5741 (0.5764)  loss_bbox_dn_0: 0.2535 (0.2527)  loss_giou_dn_0: 0.7369 (0.7370)  loss_vfl_dn_1: 0.5042 (0.5040)  loss_bbox_dn_1: 0.2241 (0.2254)  loss_giou_dn_1: 0.6701 (0.6736)  loss_vfl_dn_2: 0.4571 (0.4573)  loss_bbox_dn_2: 0.2185 (0.2217)  loss_giou_dn_2: 0.6576 (0.6642)  loss_vfl_dn_3: 0.4500 (0.4507)  loss_bbox_dn_3: 0.2186 (0.2187)  loss_giou_dn_3: 0.6588 (0.6631)  loss_vfl_dn_4: 0.4555 (0.4560)  loss_bbox_dn_4: 0.2180 (0.2191)  loss_giou_dn_4: 0.6571 (0.6621)  loss_vfl_dn_5: 0.4413 (0.4424)  loss_bbox_dn_5: 0.2177 (0.2188)  loss_giou_dn_5: 0.6572 (0.6616)  loss_vfl_enc_0: 0.8600 (0.8790)  loss_bbox_enc_0: 0.4058 (0.4210)  loss_giou_enc_0: 0.9690 (1.0091)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4001  data: 1.3122  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4295  data: 0.6721  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4469 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.139\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
            "best_stat: {'epoch': 45, 'coco_eval_bbox': 0.15701536342953115}\n",
            "Epoch: [46]  [0/8]  eta: 0:00:30  lr: 0.000002  loss: 24.7198 (24.7198)  loss_vfl: 0.5030 (0.5030)  loss_bbox: 0.4865 (0.4865)  loss_giou: 1.1358 (1.1358)  loss_vfl_aux_0: 0.8153 (0.8153)  loss_bbox_aux_0: 0.4727 (0.4727)  loss_giou_aux_0: 1.1128 (1.1128)  loss_vfl_aux_1: 0.7700 (0.7700)  loss_bbox_aux_1: 0.4869 (0.4869)  loss_giou_aux_1: 1.1299 (1.1299)  loss_vfl_aux_2: 0.7092 (0.7092)  loss_bbox_aux_2: 0.4944 (0.4944)  loss_giou_aux_2: 1.1363 (1.1363)  loss_vfl_aux_3: 0.5369 (0.5369)  loss_bbox_aux_3: 0.4906 (0.4906)  loss_giou_aux_3: 1.1424 (1.1424)  loss_vfl_aux_4: 0.5360 (0.5360)  loss_bbox_aux_4: 0.4785 (0.4785)  loss_giou_aux_4: 1.1353 (1.1353)  loss_vfl_dn_0: 0.5456 (0.5456)  loss_bbox_dn_0: 0.2717 (0.2717)  loss_giou_dn_0: 0.7810 (0.7810)  loss_vfl_dn_1: 0.5057 (0.5057)  loss_bbox_dn_1: 0.2448 (0.2448)  loss_giou_dn_1: 0.7171 (0.7171)  loss_vfl_dn_2: 0.4589 (0.4589)  loss_bbox_dn_2: 0.2417 (0.2417)  loss_giou_dn_2: 0.7087 (0.7087)  loss_vfl_dn_3: 0.4556 (0.4556)  loss_bbox_dn_3: 0.2385 (0.2385)  loss_giou_dn_3: 0.7120 (0.7120)  loss_vfl_dn_4: 0.4595 (0.4595)  loss_bbox_dn_4: 0.2385 (0.2385)  loss_giou_dn_4: 0.7088 (0.7088)  loss_vfl_dn_5: 0.4482 (0.4482)  loss_bbox_dn_5: 0.2384 (0.2384)  loss_giou_dn_5: 0.7086 (0.7086)  loss_vfl_enc_0: 0.8031 (0.8031)  loss_bbox_enc_0: 0.5055 (0.5055)  loss_giou_enc_0: 1.1555 (1.1555)  time: 3.8735  data: 3.3154  max mem: 16811\n",
            "Epoch: [46]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 22.8606 (22.9678)  loss_vfl: 0.5392 (0.5443)  loss_bbox: 0.3484 (0.3703)  loss_giou: 0.9260 (0.9430)  loss_vfl_aux_0: 0.9030 (0.9142)  loss_bbox_aux_0: 0.3989 (0.4013)  loss_giou_aux_0: 0.9699 (0.9667)  loss_vfl_aux_1: 0.8530 (0.8665)  loss_bbox_aux_1: 0.4064 (0.4094)  loss_giou_aux_1: 0.9919 (0.9846)  loss_vfl_aux_2: 0.7611 (0.7574)  loss_bbox_aux_2: 0.4068 (0.4181)  loss_giou_aux_2: 1.0016 (0.9922)  loss_vfl_aux_3: 0.5993 (0.5946)  loss_bbox_aux_3: 0.3705 (0.3753)  loss_giou_aux_3: 0.9606 (0.9721)  loss_vfl_aux_4: 0.5745 (0.5806)  loss_bbox_aux_4: 0.3541 (0.3718)  loss_giou_aux_4: 0.9302 (0.9474)  loss_vfl_dn_0: 0.5630 (0.5656)  loss_bbox_dn_0: 0.2438 (0.2492)  loss_giou_dn_0: 0.7112 (0.7312)  loss_vfl_dn_1: 0.4982 (0.5004)  loss_bbox_dn_1: 0.2233 (0.2232)  loss_giou_dn_1: 0.6532 (0.6733)  loss_vfl_dn_2: 0.4500 (0.4522)  loss_bbox_dn_2: 0.2173 (0.2184)  loss_giou_dn_2: 0.6425 (0.6599)  loss_vfl_dn_3: 0.4427 (0.4458)  loss_bbox_dn_3: 0.2158 (0.2162)  loss_giou_dn_3: 0.6384 (0.6617)  loss_vfl_dn_4: 0.4499 (0.4513)  loss_bbox_dn_4: 0.2137 (0.2157)  loss_giou_dn_4: 0.6359 (0.6580)  loss_vfl_dn_5: 0.4355 (0.4382)  loss_bbox_dn_5: 0.2135 (0.2157)  loss_giou_dn_5: 0.6348 (0.6576)  loss_vfl_enc_0: 0.8791 (0.8831)  loss_bbox_enc_0: 0.4184 (0.4245)  loss_giou_enc_0: 1.0026 (1.0171)  time: 0.9607  data: 0.4503  max mem: 16811\n",
            "Epoch: [46] Total time: 0:00:07 (0.9663 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 22.8606 (22.9678)  loss_vfl: 0.5392 (0.5443)  loss_bbox: 0.3484 (0.3703)  loss_giou: 0.9260 (0.9430)  loss_vfl_aux_0: 0.9030 (0.9142)  loss_bbox_aux_0: 0.3989 (0.4013)  loss_giou_aux_0: 0.9699 (0.9667)  loss_vfl_aux_1: 0.8530 (0.8665)  loss_bbox_aux_1: 0.4064 (0.4094)  loss_giou_aux_1: 0.9919 (0.9846)  loss_vfl_aux_2: 0.7611 (0.7574)  loss_bbox_aux_2: 0.4068 (0.4181)  loss_giou_aux_2: 1.0016 (0.9922)  loss_vfl_aux_3: 0.5993 (0.5946)  loss_bbox_aux_3: 0.3705 (0.3753)  loss_giou_aux_3: 0.9606 (0.9721)  loss_vfl_aux_4: 0.5745 (0.5806)  loss_bbox_aux_4: 0.3541 (0.3718)  loss_giou_aux_4: 0.9302 (0.9474)  loss_vfl_dn_0: 0.5630 (0.5656)  loss_bbox_dn_0: 0.2438 (0.2492)  loss_giou_dn_0: 0.7112 (0.7312)  loss_vfl_dn_1: 0.4982 (0.5004)  loss_bbox_dn_1: 0.2233 (0.2232)  loss_giou_dn_1: 0.6532 (0.6733)  loss_vfl_dn_2: 0.4500 (0.4522)  loss_bbox_dn_2: 0.2173 (0.2184)  loss_giou_dn_2: 0.6425 (0.6599)  loss_vfl_dn_3: 0.4427 (0.4458)  loss_bbox_dn_3: 0.2158 (0.2162)  loss_giou_dn_3: 0.6384 (0.6617)  loss_vfl_dn_4: 0.4499 (0.4513)  loss_bbox_dn_4: 0.2137 (0.2157)  loss_giou_dn_4: 0.6359 (0.6580)  loss_vfl_dn_5: 0.4355 (0.4382)  loss_bbox_dn_5: 0.2135 (0.2157)  loss_giou_dn_5: 0.6348 (0.6576)  loss_vfl_enc_0: 0.8791 (0.8831)  loss_bbox_enc_0: 0.4184 (0.4245)  loss_giou_enc_0: 1.0026 (1.0171)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.1868  data: 3.7550  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.8242  data: 1.8939  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8474 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            "best_stat: {'epoch': 46, 'coco_eval_bbox': 0.17315979711226326}\n",
            "Epoch: [47]  [0/8]  eta: 0:00:22  lr: 0.000002  loss: 23.5337 (23.5337)  loss_vfl: 0.6018 (0.6018)  loss_bbox: 0.3718 (0.3718)  loss_giou: 0.9128 (0.9128)  loss_vfl_aux_0: 1.0282 (1.0282)  loss_bbox_aux_0: 0.4278 (0.4278)  loss_giou_aux_0: 0.9602 (0.9602)  loss_vfl_aux_1: 0.9714 (0.9714)  loss_bbox_aux_1: 0.4317 (0.4317)  loss_giou_aux_1: 0.9685 (0.9685)  loss_vfl_aux_2: 0.8514 (0.8514)  loss_bbox_aux_2: 0.4382 (0.4382)  loss_giou_aux_2: 0.9748 (0.9748)  loss_vfl_aux_3: 0.6580 (0.6580)  loss_bbox_aux_3: 0.3802 (0.3802)  loss_giou_aux_3: 0.9620 (0.9620)  loss_vfl_aux_4: 0.6375 (0.6375)  loss_bbox_aux_4: 0.3753 (0.3753)  loss_giou_aux_4: 0.9219 (0.9219)  loss_vfl_dn_0: 0.5709 (0.5709)  loss_bbox_dn_0: 0.2491 (0.2491)  loss_giou_dn_0: 0.7120 (0.7120)  loss_vfl_dn_1: 0.5037 (0.5037)  loss_bbox_dn_1: 0.2305 (0.2305)  loss_giou_dn_1: 0.6624 (0.6624)  loss_vfl_dn_2: 0.4467 (0.4467)  loss_bbox_dn_2: 0.2243 (0.2243)  loss_giou_dn_2: 0.6474 (0.6474)  loss_vfl_dn_3: 0.4417 (0.4417)  loss_bbox_dn_3: 0.2236 (0.2236)  loss_giou_dn_3: 0.6495 (0.6495)  loss_vfl_dn_4: 0.4461 (0.4461)  loss_bbox_dn_4: 0.2228 (0.2228)  loss_giou_dn_4: 0.6442 (0.6442)  loss_vfl_dn_5: 0.4366 (0.4366)  loss_bbox_dn_5: 0.2225 (0.2225)  loss_giou_dn_5: 0.6443 (0.6443)  loss_vfl_enc_0: 0.9937 (0.9937)  loss_bbox_enc_0: 0.4621 (0.4621)  loss_giou_enc_0: 1.0257 (1.0257)  time: 2.8599  data: 2.3267  max mem: 16811\n",
            "Epoch: [47]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 22.3259 (22.4531)  loss_vfl: 0.5377 (0.5481)  loss_bbox: 0.3489 (0.3487)  loss_giou: 0.9055 (0.8996)  loss_vfl_aux_0: 0.9275 (0.9457)  loss_bbox_aux_0: 0.3815 (0.3855)  loss_giou_aux_0: 0.9271 (0.9198)  loss_vfl_aux_1: 0.8212 (0.8472)  loss_bbox_aux_1: 0.3873 (0.3890)  loss_giou_aux_1: 0.9246 (0.9401)  loss_vfl_aux_2: 0.7066 (0.7272)  loss_bbox_aux_2: 0.3932 (0.3955)  loss_giou_aux_2: 0.9474 (0.9511)  loss_vfl_aux_3: 0.5752 (0.5842)  loss_bbox_aux_3: 0.3510 (0.3506)  loss_giou_aux_3: 0.9349 (0.9333)  loss_vfl_aux_4: 0.5516 (0.5707)  loss_bbox_aux_4: 0.3514 (0.3539)  loss_giou_aux_4: 0.9077 (0.9042)  loss_vfl_dn_0: 0.5585 (0.5592)  loss_bbox_dn_0: 0.2557 (0.2501)  loss_giou_dn_0: 0.7241 (0.7287)  loss_vfl_dn_1: 0.4985 (0.4998)  loss_bbox_dn_1: 0.2290 (0.2225)  loss_giou_dn_1: 0.6630 (0.6688)  loss_vfl_dn_2: 0.4472 (0.4510)  loss_bbox_dn_2: 0.2238 (0.2169)  loss_giou_dn_2: 0.6474 (0.6547)  loss_vfl_dn_3: 0.4417 (0.4425)  loss_bbox_dn_3: 0.2222 (0.2140)  loss_giou_dn_3: 0.6502 (0.6550)  loss_vfl_dn_4: 0.4454 (0.4475)  loss_bbox_dn_4: 0.2209 (0.2135)  loss_giou_dn_4: 0.6456 (0.6511)  loss_vfl_dn_5: 0.4319 (0.4351)  loss_bbox_dn_5: 0.2210 (0.2135)  loss_giou_dn_5: 0.6453 (0.6512)  loss_vfl_enc_0: 0.8805 (0.8995)  loss_bbox_enc_0: 0.3977 (0.4081)  loss_giou_enc_0: 0.9654 (0.9761)  time: 0.8286  data: 0.3195  max mem: 16811\n",
            "Epoch: [47] Total time: 0:00:06 (0.8413 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 22.3259 (22.4531)  loss_vfl: 0.5377 (0.5481)  loss_bbox: 0.3489 (0.3487)  loss_giou: 0.9055 (0.8996)  loss_vfl_aux_0: 0.9275 (0.9457)  loss_bbox_aux_0: 0.3815 (0.3855)  loss_giou_aux_0: 0.9271 (0.9198)  loss_vfl_aux_1: 0.8212 (0.8472)  loss_bbox_aux_1: 0.3873 (0.3890)  loss_giou_aux_1: 0.9246 (0.9401)  loss_vfl_aux_2: 0.7066 (0.7272)  loss_bbox_aux_2: 0.3932 (0.3955)  loss_giou_aux_2: 0.9474 (0.9511)  loss_vfl_aux_3: 0.5752 (0.5842)  loss_bbox_aux_3: 0.3510 (0.3506)  loss_giou_aux_3: 0.9349 (0.9333)  loss_vfl_aux_4: 0.5516 (0.5707)  loss_bbox_aux_4: 0.3514 (0.3539)  loss_giou_aux_4: 0.9077 (0.9042)  loss_vfl_dn_0: 0.5585 (0.5592)  loss_bbox_dn_0: 0.2557 (0.2501)  loss_giou_dn_0: 0.7241 (0.7287)  loss_vfl_dn_1: 0.4985 (0.4998)  loss_bbox_dn_1: 0.2290 (0.2225)  loss_giou_dn_1: 0.6630 (0.6688)  loss_vfl_dn_2: 0.4472 (0.4510)  loss_bbox_dn_2: 0.2238 (0.2169)  loss_giou_dn_2: 0.6474 (0.6547)  loss_vfl_dn_3: 0.4417 (0.4425)  loss_bbox_dn_3: 0.2222 (0.2140)  loss_giou_dn_3: 0.6502 (0.6550)  loss_vfl_dn_4: 0.4454 (0.4475)  loss_bbox_dn_4: 0.2209 (0.2135)  loss_giou_dn_4: 0.6456 (0.6511)  loss_vfl_dn_5: 0.4319 (0.4351)  loss_bbox_dn_5: 0.2210 (0.2135)  loss_giou_dn_5: 0.6453 (0.6512)  loss_vfl_enc_0: 0.8805 (0.8995)  loss_bbox_enc_0: 0.3977 (0.4081)  loss_giou_enc_0: 0.9654 (0.9761)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5843  data: 4.4947  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0195  data: 2.2633  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0503 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592\n",
            "best_stat: {'epoch': 47, 'coco_eval_bbox': 0.19472749939163753}\n",
            "Epoch: [48]  [0/8]  eta: 0:00:23  lr: 0.000002  loss: 22.9857 (22.9857)  loss_vfl: 0.5363 (0.5363)  loss_bbox: 0.3764 (0.3764)  loss_giou: 0.9394 (0.9394)  loss_vfl_aux_0: 0.9332 (0.9332)  loss_bbox_aux_0: 0.4259 (0.4259)  loss_giou_aux_0: 0.9686 (0.9686)  loss_vfl_aux_1: 0.8153 (0.8153)  loss_bbox_aux_1: 0.4104 (0.4104)  loss_giou_aux_1: 0.9810 (0.9810)  loss_vfl_aux_2: 0.6878 (0.6878)  loss_bbox_aux_2: 0.4220 (0.4220)  loss_giou_aux_2: 0.9906 (0.9906)  loss_vfl_aux_3: 0.5818 (0.5818)  loss_bbox_aux_3: 0.3936 (0.3936)  loss_giou_aux_3: 0.9753 (0.9753)  loss_vfl_aux_4: 0.5627 (0.5627)  loss_bbox_aux_4: 0.3671 (0.3671)  loss_giou_aux_4: 0.9413 (0.9413)  loss_vfl_dn_0: 0.5529 (0.5529)  loss_bbox_dn_0: 0.2622 (0.2622)  loss_giou_dn_0: 0.7458 (0.7458)  loss_vfl_dn_1: 0.5073 (0.5073)  loss_bbox_dn_1: 0.2288 (0.2288)  loss_giou_dn_1: 0.6850 (0.6850)  loss_vfl_dn_2: 0.4540 (0.4540)  loss_bbox_dn_2: 0.2215 (0.2215)  loss_giou_dn_2: 0.6704 (0.6704)  loss_vfl_dn_3: 0.4487 (0.4487)  loss_bbox_dn_3: 0.2204 (0.2204)  loss_giou_dn_3: 0.6734 (0.6734)  loss_vfl_dn_4: 0.4527 (0.4527)  loss_bbox_dn_4: 0.2181 (0.2181)  loss_giou_dn_4: 0.6662 (0.6662)  loss_vfl_dn_5: 0.4401 (0.4401)  loss_bbox_dn_5: 0.2183 (0.2183)  loss_giou_dn_5: 0.6683 (0.6683)  loss_vfl_enc_0: 0.8654 (0.8654)  loss_bbox_enc_0: 0.4555 (0.4555)  loss_giou_enc_0: 1.0219 (1.0219)  time: 2.8906  data: 2.3453  max mem: 16811\n",
            "Epoch: [48]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 22.1334 (22.2800)  loss_vfl: 0.5363 (0.5409)  loss_bbox: 0.3376 (0.3478)  loss_giou: 0.8944 (0.9095)  loss_vfl_aux_0: 0.9332 (0.9418)  loss_bbox_aux_0: 0.3530 (0.3746)  loss_giou_aux_0: 0.8724 (0.9216)  loss_vfl_aux_1: 0.8158 (0.8298)  loss_bbox_aux_1: 0.3527 (0.3825)  loss_giou_aux_1: 0.8967 (0.9430)  loss_vfl_aux_2: 0.6618 (0.6724)  loss_bbox_aux_2: 0.3667 (0.3912)  loss_giou_aux_2: 0.9378 (0.9608)  loss_vfl_aux_3: 0.5868 (0.6017)  loss_bbox_aux_3: 0.3415 (0.3542)  loss_giou_aux_3: 0.9079 (0.9287)  loss_vfl_aux_4: 0.5585 (0.5629)  loss_bbox_aux_4: 0.3380 (0.3504)  loss_giou_aux_4: 0.8947 (0.9113)  loss_vfl_dn_0: 0.5609 (0.5591)  loss_bbox_dn_0: 0.2431 (0.2432)  loss_giou_dn_0: 0.7121 (0.7182)  loss_vfl_dn_1: 0.4977 (0.4993)  loss_bbox_dn_1: 0.2170 (0.2178)  loss_giou_dn_1: 0.6507 (0.6571)  loss_vfl_dn_2: 0.4484 (0.4495)  loss_bbox_dn_2: 0.2131 (0.2136)  loss_giou_dn_2: 0.6398 (0.6453)  loss_vfl_dn_3: 0.4420 (0.4457)  loss_bbox_dn_3: 0.2104 (0.2112)  loss_giou_dn_3: 0.6354 (0.6459)  loss_vfl_dn_4: 0.4495 (0.4485)  loss_bbox_dn_4: 0.2118 (0.2111)  loss_giou_dn_4: 0.6348 (0.6428)  loss_vfl_dn_5: 0.4377 (0.4373)  loss_bbox_dn_5: 0.2118 (0.2111)  loss_giou_dn_5: 0.6328 (0.6428)  loss_vfl_enc_0: 0.8805 (0.8870)  loss_bbox_enc_0: 0.3690 (0.3968)  loss_giou_enc_0: 0.9130 (0.9718)  time: 0.8419  data: 0.3237  max mem: 16811\n",
            "Epoch: [48] Total time: 0:00:06 (0.8508 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 22.1334 (22.2800)  loss_vfl: 0.5363 (0.5409)  loss_bbox: 0.3376 (0.3478)  loss_giou: 0.8944 (0.9095)  loss_vfl_aux_0: 0.9332 (0.9418)  loss_bbox_aux_0: 0.3530 (0.3746)  loss_giou_aux_0: 0.8724 (0.9216)  loss_vfl_aux_1: 0.8158 (0.8298)  loss_bbox_aux_1: 0.3527 (0.3825)  loss_giou_aux_1: 0.8967 (0.9430)  loss_vfl_aux_2: 0.6618 (0.6724)  loss_bbox_aux_2: 0.3667 (0.3912)  loss_giou_aux_2: 0.9378 (0.9608)  loss_vfl_aux_3: 0.5868 (0.6017)  loss_bbox_aux_3: 0.3415 (0.3542)  loss_giou_aux_3: 0.9079 (0.9287)  loss_vfl_aux_4: 0.5585 (0.5629)  loss_bbox_aux_4: 0.3380 (0.3504)  loss_giou_aux_4: 0.8947 (0.9113)  loss_vfl_dn_0: 0.5609 (0.5591)  loss_bbox_dn_0: 0.2431 (0.2432)  loss_giou_dn_0: 0.7121 (0.7182)  loss_vfl_dn_1: 0.4977 (0.4993)  loss_bbox_dn_1: 0.2170 (0.2178)  loss_giou_dn_1: 0.6507 (0.6571)  loss_vfl_dn_2: 0.4484 (0.4495)  loss_bbox_dn_2: 0.2131 (0.2136)  loss_giou_dn_2: 0.6398 (0.6453)  loss_vfl_dn_3: 0.4420 (0.4457)  loss_bbox_dn_3: 0.2104 (0.2112)  loss_giou_dn_3: 0.6354 (0.6459)  loss_vfl_dn_4: 0.4495 (0.4485)  loss_bbox_dn_4: 0.2118 (0.2111)  loss_giou_dn_4: 0.6348 (0.6428)  loss_vfl_dn_5: 0.4377 (0.4373)  loss_bbox_dn_5: 0.2118 (0.2111)  loss_giou_dn_5: 0.6328 (0.6428)  loss_vfl_enc_0: 0.8805 (0.8870)  loss_bbox_enc_0: 0.3690 (0.3968)  loss_giou_enc_0: 0.9130 (0.9718)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4620  data: 4.3804  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9606  data: 2.2066  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9930 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.422\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            "best_stat: {'epoch': 48, 'coco_eval_bbox': 0.20475145920594665}\n",
            "Epoch: [49]  [0/8]  eta: 0:00:25  lr: 0.000002  loss: 21.9716 (21.9716)  loss_vfl: 0.5207 (0.5207)  loss_bbox: 0.3644 (0.3644)  loss_giou: 0.9273 (0.9273)  loss_vfl_aux_0: 0.8902 (0.8902)  loss_bbox_aux_0: 0.3610 (0.3610)  loss_giou_aux_0: 0.9133 (0.9133)  loss_vfl_aux_1: 0.7886 (0.7886)  loss_bbox_aux_1: 0.3559 (0.3559)  loss_giou_aux_1: 0.9324 (0.9324)  loss_vfl_aux_2: 0.6475 (0.6475)  loss_bbox_aux_2: 0.3681 (0.3681)  loss_giou_aux_2: 0.9510 (0.9510)  loss_vfl_aux_3: 0.5539 (0.5539)  loss_bbox_aux_3: 0.3691 (0.3691)  loss_giou_aux_3: 0.9485 (0.9485)  loss_vfl_aux_4: 0.5425 (0.5425)  loss_bbox_aux_4: 0.3651 (0.3651)  loss_giou_aux_4: 0.9239 (0.9239)  loss_vfl_dn_0: 0.5529 (0.5529)  loss_bbox_dn_0: 0.2400 (0.2400)  loss_giou_dn_0: 0.7184 (0.7184)  loss_vfl_dn_1: 0.5046 (0.5046)  loss_bbox_dn_1: 0.2169 (0.2169)  loss_giou_dn_1: 0.6529 (0.6529)  loss_vfl_dn_2: 0.4575 (0.4575)  loss_bbox_dn_2: 0.2118 (0.2118)  loss_giou_dn_2: 0.6393 (0.6393)  loss_vfl_dn_3: 0.4523 (0.4523)  loss_bbox_dn_3: 0.2069 (0.2069)  loss_giou_dn_3: 0.6348 (0.6348)  loss_vfl_dn_4: 0.4547 (0.4547)  loss_bbox_dn_4: 0.2055 (0.2055)  loss_giou_dn_4: 0.6321 (0.6321)  loss_vfl_dn_5: 0.4467 (0.4467)  loss_bbox_dn_5: 0.2054 (0.2054)  loss_giou_dn_5: 0.6314 (0.6314)  loss_vfl_enc_0: 0.8507 (0.8507)  loss_bbox_enc_0: 0.3752 (0.3752)  loss_giou_enc_0: 0.9582 (0.9582)  time: 3.1559  data: 2.5551  max mem: 16811\n",
            "Epoch: [49]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 22.1844 (22.1810)  loss_vfl: 0.5233 (0.5354)  loss_bbox: 0.3644 (0.3531)  loss_giou: 0.9143 (0.9085)  loss_vfl_aux_0: 0.9300 (0.9486)  loss_bbox_aux_0: 0.3610 (0.3796)  loss_giou_aux_0: 0.9133 (0.9204)  loss_vfl_aux_1: 0.8164 (0.8270)  loss_bbox_aux_1: 0.3583 (0.3833)  loss_giou_aux_1: 0.9324 (0.9438)  loss_vfl_aux_2: 0.6662 (0.6786)  loss_bbox_aux_2: 0.3681 (0.3903)  loss_giou_aux_2: 0.9510 (0.9594)  loss_vfl_aux_3: 0.5539 (0.5644)  loss_bbox_aux_3: 0.3691 (0.3541)  loss_giou_aux_3: 0.9425 (0.9297)  loss_vfl_aux_4: 0.5382 (0.5484)  loss_bbox_aux_4: 0.3651 (0.3563)  loss_giou_aux_4: 0.9067 (0.9107)  loss_vfl_dn_0: 0.5529 (0.5577)  loss_bbox_dn_0: 0.2400 (0.2405)  loss_giou_dn_0: 0.7179 (0.7105)  loss_vfl_dn_1: 0.4936 (0.4964)  loss_bbox_dn_1: 0.2169 (0.2165)  loss_giou_dn_1: 0.6515 (0.6510)  loss_vfl_dn_2: 0.4489 (0.4507)  loss_bbox_dn_2: 0.2093 (0.2105)  loss_giou_dn_2: 0.6357 (0.6385)  loss_vfl_dn_3: 0.4460 (0.4449)  loss_bbox_dn_3: 0.2064 (0.2077)  loss_giou_dn_3: 0.6340 (0.6372)  loss_vfl_dn_4: 0.4471 (0.4483)  loss_bbox_dn_4: 0.2047 (0.2069)  loss_giou_dn_4: 0.6320 (0.6353)  loss_vfl_dn_5: 0.4414 (0.4414)  loss_bbox_dn_5: 0.2044 (0.2067)  loss_giou_dn_5: 0.6308 (0.6348)  loss_vfl_enc_0: 0.8605 (0.8833)  loss_bbox_enc_0: 0.3752 (0.3986)  loss_giou_enc_0: 0.9582 (0.9720)  time: 0.8557  data: 0.3363  max mem: 16811\n",
            "Epoch: [49] Total time: 0:00:06 (0.8613 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 22.1844 (22.1810)  loss_vfl: 0.5233 (0.5354)  loss_bbox: 0.3644 (0.3531)  loss_giou: 0.9143 (0.9085)  loss_vfl_aux_0: 0.9300 (0.9486)  loss_bbox_aux_0: 0.3610 (0.3796)  loss_giou_aux_0: 0.9133 (0.9204)  loss_vfl_aux_1: 0.8164 (0.8270)  loss_bbox_aux_1: 0.3583 (0.3833)  loss_giou_aux_1: 0.9324 (0.9438)  loss_vfl_aux_2: 0.6662 (0.6786)  loss_bbox_aux_2: 0.3681 (0.3903)  loss_giou_aux_2: 0.9510 (0.9594)  loss_vfl_aux_3: 0.5539 (0.5644)  loss_bbox_aux_3: 0.3691 (0.3541)  loss_giou_aux_3: 0.9425 (0.9297)  loss_vfl_aux_4: 0.5382 (0.5484)  loss_bbox_aux_4: 0.3651 (0.3563)  loss_giou_aux_4: 0.9067 (0.9107)  loss_vfl_dn_0: 0.5529 (0.5577)  loss_bbox_dn_0: 0.2400 (0.2405)  loss_giou_dn_0: 0.7179 (0.7105)  loss_vfl_dn_1: 0.4936 (0.4964)  loss_bbox_dn_1: 0.2169 (0.2165)  loss_giou_dn_1: 0.6515 (0.6510)  loss_vfl_dn_2: 0.4489 (0.4507)  loss_bbox_dn_2: 0.2093 (0.2105)  loss_giou_dn_2: 0.6357 (0.6385)  loss_vfl_dn_3: 0.4460 (0.4449)  loss_bbox_dn_3: 0.2064 (0.2077)  loss_giou_dn_3: 0.6340 (0.6372)  loss_vfl_dn_4: 0.4471 (0.4483)  loss_bbox_dn_4: 0.2047 (0.2069)  loss_giou_dn_4: 0.6320 (0.6353)  loss_vfl_dn_5: 0.4414 (0.4414)  loss_bbox_dn_5: 0.2044 (0.2067)  loss_giou_dn_5: 0.6308 (0.6348)  loss_vfl_enc_0: 0.8605 (0.8833)  loss_bbox_enc_0: 0.3752 (0.3986)  loss_giou_enc_0: 0.9582 (0.9720)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5347  data: 4.4471  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1789  data: 2.2403  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.2140 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            "best_stat: {'epoch': 49, 'coco_eval_bbox': 0.21323250051613532}\n",
            "Epoch: [50]  [0/8]  eta: 0:00:20  lr: 0.000002  loss: 21.9708 (21.9708)  loss_vfl: 0.5415 (0.5415)  loss_bbox: 0.3153 (0.3153)  loss_giou: 0.8834 (0.8834)  loss_vfl_aux_0: 0.9975 (0.9975)  loss_bbox_aux_0: 0.3560 (0.3560)  loss_giou_aux_0: 0.9169 (0.9169)  loss_vfl_aux_1: 0.8688 (0.8688)  loss_bbox_aux_1: 0.3569 (0.3569)  loss_giou_aux_1: 0.9341 (0.9341)  loss_vfl_aux_2: 0.6855 (0.6855)  loss_bbox_aux_2: 0.3713 (0.3713)  loss_giou_aux_2: 0.9718 (0.9718)  loss_vfl_aux_3: 0.5668 (0.5668)  loss_bbox_aux_3: 0.3274 (0.3274)  loss_giou_aux_3: 0.9020 (0.9020)  loss_vfl_aux_4: 0.5717 (0.5717)  loss_bbox_aux_4: 0.3147 (0.3147)  loss_giou_aux_4: 0.8809 (0.8809)  loss_vfl_dn_0: 0.5570 (0.5570)  loss_bbox_dn_0: 0.2256 (0.2256)  loss_giou_dn_0: 0.7064 (0.7064)  loss_vfl_dn_1: 0.4898 (0.4898)  loss_bbox_dn_1: 0.2061 (0.2061)  loss_giou_dn_1: 0.6511 (0.6511)  loss_vfl_dn_2: 0.4453 (0.4453)  loss_bbox_dn_2: 0.2012 (0.2012)  loss_giou_dn_2: 0.6350 (0.6350)  loss_vfl_dn_3: 0.4354 (0.4354)  loss_bbox_dn_3: 0.2019 (0.2019)  loss_giou_dn_3: 0.6388 (0.6388)  loss_vfl_dn_4: 0.4417 (0.4417)  loss_bbox_dn_4: 0.2023 (0.2023)  loss_giou_dn_4: 0.6361 (0.6361)  loss_vfl_dn_5: 0.4306 (0.4306)  loss_bbox_dn_5: 0.2021 (0.2021)  loss_giou_dn_5: 0.6356 (0.6356)  loss_vfl_enc_0: 0.9075 (0.9075)  loss_bbox_enc_0: 0.3843 (0.3843)  loss_giou_enc_0: 0.9746 (0.9746)  time: 2.5402  data: 1.9982  max mem: 16811\n",
            "Epoch: [50]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 21.9786 (22.0261)  loss_vfl: 0.5320 (0.5323)  loss_bbox: 0.3458 (0.3418)  loss_giou: 0.8869 (0.8905)  loss_vfl_aux_0: 0.9614 (0.9717)  loss_bbox_aux_0: 0.3673 (0.3699)  loss_giou_aux_0: 0.9169 (0.9052)  loss_vfl_aux_1: 0.8182 (0.8351)  loss_bbox_aux_1: 0.3627 (0.3756)  loss_giou_aux_1: 0.9343 (0.9297)  loss_vfl_aux_2: 0.6694 (0.6861)  loss_bbox_aux_2: 0.3717 (0.3851)  loss_giou_aux_2: 0.9514 (0.9468)  loss_vfl_aux_3: 0.5526 (0.5577)  loss_bbox_aux_3: 0.3457 (0.3459)  loss_giou_aux_3: 0.9202 (0.9138)  loss_vfl_aux_4: 0.5484 (0.5576)  loss_bbox_aux_4: 0.3524 (0.3447)  loss_giou_aux_4: 0.8884 (0.8907)  loss_vfl_dn_0: 0.5570 (0.5550)  loss_bbox_dn_0: 0.2307 (0.2411)  loss_giou_dn_0: 0.6993 (0.7077)  loss_vfl_dn_1: 0.4922 (0.4940)  loss_bbox_dn_1: 0.2061 (0.2143)  loss_giou_dn_1: 0.6279 (0.6473)  loss_vfl_dn_2: 0.4540 (0.4520)  loss_bbox_dn_2: 0.2022 (0.2096)  loss_giou_dn_2: 0.6140 (0.6333)  loss_vfl_dn_3: 0.4428 (0.4438)  loss_bbox_dn_3: 0.2016 (0.2070)  loss_giou_dn_3: 0.6132 (0.6334)  loss_vfl_dn_4: 0.4458 (0.4483)  loss_bbox_dn_4: 0.2008 (0.2064)  loss_giou_dn_4: 0.6057 (0.6289)  loss_vfl_dn_5: 0.4361 (0.4390)  loss_bbox_dn_5: 0.2006 (0.2063)  loss_giou_dn_5: 0.6051 (0.6287)  loss_vfl_enc_0: 0.8958 (0.8949)  loss_bbox_enc_0: 0.3875 (0.3928)  loss_giou_enc_0: 0.9729 (0.9620)  time: 0.7877  data: 0.2766  max mem: 16811\n",
            "Epoch: [50] Total time: 0:00:06 (0.7929 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 21.9786 (22.0261)  loss_vfl: 0.5320 (0.5323)  loss_bbox: 0.3458 (0.3418)  loss_giou: 0.8869 (0.8905)  loss_vfl_aux_0: 0.9614 (0.9717)  loss_bbox_aux_0: 0.3673 (0.3699)  loss_giou_aux_0: 0.9169 (0.9052)  loss_vfl_aux_1: 0.8182 (0.8351)  loss_bbox_aux_1: 0.3627 (0.3756)  loss_giou_aux_1: 0.9343 (0.9297)  loss_vfl_aux_2: 0.6694 (0.6861)  loss_bbox_aux_2: 0.3717 (0.3851)  loss_giou_aux_2: 0.9514 (0.9468)  loss_vfl_aux_3: 0.5526 (0.5577)  loss_bbox_aux_3: 0.3457 (0.3459)  loss_giou_aux_3: 0.9202 (0.9138)  loss_vfl_aux_4: 0.5484 (0.5576)  loss_bbox_aux_4: 0.3524 (0.3447)  loss_giou_aux_4: 0.8884 (0.8907)  loss_vfl_dn_0: 0.5570 (0.5550)  loss_bbox_dn_0: 0.2307 (0.2411)  loss_giou_dn_0: 0.6993 (0.7077)  loss_vfl_dn_1: 0.4922 (0.4940)  loss_bbox_dn_1: 0.2061 (0.2143)  loss_giou_dn_1: 0.6279 (0.6473)  loss_vfl_dn_2: 0.4540 (0.4520)  loss_bbox_dn_2: 0.2022 (0.2096)  loss_giou_dn_2: 0.6140 (0.6333)  loss_vfl_dn_3: 0.4428 (0.4438)  loss_bbox_dn_3: 0.2016 (0.2070)  loss_giou_dn_3: 0.6132 (0.6334)  loss_vfl_dn_4: 0.4458 (0.4483)  loss_bbox_dn_4: 0.2008 (0.2064)  loss_giou_dn_4: 0.6057 (0.6289)  loss_vfl_dn_5: 0.4361 (0.4390)  loss_bbox_dn_5: 0.2006 (0.2063)  loss_giou_dn_5: 0.6051 (0.6287)  loss_vfl_enc_0: 0.8958 (0.8949)  loss_bbox_enc_0: 0.3875 (0.3928)  loss_giou_enc_0: 0.9729 (0.9620)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4988  data: 4.4236  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9764  data: 2.2279  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0063 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.229\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
            "best_stat: {'epoch': 50, 'coco_eval_bbox': 0.21470508077315406}\n",
            "Epoch: [51]  [0/8]  eta: 0:00:22  lr: 0.000002  loss: 22.6771 (22.6771)  loss_vfl: 0.4773 (0.4773)  loss_bbox: 0.4045 (0.4045)  loss_giou: 0.9469 (0.9469)  loss_vfl_aux_0: 0.9187 (0.9187)  loss_bbox_aux_0: 0.4163 (0.4163)  loss_giou_aux_0: 0.9538 (0.9538)  loss_vfl_aux_1: 0.7712 (0.7712)  loss_bbox_aux_1: 0.4236 (0.4236)  loss_giou_aux_1: 0.9751 (0.9751)  loss_vfl_aux_2: 0.6390 (0.6390)  loss_bbox_aux_2: 0.4293 (0.4293)  loss_giou_aux_2: 0.9895 (0.9895)  loss_vfl_aux_3: 0.4987 (0.4987)  loss_bbox_aux_3: 0.4063 (0.4063)  loss_giou_aux_3: 0.9625 (0.9625)  loss_vfl_aux_4: 0.5109 (0.5109)  loss_bbox_aux_4: 0.4025 (0.4025)  loss_giou_aux_4: 0.9460 (0.9460)  loss_vfl_dn_0: 0.5452 (0.5452)  loss_bbox_dn_0: 0.2674 (0.2674)  loss_giou_dn_0: 0.7327 (0.7327)  loss_vfl_dn_1: 0.4988 (0.4988)  loss_bbox_dn_1: 0.2356 (0.2356)  loss_giou_dn_1: 0.6728 (0.6728)  loss_vfl_dn_2: 0.4571 (0.4571)  loss_bbox_dn_2: 0.2351 (0.2351)  loss_giou_dn_2: 0.6624 (0.6624)  loss_vfl_dn_3: 0.4469 (0.4469)  loss_bbox_dn_3: 0.2304 (0.2304)  loss_giou_dn_3: 0.6616 (0.6616)  loss_vfl_dn_4: 0.4493 (0.4493)  loss_bbox_dn_4: 0.2324 (0.2324)  loss_giou_dn_4: 0.6615 (0.6615)  loss_vfl_dn_5: 0.4370 (0.4370)  loss_bbox_dn_5: 0.2325 (0.2325)  loss_giou_dn_5: 0.6622 (0.6622)  loss_vfl_enc_0: 0.8579 (0.8579)  loss_bbox_enc_0: 0.4351 (0.4351)  loss_giou_enc_0: 0.9911 (0.9911)  time: 2.8368  data: 2.2877  max mem: 16811\n",
            "Epoch: [51]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 21.4552 (21.6877)  loss_vfl: 0.5019 (0.5104)  loss_bbox: 0.3358 (0.3386)  loss_giou: 0.8558 (0.8800)  loss_vfl_aux_0: 0.9751 (0.9776)  loss_bbox_aux_0: 0.3423 (0.3592)  loss_giou_aux_0: 0.8747 (0.8830)  loss_vfl_aux_1: 0.8011 (0.8145)  loss_bbox_aux_1: 0.3485 (0.3658)  loss_giou_aux_1: 0.9081 (0.9057)  loss_vfl_aux_2: 0.6563 (0.6827)  loss_bbox_aux_2: 0.3662 (0.3782)  loss_giou_aux_2: 0.9200 (0.9226)  loss_vfl_aux_3: 0.4988 (0.5203)  loss_bbox_aux_3: 0.3355 (0.3462)  loss_giou_aux_3: 0.8763 (0.9104)  loss_vfl_aux_4: 0.5118 (0.5328)  loss_bbox_aux_4: 0.3307 (0.3429)  loss_giou_aux_4: 0.8584 (0.8829)  loss_vfl_dn_0: 0.5490 (0.5514)  loss_bbox_dn_0: 0.2322 (0.2387)  loss_giou_dn_0: 0.7013 (0.7009)  loss_vfl_dn_1: 0.4898 (0.4916)  loss_bbox_dn_1: 0.2054 (0.2106)  loss_giou_dn_1: 0.6402 (0.6415)  loss_vfl_dn_2: 0.4465 (0.4479)  loss_bbox_dn_2: 0.2024 (0.2064)  loss_giou_dn_2: 0.6263 (0.6288)  loss_vfl_dn_3: 0.4360 (0.4377)  loss_bbox_dn_3: 0.1995 (0.2037)  loss_giou_dn_3: 0.6243 (0.6278)  loss_vfl_dn_4: 0.4400 (0.4426)  loss_bbox_dn_4: 0.1976 (0.2040)  loss_giou_dn_4: 0.6241 (0.6258)  loss_vfl_dn_5: 0.4313 (0.4339)  loss_bbox_dn_5: 0.1976 (0.2039)  loss_giou_dn_5: 0.6224 (0.6252)  loss_vfl_enc_0: 0.8840 (0.8956)  loss_bbox_enc_0: 0.3674 (0.3794)  loss_giou_enc_0: 0.9371 (0.9364)  time: 0.8221  data: 0.3074  max mem: 16811\n",
            "Epoch: [51] Total time: 0:00:06 (0.8286 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 21.4552 (21.6877)  loss_vfl: 0.5019 (0.5104)  loss_bbox: 0.3358 (0.3386)  loss_giou: 0.8558 (0.8800)  loss_vfl_aux_0: 0.9751 (0.9776)  loss_bbox_aux_0: 0.3423 (0.3592)  loss_giou_aux_0: 0.8747 (0.8830)  loss_vfl_aux_1: 0.8011 (0.8145)  loss_bbox_aux_1: 0.3485 (0.3658)  loss_giou_aux_1: 0.9081 (0.9057)  loss_vfl_aux_2: 0.6563 (0.6827)  loss_bbox_aux_2: 0.3662 (0.3782)  loss_giou_aux_2: 0.9200 (0.9226)  loss_vfl_aux_3: 0.4988 (0.5203)  loss_bbox_aux_3: 0.3355 (0.3462)  loss_giou_aux_3: 0.8763 (0.9104)  loss_vfl_aux_4: 0.5118 (0.5328)  loss_bbox_aux_4: 0.3307 (0.3429)  loss_giou_aux_4: 0.8584 (0.8829)  loss_vfl_dn_0: 0.5490 (0.5514)  loss_bbox_dn_0: 0.2322 (0.2387)  loss_giou_dn_0: 0.7013 (0.7009)  loss_vfl_dn_1: 0.4898 (0.4916)  loss_bbox_dn_1: 0.2054 (0.2106)  loss_giou_dn_1: 0.6402 (0.6415)  loss_vfl_dn_2: 0.4465 (0.4479)  loss_bbox_dn_2: 0.2024 (0.2064)  loss_giou_dn_2: 0.6263 (0.6288)  loss_vfl_dn_3: 0.4360 (0.4377)  loss_bbox_dn_3: 0.1995 (0.2037)  loss_giou_dn_3: 0.6243 (0.6278)  loss_vfl_dn_4: 0.4400 (0.4426)  loss_bbox_dn_4: 0.1976 (0.2040)  loss_giou_dn_4: 0.6241 (0.6258)  loss_vfl_dn_5: 0.4313 (0.4339)  loss_bbox_dn_5: 0.1976 (0.2039)  loss_giou_dn_5: 0.6224 (0.6252)  loss_vfl_enc_0: 0.8840 (0.8956)  loss_bbox_enc_0: 0.3674 (0.3794)  loss_giou_enc_0: 0.9371 (0.9364)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.6829  data: 1.2879  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5697  data: 0.6607  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.5993 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.463\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
            "best_stat: {'epoch': 51, 'coco_eval_bbox': 0.22523398324466049}\n",
            "Epoch: [52]  [0/8]  eta: 0:00:21  lr: 0.000002  loss: 21.2727 (21.2727)  loss_vfl: 0.5100 (0.5100)  loss_bbox: 0.3202 (0.3202)  loss_giou: 0.8712 (0.8712)  loss_vfl_aux_0: 1.0165 (1.0165)  loss_bbox_aux_0: 0.3091 (0.3091)  loss_giou_aux_0: 0.8510 (0.8510)  loss_vfl_aux_1: 0.8303 (0.8303)  loss_bbox_aux_1: 0.3173 (0.3173)  loss_giou_aux_1: 0.8744 (0.8744)  loss_vfl_aux_2: 0.6836 (0.6836)  loss_bbox_aux_2: 0.3246 (0.3246)  loss_giou_aux_2: 0.8784 (0.8784)  loss_vfl_aux_3: 0.5299 (0.5299)  loss_bbox_aux_3: 0.3130 (0.3130)  loss_giou_aux_3: 0.8876 (0.8876)  loss_vfl_aux_4: 0.5251 (0.5251)  loss_bbox_aux_4: 0.3250 (0.3250)  loss_giou_aux_4: 0.8794 (0.8794)  loss_vfl_dn_0: 0.5517 (0.5517)  loss_bbox_dn_0: 0.2303 (0.2303)  loss_giou_dn_0: 0.6926 (0.6926)  loss_vfl_dn_1: 0.4883 (0.4883)  loss_bbox_dn_1: 0.2080 (0.2080)  loss_giou_dn_1: 0.6353 (0.6353)  loss_vfl_dn_2: 0.4446 (0.4446)  loss_bbox_dn_2: 0.2033 (0.2033)  loss_giou_dn_2: 0.6276 (0.6276)  loss_vfl_dn_3: 0.4330 (0.4330)  loss_bbox_dn_3: 0.2028 (0.2028)  loss_giou_dn_3: 0.6297 (0.6297)  loss_vfl_dn_4: 0.4389 (0.4389)  loss_bbox_dn_4: 0.2023 (0.2023)  loss_giou_dn_4: 0.6267 (0.6267)  loss_vfl_dn_5: 0.4284 (0.4284)  loss_bbox_dn_5: 0.2021 (0.2021)  loss_giou_dn_5: 0.6255 (0.6255)  loss_vfl_enc_0: 0.9353 (0.9353)  loss_bbox_enc_0: 0.3254 (0.3254)  loss_giou_enc_0: 0.8941 (0.8941)  time: 2.7326  data: 2.1659  max mem: 16811\n",
            "Epoch: [52]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 21.1690 (21.3404)  loss_vfl: 0.5100 (0.5166)  loss_bbox: 0.3273 (0.3306)  loss_giou: 0.8506 (0.8604)  loss_vfl_aux_0: 0.9897 (0.9882)  loss_bbox_aux_0: 0.3206 (0.3384)  loss_giou_aux_0: 0.8461 (0.8519)  loss_vfl_aux_1: 0.8207 (0.8123)  loss_bbox_aux_1: 0.3313 (0.3459)  loss_giou_aux_1: 0.8744 (0.8790)  loss_vfl_aux_2: 0.6466 (0.6535)  loss_bbox_aux_2: 0.3482 (0.3587)  loss_giou_aux_2: 0.8796 (0.8977)  loss_vfl_aux_3: 0.5274 (0.5244)  loss_bbox_aux_3: 0.3292 (0.3303)  loss_giou_aux_3: 0.8826 (0.8822)  loss_vfl_aux_4: 0.5197 (0.5305)  loss_bbox_aux_4: 0.3218 (0.3314)  loss_giou_aux_4: 0.8563 (0.8634)  loss_vfl_dn_0: 0.5465 (0.5471)  loss_bbox_dn_0: 0.2346 (0.2375)  loss_giou_dn_0: 0.6862 (0.6959)  loss_vfl_dn_1: 0.4886 (0.4895)  loss_bbox_dn_1: 0.2047 (0.2099)  loss_giou_dn_1: 0.6280 (0.6371)  loss_vfl_dn_2: 0.4446 (0.4458)  loss_bbox_dn_2: 0.2012 (0.2052)  loss_giou_dn_2: 0.6194 (0.6260)  loss_vfl_dn_3: 0.4358 (0.4367)  loss_bbox_dn_3: 0.1991 (0.2022)  loss_giou_dn_3: 0.6161 (0.6239)  loss_vfl_dn_4: 0.4390 (0.4407)  loss_bbox_dn_4: 0.2018 (0.2022)  loss_giou_dn_4: 0.6135 (0.6212)  loss_vfl_dn_5: 0.4326 (0.4342)  loss_bbox_dn_5: 0.2016 (0.2020)  loss_giou_dn_5: 0.6134 (0.6206)  loss_vfl_enc_0: 0.8975 (0.8990)  loss_bbox_enc_0: 0.3467 (0.3609)  loss_giou_enc_0: 0.9004 (0.9074)  time: 0.8182  data: 0.2986  max mem: 16811\n",
            "Epoch: [52] Total time: 0:00:06 (0.8241 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 21.1690 (21.3404)  loss_vfl: 0.5100 (0.5166)  loss_bbox: 0.3273 (0.3306)  loss_giou: 0.8506 (0.8604)  loss_vfl_aux_0: 0.9897 (0.9882)  loss_bbox_aux_0: 0.3206 (0.3384)  loss_giou_aux_0: 0.8461 (0.8519)  loss_vfl_aux_1: 0.8207 (0.8123)  loss_bbox_aux_1: 0.3313 (0.3459)  loss_giou_aux_1: 0.8744 (0.8790)  loss_vfl_aux_2: 0.6466 (0.6535)  loss_bbox_aux_2: 0.3482 (0.3587)  loss_giou_aux_2: 0.8796 (0.8977)  loss_vfl_aux_3: 0.5274 (0.5244)  loss_bbox_aux_3: 0.3292 (0.3303)  loss_giou_aux_3: 0.8826 (0.8822)  loss_vfl_aux_4: 0.5197 (0.5305)  loss_bbox_aux_4: 0.3218 (0.3314)  loss_giou_aux_4: 0.8563 (0.8634)  loss_vfl_dn_0: 0.5465 (0.5471)  loss_bbox_dn_0: 0.2346 (0.2375)  loss_giou_dn_0: 0.6862 (0.6959)  loss_vfl_dn_1: 0.4886 (0.4895)  loss_bbox_dn_1: 0.2047 (0.2099)  loss_giou_dn_1: 0.6280 (0.6371)  loss_vfl_dn_2: 0.4446 (0.4458)  loss_bbox_dn_2: 0.2012 (0.2052)  loss_giou_dn_2: 0.6194 (0.6260)  loss_vfl_dn_3: 0.4358 (0.4367)  loss_bbox_dn_3: 0.1991 (0.2022)  loss_giou_dn_3: 0.6161 (0.6239)  loss_vfl_dn_4: 0.4390 (0.4407)  loss_bbox_dn_4: 0.2018 (0.2022)  loss_giou_dn_4: 0.6135 (0.6212)  loss_vfl_dn_5: 0.4326 (0.4342)  loss_bbox_dn_5: 0.2016 (0.2020)  loss_giou_dn_5: 0.6134 (0.6206)  loss_vfl_enc_0: 0.8975 (0.8990)  loss_bbox_enc_0: 0.3467 (0.3609)  loss_giou_enc_0: 0.9004 (0.9074)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4054  data: 4.3194  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9335  data: 2.1763  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9569 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.483\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            "best_stat: {'epoch': 52, 'coco_eval_bbox': 0.23407739531050112}\n",
            "Epoch: [53]  [0/8]  eta: 0:00:23  lr: 0.000002  loss: 22.4922 (22.4922)  loss_vfl: 0.4931 (0.4931)  loss_bbox: 0.3663 (0.3663)  loss_giou: 0.9061 (0.9061)  loss_vfl_aux_0: 0.9810 (0.9810)  loss_bbox_aux_0: 0.4207 (0.4207)  loss_giou_aux_0: 0.9378 (0.9378)  loss_vfl_aux_1: 0.7998 (0.7998)  loss_bbox_aux_1: 0.4302 (0.4302)  loss_giou_aux_1: 0.9619 (0.9619)  loss_vfl_aux_2: 0.6171 (0.6171)  loss_bbox_aux_2: 0.4495 (0.4495)  loss_giou_aux_2: 0.9839 (0.9839)  loss_vfl_aux_3: 0.4924 (0.4924)  loss_bbox_aux_3: 0.3945 (0.3945)  loss_giou_aux_3: 0.9511 (0.9511)  loss_vfl_aux_4: 0.5186 (0.5186)  loss_bbox_aux_4: 0.3698 (0.3698)  loss_giou_aux_4: 0.9018 (0.9018)  loss_vfl_dn_0: 0.5443 (0.5443)  loss_bbox_dn_0: 0.2609 (0.2609)  loss_giou_dn_0: 0.7206 (0.7206)  loss_vfl_dn_1: 0.4955 (0.4955)  loss_bbox_dn_1: 0.2345 (0.2345)  loss_giou_dn_1: 0.6628 (0.6628)  loss_vfl_dn_2: 0.4497 (0.4497)  loss_bbox_dn_2: 0.2262 (0.2262)  loss_giou_dn_2: 0.6515 (0.6515)  loss_vfl_dn_3: 0.4404 (0.4404)  loss_bbox_dn_3: 0.2244 (0.2244)  loss_giou_dn_3: 0.6522 (0.6522)  loss_vfl_dn_4: 0.4403 (0.4403)  loss_bbox_dn_4: 0.2248 (0.2248)  loss_giou_dn_4: 0.6530 (0.6530)  loss_vfl_dn_5: 0.4325 (0.4325)  loss_bbox_dn_5: 0.2247 (0.2247)  loss_giou_dn_5: 0.6525 (0.6525)  loss_vfl_enc_0: 0.8898 (0.8898)  loss_bbox_enc_0: 0.4359 (0.4359)  loss_giou_enc_0: 1.0000 (1.0000)  time: 2.8983  data: 2.3562  max mem: 16811\n",
            "Epoch: [53]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 20.9942 (21.2558)  loss_vfl: 0.5170 (0.5218)  loss_bbox: 0.3064 (0.3201)  loss_giou: 0.8434 (0.8439)  loss_vfl_aux_0: 0.9810 (1.0045)  loss_bbox_aux_0: 0.3185 (0.3320)  loss_giou_aux_0: 0.8301 (0.8348)  loss_vfl_aux_1: 0.8051 (0.8315)  loss_bbox_aux_1: 0.3223 (0.3406)  loss_giou_aux_1: 0.8715 (0.8665)  loss_vfl_aux_2: 0.6330 (0.6413)  loss_bbox_aux_2: 0.3336 (0.3535)  loss_giou_aux_2: 0.8891 (0.8888)  loss_vfl_aux_3: 0.5347 (0.5410)  loss_bbox_aux_3: 0.3143 (0.3272)  loss_giou_aux_3: 0.8760 (0.8670)  loss_vfl_aux_4: 0.5270 (0.5347)  loss_bbox_aux_4: 0.3122 (0.3213)  loss_giou_aux_4: 0.8413 (0.8449)  loss_vfl_dn_0: 0.5466 (0.5481)  loss_bbox_dn_0: 0.2309 (0.2348)  loss_giou_dn_0: 0.6948 (0.6937)  loss_vfl_dn_1: 0.4888 (0.4892)  loss_bbox_dn_1: 0.2061 (0.2099)  loss_giou_dn_1: 0.6322 (0.6389)  loss_vfl_dn_2: 0.4437 (0.4442)  loss_bbox_dn_2: 0.2015 (0.2056)  loss_giou_dn_2: 0.6219 (0.6275)  loss_vfl_dn_3: 0.4404 (0.4394)  loss_bbox_dn_3: 0.1980 (0.2027)  loss_giou_dn_3: 0.6156 (0.6250)  loss_vfl_dn_4: 0.4403 (0.4407)  loss_bbox_dn_4: 0.1984 (0.2032)  loss_giou_dn_4: 0.6148 (0.6232)  loss_vfl_dn_5: 0.4352 (0.4340)  loss_bbox_dn_5: 0.1982 (0.2030)  loss_giou_dn_5: 0.6133 (0.6220)  loss_vfl_enc_0: 0.8898 (0.9061)  loss_bbox_enc_0: 0.3450 (0.3536)  loss_giou_enc_0: 0.8855 (0.8959)  time: 0.8686  data: 0.3233  max mem: 16811\n",
            "Epoch: [53] Total time: 0:00:07 (0.8765 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 20.9942 (21.2558)  loss_vfl: 0.5170 (0.5218)  loss_bbox: 0.3064 (0.3201)  loss_giou: 0.8434 (0.8439)  loss_vfl_aux_0: 0.9810 (1.0045)  loss_bbox_aux_0: 0.3185 (0.3320)  loss_giou_aux_0: 0.8301 (0.8348)  loss_vfl_aux_1: 0.8051 (0.8315)  loss_bbox_aux_1: 0.3223 (0.3406)  loss_giou_aux_1: 0.8715 (0.8665)  loss_vfl_aux_2: 0.6330 (0.6413)  loss_bbox_aux_2: 0.3336 (0.3535)  loss_giou_aux_2: 0.8891 (0.8888)  loss_vfl_aux_3: 0.5347 (0.5410)  loss_bbox_aux_3: 0.3143 (0.3272)  loss_giou_aux_3: 0.8760 (0.8670)  loss_vfl_aux_4: 0.5270 (0.5347)  loss_bbox_aux_4: 0.3122 (0.3213)  loss_giou_aux_4: 0.8413 (0.8449)  loss_vfl_dn_0: 0.5466 (0.5481)  loss_bbox_dn_0: 0.2309 (0.2348)  loss_giou_dn_0: 0.6948 (0.6937)  loss_vfl_dn_1: 0.4888 (0.4892)  loss_bbox_dn_1: 0.2061 (0.2099)  loss_giou_dn_1: 0.6322 (0.6389)  loss_vfl_dn_2: 0.4437 (0.4442)  loss_bbox_dn_2: 0.2015 (0.2056)  loss_giou_dn_2: 0.6219 (0.6275)  loss_vfl_dn_3: 0.4404 (0.4394)  loss_bbox_dn_3: 0.1980 (0.2027)  loss_giou_dn_3: 0.6156 (0.6250)  loss_vfl_dn_4: 0.4403 (0.4407)  loss_bbox_dn_4: 0.1984 (0.2032)  loss_giou_dn_4: 0.6148 (0.6232)  loss_vfl_dn_5: 0.4352 (0.4340)  loss_bbox_dn_5: 0.1982 (0.2030)  loss_giou_dn_5: 0.6133 (0.6220)  loss_vfl_enc_0: 0.8898 (0.9061)  loss_bbox_enc_0: 0.3450 (0.3536)  loss_giou_enc_0: 0.8855 (0.8959)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4995  data: 4.4282  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9753  data: 2.2303  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0074 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.498\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            "best_stat: {'epoch': 53, 'coco_eval_bbox': 0.24193684803654514}\n",
            "Epoch: [54]  [0/8]  eta: 0:00:24  lr: 0.000002  loss: 20.7643 (20.7643)  loss_vfl: 0.5465 (0.5465)  loss_bbox: 0.3277 (0.3277)  loss_giou: 0.7643 (0.7643)  loss_vfl_aux_0: 1.0957 (1.0957)  loss_bbox_aux_0: 0.3044 (0.3044)  loss_giou_aux_0: 0.7001 (0.7001)  loss_vfl_aux_1: 0.8930 (0.8930)  loss_bbox_aux_1: 0.3146 (0.3146)  loss_giou_aux_1: 0.7524 (0.7524)  loss_vfl_aux_2: 0.7033 (0.7033)  loss_bbox_aux_2: 0.3270 (0.3270)  loss_giou_aux_2: 0.7668 (0.7668)  loss_vfl_aux_3: 0.6034 (0.6034)  loss_bbox_aux_3: 0.3209 (0.3209)  loss_giou_aux_3: 0.7581 (0.7581)  loss_vfl_aux_4: 0.5615 (0.5615)  loss_bbox_aux_4: 0.3175 (0.3175)  loss_giou_aux_4: 0.7598 (0.7598)  loss_vfl_dn_0: 0.5526 (0.5526)  loss_bbox_dn_0: 0.2684 (0.2684)  loss_giou_dn_0: 0.6778 (0.6778)  loss_vfl_dn_1: 0.4922 (0.4922)  loss_bbox_dn_1: 0.2374 (0.2374)  loss_giou_dn_1: 0.6182 (0.6182)  loss_vfl_dn_2: 0.4457 (0.4457)  loss_bbox_dn_2: 0.2268 (0.2268)  loss_giou_dn_2: 0.5996 (0.5996)  loss_vfl_dn_3: 0.4380 (0.4380)  loss_bbox_dn_3: 0.2229 (0.2229)  loss_giou_dn_3: 0.5945 (0.5945)  loss_vfl_dn_4: 0.4383 (0.4383)  loss_bbox_dn_4: 0.2207 (0.2207)  loss_giou_dn_4: 0.5907 (0.5907)  loss_vfl_dn_5: 0.4347 (0.4347)  loss_bbox_dn_5: 0.2204 (0.2204)  loss_giou_dn_5: 0.5901 (0.5901)  loss_vfl_enc_0: 0.9703 (0.9703)  loss_bbox_enc_0: 0.3349 (0.3349)  loss_giou_enc_0: 0.7732 (0.7732)  time: 3.0101  data: 2.4513  max mem: 16811\n",
            "Epoch: [54]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 21.1387 (21.0704)  loss_vfl: 0.5139 (0.5249)  loss_bbox: 0.3196 (0.3194)  loss_giou: 0.8472 (0.8403)  loss_vfl_aux_0: 0.9928 (1.0093)  loss_bbox_aux_0: 0.3349 (0.3302)  loss_giou_aux_0: 0.8183 (0.8185)  loss_vfl_aux_1: 0.8170 (0.8258)  loss_bbox_aux_1: 0.3411 (0.3364)  loss_giou_aux_1: 0.8438 (0.8495)  loss_vfl_aux_2: 0.6328 (0.6378)  loss_bbox_aux_2: 0.3508 (0.3476)  loss_giou_aux_2: 0.8541 (0.8704)  loss_vfl_aux_3: 0.5470 (0.5603)  loss_bbox_aux_3: 0.3257 (0.3268)  loss_giou_aux_3: 0.8600 (0.8584)  loss_vfl_aux_4: 0.5304 (0.5343)  loss_bbox_aux_4: 0.3185 (0.3205)  loss_giou_aux_4: 0.8454 (0.8451)  loss_vfl_dn_0: 0.5492 (0.5454)  loss_bbox_dn_0: 0.2267 (0.2343)  loss_giou_dn_0: 0.6778 (0.6870)  loss_vfl_dn_1: 0.4907 (0.4864)  loss_bbox_dn_1: 0.2072 (0.2073)  loss_giou_dn_1: 0.6182 (0.6249)  loss_vfl_dn_2: 0.4431 (0.4424)  loss_bbox_dn_2: 0.2009 (0.2021)  loss_giou_dn_2: 0.6036 (0.6134)  loss_vfl_dn_3: 0.4371 (0.4377)  loss_bbox_dn_3: 0.1977 (0.1989)  loss_giou_dn_3: 0.6023 (0.6107)  loss_vfl_dn_4: 0.4382 (0.4389)  loss_bbox_dn_4: 0.1970 (0.1981)  loss_giou_dn_4: 0.5982 (0.6075)  loss_vfl_dn_5: 0.4313 (0.4329)  loss_bbox_dn_5: 0.1969 (0.1980)  loss_giou_dn_5: 0.5984 (0.6070)  loss_vfl_enc_0: 0.9066 (0.9107)  loss_bbox_enc_0: 0.3573 (0.3511)  loss_giou_enc_0: 0.8807 (0.8802)  time: 0.8431  data: 0.3270  max mem: 16811\n",
            "Epoch: [54] Total time: 0:00:06 (0.8500 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 21.1387 (21.0704)  loss_vfl: 0.5139 (0.5249)  loss_bbox: 0.3196 (0.3194)  loss_giou: 0.8472 (0.8403)  loss_vfl_aux_0: 0.9928 (1.0093)  loss_bbox_aux_0: 0.3349 (0.3302)  loss_giou_aux_0: 0.8183 (0.8185)  loss_vfl_aux_1: 0.8170 (0.8258)  loss_bbox_aux_1: 0.3411 (0.3364)  loss_giou_aux_1: 0.8438 (0.8495)  loss_vfl_aux_2: 0.6328 (0.6378)  loss_bbox_aux_2: 0.3508 (0.3476)  loss_giou_aux_2: 0.8541 (0.8704)  loss_vfl_aux_3: 0.5470 (0.5603)  loss_bbox_aux_3: 0.3257 (0.3268)  loss_giou_aux_3: 0.8600 (0.8584)  loss_vfl_aux_4: 0.5304 (0.5343)  loss_bbox_aux_4: 0.3185 (0.3205)  loss_giou_aux_4: 0.8454 (0.8451)  loss_vfl_dn_0: 0.5492 (0.5454)  loss_bbox_dn_0: 0.2267 (0.2343)  loss_giou_dn_0: 0.6778 (0.6870)  loss_vfl_dn_1: 0.4907 (0.4864)  loss_bbox_dn_1: 0.2072 (0.2073)  loss_giou_dn_1: 0.6182 (0.6249)  loss_vfl_dn_2: 0.4431 (0.4424)  loss_bbox_dn_2: 0.2009 (0.2021)  loss_giou_dn_2: 0.6036 (0.6134)  loss_vfl_dn_3: 0.4371 (0.4377)  loss_bbox_dn_3: 0.1977 (0.1989)  loss_giou_dn_3: 0.6023 (0.6107)  loss_vfl_dn_4: 0.4382 (0.4389)  loss_bbox_dn_4: 0.1970 (0.1981)  loss_giou_dn_4: 0.5982 (0.6075)  loss_vfl_dn_5: 0.4313 (0.4329)  loss_bbox_dn_5: 0.1969 (0.1980)  loss_giou_dn_5: 0.5984 (0.6070)  loss_vfl_enc_0: 0.9066 (0.9107)  loss_bbox_enc_0: 0.3573 (0.3511)  loss_giou_enc_0: 0.8807 (0.8802)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.2402  data: 2.8358  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3487  data: 1.4341  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3700 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592\n",
            "best_stat: {'epoch': 54, 'coco_eval_bbox': 0.24630669645298092}\n",
            "Epoch: [55]  [0/8]  eta: 0:00:24  lr: 0.000002  loss: 21.4195 (21.4195)  loss_vfl: 0.4792 (0.4792)  loss_bbox: 0.3165 (0.3165)  loss_giou: 0.9008 (0.9008)  loss_vfl_aux_0: 0.9036 (0.9036)  loss_bbox_aux_0: 0.3856 (0.3856)  loss_giou_aux_0: 0.9342 (0.9342)  loss_vfl_aux_1: 0.7146 (0.7146)  loss_bbox_aux_1: 0.3927 (0.3927)  loss_giou_aux_1: 0.9562 (0.9562)  loss_vfl_aux_2: 0.5761 (0.5761)  loss_bbox_aux_2: 0.4030 (0.4030)  loss_giou_aux_2: 0.9698 (0.9698)  loss_vfl_aux_3: 0.4926 (0.4926)  loss_bbox_aux_3: 0.3377 (0.3377)  loss_giou_aux_3: 0.9383 (0.9383)  loss_vfl_aux_4: 0.4792 (0.4792)  loss_bbox_aux_4: 0.3241 (0.3241)  loss_giou_aux_4: 0.9092 (0.9092)  loss_vfl_dn_0: 0.5424 (0.5424)  loss_bbox_dn_0: 0.2203 (0.2203)  loss_giou_dn_0: 0.6939 (0.6939)  loss_vfl_dn_1: 0.4924 (0.4924)  loss_bbox_dn_1: 0.1915 (0.1915)  loss_giou_dn_1: 0.6382 (0.6382)  loss_vfl_dn_2: 0.4501 (0.4501)  loss_bbox_dn_2: 0.1847 (0.1847)  loss_giou_dn_2: 0.6242 (0.6242)  loss_vfl_dn_3: 0.4424 (0.4424)  loss_bbox_dn_3: 0.1839 (0.1839)  loss_giou_dn_3: 0.6268 (0.6268)  loss_vfl_dn_4: 0.4390 (0.4390)  loss_bbox_dn_4: 0.1828 (0.1828)  loss_giou_dn_4: 0.6225 (0.6225)  loss_vfl_dn_5: 0.4316 (0.4316)  loss_bbox_dn_5: 0.1827 (0.1827)  loss_giou_dn_5: 0.6233 (0.6233)  loss_vfl_enc_0: 0.8255 (0.8255)  loss_bbox_enc_0: 0.4127 (0.4127)  loss_giou_enc_0: 0.9952 (0.9952)  time: 3.1017  data: 2.5120  max mem: 16811\n",
            "Epoch: [55]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 20.7420 (20.7852)  loss_vfl: 0.5290 (0.5263)  loss_bbox: 0.2937 (0.2999)  loss_giou: 0.7921 (0.8223)  loss_vfl_aux_0: 0.9709 (1.0079)  loss_bbox_aux_0: 0.2956 (0.3157)  loss_giou_aux_0: 0.7877 (0.8148)  loss_vfl_aux_1: 0.7682 (0.7934)  loss_bbox_aux_1: 0.3193 (0.3259)  loss_giou_aux_1: 0.8202 (0.8459)  loss_vfl_aux_2: 0.5879 (0.6142)  loss_bbox_aux_2: 0.3314 (0.3400)  loss_giou_aux_2: 0.8488 (0.8687)  loss_vfl_aux_3: 0.5231 (0.5369)  loss_bbox_aux_3: 0.2992 (0.3112)  loss_giou_aux_3: 0.8165 (0.8489)  loss_vfl_aux_4: 0.5280 (0.5353)  loss_bbox_aux_4: 0.2975 (0.3027)  loss_giou_aux_4: 0.8028 (0.8259)  loss_vfl_dn_0: 0.5424 (0.5435)  loss_bbox_dn_0: 0.2250 (0.2300)  loss_giou_dn_0: 0.6823 (0.6863)  loss_vfl_dn_1: 0.4869 (0.4840)  loss_bbox_dn_1: 0.1983 (0.2032)  loss_giou_dn_1: 0.6245 (0.6265)  loss_vfl_dn_2: 0.4398 (0.4422)  loss_bbox_dn_2: 0.1913 (0.1960)  loss_giou_dn_2: 0.6084 (0.6104)  loss_vfl_dn_3: 0.4319 (0.4349)  loss_bbox_dn_3: 0.1870 (0.1934)  loss_giou_dn_3: 0.6047 (0.6081)  loss_vfl_dn_4: 0.4363 (0.4370)  loss_bbox_dn_4: 0.1873 (0.1931)  loss_giou_dn_4: 0.6028 (0.6068)  loss_vfl_dn_5: 0.4282 (0.4301)  loss_bbox_dn_5: 0.1873 (0.1929)  loss_giou_dn_5: 0.6019 (0.6061)  loss_vfl_enc_0: 0.9149 (0.9127)  loss_bbox_enc_0: 0.3194 (0.3374)  loss_giou_enc_0: 0.8495 (0.8746)  time: 0.8605  data: 0.3391  max mem: 16811\n",
            "Epoch: [55] Total time: 0:00:06 (0.8666 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 20.7420 (20.7852)  loss_vfl: 0.5290 (0.5263)  loss_bbox: 0.2937 (0.2999)  loss_giou: 0.7921 (0.8223)  loss_vfl_aux_0: 0.9709 (1.0079)  loss_bbox_aux_0: 0.2956 (0.3157)  loss_giou_aux_0: 0.7877 (0.8148)  loss_vfl_aux_1: 0.7682 (0.7934)  loss_bbox_aux_1: 0.3193 (0.3259)  loss_giou_aux_1: 0.8202 (0.8459)  loss_vfl_aux_2: 0.5879 (0.6142)  loss_bbox_aux_2: 0.3314 (0.3400)  loss_giou_aux_2: 0.8488 (0.8687)  loss_vfl_aux_3: 0.5231 (0.5369)  loss_bbox_aux_3: 0.2992 (0.3112)  loss_giou_aux_3: 0.8165 (0.8489)  loss_vfl_aux_4: 0.5280 (0.5353)  loss_bbox_aux_4: 0.2975 (0.3027)  loss_giou_aux_4: 0.8028 (0.8259)  loss_vfl_dn_0: 0.5424 (0.5435)  loss_bbox_dn_0: 0.2250 (0.2300)  loss_giou_dn_0: 0.6823 (0.6863)  loss_vfl_dn_1: 0.4869 (0.4840)  loss_bbox_dn_1: 0.1983 (0.2032)  loss_giou_dn_1: 0.6245 (0.6265)  loss_vfl_dn_2: 0.4398 (0.4422)  loss_bbox_dn_2: 0.1913 (0.1960)  loss_giou_dn_2: 0.6084 (0.6104)  loss_vfl_dn_3: 0.4319 (0.4349)  loss_bbox_dn_3: 0.1870 (0.1934)  loss_giou_dn_3: 0.6047 (0.6081)  loss_vfl_dn_4: 0.4363 (0.4370)  loss_bbox_dn_4: 0.1873 (0.1931)  loss_giou_dn_4: 0.6028 (0.6068)  loss_vfl_dn_5: 0.4282 (0.4301)  loss_bbox_dn_5: 0.1873 (0.1929)  loss_giou_dn_5: 0.6019 (0.6061)  loss_vfl_enc_0: 0.9149 (0.9127)  loss_bbox_enc_0: 0.3194 (0.3374)  loss_giou_enc_0: 0.8495 (0.8746)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.3644  data: 4.3026  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9094  data: 2.1675  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9266 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.518\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            "best_stat: {'epoch': 55, 'coco_eval_bbox': 0.25663712206630124}\n",
            "Epoch: [56]  [0/8]  eta: 0:00:22  lr: 0.000002  loss: 20.8538 (20.8538)  loss_vfl: 0.5338 (0.5338)  loss_bbox: 0.2828 (0.2828)  loss_giou: 0.8310 (0.8310)  loss_vfl_aux_0: 1.0441 (1.0441)  loss_bbox_aux_0: 0.3177 (0.3177)  loss_giou_aux_0: 0.8429 (0.8429)  loss_vfl_aux_1: 0.8318 (0.8318)  loss_bbox_aux_1: 0.3188 (0.3188)  loss_giou_aux_1: 0.8594 (0.8594)  loss_vfl_aux_2: 0.6402 (0.6402)  loss_bbox_aux_2: 0.3297 (0.3297)  loss_giou_aux_2: 0.8846 (0.8846)  loss_vfl_aux_3: 0.5401 (0.5401)  loss_bbox_aux_3: 0.3077 (0.3077)  loss_giou_aux_3: 0.8639 (0.8639)  loss_vfl_aux_4: 0.5447 (0.5447)  loss_bbox_aux_4: 0.2903 (0.2903)  loss_giou_aux_4: 0.8335 (0.8335)  loss_vfl_dn_0: 0.5455 (0.5455)  loss_bbox_dn_0: 0.2236 (0.2236)  loss_giou_dn_0: 0.6694 (0.6694)  loss_vfl_dn_1: 0.4823 (0.4823)  loss_bbox_dn_1: 0.1960 (0.1960)  loss_giou_dn_1: 0.6150 (0.6150)  loss_vfl_dn_2: 0.4398 (0.4398)  loss_bbox_dn_2: 0.1856 (0.1856)  loss_giou_dn_2: 0.5935 (0.5935)  loss_vfl_dn_3: 0.4270 (0.4270)  loss_bbox_dn_3: 0.1859 (0.1859)  loss_giou_dn_3: 0.5932 (0.5932)  loss_vfl_dn_4: 0.4339 (0.4339)  loss_bbox_dn_4: 0.1852 (0.1852)  loss_giou_dn_4: 0.5923 (0.5923)  loss_vfl_dn_5: 0.4239 (0.4239)  loss_bbox_dn_5: 0.1851 (0.1851)  loss_giou_dn_5: 0.5912 (0.5912)  loss_vfl_enc_0: 0.9378 (0.9378)  loss_bbox_enc_0: 0.3427 (0.3427)  loss_giou_enc_0: 0.9080 (0.9080)  time: 2.8561  data: 2.3247  max mem: 16811\n",
            "Epoch: [56]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 20.7635 (20.6463)  loss_vfl: 0.5031 (0.5185)  loss_bbox: 0.2907 (0.2983)  loss_giou: 0.8310 (0.8112)  loss_vfl_aux_0: 1.0212 (1.0126)  loss_bbox_aux_0: 0.3177 (0.3196)  loss_giou_aux_0: 0.8307 (0.8107)  loss_vfl_aux_1: 0.7589 (0.7808)  loss_bbox_aux_1: 0.3188 (0.3225)  loss_giou_aux_1: 0.8594 (0.8433)  loss_vfl_aux_2: 0.5860 (0.6032)  loss_bbox_aux_2: 0.3314 (0.3357)  loss_giou_aux_2: 0.8841 (0.8603)  loss_vfl_aux_3: 0.5194 (0.5212)  loss_bbox_aux_3: 0.3077 (0.3098)  loss_giou_aux_3: 0.8528 (0.8383)  loss_vfl_aux_4: 0.5204 (0.5328)  loss_bbox_aux_4: 0.2910 (0.3040)  loss_giou_aux_4: 0.8335 (0.8151)  loss_vfl_dn_0: 0.5426 (0.5425)  loss_bbox_dn_0: 0.2236 (0.2270)  loss_giou_dn_0: 0.6702 (0.6791)  loss_vfl_dn_1: 0.4823 (0.4814)  loss_bbox_dn_1: 0.2006 (0.2029)  loss_giou_dn_1: 0.6178 (0.6233)  loss_vfl_dn_2: 0.4382 (0.4383)  loss_bbox_dn_2: 0.1943 (0.1953)  loss_giou_dn_2: 0.6060 (0.6088)  loss_vfl_dn_3: 0.4270 (0.4293)  loss_bbox_dn_3: 0.1890 (0.1931)  loss_giou_dn_3: 0.6043 (0.6071)  loss_vfl_dn_4: 0.4316 (0.4327)  loss_bbox_dn_4: 0.1885 (0.1928)  loss_giou_dn_4: 0.6025 (0.6050)  loss_vfl_dn_5: 0.4252 (0.4270)  loss_bbox_dn_5: 0.1883 (0.1924)  loss_giou_dn_5: 0.6011 (0.6034)  loss_vfl_enc_0: 0.9271 (0.9195)  loss_bbox_enc_0: 0.3363 (0.3415)  loss_giou_enc_0: 0.8858 (0.8658)  time: 0.8338  data: 0.3200  max mem: 16811\n",
            "Epoch: [56] Total time: 0:00:06 (0.8410 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 20.7635 (20.6463)  loss_vfl: 0.5031 (0.5185)  loss_bbox: 0.2907 (0.2983)  loss_giou: 0.8310 (0.8112)  loss_vfl_aux_0: 1.0212 (1.0126)  loss_bbox_aux_0: 0.3177 (0.3196)  loss_giou_aux_0: 0.8307 (0.8107)  loss_vfl_aux_1: 0.7589 (0.7808)  loss_bbox_aux_1: 0.3188 (0.3225)  loss_giou_aux_1: 0.8594 (0.8433)  loss_vfl_aux_2: 0.5860 (0.6032)  loss_bbox_aux_2: 0.3314 (0.3357)  loss_giou_aux_2: 0.8841 (0.8603)  loss_vfl_aux_3: 0.5194 (0.5212)  loss_bbox_aux_3: 0.3077 (0.3098)  loss_giou_aux_3: 0.8528 (0.8383)  loss_vfl_aux_4: 0.5204 (0.5328)  loss_bbox_aux_4: 0.2910 (0.3040)  loss_giou_aux_4: 0.8335 (0.8151)  loss_vfl_dn_0: 0.5426 (0.5425)  loss_bbox_dn_0: 0.2236 (0.2270)  loss_giou_dn_0: 0.6702 (0.6791)  loss_vfl_dn_1: 0.4823 (0.4814)  loss_bbox_dn_1: 0.2006 (0.2029)  loss_giou_dn_1: 0.6178 (0.6233)  loss_vfl_dn_2: 0.4382 (0.4383)  loss_bbox_dn_2: 0.1943 (0.1953)  loss_giou_dn_2: 0.6060 (0.6088)  loss_vfl_dn_3: 0.4270 (0.4293)  loss_bbox_dn_3: 0.1890 (0.1931)  loss_giou_dn_3: 0.6043 (0.6071)  loss_vfl_dn_4: 0.4316 (0.4327)  loss_bbox_dn_4: 0.1885 (0.1928)  loss_giou_dn_4: 0.6025 (0.6050)  loss_vfl_dn_5: 0.4252 (0.4270)  loss_bbox_dn_5: 0.1883 (0.1924)  loss_giou_dn_5: 0.6011 (0.6034)  loss_vfl_enc_0: 0.9271 (0.9195)  loss_bbox_enc_0: 0.3363 (0.3415)  loss_giou_enc_0: 0.8858 (0.8658)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8189  data: 4.4082  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1350  data: 2.2206  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1675 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            "best_stat: {'epoch': 55, 'coco_eval_bbox': 0.25663712206630124}\n",
            "Epoch: [57]  [0/8]  eta: 0:00:11  lr: 0.000002  loss: 20.9938 (20.9938)  loss_vfl: 0.4499 (0.4499)  loss_bbox: 0.3383 (0.3383)  loss_giou: 0.8791 (0.8791)  loss_vfl_aux_0: 0.9121 (0.9121)  loss_bbox_aux_0: 0.3803 (0.3803)  loss_giou_aux_0: 0.9204 (0.9204)  loss_vfl_aux_1: 0.7106 (0.7106)  loss_bbox_aux_1: 0.3932 (0.3932)  loss_giou_aux_1: 0.9445 (0.9445)  loss_vfl_aux_2: 0.5447 (0.5447)  loss_bbox_aux_2: 0.4011 (0.4011)  loss_giou_aux_2: 0.9569 (0.9569)  loss_vfl_aux_3: 0.4450 (0.4450)  loss_bbox_aux_3: 0.3520 (0.3520)  loss_giou_aux_3: 0.9148 (0.9148)  loss_vfl_aux_4: 0.4600 (0.4600)  loss_bbox_aux_4: 0.3378 (0.3378)  loss_giou_aux_4: 0.8916 (0.8916)  loss_vfl_dn_0: 0.5449 (0.5449)  loss_bbox_dn_0: 0.2186 (0.2186)  loss_giou_dn_0: 0.6614 (0.6614)  loss_vfl_dn_1: 0.4793 (0.4793)  loss_bbox_dn_1: 0.1918 (0.1918)  loss_giou_dn_1: 0.6011 (0.6011)  loss_vfl_dn_2: 0.4381 (0.4381)  loss_bbox_dn_2: 0.1864 (0.1864)  loss_giou_dn_2: 0.5920 (0.5920)  loss_vfl_dn_3: 0.4298 (0.4298)  loss_bbox_dn_3: 0.1863 (0.1863)  loss_giou_dn_3: 0.5932 (0.5932)  loss_vfl_dn_4: 0.4342 (0.4342)  loss_bbox_dn_4: 0.1858 (0.1858)  loss_giou_dn_4: 0.5888 (0.5888)  loss_vfl_dn_5: 0.4302 (0.4302)  loss_bbox_dn_5: 0.1853 (0.1853)  loss_giou_dn_5: 0.5888 (0.5888)  loss_vfl_enc_0: 0.8437 (0.8437)  loss_bbox_enc_0: 0.4052 (0.4052)  loss_giou_enc_0: 0.9767 (0.9767)  time: 1.4819  data: 0.9393  max mem: 16811\n",
            "Epoch: [57]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 20.3512 (20.6312)  loss_vfl: 0.5349 (0.5300)  loss_bbox: 0.2889 (0.2980)  loss_giou: 0.7803 (0.8055)  loss_vfl_aux_0: 1.0123 (1.0215)  loss_bbox_aux_0: 0.2969 (0.3133)  loss_giou_aux_0: 0.7705 (0.7974)  loss_vfl_aux_1: 0.8098 (0.8140)  loss_bbox_aux_1: 0.3107 (0.3223)  loss_giou_aux_1: 0.8051 (0.8325)  loss_vfl_aux_2: 0.6344 (0.6281)  loss_bbox_aux_2: 0.3284 (0.3357)  loss_giou_aux_2: 0.8218 (0.8505)  loss_vfl_aux_3: 0.5468 (0.5456)  loss_bbox_aux_3: 0.2969 (0.3115)  loss_giou_aux_3: 0.8097 (0.8327)  loss_vfl_aux_4: 0.5502 (0.5480)  loss_bbox_aux_4: 0.2937 (0.3009)  loss_giou_aux_4: 0.7860 (0.8110)  loss_vfl_dn_0: 0.5449 (0.5439)  loss_bbox_dn_0: 0.2188 (0.2262)  loss_giou_dn_0: 0.6614 (0.6703)  loss_vfl_dn_1: 0.4810 (0.4807)  loss_bbox_dn_1: 0.1930 (0.1991)  loss_giou_dn_1: 0.6011 (0.6113)  loss_vfl_dn_2: 0.4383 (0.4404)  loss_bbox_dn_2: 0.1864 (0.1928)  loss_giou_dn_2: 0.5920 (0.5975)  loss_vfl_dn_3: 0.4315 (0.4324)  loss_bbox_dn_3: 0.1863 (0.1909)  loss_giou_dn_3: 0.5932 (0.5970)  loss_vfl_dn_4: 0.4337 (0.4338)  loss_bbox_dn_4: 0.1858 (0.1909)  loss_giou_dn_4: 0.5888 (0.5945)  loss_vfl_dn_5: 0.4300 (0.4298)  loss_bbox_dn_5: 0.1853 (0.1909)  loss_giou_dn_5: 0.5888 (0.5942)  loss_vfl_enc_0: 0.8974 (0.9206)  loss_bbox_enc_0: 0.3273 (0.3351)  loss_giou_enc_0: 0.8284 (0.8603)  time: 0.6493  data: 0.1375  max mem: 16811\n",
            "Epoch: [57] Total time: 0:00:05 (0.6585 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 20.3512 (20.6312)  loss_vfl: 0.5349 (0.5300)  loss_bbox: 0.2889 (0.2980)  loss_giou: 0.7803 (0.8055)  loss_vfl_aux_0: 1.0123 (1.0215)  loss_bbox_aux_0: 0.2969 (0.3133)  loss_giou_aux_0: 0.7705 (0.7974)  loss_vfl_aux_1: 0.8098 (0.8140)  loss_bbox_aux_1: 0.3107 (0.3223)  loss_giou_aux_1: 0.8051 (0.8325)  loss_vfl_aux_2: 0.6344 (0.6281)  loss_bbox_aux_2: 0.3284 (0.3357)  loss_giou_aux_2: 0.8218 (0.8505)  loss_vfl_aux_3: 0.5468 (0.5456)  loss_bbox_aux_3: 0.2969 (0.3115)  loss_giou_aux_3: 0.8097 (0.8327)  loss_vfl_aux_4: 0.5502 (0.5480)  loss_bbox_aux_4: 0.2937 (0.3009)  loss_giou_aux_4: 0.7860 (0.8110)  loss_vfl_dn_0: 0.5449 (0.5439)  loss_bbox_dn_0: 0.2188 (0.2262)  loss_giou_dn_0: 0.6614 (0.6703)  loss_vfl_dn_1: 0.4810 (0.4807)  loss_bbox_dn_1: 0.1930 (0.1991)  loss_giou_dn_1: 0.6011 (0.6113)  loss_vfl_dn_2: 0.4383 (0.4404)  loss_bbox_dn_2: 0.1864 (0.1928)  loss_giou_dn_2: 0.5920 (0.5975)  loss_vfl_dn_3: 0.4315 (0.4324)  loss_bbox_dn_3: 0.1863 (0.1909)  loss_giou_dn_3: 0.5932 (0.5970)  loss_vfl_dn_4: 0.4337 (0.4338)  loss_bbox_dn_4: 0.1858 (0.1909)  loss_giou_dn_4: 0.5888 (0.5945)  loss_vfl_dn_5: 0.4300 (0.4298)  loss_bbox_dn_5: 0.1853 (0.1909)  loss_giou_dn_5: 0.5888 (0.5942)  loss_vfl_enc_0: 0.8974 (0.9206)  loss_bbox_enc_0: 0.3273 (0.3351)  loss_giou_enc_0: 0.8284 (0.8603)\n",
            "Test:  [0/2]  eta: 0:00:07    time: 3.5332  data: 2.4595  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.9936  data: 1.2461  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.0216 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.521\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
            "best_stat: {'epoch': 57, 'coco_eval_bbox': 0.2628560419180747}\n",
            "Epoch: [58]  [0/8]  eta: 0:00:25  lr: 0.000002  loss: 21.6769 (21.6769)  loss_vfl: 0.5419 (0.5419)  loss_bbox: 0.3215 (0.3215)  loss_giou: 0.8541 (0.8541)  loss_vfl_aux_0: 0.9709 (0.9709)  loss_bbox_aux_0: 0.3600 (0.3600)  loss_giou_aux_0: 0.8805 (0.8805)  loss_vfl_aux_1: 0.7800 (0.7800)  loss_bbox_aux_1: 0.3775 (0.3775)  loss_giou_aux_1: 0.9203 (0.9203)  loss_vfl_aux_2: 0.6209 (0.6209)  loss_bbox_aux_2: 0.3790 (0.3790)  loss_giou_aux_2: 0.9293 (0.9293)  loss_vfl_aux_3: 0.5828 (0.5828)  loss_bbox_aux_3: 0.3270 (0.3270)  loss_giou_aux_3: 0.8761 (0.8761)  loss_vfl_aux_4: 0.5533 (0.5533)  loss_bbox_aux_4: 0.3269 (0.3269)  loss_giou_aux_4: 0.8653 (0.8653)  loss_vfl_dn_0: 0.5295 (0.5295)  loss_bbox_dn_0: 0.2285 (0.2285)  loss_giou_dn_0: 0.7296 (0.7296)  loss_vfl_dn_1: 0.4741 (0.4741)  loss_bbox_dn_1: 0.2050 (0.2050)  loss_giou_dn_1: 0.6755 (0.6755)  loss_vfl_dn_2: 0.4365 (0.4365)  loss_bbox_dn_2: 0.1998 (0.1998)  loss_giou_dn_2: 0.6613 (0.6613)  loss_vfl_dn_3: 0.4294 (0.4294)  loss_bbox_dn_3: 0.1958 (0.1958)  loss_giou_dn_3: 0.6579 (0.6579)  loss_vfl_dn_4: 0.4301 (0.4301)  loss_bbox_dn_4: 0.1959 (0.1959)  loss_giou_dn_4: 0.6572 (0.6572)  loss_vfl_dn_5: 0.4271 (0.4271)  loss_bbox_dn_5: 0.1960 (0.1960)  loss_giou_dn_5: 0.6576 (0.6576)  loss_vfl_enc_0: 0.9032 (0.9032)  loss_bbox_enc_0: 0.3818 (0.3818)  loss_giou_enc_0: 0.9378 (0.9378)  time: 3.2326  data: 2.6941  max mem: 16811\n",
            "Epoch: [58]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 20.3761 (20.5128)  loss_vfl: 0.5055 (0.5132)  loss_bbox: 0.2912 (0.2950)  loss_giou: 0.8144 (0.8069)  loss_vfl_aux_0: 0.9764 (1.0144)  loss_bbox_aux_0: 0.3029 (0.3133)  loss_giou_aux_0: 0.8152 (0.7985)  loss_vfl_aux_1: 0.7800 (0.8062)  loss_bbox_aux_1: 0.3140 (0.3208)  loss_giou_aux_1: 0.8442 (0.8344)  loss_vfl_aux_2: 0.5978 (0.6066)  loss_bbox_aux_2: 0.3259 (0.3294)  loss_giou_aux_2: 0.8659 (0.8524)  loss_vfl_aux_3: 0.5288 (0.5446)  loss_bbox_aux_3: 0.3009 (0.3029)  loss_giou_aux_3: 0.8445 (0.8286)  loss_vfl_aux_4: 0.5179 (0.5284)  loss_bbox_aux_4: 0.2928 (0.2975)  loss_giou_aux_4: 0.8149 (0.8128)  loss_vfl_dn_0: 0.5380 (0.5403)  loss_bbox_dn_0: 0.2206 (0.2230)  loss_giou_dn_0: 0.6527 (0.6711)  loss_vfl_dn_1: 0.4741 (0.4747)  loss_bbox_dn_1: 0.1942 (0.1985)  loss_giou_dn_1: 0.6048 (0.6163)  loss_vfl_dn_2: 0.4350 (0.4374)  loss_bbox_dn_2: 0.1870 (0.1911)  loss_giou_dn_2: 0.5810 (0.5981)  loss_vfl_dn_3: 0.4294 (0.4298)  loss_bbox_dn_3: 0.1871 (0.1891)  loss_giou_dn_3: 0.5800 (0.5973)  loss_vfl_dn_4: 0.4293 (0.4306)  loss_bbox_dn_4: 0.1874 (0.1888)  loss_giou_dn_4: 0.5727 (0.5949)  loss_vfl_dn_5: 0.4271 (0.4268)  loss_bbox_dn_5: 0.1872 (0.1884)  loss_giou_dn_5: 0.5726 (0.5940)  loss_vfl_enc_0: 0.9032 (0.9179)  loss_bbox_enc_0: 0.3258 (0.3384)  loss_giou_enc_0: 0.8741 (0.8606)  time: 0.8736  data: 0.3633  max mem: 16811\n",
            "Epoch: [58] Total time: 0:00:07 (0.8784 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 20.3761 (20.5128)  loss_vfl: 0.5055 (0.5132)  loss_bbox: 0.2912 (0.2950)  loss_giou: 0.8144 (0.8069)  loss_vfl_aux_0: 0.9764 (1.0144)  loss_bbox_aux_0: 0.3029 (0.3133)  loss_giou_aux_0: 0.8152 (0.7985)  loss_vfl_aux_1: 0.7800 (0.8062)  loss_bbox_aux_1: 0.3140 (0.3208)  loss_giou_aux_1: 0.8442 (0.8344)  loss_vfl_aux_2: 0.5978 (0.6066)  loss_bbox_aux_2: 0.3259 (0.3294)  loss_giou_aux_2: 0.8659 (0.8524)  loss_vfl_aux_3: 0.5288 (0.5446)  loss_bbox_aux_3: 0.3009 (0.3029)  loss_giou_aux_3: 0.8445 (0.8286)  loss_vfl_aux_4: 0.5179 (0.5284)  loss_bbox_aux_4: 0.2928 (0.2975)  loss_giou_aux_4: 0.8149 (0.8128)  loss_vfl_dn_0: 0.5380 (0.5403)  loss_bbox_dn_0: 0.2206 (0.2230)  loss_giou_dn_0: 0.6527 (0.6711)  loss_vfl_dn_1: 0.4741 (0.4747)  loss_bbox_dn_1: 0.1942 (0.1985)  loss_giou_dn_1: 0.6048 (0.6163)  loss_vfl_dn_2: 0.4350 (0.4374)  loss_bbox_dn_2: 0.1870 (0.1911)  loss_giou_dn_2: 0.5810 (0.5981)  loss_vfl_dn_3: 0.4294 (0.4298)  loss_bbox_dn_3: 0.1871 (0.1891)  loss_giou_dn_3: 0.5800 (0.5973)  loss_vfl_dn_4: 0.4293 (0.4306)  loss_bbox_dn_4: 0.1874 (0.1888)  loss_giou_dn_4: 0.5727 (0.5949)  loss_vfl_dn_5: 0.4271 (0.4268)  loss_bbox_dn_5: 0.1872 (0.1884)  loss_giou_dn_5: 0.5726 (0.5940)  loss_vfl_enc_0: 0.9032 (0.9179)  loss_bbox_enc_0: 0.3258 (0.3384)  loss_giou_enc_0: 0.8741 (0.8606)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.5299  data: 1.4121  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4897  data: 0.7221  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.5210 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n",
            "best_stat: {'epoch': 58, 'coco_eval_bbox': 0.26427617396874553}\n",
            "Epoch: [59]  [0/8]  eta: 0:00:32  lr: 0.000002  loss: 20.9465 (20.9465)  loss_vfl: 0.5309 (0.5309)  loss_bbox: 0.3218 (0.3218)  loss_giou: 0.8316 (0.8316)  loss_vfl_aux_0: 1.0334 (1.0334)  loss_bbox_aux_0: 0.3203 (0.3203)  loss_giou_aux_0: 0.7779 (0.7779)  loss_vfl_aux_1: 0.8148 (0.8148)  loss_bbox_aux_1: 0.3319 (0.3319)  loss_giou_aux_1: 0.8139 (0.8139)  loss_vfl_aux_2: 0.6074 (0.6074)  loss_bbox_aux_2: 0.3439 (0.3439)  loss_giou_aux_2: 0.8467 (0.8467)  loss_vfl_aux_3: 0.5363 (0.5363)  loss_bbox_aux_3: 0.3249 (0.3249)  loss_giou_aux_3: 0.8429 (0.8429)  loss_vfl_aux_4: 0.5389 (0.5389)  loss_bbox_aux_4: 0.3271 (0.3271)  loss_giou_aux_4: 0.8355 (0.8355)  loss_vfl_dn_0: 0.5315 (0.5315)  loss_bbox_dn_0: 0.2469 (0.2469)  loss_giou_dn_0: 0.7047 (0.7047)  loss_vfl_dn_1: 0.4702 (0.4702)  loss_bbox_dn_1: 0.2209 (0.2209)  loss_giou_dn_1: 0.6477 (0.6477)  loss_vfl_dn_2: 0.4320 (0.4320)  loss_bbox_dn_2: 0.2135 (0.2135)  loss_giou_dn_2: 0.6282 (0.6282)  loss_vfl_dn_3: 0.4219 (0.4219)  loss_bbox_dn_3: 0.2100 (0.2100)  loss_giou_dn_3: 0.6253 (0.6253)  loss_vfl_dn_4: 0.4214 (0.4214)  loss_bbox_dn_4: 0.2085 (0.2085)  loss_giou_dn_4: 0.6239 (0.6239)  loss_vfl_dn_5: 0.4223 (0.4223)  loss_bbox_dn_5: 0.2083 (0.2083)  loss_giou_dn_5: 0.6227 (0.6227)  loss_vfl_enc_0: 0.9153 (0.9153)  loss_bbox_enc_0: 0.3462 (0.3462)  loss_giou_enc_0: 0.8451 (0.8451)  time: 4.0908  data: 3.5322  max mem: 16811\n",
            "Epoch: [59]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 20.2936 (20.2865)  loss_vfl: 0.5186 (0.5167)  loss_bbox: 0.2863 (0.2916)  loss_giou: 0.7925 (0.7956)  loss_vfl_aux_0: 1.0232 (1.0120)  loss_bbox_aux_0: 0.3062 (0.3052)  loss_giou_aux_0: 0.7779 (0.7841)  loss_vfl_aux_1: 0.7897 (0.7788)  loss_bbox_aux_1: 0.3170 (0.3157)  loss_giou_aux_1: 0.8139 (0.8155)  loss_vfl_aux_2: 0.5856 (0.5905)  loss_bbox_aux_2: 0.3330 (0.3265)  loss_giou_aux_2: 0.8386 (0.8355)  loss_vfl_aux_3: 0.5119 (0.5143)  loss_bbox_aux_3: 0.2971 (0.3011)  loss_giou_aux_3: 0.8125 (0.8161)  loss_vfl_aux_4: 0.5219 (0.5190)  loss_bbox_aux_4: 0.2976 (0.2978)  loss_giou_aux_4: 0.7945 (0.8019)  loss_vfl_dn_0: 0.5374 (0.5381)  loss_bbox_dn_0: 0.2315 (0.2241)  loss_giou_dn_0: 0.6645 (0.6694)  loss_vfl_dn_1: 0.4703 (0.4723)  loss_bbox_dn_1: 0.2048 (0.2000)  loss_giou_dn_1: 0.6051 (0.6113)  loss_vfl_dn_2: 0.4347 (0.4336)  loss_bbox_dn_2: 0.1958 (0.1936)  loss_giou_dn_2: 0.5951 (0.5972)  loss_vfl_dn_3: 0.4245 (0.4264)  loss_bbox_dn_3: 0.1927 (0.1908)  loss_giou_dn_3: 0.5915 (0.5945)  loss_vfl_dn_4: 0.4269 (0.4289)  loss_bbox_dn_4: 0.1924 (0.1903)  loss_giou_dn_4: 0.5900 (0.5921)  loss_vfl_dn_5: 0.4297 (0.4290)  loss_bbox_dn_5: 0.1922 (0.1901)  loss_giou_dn_5: 0.5904 (0.5914)  loss_vfl_enc_0: 0.9153 (0.9171)  loss_bbox_enc_0: 0.3260 (0.3291)  loss_giou_enc_0: 0.8451 (0.8495)  time: 0.9742  data: 0.4576  max mem: 16811\n",
            "Epoch: [59] Total time: 0:00:07 (0.9812 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 20.2936 (20.2865)  loss_vfl: 0.5186 (0.5167)  loss_bbox: 0.2863 (0.2916)  loss_giou: 0.7925 (0.7956)  loss_vfl_aux_0: 1.0232 (1.0120)  loss_bbox_aux_0: 0.3062 (0.3052)  loss_giou_aux_0: 0.7779 (0.7841)  loss_vfl_aux_1: 0.7897 (0.7788)  loss_bbox_aux_1: 0.3170 (0.3157)  loss_giou_aux_1: 0.8139 (0.8155)  loss_vfl_aux_2: 0.5856 (0.5905)  loss_bbox_aux_2: 0.3330 (0.3265)  loss_giou_aux_2: 0.8386 (0.8355)  loss_vfl_aux_3: 0.5119 (0.5143)  loss_bbox_aux_3: 0.2971 (0.3011)  loss_giou_aux_3: 0.8125 (0.8161)  loss_vfl_aux_4: 0.5219 (0.5190)  loss_bbox_aux_4: 0.2976 (0.2978)  loss_giou_aux_4: 0.7945 (0.8019)  loss_vfl_dn_0: 0.5374 (0.5381)  loss_bbox_dn_0: 0.2315 (0.2241)  loss_giou_dn_0: 0.6645 (0.6694)  loss_vfl_dn_1: 0.4703 (0.4723)  loss_bbox_dn_1: 0.2048 (0.2000)  loss_giou_dn_1: 0.6051 (0.6113)  loss_vfl_dn_2: 0.4347 (0.4336)  loss_bbox_dn_2: 0.1958 (0.1936)  loss_giou_dn_2: 0.5951 (0.5972)  loss_vfl_dn_3: 0.4245 (0.4264)  loss_bbox_dn_3: 0.1927 (0.1908)  loss_giou_dn_3: 0.5915 (0.5945)  loss_vfl_dn_4: 0.4269 (0.4289)  loss_bbox_dn_4: 0.1924 (0.1903)  loss_giou_dn_4: 0.5900 (0.5921)  loss_vfl_dn_5: 0.4297 (0.4290)  loss_bbox_dn_5: 0.1922 (0.1901)  loss_giou_dn_5: 0.5904 (0.5914)  loss_vfl_enc_0: 0.9153 (0.9171)  loss_bbox_enc_0: 0.3260 (0.3291)  loss_giou_enc_0: 0.8451 (0.8495)\n",
            "Test:  [0/2]  eta: 0:00:07    time: 3.7482  data: 2.3340  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.1028  data: 1.1833  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.1315 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.241\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n",
            "best_stat: {'epoch': 59, 'coco_eval_bbox': 0.2644223258854222}\n",
            "Epoch: [60]  [0/8]  eta: 0:00:29  lr: 0.000002  loss: 19.2645 (19.2645)  loss_vfl: 0.5515 (0.5515)  loss_bbox: 0.2294 (0.2294)  loss_giou: 0.6948 (0.6948)  loss_vfl_aux_0: 1.1218 (1.1218)  loss_bbox_aux_0: 0.2671 (0.2671)  loss_giou_aux_0: 0.6938 (0.6938)  loss_vfl_aux_1: 0.8632 (0.8632)  loss_bbox_aux_1: 0.2864 (0.2864)  loss_giou_aux_1: 0.7332 (0.7332)  loss_vfl_aux_2: 0.6450 (0.6450)  loss_bbox_aux_2: 0.2831 (0.2831)  loss_giou_aux_2: 0.7523 (0.7523)  loss_vfl_aux_3: 0.5402 (0.5402)  loss_bbox_aux_3: 0.2405 (0.2405)  loss_giou_aux_3: 0.7177 (0.7177)  loss_vfl_aux_4: 0.5595 (0.5595)  loss_bbox_aux_4: 0.2355 (0.2355)  loss_giou_aux_4: 0.7031 (0.7031)  loss_vfl_dn_0: 0.5457 (0.5457)  loss_bbox_dn_0: 0.1959 (0.1959)  loss_giou_dn_0: 0.6196 (0.6196)  loss_vfl_dn_1: 0.4646 (0.4646)  loss_bbox_dn_1: 0.1708 (0.1708)  loss_giou_dn_1: 0.5573 (0.5573)  loss_vfl_dn_2: 0.4303 (0.4303)  loss_bbox_dn_2: 0.1639 (0.1639)  loss_giou_dn_2: 0.5416 (0.5416)  loss_vfl_dn_3: 0.4270 (0.4270)  loss_bbox_dn_3: 0.1630 (0.1630)  loss_giou_dn_3: 0.5405 (0.5405)  loss_vfl_dn_4: 0.4255 (0.4255)  loss_bbox_dn_4: 0.1626 (0.1626)  loss_giou_dn_4: 0.5363 (0.5363)  loss_vfl_dn_5: 0.4231 (0.4231)  loss_bbox_dn_5: 0.1624 (0.1624)  loss_giou_dn_5: 0.5350 (0.5350)  loss_vfl_enc_0: 1.0061 (1.0061)  loss_bbox_enc_0: 0.2993 (0.2993)  loss_giou_enc_0: 0.7756 (0.7756)  time: 3.6539  data: 3.1227  max mem: 16811\n",
            "Epoch: [60]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 19.9699 (20.0701)  loss_vfl: 0.5024 (0.5157)  loss_bbox: 0.2712 (0.2812)  loss_giou: 0.7969 (0.7883)  loss_vfl_aux_0: 1.0013 (1.0152)  loss_bbox_aux_0: 0.2890 (0.2975)  loss_giou_aux_0: 0.7764 (0.7760)  loss_vfl_aux_1: 0.7539 (0.7701)  loss_bbox_aux_1: 0.3034 (0.3061)  loss_giou_aux_1: 0.8094 (0.8054)  loss_vfl_aux_2: 0.5812 (0.5948)  loss_bbox_aux_2: 0.3075 (0.3140)  loss_giou_aux_2: 0.8219 (0.8209)  loss_vfl_aux_3: 0.4888 (0.4986)  loss_bbox_aux_3: 0.2795 (0.2872)  loss_giou_aux_3: 0.8200 (0.8109)  loss_vfl_aux_4: 0.5051 (0.5171)  loss_bbox_aux_4: 0.2729 (0.2873)  loss_giou_aux_4: 0.8023 (0.7937)  loss_vfl_dn_0: 0.5355 (0.5354)  loss_bbox_dn_0: 0.2125 (0.2191)  loss_giou_dn_0: 0.6518 (0.6661)  loss_vfl_dn_1: 0.4728 (0.4734)  loss_bbox_dn_1: 0.1840 (0.1929)  loss_giou_dn_1: 0.5990 (0.6086)  loss_vfl_dn_2: 0.4373 (0.4362)  loss_bbox_dn_2: 0.1797 (0.1844)  loss_giou_dn_2: 0.5762 (0.5917)  loss_vfl_dn_3: 0.4270 (0.4278)  loss_bbox_dn_3: 0.1788 (0.1825)  loss_giou_dn_3: 0.5737 (0.5898)  loss_vfl_dn_4: 0.4306 (0.4309)  loss_bbox_dn_4: 0.1788 (0.1820)  loss_giou_dn_4: 0.5690 (0.5862)  loss_vfl_dn_5: 0.4313 (0.4301)  loss_bbox_dn_5: 0.1788 (0.1819)  loss_giou_dn_5: 0.5694 (0.5855)  loss_vfl_enc_0: 0.8971 (0.9202)  loss_bbox_enc_0: 0.3086 (0.3241)  loss_giou_enc_0: 0.8468 (0.8413)  time: 0.9272  data: 0.4173  max mem: 16811\n",
            "Epoch: [60] Total time: 0:00:07 (0.9349 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 19.9699 (20.0701)  loss_vfl: 0.5024 (0.5157)  loss_bbox: 0.2712 (0.2812)  loss_giou: 0.7969 (0.7883)  loss_vfl_aux_0: 1.0013 (1.0152)  loss_bbox_aux_0: 0.2890 (0.2975)  loss_giou_aux_0: 0.7764 (0.7760)  loss_vfl_aux_1: 0.7539 (0.7701)  loss_bbox_aux_1: 0.3034 (0.3061)  loss_giou_aux_1: 0.8094 (0.8054)  loss_vfl_aux_2: 0.5812 (0.5948)  loss_bbox_aux_2: 0.3075 (0.3140)  loss_giou_aux_2: 0.8219 (0.8209)  loss_vfl_aux_3: 0.4888 (0.4986)  loss_bbox_aux_3: 0.2795 (0.2872)  loss_giou_aux_3: 0.8200 (0.8109)  loss_vfl_aux_4: 0.5051 (0.5171)  loss_bbox_aux_4: 0.2729 (0.2873)  loss_giou_aux_4: 0.8023 (0.7937)  loss_vfl_dn_0: 0.5355 (0.5354)  loss_bbox_dn_0: 0.2125 (0.2191)  loss_giou_dn_0: 0.6518 (0.6661)  loss_vfl_dn_1: 0.4728 (0.4734)  loss_bbox_dn_1: 0.1840 (0.1929)  loss_giou_dn_1: 0.5990 (0.6086)  loss_vfl_dn_2: 0.4373 (0.4362)  loss_bbox_dn_2: 0.1797 (0.1844)  loss_giou_dn_2: 0.5762 (0.5917)  loss_vfl_dn_3: 0.4270 (0.4278)  loss_bbox_dn_3: 0.1788 (0.1825)  loss_giou_dn_3: 0.5737 (0.5898)  loss_vfl_dn_4: 0.4306 (0.4309)  loss_bbox_dn_4: 0.1788 (0.1820)  loss_giou_dn_4: 0.5690 (0.5862)  loss_vfl_dn_5: 0.4313 (0.4301)  loss_bbox_dn_5: 0.1788 (0.1819)  loss_giou_dn_5: 0.5694 (0.5855)  loss_vfl_enc_0: 0.8971 (0.9202)  loss_bbox_enc_0: 0.3086 (0.3241)  loss_giou_enc_0: 0.8468 (0.8413)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.3182  data: 3.2516  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3840  data: 1.6419  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.4017 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.548\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n",
            "best_stat: {'epoch': 60, 'coco_eval_bbox': 0.27791700515028167}\n",
            "Epoch: [61]  [0/8]  eta: 0:00:25  lr: 0.000002  loss: 20.4174 (20.4174)  loss_vfl: 0.4952 (0.4952)  loss_bbox: 0.2941 (0.2941)  loss_giou: 0.8220 (0.8220)  loss_vfl_aux_0: 0.9470 (0.9470)  loss_bbox_aux_0: 0.3021 (0.3021)  loss_giou_aux_0: 0.8032 (0.8032)  loss_vfl_aux_1: 0.7450 (0.7450)  loss_bbox_aux_1: 0.3054 (0.3054)  loss_giou_aux_1: 0.8307 (0.8307)  loss_vfl_aux_2: 0.5928 (0.5928)  loss_bbox_aux_2: 0.3148 (0.3148)  loss_giou_aux_2: 0.8383 (0.8383)  loss_vfl_aux_3: 0.4873 (0.4873)  loss_bbox_aux_3: 0.3057 (0.3057)  loss_giou_aux_3: 0.8342 (0.8342)  loss_vfl_aux_4: 0.4987 (0.4987)  loss_bbox_aux_4: 0.2962 (0.2962)  loss_giou_aux_4: 0.8279 (0.8279)  loss_vfl_dn_0: 0.5286 (0.5286)  loss_bbox_dn_0: 0.2373 (0.2373)  loss_giou_dn_0: 0.6991 (0.6991)  loss_vfl_dn_1: 0.4711 (0.4711)  loss_bbox_dn_1: 0.2099 (0.2099)  loss_giou_dn_1: 0.6456 (0.6456)  loss_vfl_dn_2: 0.4387 (0.4387)  loss_bbox_dn_2: 0.2010 (0.2010)  loss_giou_dn_2: 0.6254 (0.6254)  loss_vfl_dn_3: 0.4380 (0.4380)  loss_bbox_dn_3: 0.1988 (0.1988)  loss_giou_dn_3: 0.6238 (0.6238)  loss_vfl_dn_4: 0.4332 (0.4332)  loss_bbox_dn_4: 0.1997 (0.1997)  loss_giou_dn_4: 0.6233 (0.6233)  loss_vfl_dn_5: 0.4288 (0.4288)  loss_bbox_dn_5: 0.1993 (0.1993)  loss_giou_dn_5: 0.6218 (0.6218)  loss_vfl_enc_0: 0.8683 (0.8683)  loss_bbox_enc_0: 0.3213 (0.3213)  loss_giou_enc_0: 0.8638 (0.8638)  time: 3.1642  data: 2.5711  max mem: 16811\n",
            "Epoch: [61]  [7/8]  eta: 0:00:00  lr: 0.000002  loss: 19.6683 (19.9325)  loss_vfl: 0.4962 (0.5096)  loss_bbox: 0.2658 (0.2783)  loss_giou: 0.7681 (0.7706)  loss_vfl_aux_0: 1.0373 (1.0190)  loss_bbox_aux_0: 0.2729 (0.2902)  loss_giou_aux_0: 0.7220 (0.7710)  loss_vfl_aux_1: 0.7826 (0.7832)  loss_bbox_aux_1: 0.2767 (0.3001)  loss_giou_aux_1: 0.7810 (0.7984)  loss_vfl_aux_2: 0.5928 (0.5988)  loss_bbox_aux_2: 0.2837 (0.3076)  loss_giou_aux_2: 0.8076 (0.8144)  loss_vfl_aux_3: 0.5150 (0.5170)  loss_bbox_aux_3: 0.2761 (0.2897)  loss_giou_aux_3: 0.7932 (0.7972)  loss_vfl_aux_4: 0.5135 (0.5215)  loss_bbox_aux_4: 0.2715 (0.2835)  loss_giou_aux_4: 0.7680 (0.7744)  loss_vfl_dn_0: 0.5342 (0.5365)  loss_bbox_dn_0: 0.2143 (0.2176)  loss_giou_dn_0: 0.6375 (0.6570)  loss_vfl_dn_1: 0.4671 (0.4681)  loss_bbox_dn_1: 0.1929 (0.1923)  loss_giou_dn_1: 0.5885 (0.6011)  loss_vfl_dn_2: 0.4299 (0.4312)  loss_bbox_dn_2: 0.1819 (0.1845)  loss_giou_dn_2: 0.5719 (0.5836)  loss_vfl_dn_3: 0.4253 (0.4274)  loss_bbox_dn_3: 0.1792 (0.1826)  loss_giou_dn_3: 0.5712 (0.5816)  loss_vfl_dn_4: 0.4266 (0.4285)  loss_bbox_dn_4: 0.1777 (0.1821)  loss_giou_dn_4: 0.5671 (0.5783)  loss_vfl_dn_5: 0.4241 (0.4239)  loss_bbox_dn_5: 0.1775 (0.1819)  loss_giou_dn_5: 0.5673 (0.5778)  loss_vfl_enc_0: 0.9262 (0.9227)  loss_bbox_enc_0: 0.3020 (0.3158)  loss_giou_enc_0: 0.7837 (0.8335)  time: 0.8516  data: 0.3370  max mem: 16811\n",
            "Epoch: [61] Total time: 0:00:06 (0.8575 s / it)\n",
            "Averaged stats: lr: 0.000002  loss: 19.6683 (19.9325)  loss_vfl: 0.4962 (0.5096)  loss_bbox: 0.2658 (0.2783)  loss_giou: 0.7681 (0.7706)  loss_vfl_aux_0: 1.0373 (1.0190)  loss_bbox_aux_0: 0.2729 (0.2902)  loss_giou_aux_0: 0.7220 (0.7710)  loss_vfl_aux_1: 0.7826 (0.7832)  loss_bbox_aux_1: 0.2767 (0.3001)  loss_giou_aux_1: 0.7810 (0.7984)  loss_vfl_aux_2: 0.5928 (0.5988)  loss_bbox_aux_2: 0.2837 (0.3076)  loss_giou_aux_2: 0.8076 (0.8144)  loss_vfl_aux_3: 0.5150 (0.5170)  loss_bbox_aux_3: 0.2761 (0.2897)  loss_giou_aux_3: 0.7932 (0.7972)  loss_vfl_aux_4: 0.5135 (0.5215)  loss_bbox_aux_4: 0.2715 (0.2835)  loss_giou_aux_4: 0.7680 (0.7744)  loss_vfl_dn_0: 0.5342 (0.5365)  loss_bbox_dn_0: 0.2143 (0.2176)  loss_giou_dn_0: 0.6375 (0.6570)  loss_vfl_dn_1: 0.4671 (0.4681)  loss_bbox_dn_1: 0.1929 (0.1923)  loss_giou_dn_1: 0.5885 (0.6011)  loss_vfl_dn_2: 0.4299 (0.4312)  loss_bbox_dn_2: 0.1819 (0.1845)  loss_giou_dn_2: 0.5719 (0.5836)  loss_vfl_dn_3: 0.4253 (0.4274)  loss_bbox_dn_3: 0.1792 (0.1826)  loss_giou_dn_3: 0.5712 (0.5816)  loss_vfl_dn_4: 0.4266 (0.4285)  loss_bbox_dn_4: 0.1777 (0.1821)  loss_giou_dn_4: 0.5671 (0.5783)  loss_vfl_dn_5: 0.4241 (0.4239)  loss_bbox_dn_5: 0.1775 (0.1819)  loss_giou_dn_5: 0.5673 (0.5778)  loss_vfl_enc_0: 0.9262 (0.9227)  loss_bbox_enc_0: 0.3020 (0.3158)  loss_giou_enc_0: 0.7837 (0.8335)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.0143  data: 2.9509  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.2331  data: 1.4915  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.2511 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.551\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
            "best_stat: {'epoch': 60, 'coco_eval_bbox': 0.27791700515028167}\n",
            "Epoch: [62]  [0/8]  eta: 0:00:12  lr: 0.000002  loss: 19.2358 (19.2358)  loss_vfl: 0.4939 (0.4939)  loss_bbox: 0.2582 (0.2582)  loss_giou: 0.7568 (0.7568)  loss_vfl_aux_0: 1.0134 (1.0134)  loss_bbox_aux_0: 0.2604 (0.2604)  loss_giou_aux_0: 0.7491 (0.7491)  loss_vfl_aux_1: 0.7519 (0.7519)  loss_bbox_aux_1: 0.2709 (0.2709)  loss_giou_aux_1: 0.7774 (0.7774)  loss_vfl_aux_2: 0.5832 (0.5832)  loss_bbox_aux_2: 0.2836 (0.2836)  loss_giou_aux_2: 0.8076 (0.8076)  loss_vfl_aux_3: 0.5376 (0.5376)  loss_bbox_aux_3: 0.2666 (0.2666)  loss_giou_aux_3: 0.7729 (0.7729)  loss_vfl_aux_4: 0.5139 (0.5139)  loss_bbox_aux_4: 0.2607 (0.2607)  loss_giou_aux_4: 0.7563 (0.7563)  loss_vfl_dn_0: 0.5403 (0.5403)  loss_bbox_dn_0: 0.1961 (0.1961)  loss_giou_dn_0: 0.6283 (0.6283)  loss_vfl_dn_1: 0.4671 (0.4671)  loss_bbox_dn_1: 0.1671 (0.1671)  loss_giou_dn_1: 0.5625 (0.5625)  loss_vfl_dn_2: 0.4283 (0.4283)  loss_bbox_dn_2: 0.1608 (0.1608)  loss_giou_dn_2: 0.5501 (0.5501)  loss_vfl_dn_3: 0.4214 (0.4214)  loss_bbox_dn_3: 0.1597 (0.1597)  loss_giou_dn_3: 0.5475 (0.5475)  loss_vfl_dn_4: 0.4253 (0.4253)  loss_bbox_dn_4: 0.1613 (0.1613)  loss_giou_dn_4: 0.5465 (0.5465)  loss_vfl_dn_5: 0.4216 (0.4216)  loss_bbox_dn_5: 0.1610 (0.1610)  loss_giou_dn_5: 0.5453 (0.5453)  loss_vfl_enc_0: 0.9332 (0.9332)  loss_bbox_enc_0: 0.2905 (0.2905)  loss_giou_enc_0: 0.8073 (0.8073)  time: 1.5298  data: 0.9758  max mem: 16811\n",
            "Epoch: [62]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 19.8062 (19.8853)  loss_vfl: 0.5056 (0.5146)  loss_bbox: 0.2790 (0.2776)  loss_giou: 0.7568 (0.7647)  loss_vfl_aux_0: 1.0319 (1.0371)  loss_bbox_aux_0: 0.2869 (0.2918)  loss_giou_aux_0: 0.7491 (0.7565)  loss_vfl_aux_1: 0.7575 (0.7761)  loss_bbox_aux_1: 0.2924 (0.2978)  loss_giou_aux_1: 0.7774 (0.7847)  loss_vfl_aux_2: 0.5974 (0.6024)  loss_bbox_aux_2: 0.3005 (0.3041)  loss_giou_aux_2: 0.8024 (0.8027)  loss_vfl_aux_3: 0.5376 (0.5472)  loss_bbox_aux_3: 0.2893 (0.2879)  loss_giou_aux_3: 0.7706 (0.7851)  loss_vfl_aux_4: 0.5203 (0.5241)  loss_bbox_aux_4: 0.2843 (0.2822)  loss_giou_aux_4: 0.7563 (0.7699)  loss_vfl_dn_0: 0.5366 (0.5352)  loss_bbox_dn_0: 0.2191 (0.2181)  loss_giou_dn_0: 0.6507 (0.6525)  loss_vfl_dn_1: 0.4686 (0.4696)  loss_bbox_dn_1: 0.1957 (0.1922)  loss_giou_dn_1: 0.5911 (0.5932)  loss_vfl_dn_2: 0.4327 (0.4330)  loss_bbox_dn_2: 0.1890 (0.1860)  loss_giou_dn_2: 0.5718 (0.5798)  loss_vfl_dn_3: 0.4305 (0.4272)  loss_bbox_dn_3: 0.1872 (0.1831)  loss_giou_dn_3: 0.5686 (0.5754)  loss_vfl_dn_4: 0.4292 (0.4283)  loss_bbox_dn_4: 0.1867 (0.1832)  loss_giou_dn_4: 0.5635 (0.5741)  loss_vfl_dn_5: 0.4245 (0.4243)  loss_bbox_dn_5: 0.1866 (0.1828)  loss_giou_dn_5: 0.5626 (0.5726)  loss_vfl_enc_0: 0.9295 (0.9324)  loss_bbox_enc_0: 0.2986 (0.3165)  loss_giou_enc_0: 0.8073 (0.8192)  time: 0.6585  data: 0.1464  max mem: 16811\n",
            "Epoch: [62] Total time: 0:00:05 (0.6646 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 19.8062 (19.8853)  loss_vfl: 0.5056 (0.5146)  loss_bbox: 0.2790 (0.2776)  loss_giou: 0.7568 (0.7647)  loss_vfl_aux_0: 1.0319 (1.0371)  loss_bbox_aux_0: 0.2869 (0.2918)  loss_giou_aux_0: 0.7491 (0.7565)  loss_vfl_aux_1: 0.7575 (0.7761)  loss_bbox_aux_1: 0.2924 (0.2978)  loss_giou_aux_1: 0.7774 (0.7847)  loss_vfl_aux_2: 0.5974 (0.6024)  loss_bbox_aux_2: 0.3005 (0.3041)  loss_giou_aux_2: 0.8024 (0.8027)  loss_vfl_aux_3: 0.5376 (0.5472)  loss_bbox_aux_3: 0.2893 (0.2879)  loss_giou_aux_3: 0.7706 (0.7851)  loss_vfl_aux_4: 0.5203 (0.5241)  loss_bbox_aux_4: 0.2843 (0.2822)  loss_giou_aux_4: 0.7563 (0.7699)  loss_vfl_dn_0: 0.5366 (0.5352)  loss_bbox_dn_0: 0.2191 (0.2181)  loss_giou_dn_0: 0.6507 (0.6525)  loss_vfl_dn_1: 0.4686 (0.4696)  loss_bbox_dn_1: 0.1957 (0.1922)  loss_giou_dn_1: 0.5911 (0.5932)  loss_vfl_dn_2: 0.4327 (0.4330)  loss_bbox_dn_2: 0.1890 (0.1860)  loss_giou_dn_2: 0.5718 (0.5798)  loss_vfl_dn_3: 0.4305 (0.4272)  loss_bbox_dn_3: 0.1872 (0.1831)  loss_giou_dn_3: 0.5686 (0.5754)  loss_vfl_dn_4: 0.4292 (0.4283)  loss_bbox_dn_4: 0.1867 (0.1832)  loss_giou_dn_4: 0.5635 (0.5741)  loss_vfl_dn_5: 0.4245 (0.4243)  loss_bbox_dn_5: 0.1866 (0.1828)  loss_giou_dn_5: 0.5626 (0.5726)  loss_vfl_enc_0: 0.9295 (0.9324)  loss_bbox_enc_0: 0.2986 (0.3165)  loss_giou_enc_0: 0.8073 (0.8192)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3902  data: 1.3125  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4213  data: 0.6726  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4457 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
            "best_stat: {'epoch': 60, 'coco_eval_bbox': 0.27791700515028167}\n",
            "Epoch: [63]  [0/8]  eta: 0:00:17  lr: 0.000003  loss: 20.0493 (20.0493)  loss_vfl: 0.4895 (0.4895)  loss_bbox: 0.2857 (0.2857)  loss_giou: 0.7880 (0.7880)  loss_vfl_aux_0: 1.0299 (1.0299)  loss_bbox_aux_0: 0.2759 (0.2759)  loss_giou_aux_0: 0.7741 (0.7741)  loss_vfl_aux_1: 0.7465 (0.7465)  loss_bbox_aux_1: 0.3035 (0.3035)  loss_giou_aux_1: 0.8004 (0.8004)  loss_vfl_aux_2: 0.5825 (0.5825)  loss_bbox_aux_2: 0.3015 (0.3015)  loss_giou_aux_2: 0.8053 (0.8053)  loss_vfl_aux_3: 0.5114 (0.5114)  loss_bbox_aux_3: 0.2964 (0.2964)  loss_giou_aux_3: 0.7918 (0.7918)  loss_vfl_aux_4: 0.4993 (0.4993)  loss_bbox_aux_4: 0.3034 (0.3034)  loss_giou_aux_4: 0.7913 (0.7913)  loss_vfl_dn_0: 0.5237 (0.5237)  loss_bbox_dn_0: 0.2292 (0.2292)  loss_giou_dn_0: 0.6868 (0.6868)  loss_vfl_dn_1: 0.4603 (0.4603)  loss_bbox_dn_1: 0.2004 (0.2004)  loss_giou_dn_1: 0.6294 (0.6294)  loss_vfl_dn_2: 0.4270 (0.4270)  loss_bbox_dn_2: 0.1949 (0.1949)  loss_giou_dn_2: 0.6138 (0.6138)  loss_vfl_dn_3: 0.4206 (0.4206)  loss_bbox_dn_3: 0.1912 (0.1912)  loss_giou_dn_3: 0.6059 (0.6059)  loss_vfl_dn_4: 0.4225 (0.4225)  loss_bbox_dn_4: 0.1914 (0.1914)  loss_giou_dn_4: 0.6054 (0.6054)  loss_vfl_dn_5: 0.4183 (0.4183)  loss_bbox_dn_5: 0.1909 (0.1909)  loss_giou_dn_5: 0.6033 (0.6033)  loss_vfl_enc_0: 0.9212 (0.9212)  loss_bbox_enc_0: 0.3045 (0.3045)  loss_giou_enc_0: 0.8320 (0.8320)  time: 2.1774  data: 1.6326  max mem: 16811\n",
            "Epoch: [63]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 19.3855 (19.5501)  loss_vfl: 0.5088 (0.5139)  loss_bbox: 0.2692 (0.2688)  loss_giou: 0.7382 (0.7486)  loss_vfl_aux_0: 1.0235 (1.0221)  loss_bbox_aux_0: 0.2747 (0.2832)  loss_giou_aux_0: 0.7265 (0.7443)  loss_vfl_aux_1: 0.7457 (0.7454)  loss_bbox_aux_1: 0.2854 (0.2938)  loss_giou_aux_1: 0.7551 (0.7782)  loss_vfl_aux_2: 0.5825 (0.5780)  loss_bbox_aux_2: 0.2854 (0.2975)  loss_giou_aux_2: 0.7712 (0.7865)  loss_vfl_aux_3: 0.5108 (0.5130)  loss_bbox_aux_3: 0.2758 (0.2785)  loss_giou_aux_3: 0.7544 (0.7697)  loss_vfl_aux_4: 0.4993 (0.5136)  loss_bbox_aux_4: 0.2759 (0.2739)  loss_giou_aux_4: 0.7444 (0.7527)  loss_vfl_dn_0: 0.5332 (0.5330)  loss_bbox_dn_0: 0.2140 (0.2169)  loss_giou_dn_0: 0.6426 (0.6531)  loss_vfl_dn_1: 0.4650 (0.4663)  loss_bbox_dn_1: 0.1854 (0.1885)  loss_giou_dn_1: 0.5848 (0.5916)  loss_vfl_dn_2: 0.4270 (0.4284)  loss_bbox_dn_2: 0.1786 (0.1808)  loss_giou_dn_2: 0.5733 (0.5747)  loss_vfl_dn_3: 0.4206 (0.4227)  loss_bbox_dn_3: 0.1761 (0.1780)  loss_giou_dn_3: 0.5727 (0.5712)  loss_vfl_dn_4: 0.4225 (0.4254)  loss_bbox_dn_4: 0.1748 (0.1775)  loss_giou_dn_4: 0.5699 (0.5683)  loss_vfl_dn_5: 0.4191 (0.4235)  loss_bbox_dn_5: 0.1743 (0.1772)  loss_giou_dn_5: 0.5686 (0.5670)  loss_vfl_enc_0: 0.9212 (0.9265)  loss_bbox_enc_0: 0.3045 (0.3098)  loss_giou_enc_0: 0.7902 (0.8079)  time: 0.7436  data: 0.2293  max mem: 16811\n",
            "Epoch: [63] Total time: 0:00:06 (0.7514 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 19.3855 (19.5501)  loss_vfl: 0.5088 (0.5139)  loss_bbox: 0.2692 (0.2688)  loss_giou: 0.7382 (0.7486)  loss_vfl_aux_0: 1.0235 (1.0221)  loss_bbox_aux_0: 0.2747 (0.2832)  loss_giou_aux_0: 0.7265 (0.7443)  loss_vfl_aux_1: 0.7457 (0.7454)  loss_bbox_aux_1: 0.2854 (0.2938)  loss_giou_aux_1: 0.7551 (0.7782)  loss_vfl_aux_2: 0.5825 (0.5780)  loss_bbox_aux_2: 0.2854 (0.2975)  loss_giou_aux_2: 0.7712 (0.7865)  loss_vfl_aux_3: 0.5108 (0.5130)  loss_bbox_aux_3: 0.2758 (0.2785)  loss_giou_aux_3: 0.7544 (0.7697)  loss_vfl_aux_4: 0.4993 (0.5136)  loss_bbox_aux_4: 0.2759 (0.2739)  loss_giou_aux_4: 0.7444 (0.7527)  loss_vfl_dn_0: 0.5332 (0.5330)  loss_bbox_dn_0: 0.2140 (0.2169)  loss_giou_dn_0: 0.6426 (0.6531)  loss_vfl_dn_1: 0.4650 (0.4663)  loss_bbox_dn_1: 0.1854 (0.1885)  loss_giou_dn_1: 0.5848 (0.5916)  loss_vfl_dn_2: 0.4270 (0.4284)  loss_bbox_dn_2: 0.1786 (0.1808)  loss_giou_dn_2: 0.5733 (0.5747)  loss_vfl_dn_3: 0.4206 (0.4227)  loss_bbox_dn_3: 0.1761 (0.1780)  loss_giou_dn_3: 0.5727 (0.5712)  loss_vfl_dn_4: 0.4225 (0.4254)  loss_bbox_dn_4: 0.1748 (0.1775)  loss_giou_dn_4: 0.5699 (0.5683)  loss_vfl_dn_5: 0.4191 (0.4235)  loss_bbox_dn_5: 0.1743 (0.1772)  loss_giou_dn_5: 0.5686 (0.5670)  loss_vfl_enc_0: 0.9212 (0.9265)  loss_bbox_enc_0: 0.3045 (0.3098)  loss_giou_enc_0: 0.7902 (0.8079)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4422  data: 4.3685  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9463  data: 2.2004  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9642 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.554\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
            "best_stat: {'epoch': 63, 'coco_eval_bbox': 0.2780421346105794}\n",
            "Epoch: [64]  [0/8]  eta: 0:00:23  lr: 0.000003  loss: 20.0838 (20.0838)  loss_vfl: 0.5436 (0.5436)  loss_bbox: 0.2893 (0.2893)  loss_giou: 0.7695 (0.7695)  loss_vfl_aux_0: 1.0555 (1.0555)  loss_bbox_aux_0: 0.3142 (0.3142)  loss_giou_aux_0: 0.7659 (0.7659)  loss_vfl_aux_1: 0.7571 (0.7571)  loss_bbox_aux_1: 0.3189 (0.3189)  loss_giou_aux_1: 0.8065 (0.8065)  loss_vfl_aux_2: 0.5975 (0.5975)  loss_bbox_aux_2: 0.3282 (0.3282)  loss_giou_aux_2: 0.8125 (0.8125)  loss_vfl_aux_3: 0.5171 (0.5171)  loss_bbox_aux_3: 0.3007 (0.3007)  loss_giou_aux_3: 0.7939 (0.7939)  loss_vfl_aux_4: 0.5344 (0.5344)  loss_bbox_aux_4: 0.2910 (0.2910)  loss_giou_aux_4: 0.7716 (0.7716)  loss_vfl_dn_0: 0.5281 (0.5281)  loss_bbox_dn_0: 0.2137 (0.2137)  loss_giou_dn_0: 0.6483 (0.6483)  loss_vfl_dn_1: 0.4606 (0.4606)  loss_bbox_dn_1: 0.1860 (0.1860)  loss_giou_dn_1: 0.5906 (0.5906)  loss_vfl_dn_2: 0.4304 (0.4304)  loss_bbox_dn_2: 0.1786 (0.1786)  loss_giou_dn_2: 0.5769 (0.5769)  loss_vfl_dn_3: 0.4266 (0.4266)  loss_bbox_dn_3: 0.1778 (0.1778)  loss_giou_dn_3: 0.5765 (0.5765)  loss_vfl_dn_4: 0.4269 (0.4269)  loss_bbox_dn_4: 0.1774 (0.1774)  loss_giou_dn_4: 0.5756 (0.5756)  loss_vfl_dn_5: 0.4282 (0.4282)  loss_bbox_dn_5: 0.1773 (0.1773)  loss_giou_dn_5: 0.5750 (0.5750)  loss_vfl_enc_0: 0.9864 (0.9864)  loss_bbox_enc_0: 0.3364 (0.3364)  loss_giou_enc_0: 0.8390 (0.8390)  time: 2.9748  data: 2.3879  max mem: 16811\n",
            "Epoch: [64]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 19.7592 (19.7153)  loss_vfl: 0.5206 (0.5230)  loss_bbox: 0.2701 (0.2754)  loss_giou: 0.7640 (0.7644)  loss_vfl_aux_0: 1.0245 (1.0239)  loss_bbox_aux_0: 0.2809 (0.2914)  loss_giou_aux_0: 0.7363 (0.7526)  loss_vfl_aux_1: 0.7571 (0.7514)  loss_bbox_aux_1: 0.2981 (0.3031)  loss_giou_aux_1: 0.7704 (0.7920)  loss_vfl_aux_2: 0.5625 (0.5684)  loss_bbox_aux_2: 0.2955 (0.3019)  loss_giou_aux_2: 0.7958 (0.8015)  loss_vfl_aux_3: 0.5170 (0.5188)  loss_bbox_aux_3: 0.2771 (0.2837)  loss_giou_aux_3: 0.7777 (0.7846)  loss_vfl_aux_4: 0.5152 (0.5197)  loss_bbox_aux_4: 0.2744 (0.2785)  loss_giou_aux_4: 0.7617 (0.7678)  loss_vfl_dn_0: 0.5281 (0.5304)  loss_bbox_dn_0: 0.2116 (0.2170)  loss_giou_dn_0: 0.6483 (0.6515)  loss_vfl_dn_1: 0.4615 (0.4633)  loss_bbox_dn_1: 0.1851 (0.1896)  loss_giou_dn_1: 0.5885 (0.5944)  loss_vfl_dn_2: 0.4274 (0.4287)  loss_bbox_dn_2: 0.1785 (0.1805)  loss_giou_dn_2: 0.5693 (0.5762)  loss_vfl_dn_3: 0.4219 (0.4233)  loss_bbox_dn_3: 0.1759 (0.1782)  loss_giou_dn_3: 0.5676 (0.5744)  loss_vfl_dn_4: 0.4239 (0.4255)  loss_bbox_dn_4: 0.1760 (0.1772)  loss_giou_dn_4: 0.5643 (0.5706)  loss_vfl_dn_5: 0.4235 (0.4245)  loss_bbox_dn_5: 0.1757 (0.1770)  loss_giou_dn_5: 0.5642 (0.5701)  loss_vfl_enc_0: 0.9225 (0.9329)  loss_bbox_enc_0: 0.3002 (0.3133)  loss_giou_enc_0: 0.8043 (0.8148)  time: 0.8439  data: 0.3235  max mem: 16811\n",
            "Epoch: [64] Total time: 0:00:06 (0.8491 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 19.7592 (19.7153)  loss_vfl: 0.5206 (0.5230)  loss_bbox: 0.2701 (0.2754)  loss_giou: 0.7640 (0.7644)  loss_vfl_aux_0: 1.0245 (1.0239)  loss_bbox_aux_0: 0.2809 (0.2914)  loss_giou_aux_0: 0.7363 (0.7526)  loss_vfl_aux_1: 0.7571 (0.7514)  loss_bbox_aux_1: 0.2981 (0.3031)  loss_giou_aux_1: 0.7704 (0.7920)  loss_vfl_aux_2: 0.5625 (0.5684)  loss_bbox_aux_2: 0.2955 (0.3019)  loss_giou_aux_2: 0.7958 (0.8015)  loss_vfl_aux_3: 0.5170 (0.5188)  loss_bbox_aux_3: 0.2771 (0.2837)  loss_giou_aux_3: 0.7777 (0.7846)  loss_vfl_aux_4: 0.5152 (0.5197)  loss_bbox_aux_4: 0.2744 (0.2785)  loss_giou_aux_4: 0.7617 (0.7678)  loss_vfl_dn_0: 0.5281 (0.5304)  loss_bbox_dn_0: 0.2116 (0.2170)  loss_giou_dn_0: 0.6483 (0.6515)  loss_vfl_dn_1: 0.4615 (0.4633)  loss_bbox_dn_1: 0.1851 (0.1896)  loss_giou_dn_1: 0.5885 (0.5944)  loss_vfl_dn_2: 0.4274 (0.4287)  loss_bbox_dn_2: 0.1785 (0.1805)  loss_giou_dn_2: 0.5693 (0.5762)  loss_vfl_dn_3: 0.4219 (0.4233)  loss_bbox_dn_3: 0.1759 (0.1782)  loss_giou_dn_3: 0.5676 (0.5744)  loss_vfl_dn_4: 0.4239 (0.4255)  loss_bbox_dn_4: 0.1760 (0.1772)  loss_giou_dn_4: 0.5643 (0.5706)  loss_vfl_dn_5: 0.4235 (0.4245)  loss_bbox_dn_5: 0.1757 (0.1770)  loss_giou_dn_5: 0.5642 (0.5701)  loss_vfl_enc_0: 0.9225 (0.9329)  loss_bbox_enc_0: 0.3002 (0.3133)  loss_giou_enc_0: 0.8043 (0.8148)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.4034  data: 2.3334  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.9285  data: 1.1833  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.9602 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
            "best_stat: {'epoch': 64, 'coco_eval_bbox': 0.2805871652595877}\n",
            "Epoch: [65]  [0/8]  eta: 0:00:29  lr: 0.000003  loss: 19.8819 (19.8819)  loss_vfl: 0.5212 (0.5212)  loss_bbox: 0.2777 (0.2777)  loss_giou: 0.7445 (0.7445)  loss_vfl_aux_0: 1.0232 (1.0232)  loss_bbox_aux_0: 0.3315 (0.3315)  loss_giou_aux_0: 0.7773 (0.7773)  loss_vfl_aux_1: 0.7635 (0.7635)  loss_bbox_aux_1: 0.3409 (0.3409)  loss_giou_aux_1: 0.8142 (0.8142)  loss_vfl_aux_2: 0.5503 (0.5503)  loss_bbox_aux_2: 0.3505 (0.3505)  loss_giou_aux_2: 0.8195 (0.8195)  loss_vfl_aux_3: 0.5219 (0.5219)  loss_bbox_aux_3: 0.2937 (0.2937)  loss_giou_aux_3: 0.7793 (0.7793)  loss_vfl_aux_4: 0.5333 (0.5333)  loss_bbox_aux_4: 0.2846 (0.2846)  loss_giou_aux_4: 0.7482 (0.7482)  loss_vfl_dn_0: 0.5338 (0.5338)  loss_bbox_dn_0: 0.2200 (0.2200)  loss_giou_dn_0: 0.6303 (0.6303)  loss_vfl_dn_1: 0.4630 (0.4630)  loss_bbox_dn_1: 0.1979 (0.1979)  loss_giou_dn_1: 0.5820 (0.5820)  loss_vfl_dn_2: 0.4308 (0.4308)  loss_bbox_dn_2: 0.1863 (0.1863)  loss_giou_dn_2: 0.5626 (0.5626)  loss_vfl_dn_3: 0.4222 (0.4222)  loss_bbox_dn_3: 0.1835 (0.1835)  loss_giou_dn_3: 0.5596 (0.5596)  loss_vfl_dn_4: 0.4232 (0.4232)  loss_bbox_dn_4: 0.1834 (0.1834)  loss_giou_dn_4: 0.5574 (0.5574)  loss_vfl_dn_5: 0.4199 (0.4199)  loss_bbox_dn_5: 0.1832 (0.1832)  loss_giou_dn_5: 0.5572 (0.5572)  loss_vfl_enc_0: 0.9167 (0.9167)  loss_bbox_enc_0: 0.3560 (0.3560)  loss_giou_enc_0: 0.8377 (0.8377)  time: 3.6332  data: 3.0903  max mem: 16811\n",
            "Epoch: [65]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 19.4758 (19.4829)  loss_vfl: 0.5113 (0.5144)  loss_bbox: 0.2631 (0.2642)  loss_giou: 0.7312 (0.7387)  loss_vfl_aux_0: 1.0232 (1.0332)  loss_bbox_aux_0: 0.2744 (0.2810)  loss_giou_aux_0: 0.7141 (0.7308)  loss_vfl_aux_1: 0.7910 (0.7924)  loss_bbox_aux_1: 0.2709 (0.2865)  loss_giou_aux_1: 0.7441 (0.7586)  loss_vfl_aux_2: 0.5744 (0.5668)  loss_bbox_aux_2: 0.2768 (0.2893)  loss_giou_aux_2: 0.7662 (0.7709)  loss_vfl_aux_3: 0.5262 (0.5327)  loss_bbox_aux_3: 0.2712 (0.2716)  loss_giou_aux_3: 0.7488 (0.7559)  loss_vfl_aux_4: 0.5325 (0.5282)  loss_bbox_aux_4: 0.2592 (0.2640)  loss_giou_aux_4: 0.7360 (0.7393)  loss_vfl_dn_0: 0.5311 (0.5293)  loss_bbox_dn_0: 0.2144 (0.2165)  loss_giou_dn_0: 0.6303 (0.6464)  loss_vfl_dn_1: 0.4568 (0.4610)  loss_bbox_dn_1: 0.1923 (0.1919)  loss_giou_dn_1: 0.5820 (0.5907)  loss_vfl_dn_2: 0.4255 (0.4270)  loss_bbox_dn_2: 0.1847 (0.1830)  loss_giou_dn_2: 0.5626 (0.5733)  loss_vfl_dn_3: 0.4207 (0.4201)  loss_bbox_dn_3: 0.1816 (0.1794)  loss_giou_dn_3: 0.5584 (0.5703)  loss_vfl_dn_4: 0.4214 (0.4215)  loss_bbox_dn_4: 0.1815 (0.1797)  loss_giou_dn_4: 0.5571 (0.5686)  loss_vfl_dn_5: 0.4172 (0.4175)  loss_bbox_dn_5: 0.1815 (0.1795)  loss_giou_dn_5: 0.5559 (0.5680)  loss_vfl_enc_0: 0.9167 (0.9380)  loss_bbox_enc_0: 0.3066 (0.3058)  loss_giou_enc_0: 0.7871 (0.7971)  time: 0.9286  data: 0.4184  max mem: 16811\n",
            "Epoch: [65] Total time: 0:00:07 (0.9354 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 19.4758 (19.4829)  loss_vfl: 0.5113 (0.5144)  loss_bbox: 0.2631 (0.2642)  loss_giou: 0.7312 (0.7387)  loss_vfl_aux_0: 1.0232 (1.0332)  loss_bbox_aux_0: 0.2744 (0.2810)  loss_giou_aux_0: 0.7141 (0.7308)  loss_vfl_aux_1: 0.7910 (0.7924)  loss_bbox_aux_1: 0.2709 (0.2865)  loss_giou_aux_1: 0.7441 (0.7586)  loss_vfl_aux_2: 0.5744 (0.5668)  loss_bbox_aux_2: 0.2768 (0.2893)  loss_giou_aux_2: 0.7662 (0.7709)  loss_vfl_aux_3: 0.5262 (0.5327)  loss_bbox_aux_3: 0.2712 (0.2716)  loss_giou_aux_3: 0.7488 (0.7559)  loss_vfl_aux_4: 0.5325 (0.5282)  loss_bbox_aux_4: 0.2592 (0.2640)  loss_giou_aux_4: 0.7360 (0.7393)  loss_vfl_dn_0: 0.5311 (0.5293)  loss_bbox_dn_0: 0.2144 (0.2165)  loss_giou_dn_0: 0.6303 (0.6464)  loss_vfl_dn_1: 0.4568 (0.4610)  loss_bbox_dn_1: 0.1923 (0.1919)  loss_giou_dn_1: 0.5820 (0.5907)  loss_vfl_dn_2: 0.4255 (0.4270)  loss_bbox_dn_2: 0.1847 (0.1830)  loss_giou_dn_2: 0.5626 (0.5733)  loss_vfl_dn_3: 0.4207 (0.4201)  loss_bbox_dn_3: 0.1816 (0.1794)  loss_giou_dn_3: 0.5584 (0.5703)  loss_vfl_dn_4: 0.4214 (0.4215)  loss_bbox_dn_4: 0.1815 (0.1797)  loss_giou_dn_4: 0.5571 (0.5686)  loss_vfl_dn_5: 0.4172 (0.4175)  loss_bbox_dn_5: 0.1815 (0.1795)  loss_giou_dn_5: 0.5559 (0.5680)  loss_vfl_enc_0: 0.9167 (0.9380)  loss_bbox_enc_0: 0.3066 (0.3058)  loss_giou_enc_0: 0.7871 (0.7971)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.6345  data: 3.5659  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.5442  data: 1.7994  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.5615 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.576\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
            "best_stat: {'epoch': 65, 'coco_eval_bbox': 0.28460209546146376}\n",
            "Epoch: [66]  [0/8]  eta: 0:00:23  lr: 0.000003  loss: 19.8432 (19.8432)  loss_vfl: 0.4554 (0.4554)  loss_bbox: 0.2911 (0.2911)  loss_giou: 0.8033 (0.8033)  loss_vfl_aux_0: 0.9860 (0.9860)  loss_bbox_aux_0: 0.3295 (0.3295)  loss_giou_aux_0: 0.8243 (0.8243)  loss_vfl_aux_1: 0.7211 (0.7211)  loss_bbox_aux_1: 0.3408 (0.3408)  loss_giou_aux_1: 0.8311 (0.8311)  loss_vfl_aux_2: 0.5194 (0.5194)  loss_bbox_aux_2: 0.3193 (0.3193)  loss_giou_aux_2: 0.8391 (0.8391)  loss_vfl_aux_3: 0.4634 (0.4634)  loss_bbox_aux_3: 0.2994 (0.2994)  loss_giou_aux_3: 0.8299 (0.8299)  loss_vfl_aux_4: 0.4623 (0.4623)  loss_bbox_aux_4: 0.2983 (0.2983)  loss_giou_aux_4: 0.8067 (0.8067)  loss_vfl_dn_0: 0.5343 (0.5343)  loss_bbox_dn_0: 0.2131 (0.2131)  loss_giou_dn_0: 0.6398 (0.6398)  loss_vfl_dn_1: 0.4697 (0.4697)  loss_bbox_dn_1: 0.1883 (0.1883)  loss_giou_dn_1: 0.5845 (0.5845)  loss_vfl_dn_2: 0.4295 (0.4295)  loss_bbox_dn_2: 0.1780 (0.1780)  loss_giou_dn_2: 0.5658 (0.5658)  loss_vfl_dn_3: 0.4238 (0.4238)  loss_bbox_dn_3: 0.1781 (0.1781)  loss_giou_dn_3: 0.5677 (0.5677)  loss_vfl_dn_4: 0.4277 (0.4277)  loss_bbox_dn_4: 0.1783 (0.1783)  loss_giou_dn_4: 0.5648 (0.5648)  loss_vfl_dn_5: 0.4232 (0.4232)  loss_bbox_dn_5: 0.1781 (0.1781)  loss_giou_dn_5: 0.5636 (0.5636)  loss_vfl_enc_0: 0.8885 (0.8885)  loss_bbox_enc_0: 0.3518 (0.3518)  loss_giou_enc_0: 0.8743 (0.8743)  time: 2.9675  data: 2.4072  max mem: 16811\n",
            "Epoch: [66]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 19.0893 (19.2594)  loss_vfl: 0.4931 (0.5145)  loss_bbox: 0.2424 (0.2587)  loss_giou: 0.7315 (0.7365)  loss_vfl_aux_0: 1.0040 (1.0321)  loss_bbox_aux_0: 0.2665 (0.2667)  loss_giou_aux_0: 0.6970 (0.7140)  loss_vfl_aux_1: 0.7389 (0.7592)  loss_bbox_aux_1: 0.2597 (0.2795)  loss_giou_aux_1: 0.7383 (0.7478)  loss_vfl_aux_2: 0.5611 (0.5728)  loss_bbox_aux_2: 0.2643 (0.2788)  loss_giou_aux_2: 0.7526 (0.7596)  loss_vfl_aux_3: 0.5073 (0.5152)  loss_bbox_aux_3: 0.2460 (0.2650)  loss_giou_aux_3: 0.7438 (0.7500)  loss_vfl_aux_4: 0.4972 (0.5156)  loss_bbox_aux_4: 0.2492 (0.2643)  loss_giou_aux_4: 0.7384 (0.7428)  loss_vfl_dn_0: 0.5303 (0.5306)  loss_bbox_dn_0: 0.2097 (0.2115)  loss_giou_dn_0: 0.6398 (0.6402)  loss_vfl_dn_1: 0.4697 (0.4693)  loss_bbox_dn_1: 0.1853 (0.1850)  loss_giou_dn_1: 0.5845 (0.5818)  loss_vfl_dn_2: 0.4312 (0.4336)  loss_bbox_dn_2: 0.1780 (0.1773)  loss_giou_dn_2: 0.5646 (0.5649)  loss_vfl_dn_3: 0.4275 (0.4273)  loss_bbox_dn_3: 0.1764 (0.1755)  loss_giou_dn_3: 0.5610 (0.5620)  loss_vfl_dn_4: 0.4290 (0.4299)  loss_bbox_dn_4: 0.1757 (0.1752)  loss_giou_dn_4: 0.5607 (0.5592)  loss_vfl_dn_5: 0.4262 (0.4274)  loss_bbox_dn_5: 0.1753 (0.1751)  loss_giou_dn_5: 0.5597 (0.5582)  loss_vfl_enc_0: 0.9217 (0.9361)  loss_bbox_enc_0: 0.2895 (0.2879)  loss_giou_enc_0: 0.7588 (0.7784)  time: 0.8479  data: 0.3292  max mem: 16811\n",
            "Epoch: [66] Total time: 0:00:06 (0.8536 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 19.0893 (19.2594)  loss_vfl: 0.4931 (0.5145)  loss_bbox: 0.2424 (0.2587)  loss_giou: 0.7315 (0.7365)  loss_vfl_aux_0: 1.0040 (1.0321)  loss_bbox_aux_0: 0.2665 (0.2667)  loss_giou_aux_0: 0.6970 (0.7140)  loss_vfl_aux_1: 0.7389 (0.7592)  loss_bbox_aux_1: 0.2597 (0.2795)  loss_giou_aux_1: 0.7383 (0.7478)  loss_vfl_aux_2: 0.5611 (0.5728)  loss_bbox_aux_2: 0.2643 (0.2788)  loss_giou_aux_2: 0.7526 (0.7596)  loss_vfl_aux_3: 0.5073 (0.5152)  loss_bbox_aux_3: 0.2460 (0.2650)  loss_giou_aux_3: 0.7438 (0.7500)  loss_vfl_aux_4: 0.4972 (0.5156)  loss_bbox_aux_4: 0.2492 (0.2643)  loss_giou_aux_4: 0.7384 (0.7428)  loss_vfl_dn_0: 0.5303 (0.5306)  loss_bbox_dn_0: 0.2097 (0.2115)  loss_giou_dn_0: 0.6398 (0.6402)  loss_vfl_dn_1: 0.4697 (0.4693)  loss_bbox_dn_1: 0.1853 (0.1850)  loss_giou_dn_1: 0.5845 (0.5818)  loss_vfl_dn_2: 0.4312 (0.4336)  loss_bbox_dn_2: 0.1780 (0.1773)  loss_giou_dn_2: 0.5646 (0.5649)  loss_vfl_dn_3: 0.4275 (0.4273)  loss_bbox_dn_3: 0.1764 (0.1755)  loss_giou_dn_3: 0.5610 (0.5620)  loss_vfl_dn_4: 0.4290 (0.4299)  loss_bbox_dn_4: 0.1757 (0.1752)  loss_giou_dn_4: 0.5607 (0.5592)  loss_vfl_dn_5: 0.4262 (0.4274)  loss_bbox_dn_5: 0.1753 (0.1751)  loss_giou_dn_5: 0.5597 (0.5582)  loss_vfl_enc_0: 0.9217 (0.9361)  loss_bbox_enc_0: 0.2895 (0.2879)  loss_giou_enc_0: 0.7588 (0.7784)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7353  data: 1.3169  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5932  data: 0.6749  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6208 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.577\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "best_stat: {'epoch': 66, 'coco_eval_bbox': 0.2865520522005036}\n",
            "Epoch: [67]  [0/8]  eta: 0:00:24  lr: 0.000003  loss: 18.9134 (18.9134)  loss_vfl: 0.5124 (0.5124)  loss_bbox: 0.2376 (0.2376)  loss_giou: 0.7181 (0.7181)  loss_vfl_aux_0: 1.0119 (1.0119)  loss_bbox_aux_0: 0.2434 (0.2434)  loss_giou_aux_0: 0.6975 (0.6975)  loss_vfl_aux_1: 0.7288 (0.7288)  loss_bbox_aux_1: 0.2446 (0.2446)  loss_giou_aux_1: 0.7210 (0.7210)  loss_vfl_aux_2: 0.5768 (0.5768)  loss_bbox_aux_2: 0.2475 (0.2475)  loss_giou_aux_2: 0.7333 (0.7333)  loss_vfl_aux_3: 0.5010 (0.5010)  loss_bbox_aux_3: 0.2535 (0.2535)  loss_giou_aux_3: 0.7496 (0.7496)  loss_vfl_aux_4: 0.5081 (0.5081)  loss_bbox_aux_4: 0.2453 (0.2453)  loss_giou_aux_4: 0.7297 (0.7297)  loss_vfl_dn_0: 0.5276 (0.5276)  loss_bbox_dn_0: 0.2065 (0.2065)  loss_giou_dn_0: 0.6535 (0.6535)  loss_vfl_dn_1: 0.4659 (0.4659)  loss_bbox_dn_1: 0.1821 (0.1821)  loss_giou_dn_1: 0.5934 (0.5934)  loss_vfl_dn_2: 0.4293 (0.4293)  loss_bbox_dn_2: 0.1728 (0.1728)  loss_giou_dn_2: 0.5803 (0.5803)  loss_vfl_dn_3: 0.4220 (0.4220)  loss_bbox_dn_3: 0.1702 (0.1702)  loss_giou_dn_3: 0.5758 (0.5758)  loss_vfl_dn_4: 0.4250 (0.4250)  loss_bbox_dn_4: 0.1683 (0.1683)  loss_giou_dn_4: 0.5735 (0.5735)  loss_vfl_dn_5: 0.4226 (0.4226)  loss_bbox_dn_5: 0.1682 (0.1682)  loss_giou_dn_5: 0.5724 (0.5724)  loss_vfl_enc_0: 0.9207 (0.9207)  loss_bbox_enc_0: 0.2670 (0.2670)  loss_giou_enc_0: 0.7558 (0.7558)  time: 3.1162  data: 2.5665  max mem: 16811\n",
            "Epoch: [67]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.9134 (19.1011)  loss_vfl: 0.5124 (0.5161)  loss_bbox: 0.2492 (0.2567)  loss_giou: 0.7190 (0.7277)  loss_vfl_aux_0: 1.0119 (1.0351)  loss_bbox_aux_0: 0.2623 (0.2653)  loss_giou_aux_0: 0.7028 (0.7195)  loss_vfl_aux_1: 0.7305 (0.7374)  loss_bbox_aux_1: 0.2716 (0.2764)  loss_giou_aux_1: 0.7478 (0.7510)  loss_vfl_aux_2: 0.5757 (0.5830)  loss_bbox_aux_2: 0.2680 (0.2718)  loss_giou_aux_2: 0.7488 (0.7568)  loss_vfl_aux_3: 0.5010 (0.5041)  loss_bbox_aux_3: 0.2544 (0.2663)  loss_giou_aux_3: 0.7362 (0.7486)  loss_vfl_aux_4: 0.5081 (0.5201)  loss_bbox_aux_4: 0.2512 (0.2593)  loss_giou_aux_4: 0.7261 (0.7336)  loss_vfl_dn_0: 0.5276 (0.5293)  loss_bbox_dn_0: 0.2063 (0.2074)  loss_giou_dn_0: 0.6272 (0.6343)  loss_vfl_dn_1: 0.4635 (0.4645)  loss_bbox_dn_1: 0.1733 (0.1807)  loss_giou_dn_1: 0.5621 (0.5733)  loss_vfl_dn_2: 0.4293 (0.4292)  loss_bbox_dn_2: 0.1630 (0.1709)  loss_giou_dn_2: 0.5467 (0.5552)  loss_vfl_dn_3: 0.4204 (0.4212)  loss_bbox_dn_3: 0.1614 (0.1686)  loss_giou_dn_3: 0.5404 (0.5517)  loss_vfl_dn_4: 0.4240 (0.4243)  loss_bbox_dn_4: 0.1604 (0.1679)  loss_giou_dn_4: 0.5397 (0.5491)  loss_vfl_dn_5: 0.4226 (0.4217)  loss_bbox_dn_5: 0.1603 (0.1677)  loss_giou_dn_5: 0.5399 (0.5481)  loss_vfl_enc_0: 0.9207 (0.9318)  loss_bbox_enc_0: 0.2906 (0.2903)  loss_giou_enc_0: 0.7812 (0.7852)  time: 0.8604  data: 0.3438  max mem: 16811\n",
            "Epoch: [67] Total time: 0:00:06 (0.8679 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.9134 (19.1011)  loss_vfl: 0.5124 (0.5161)  loss_bbox: 0.2492 (0.2567)  loss_giou: 0.7190 (0.7277)  loss_vfl_aux_0: 1.0119 (1.0351)  loss_bbox_aux_0: 0.2623 (0.2653)  loss_giou_aux_0: 0.7028 (0.7195)  loss_vfl_aux_1: 0.7305 (0.7374)  loss_bbox_aux_1: 0.2716 (0.2764)  loss_giou_aux_1: 0.7478 (0.7510)  loss_vfl_aux_2: 0.5757 (0.5830)  loss_bbox_aux_2: 0.2680 (0.2718)  loss_giou_aux_2: 0.7488 (0.7568)  loss_vfl_aux_3: 0.5010 (0.5041)  loss_bbox_aux_3: 0.2544 (0.2663)  loss_giou_aux_3: 0.7362 (0.7486)  loss_vfl_aux_4: 0.5081 (0.5201)  loss_bbox_aux_4: 0.2512 (0.2593)  loss_giou_aux_4: 0.7261 (0.7336)  loss_vfl_dn_0: 0.5276 (0.5293)  loss_bbox_dn_0: 0.2063 (0.2074)  loss_giou_dn_0: 0.6272 (0.6343)  loss_vfl_dn_1: 0.4635 (0.4645)  loss_bbox_dn_1: 0.1733 (0.1807)  loss_giou_dn_1: 0.5621 (0.5733)  loss_vfl_dn_2: 0.4293 (0.4292)  loss_bbox_dn_2: 0.1630 (0.1709)  loss_giou_dn_2: 0.5467 (0.5552)  loss_vfl_dn_3: 0.4204 (0.4212)  loss_bbox_dn_3: 0.1614 (0.1686)  loss_giou_dn_3: 0.5404 (0.5517)  loss_vfl_dn_4: 0.4240 (0.4243)  loss_bbox_dn_4: 0.1604 (0.1679)  loss_giou_dn_4: 0.5397 (0.5491)  loss_vfl_dn_5: 0.4226 (0.4217)  loss_bbox_dn_5: 0.1603 (0.1677)  loss_giou_dn_5: 0.5399 (0.5481)  loss_vfl_enc_0: 0.9207 (0.9318)  loss_bbox_enc_0: 0.2906 (0.2903)  loss_giou_enc_0: 0.7812 (0.7852)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4596  data: 4.3920  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9577  data: 2.2130  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9828 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
            "best_stat: {'epoch': 66, 'coco_eval_bbox': 0.2865520522005036}\n",
            "Epoch: [68]  [0/8]  eta: 0:00:12  lr: 0.000003  loss: 19.2886 (19.2886)  loss_vfl: 0.5004 (0.5004)  loss_bbox: 0.2499 (0.2499)  loss_giou: 0.7580 (0.7580)  loss_vfl_aux_0: 1.0324 (1.0324)  loss_bbox_aux_0: 0.2752 (0.2752)  loss_giou_aux_0: 0.7626 (0.7626)  loss_vfl_aux_1: 0.7331 (0.7331)  loss_bbox_aux_1: 0.2641 (0.2641)  loss_giou_aux_1: 0.7819 (0.7819)  loss_vfl_aux_2: 0.5891 (0.5891)  loss_bbox_aux_2: 0.2686 (0.2686)  loss_giou_aux_2: 0.8168 (0.8168)  loss_vfl_aux_3: 0.5162 (0.5162)  loss_bbox_aux_3: 0.2567 (0.2567)  loss_giou_aux_3: 0.7848 (0.7848)  loss_vfl_aux_4: 0.5176 (0.5176)  loss_bbox_aux_4: 0.2645 (0.2645)  loss_giou_aux_4: 0.7556 (0.7556)  loss_vfl_dn_0: 0.5283 (0.5283)  loss_bbox_dn_0: 0.1898 (0.1898)  loss_giou_dn_0: 0.6369 (0.6369)  loss_vfl_dn_1: 0.4569 (0.4569)  loss_bbox_dn_1: 0.1664 (0.1664)  loss_giou_dn_1: 0.5847 (0.5847)  loss_vfl_dn_2: 0.4265 (0.4265)  loss_bbox_dn_2: 0.1588 (0.1588)  loss_giou_dn_2: 0.5668 (0.5668)  loss_vfl_dn_3: 0.4194 (0.4194)  loss_bbox_dn_3: 0.1562 (0.1562)  loss_giou_dn_3: 0.5615 (0.5615)  loss_vfl_dn_4: 0.4202 (0.4202)  loss_bbox_dn_4: 0.1557 (0.1557)  loss_giou_dn_4: 0.5599 (0.5599)  loss_vfl_dn_5: 0.4156 (0.4156)  loss_bbox_dn_5: 0.1554 (0.1554)  loss_giou_dn_5: 0.5586 (0.5586)  loss_vfl_enc_0: 0.9291 (0.9291)  loss_bbox_enc_0: 0.2965 (0.2965)  loss_giou_enc_0: 0.8177 (0.8177)  time: 1.5103  data: 0.9043  max mem: 16811\n",
            "Epoch: [68]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 19.0144 (18.9826)  loss_vfl: 0.5004 (0.4992)  loss_bbox: 0.2491 (0.2502)  loss_giou: 0.7172 (0.7210)  loss_vfl_aux_0: 1.0321 (1.0405)  loss_bbox_aux_0: 0.2573 (0.2634)  loss_giou_aux_0: 0.6999 (0.7056)  loss_vfl_aux_1: 0.7336 (0.7437)  loss_bbox_aux_1: 0.2692 (0.2744)  loss_giou_aux_1: 0.7455 (0.7434)  loss_vfl_aux_2: 0.5729 (0.5766)  loss_bbox_aux_2: 0.2684 (0.2687)  loss_giou_aux_2: 0.7539 (0.7502)  loss_vfl_aux_3: 0.5054 (0.5080)  loss_bbox_aux_3: 0.2567 (0.2583)  loss_giou_aux_3: 0.7453 (0.7409)  loss_vfl_aux_4: 0.5068 (0.5103)  loss_bbox_aux_4: 0.2555 (0.2568)  loss_giou_aux_4: 0.7184 (0.7244)  loss_vfl_dn_0: 0.5311 (0.5310)  loss_bbox_dn_0: 0.2058 (0.2043)  loss_giou_dn_0: 0.6318 (0.6272)  loss_vfl_dn_1: 0.4605 (0.4611)  loss_bbox_dn_1: 0.1819 (0.1809)  loss_giou_dn_1: 0.5763 (0.5738)  loss_vfl_dn_2: 0.4265 (0.4271)  loss_bbox_dn_2: 0.1753 (0.1722)  loss_giou_dn_2: 0.5586 (0.5551)  loss_vfl_dn_3: 0.4197 (0.4195)  loss_bbox_dn_3: 0.1749 (0.1703)  loss_giou_dn_3: 0.5597 (0.5536)  loss_vfl_dn_4: 0.4211 (0.4205)  loss_bbox_dn_4: 0.1732 (0.1699)  loss_giou_dn_4: 0.5550 (0.5504)  loss_vfl_dn_5: 0.4176 (0.4181)  loss_bbox_dn_5: 0.1732 (0.1697)  loss_giou_dn_5: 0.5540 (0.5494)  loss_vfl_enc_0: 0.9291 (0.9335)  loss_bbox_enc_0: 0.2835 (0.2898)  loss_giou_enc_0: 0.7628 (0.7698)  time: 0.6595  data: 0.1381  max mem: 16811\n",
            "Epoch: [68] Total time: 0:00:05 (0.6655 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 19.0144 (18.9826)  loss_vfl: 0.5004 (0.4992)  loss_bbox: 0.2491 (0.2502)  loss_giou: 0.7172 (0.7210)  loss_vfl_aux_0: 1.0321 (1.0405)  loss_bbox_aux_0: 0.2573 (0.2634)  loss_giou_aux_0: 0.6999 (0.7056)  loss_vfl_aux_1: 0.7336 (0.7437)  loss_bbox_aux_1: 0.2692 (0.2744)  loss_giou_aux_1: 0.7455 (0.7434)  loss_vfl_aux_2: 0.5729 (0.5766)  loss_bbox_aux_2: 0.2684 (0.2687)  loss_giou_aux_2: 0.7539 (0.7502)  loss_vfl_aux_3: 0.5054 (0.5080)  loss_bbox_aux_3: 0.2567 (0.2583)  loss_giou_aux_3: 0.7453 (0.7409)  loss_vfl_aux_4: 0.5068 (0.5103)  loss_bbox_aux_4: 0.2555 (0.2568)  loss_giou_aux_4: 0.7184 (0.7244)  loss_vfl_dn_0: 0.5311 (0.5310)  loss_bbox_dn_0: 0.2058 (0.2043)  loss_giou_dn_0: 0.6318 (0.6272)  loss_vfl_dn_1: 0.4605 (0.4611)  loss_bbox_dn_1: 0.1819 (0.1809)  loss_giou_dn_1: 0.5763 (0.5738)  loss_vfl_dn_2: 0.4265 (0.4271)  loss_bbox_dn_2: 0.1753 (0.1722)  loss_giou_dn_2: 0.5586 (0.5551)  loss_vfl_dn_3: 0.4197 (0.4195)  loss_bbox_dn_3: 0.1749 (0.1703)  loss_giou_dn_3: 0.5597 (0.5536)  loss_vfl_dn_4: 0.4211 (0.4205)  loss_bbox_dn_4: 0.1732 (0.1699)  loss_giou_dn_4: 0.5550 (0.5504)  loss_vfl_dn_5: 0.4176 (0.4181)  loss_bbox_dn_5: 0.1732 (0.1697)  loss_giou_dn_5: 0.5540 (0.5494)  loss_vfl_enc_0: 0.9291 (0.9335)  loss_bbox_enc_0: 0.2835 (0.2898)  loss_giou_enc_0: 0.7628 (0.7698)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.3590  data: 2.2922  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.9056  data: 1.1624  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.9485 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n",
            "best_stat: {'epoch': 68, 'coco_eval_bbox': 0.29288241094691203}\n",
            "Epoch: [69]  [0/8]  eta: 0:00:26  lr: 0.000003  loss: 19.2826 (19.2826)  loss_vfl: 0.5055 (0.5055)  loss_bbox: 0.2896 (0.2896)  loss_giou: 0.7174 (0.7174)  loss_vfl_aux_0: 1.0295 (1.0295)  loss_bbox_aux_0: 0.2948 (0.2948)  loss_giou_aux_0: 0.7103 (0.7103)  loss_vfl_aux_1: 0.7332 (0.7332)  loss_bbox_aux_1: 0.3065 (0.3065)  loss_giou_aux_1: 0.7527 (0.7527)  loss_vfl_aux_2: 0.5533 (0.5533)  loss_bbox_aux_2: 0.3143 (0.3143)  loss_giou_aux_2: 0.7493 (0.7493)  loss_vfl_aux_3: 0.5095 (0.5095)  loss_bbox_aux_3: 0.3011 (0.3011)  loss_giou_aux_3: 0.7287 (0.7287)  loss_vfl_aux_4: 0.5121 (0.5121)  loss_bbox_aux_4: 0.2830 (0.2830)  loss_giou_aux_4: 0.7234 (0.7234)  loss_vfl_dn_0: 0.5365 (0.5365)  loss_bbox_dn_0: 0.2266 (0.2266)  loss_giou_dn_0: 0.6200 (0.6200)  loss_vfl_dn_1: 0.4704 (0.4704)  loss_bbox_dn_1: 0.1975 (0.1975)  loss_giou_dn_1: 0.5627 (0.5627)  loss_vfl_dn_2: 0.4361 (0.4361)  loss_bbox_dn_2: 0.1867 (0.1867)  loss_giou_dn_2: 0.5453 (0.5453)  loss_vfl_dn_3: 0.4329 (0.4329)  loss_bbox_dn_3: 0.1839 (0.1839)  loss_giou_dn_3: 0.5432 (0.5432)  loss_vfl_dn_4: 0.4344 (0.4344)  loss_bbox_dn_4: 0.1831 (0.1831)  loss_giou_dn_4: 0.5393 (0.5393)  loss_vfl_dn_5: 0.4315 (0.4315)  loss_bbox_dn_5: 0.1828 (0.1828)  loss_giou_dn_5: 0.5386 (0.5386)  loss_vfl_enc_0: 0.9002 (0.9002)  loss_bbox_enc_0: 0.3294 (0.3294)  loss_giou_enc_0: 0.7873 (0.7873)  time: 3.3729  data: 2.8277  max mem: 16811\n",
            "Epoch: [69]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.8602 (19.0326)  loss_vfl: 0.5144 (0.5166)  loss_bbox: 0.2472 (0.2519)  loss_giou: 0.7094 (0.7100)  loss_vfl_aux_0: 1.0384 (1.0558)  loss_bbox_aux_0: 0.2560 (0.2595)  loss_giou_aux_0: 0.6875 (0.6939)  loss_vfl_aux_1: 0.7433 (0.7454)  loss_bbox_aux_1: 0.2757 (0.2742)  loss_giou_aux_1: 0.7305 (0.7374)  loss_vfl_aux_2: 0.5674 (0.5639)  loss_bbox_aux_2: 0.2644 (0.2718)  loss_giou_aux_2: 0.7342 (0.7389)  loss_vfl_aux_3: 0.5151 (0.5227)  loss_bbox_aux_3: 0.2504 (0.2620)  loss_giou_aux_3: 0.7171 (0.7263)  loss_vfl_aux_4: 0.5163 (0.5188)  loss_bbox_aux_4: 0.2498 (0.2548)  loss_giou_aux_4: 0.7143 (0.7145)  loss_vfl_dn_0: 0.5241 (0.5258)  loss_bbox_dn_0: 0.2060 (0.2100)  loss_giou_dn_0: 0.6219 (0.6364)  loss_vfl_dn_1: 0.4572 (0.4590)  loss_bbox_dn_1: 0.1824 (0.1836)  loss_giou_dn_1: 0.5629 (0.5791)  loss_vfl_dn_2: 0.4294 (0.4275)  loss_bbox_dn_2: 0.1759 (0.1772)  loss_giou_dn_2: 0.5488 (0.5636)  loss_vfl_dn_3: 0.4235 (0.4232)  loss_bbox_dn_3: 0.1732 (0.1750)  loss_giou_dn_3: 0.5441 (0.5594)  loss_vfl_dn_4: 0.4218 (0.4242)  loss_bbox_dn_4: 0.1743 (0.1750)  loss_giou_dn_4: 0.5425 (0.5579)  loss_vfl_dn_5: 0.4218 (0.4224)  loss_bbox_dn_5: 0.1738 (0.1747)  loss_giou_dn_5: 0.5413 (0.5568)  loss_vfl_enc_0: 0.9245 (0.9365)  loss_bbox_enc_0: 0.2803 (0.2838)  loss_giou_enc_0: 0.7498 (0.7630)  time: 0.8925  data: 0.3783  max mem: 16811\n",
            "Epoch: [69] Total time: 0:00:07 (0.8991 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.8602 (19.0326)  loss_vfl: 0.5144 (0.5166)  loss_bbox: 0.2472 (0.2519)  loss_giou: 0.7094 (0.7100)  loss_vfl_aux_0: 1.0384 (1.0558)  loss_bbox_aux_0: 0.2560 (0.2595)  loss_giou_aux_0: 0.6875 (0.6939)  loss_vfl_aux_1: 0.7433 (0.7454)  loss_bbox_aux_1: 0.2757 (0.2742)  loss_giou_aux_1: 0.7305 (0.7374)  loss_vfl_aux_2: 0.5674 (0.5639)  loss_bbox_aux_2: 0.2644 (0.2718)  loss_giou_aux_2: 0.7342 (0.7389)  loss_vfl_aux_3: 0.5151 (0.5227)  loss_bbox_aux_3: 0.2504 (0.2620)  loss_giou_aux_3: 0.7171 (0.7263)  loss_vfl_aux_4: 0.5163 (0.5188)  loss_bbox_aux_4: 0.2498 (0.2548)  loss_giou_aux_4: 0.7143 (0.7145)  loss_vfl_dn_0: 0.5241 (0.5258)  loss_bbox_dn_0: 0.2060 (0.2100)  loss_giou_dn_0: 0.6219 (0.6364)  loss_vfl_dn_1: 0.4572 (0.4590)  loss_bbox_dn_1: 0.1824 (0.1836)  loss_giou_dn_1: 0.5629 (0.5791)  loss_vfl_dn_2: 0.4294 (0.4275)  loss_bbox_dn_2: 0.1759 (0.1772)  loss_giou_dn_2: 0.5488 (0.5636)  loss_vfl_dn_3: 0.4235 (0.4232)  loss_bbox_dn_3: 0.1732 (0.1750)  loss_giou_dn_3: 0.5441 (0.5594)  loss_vfl_dn_4: 0.4218 (0.4242)  loss_bbox_dn_4: 0.1743 (0.1750)  loss_giou_dn_4: 0.5425 (0.5579)  loss_vfl_dn_5: 0.4218 (0.4224)  loss_bbox_dn_5: 0.1738 (0.1747)  loss_giou_dn_5: 0.5413 (0.5568)  loss_vfl_enc_0: 0.9245 (0.9365)  loss_bbox_enc_0: 0.2803 (0.2838)  loss_giou_enc_0: 0.7498 (0.7630)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4256  data: 1.3450  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4462  data: 0.6889  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4725 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
            "best_stat: {'epoch': 69, 'coco_eval_bbox': 0.29453349372354}\n",
            "Epoch: [70]  [0/8]  eta: 0:00:24  lr: 0.000003  loss: 19.0102 (19.0102)  loss_vfl: 0.4988 (0.4988)  loss_bbox: 0.2445 (0.2445)  loss_giou: 0.7387 (0.7387)  loss_vfl_aux_0: 1.0029 (1.0029)  loss_bbox_aux_0: 0.2714 (0.2714)  loss_giou_aux_0: 0.7578 (0.7578)  loss_vfl_aux_1: 0.7409 (0.7409)  loss_bbox_aux_1: 0.2898 (0.2898)  loss_giou_aux_1: 0.7838 (0.7838)  loss_vfl_aux_2: 0.5466 (0.5466)  loss_bbox_aux_2: 0.2849 (0.2849)  loss_giou_aux_2: 0.7655 (0.7655)  loss_vfl_aux_3: 0.4954 (0.4954)  loss_bbox_aux_3: 0.2559 (0.2559)  loss_giou_aux_3: 0.7633 (0.7633)  loss_vfl_aux_4: 0.4923 (0.4923)  loss_bbox_aux_4: 0.2480 (0.2480)  loss_giou_aux_4: 0.7450 (0.7450)  loss_vfl_dn_0: 0.5187 (0.5187)  loss_bbox_dn_0: 0.2039 (0.2039)  loss_giou_dn_0: 0.6360 (0.6360)  loss_vfl_dn_1: 0.4574 (0.4574)  loss_bbox_dn_1: 0.1758 (0.1758)  loss_giou_dn_1: 0.5711 (0.5711)  loss_vfl_dn_2: 0.4254 (0.4254)  loss_bbox_dn_2: 0.1658 (0.1658)  loss_giou_dn_2: 0.5500 (0.5500)  loss_vfl_dn_3: 0.4203 (0.4203)  loss_bbox_dn_3: 0.1635 (0.1635)  loss_giou_dn_3: 0.5467 (0.5467)  loss_vfl_dn_4: 0.4199 (0.4199)  loss_bbox_dn_4: 0.1629 (0.1629)  loss_giou_dn_4: 0.5417 (0.5417)  loss_vfl_dn_5: 0.4196 (0.4196)  loss_bbox_dn_5: 0.1626 (0.1626)  loss_giou_dn_5: 0.5416 (0.5416)  loss_vfl_enc_0: 0.9040 (0.9040)  loss_bbox_enc_0: 0.2885 (0.2885)  loss_giou_enc_0: 0.8093 (0.8093)  time: 3.0376  data: 2.4764  max mem: 16811\n",
            "Epoch: [70]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.8311 (18.8912)  loss_vfl: 0.5090 (0.5113)  loss_bbox: 0.2445 (0.2478)  loss_giou: 0.6913 (0.7101)  loss_vfl_aux_0: 1.0457 (1.0687)  loss_bbox_aux_0: 0.2549 (0.2617)  loss_giou_aux_0: 0.6473 (0.6939)  loss_vfl_aux_1: 0.7498 (0.7602)  loss_bbox_aux_1: 0.2640 (0.2713)  loss_giou_aux_1: 0.6885 (0.7266)  loss_vfl_aux_2: 0.5475 (0.5580)  loss_bbox_aux_2: 0.2603 (0.2658)  loss_giou_aux_2: 0.7264 (0.7341)  loss_vfl_aux_3: 0.5134 (0.5193)  loss_bbox_aux_3: 0.2569 (0.2598)  loss_giou_aux_3: 0.7037 (0.7297)  loss_vfl_aux_4: 0.5091 (0.5162)  loss_bbox_aux_4: 0.2480 (0.2510)  loss_giou_aux_4: 0.6908 (0.7143)  loss_vfl_dn_0: 0.5250 (0.5247)  loss_bbox_dn_0: 0.2029 (0.2065)  loss_giou_dn_0: 0.6306 (0.6286)  loss_vfl_dn_1: 0.4570 (0.4576)  loss_bbox_dn_1: 0.1758 (0.1790)  loss_giou_dn_1: 0.5613 (0.5675)  loss_vfl_dn_2: 0.4251 (0.4252)  loss_bbox_dn_2: 0.1669 (0.1702)  loss_giou_dn_2: 0.5438 (0.5484)  loss_vfl_dn_3: 0.4183 (0.4192)  loss_bbox_dn_3: 0.1654 (0.1685)  loss_giou_dn_3: 0.5407 (0.5462)  loss_vfl_dn_4: 0.4178 (0.4185)  loss_bbox_dn_4: 0.1660 (0.1685)  loss_giou_dn_4: 0.5398 (0.5438)  loss_vfl_dn_5: 0.4180 (0.4171)  loss_bbox_dn_5: 0.1655 (0.1683)  loss_giou_dn_5: 0.5378 (0.5427)  loss_vfl_enc_0: 0.9398 (0.9446)  loss_bbox_enc_0: 0.2751 (0.2845)  loss_giou_enc_0: 0.7153 (0.7621)  time: 0.8405  data: 0.3257  max mem: 16811\n",
            "Epoch: [70] Total time: 0:00:06 (0.8473 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.8311 (18.8912)  loss_vfl: 0.5090 (0.5113)  loss_bbox: 0.2445 (0.2478)  loss_giou: 0.6913 (0.7101)  loss_vfl_aux_0: 1.0457 (1.0687)  loss_bbox_aux_0: 0.2549 (0.2617)  loss_giou_aux_0: 0.6473 (0.6939)  loss_vfl_aux_1: 0.7498 (0.7602)  loss_bbox_aux_1: 0.2640 (0.2713)  loss_giou_aux_1: 0.6885 (0.7266)  loss_vfl_aux_2: 0.5475 (0.5580)  loss_bbox_aux_2: 0.2603 (0.2658)  loss_giou_aux_2: 0.7264 (0.7341)  loss_vfl_aux_3: 0.5134 (0.5193)  loss_bbox_aux_3: 0.2569 (0.2598)  loss_giou_aux_3: 0.7037 (0.7297)  loss_vfl_aux_4: 0.5091 (0.5162)  loss_bbox_aux_4: 0.2480 (0.2510)  loss_giou_aux_4: 0.6908 (0.7143)  loss_vfl_dn_0: 0.5250 (0.5247)  loss_bbox_dn_0: 0.2029 (0.2065)  loss_giou_dn_0: 0.6306 (0.6286)  loss_vfl_dn_1: 0.4570 (0.4576)  loss_bbox_dn_1: 0.1758 (0.1790)  loss_giou_dn_1: 0.5613 (0.5675)  loss_vfl_dn_2: 0.4251 (0.4252)  loss_bbox_dn_2: 0.1669 (0.1702)  loss_giou_dn_2: 0.5438 (0.5484)  loss_vfl_dn_3: 0.4183 (0.4192)  loss_bbox_dn_3: 0.1654 (0.1685)  loss_giou_dn_3: 0.5407 (0.5462)  loss_vfl_dn_4: 0.4178 (0.4185)  loss_bbox_dn_4: 0.1660 (0.1685)  loss_giou_dn_4: 0.5398 (0.5438)  loss_vfl_dn_5: 0.4180 (0.4171)  loss_bbox_dn_5: 0.1655 (0.1683)  loss_giou_dn_5: 0.5378 (0.5427)  loss_vfl_enc_0: 0.9398 (0.9446)  loss_bbox_enc_0: 0.2751 (0.2845)  loss_giou_enc_0: 0.7153 (0.7621)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.7124  data: 3.6384  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.5847  data: 1.8353  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.6124 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            "best_stat: {'epoch': 70, 'coco_eval_bbox': 0.29896410258477624}\n",
            "Epoch: [71]  [0/8]  eta: 0:00:23  lr: 0.000003  loss: 18.4436 (18.4436)  loss_vfl: 0.5109 (0.5109)  loss_bbox: 0.2094 (0.2094)  loss_giou: 0.6805 (0.6805)  loss_vfl_aux_0: 1.1005 (1.1005)  loss_bbox_aux_0: 0.2456 (0.2456)  loss_giou_aux_0: 0.6765 (0.6765)  loss_vfl_aux_1: 0.7406 (0.7406)  loss_bbox_aux_1: 0.2497 (0.2497)  loss_giou_aux_1: 0.7094 (0.7094)  loss_vfl_aux_2: 0.5584 (0.5584)  loss_bbox_aux_2: 0.2456 (0.2456)  loss_giou_aux_2: 0.7126 (0.7126)  loss_vfl_aux_3: 0.5127 (0.5127)  loss_bbox_aux_3: 0.2189 (0.2189)  loss_giou_aux_3: 0.7047 (0.7047)  loss_vfl_aux_4: 0.5155 (0.5155)  loss_bbox_aux_4: 0.2151 (0.2151)  loss_giou_aux_4: 0.6842 (0.6842)  loss_vfl_dn_0: 0.5209 (0.5209)  loss_bbox_dn_0: 0.1940 (0.1940)  loss_giou_dn_0: 0.6167 (0.6167)  loss_vfl_dn_1: 0.4592 (0.4592)  loss_bbox_dn_1: 0.1648 (0.1648)  loss_giou_dn_1: 0.5647 (0.5647)  loss_vfl_dn_2: 0.4243 (0.4243)  loss_bbox_dn_2: 0.1545 (0.1545)  loss_giou_dn_2: 0.5445 (0.5445)  loss_vfl_dn_3: 0.4155 (0.4155)  loss_bbox_dn_3: 0.1531 (0.1531)  loss_giou_dn_3: 0.5444 (0.5444)  loss_vfl_dn_4: 0.4187 (0.4187)  loss_bbox_dn_4: 0.1522 (0.1522)  loss_giou_dn_4: 0.5402 (0.5402)  loss_vfl_dn_5: 0.4185 (0.4185)  loss_bbox_dn_5: 0.1520 (0.1520)  loss_giou_dn_5: 0.5384 (0.5384)  loss_vfl_enc_0: 0.9374 (0.9374)  loss_bbox_enc_0: 0.2738 (0.2738)  loss_giou_enc_0: 0.7648 (0.7648)  time: 2.9375  data: 2.3684  max mem: 16811\n",
            "Epoch: [71]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.7332 (18.6745)  loss_vfl: 0.5109 (0.5089)  loss_bbox: 0.2383 (0.2417)  loss_giou: 0.6805 (0.6924)  loss_vfl_aux_0: 1.0437 (1.0596)  loss_bbox_aux_0: 0.2467 (0.2576)  loss_giou_aux_0: 0.6803 (0.6851)  loss_vfl_aux_1: 0.7370 (0.7433)  loss_bbox_aux_1: 0.2659 (0.2658)  loss_giou_aux_1: 0.7191 (0.7205)  loss_vfl_aux_2: 0.5422 (0.5456)  loss_bbox_aux_2: 0.2639 (0.2655)  loss_giou_aux_2: 0.7228 (0.7273)  loss_vfl_aux_3: 0.5127 (0.5088)  loss_bbox_aux_3: 0.2417 (0.2509)  loss_giou_aux_3: 0.6967 (0.7129)  loss_vfl_aux_4: 0.5155 (0.5112)  loss_bbox_aux_4: 0.2428 (0.2463)  loss_giou_aux_4: 0.6873 (0.6990)  loss_vfl_dn_0: 0.5238 (0.5238)  loss_bbox_dn_0: 0.2003 (0.2018)  loss_giou_dn_0: 0.6163 (0.6206)  loss_vfl_dn_1: 0.4572 (0.4563)  loss_bbox_dn_1: 0.1770 (0.1770)  loss_giou_dn_1: 0.5647 (0.5637)  loss_vfl_dn_2: 0.4243 (0.4248)  loss_bbox_dn_2: 0.1668 (0.1690)  loss_giou_dn_2: 0.5443 (0.5455)  loss_vfl_dn_3: 0.4155 (0.4165)  loss_bbox_dn_3: 0.1655 (0.1669)  loss_giou_dn_3: 0.5410 (0.5424)  loss_vfl_dn_4: 0.4187 (0.4187)  loss_bbox_dn_4: 0.1652 (0.1663)  loss_giou_dn_4: 0.5384 (0.5399)  loss_vfl_dn_5: 0.4179 (0.4164)  loss_bbox_dn_5: 0.1650 (0.1661)  loss_giou_dn_5: 0.5370 (0.5388)  loss_vfl_enc_0: 0.9306 (0.9434)  loss_bbox_enc_0: 0.2812 (0.2819)  loss_giou_enc_0: 0.7584 (0.7526)  time: 0.8437  data: 0.3291  max mem: 16811\n",
            "Epoch: [71] Total time: 0:00:06 (0.8512 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.7332 (18.6745)  loss_vfl: 0.5109 (0.5089)  loss_bbox: 0.2383 (0.2417)  loss_giou: 0.6805 (0.6924)  loss_vfl_aux_0: 1.0437 (1.0596)  loss_bbox_aux_0: 0.2467 (0.2576)  loss_giou_aux_0: 0.6803 (0.6851)  loss_vfl_aux_1: 0.7370 (0.7433)  loss_bbox_aux_1: 0.2659 (0.2658)  loss_giou_aux_1: 0.7191 (0.7205)  loss_vfl_aux_2: 0.5422 (0.5456)  loss_bbox_aux_2: 0.2639 (0.2655)  loss_giou_aux_2: 0.7228 (0.7273)  loss_vfl_aux_3: 0.5127 (0.5088)  loss_bbox_aux_3: 0.2417 (0.2509)  loss_giou_aux_3: 0.6967 (0.7129)  loss_vfl_aux_4: 0.5155 (0.5112)  loss_bbox_aux_4: 0.2428 (0.2463)  loss_giou_aux_4: 0.6873 (0.6990)  loss_vfl_dn_0: 0.5238 (0.5238)  loss_bbox_dn_0: 0.2003 (0.2018)  loss_giou_dn_0: 0.6163 (0.6206)  loss_vfl_dn_1: 0.4572 (0.4563)  loss_bbox_dn_1: 0.1770 (0.1770)  loss_giou_dn_1: 0.5647 (0.5637)  loss_vfl_dn_2: 0.4243 (0.4248)  loss_bbox_dn_2: 0.1668 (0.1690)  loss_giou_dn_2: 0.5443 (0.5455)  loss_vfl_dn_3: 0.4155 (0.4165)  loss_bbox_dn_3: 0.1655 (0.1669)  loss_giou_dn_3: 0.5410 (0.5424)  loss_vfl_dn_4: 0.4187 (0.4187)  loss_bbox_dn_4: 0.1652 (0.1663)  loss_giou_dn_4: 0.5384 (0.5399)  loss_vfl_dn_5: 0.4179 (0.4164)  loss_bbox_dn_5: 0.1650 (0.1661)  loss_giou_dn_5: 0.5370 (0.5388)  loss_vfl_enc_0: 0.9306 (0.9434)  loss_bbox_enc_0: 0.2812 (0.2819)  loss_giou_enc_0: 0.7584 (0.7526)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8267  data: 4.4230  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1405  data: 2.2279  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1673 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.596\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            "best_stat: {'epoch': 70, 'coco_eval_bbox': 0.29896410258477624}\n",
            "Epoch: [72]  [0/8]  eta: 0:00:12  lr: 0.000003  loss: 19.3479 (19.3479)  loss_vfl: 0.5354 (0.5354)  loss_bbox: 0.2625 (0.2625)  loss_giou: 0.7077 (0.7077)  loss_vfl_aux_0: 1.0237 (1.0237)  loss_bbox_aux_0: 0.2397 (0.2397)  loss_giou_aux_0: 0.6551 (0.6551)  loss_vfl_aux_1: 0.7502 (0.7502)  loss_bbox_aux_1: 0.2714 (0.2714)  loss_giou_aux_1: 0.7061 (0.7061)  loss_vfl_aux_2: 0.5748 (0.5748)  loss_bbox_aux_2: 0.2811 (0.2811)  loss_giou_aux_2: 0.7169 (0.7169)  loss_vfl_aux_3: 0.5264 (0.5264)  loss_bbox_aux_3: 0.2758 (0.2758)  loss_giou_aux_3: 0.7325 (0.7325)  loss_vfl_aux_4: 0.5222 (0.5222)  loss_bbox_aux_4: 0.2727 (0.2727)  loss_giou_aux_4: 0.7240 (0.7240)  loss_vfl_dn_0: 0.5183 (0.5183)  loss_bbox_dn_0: 0.2440 (0.2440)  loss_giou_dn_0: 0.6705 (0.6705)  loss_vfl_dn_1: 0.4540 (0.4540)  loss_bbox_dn_1: 0.2247 (0.2247)  loss_giou_dn_1: 0.6270 (0.6270)  loss_vfl_dn_2: 0.4276 (0.4276)  loss_bbox_dn_2: 0.2155 (0.2155)  loss_giou_dn_2: 0.6092 (0.6092)  loss_vfl_dn_3: 0.4187 (0.4187)  loss_bbox_dn_3: 0.2124 (0.2124)  loss_giou_dn_3: 0.6070 (0.6070)  loss_vfl_dn_4: 0.4181 (0.4181)  loss_bbox_dn_4: 0.2113 (0.2113)  loss_giou_dn_4: 0.6032 (0.6032)  loss_vfl_dn_5: 0.4193 (0.4193)  loss_bbox_dn_5: 0.2109 (0.2109)  loss_giou_dn_5: 0.6018 (0.6018)  loss_vfl_enc_0: 0.9337 (0.9337)  loss_bbox_enc_0: 0.2536 (0.2536)  loss_giou_enc_0: 0.6889 (0.6889)  time: 1.5764  data: 1.0305  max mem: 16811\n",
            "Epoch: [72]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.5589 (18.6505)  loss_vfl: 0.5070 (0.5162)  loss_bbox: 0.2365 (0.2458)  loss_giou: 0.6946 (0.6922)  loss_vfl_aux_0: 1.0348 (1.0534)  loss_bbox_aux_0: 0.2487 (0.2488)  loss_giou_aux_0: 0.6895 (0.6791)  loss_vfl_aux_1: 0.7276 (0.7283)  loss_bbox_aux_1: 0.2622 (0.2543)  loss_giou_aux_1: 0.7061 (0.7109)  loss_vfl_aux_2: 0.5519 (0.5560)  loss_bbox_aux_2: 0.2585 (0.2569)  loss_giou_aux_2: 0.7152 (0.7151)  loss_vfl_aux_3: 0.5165 (0.5212)  loss_bbox_aux_3: 0.2426 (0.2487)  loss_giou_aux_3: 0.7161 (0.7070)  loss_vfl_aux_4: 0.5118 (0.5191)  loss_bbox_aux_4: 0.2390 (0.2478)  loss_giou_aux_4: 0.7003 (0.6967)  loss_vfl_dn_0: 0.5203 (0.5217)  loss_bbox_dn_0: 0.1963 (0.2045)  loss_giou_dn_0: 0.6194 (0.6256)  loss_vfl_dn_1: 0.4527 (0.4517)  loss_bbox_dn_1: 0.1702 (0.1791)  loss_giou_dn_1: 0.5648 (0.5703)  loss_vfl_dn_2: 0.4208 (0.4215)  loss_bbox_dn_2: 0.1646 (0.1714)  loss_giou_dn_2: 0.5448 (0.5517)  loss_vfl_dn_3: 0.4138 (0.4147)  loss_bbox_dn_3: 0.1643 (0.1691)  loss_giou_dn_3: 0.5421 (0.5499)  loss_vfl_dn_4: 0.4161 (0.4162)  loss_bbox_dn_4: 0.1644 (0.1688)  loss_giou_dn_4: 0.5405 (0.5475)  loss_vfl_dn_5: 0.4156 (0.4153)  loss_bbox_dn_5: 0.1641 (0.1687)  loss_giou_dn_5: 0.5397 (0.5467)  loss_vfl_enc_0: 0.9297 (0.9418)  loss_bbox_enc_0: 0.2734 (0.2719)  loss_giou_enc_0: 0.7544 (0.7450)  time: 0.6586  data: 0.1463  max mem: 16811\n",
            "Epoch: [72] Total time: 0:00:05 (0.6639 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.5589 (18.6505)  loss_vfl: 0.5070 (0.5162)  loss_bbox: 0.2365 (0.2458)  loss_giou: 0.6946 (0.6922)  loss_vfl_aux_0: 1.0348 (1.0534)  loss_bbox_aux_0: 0.2487 (0.2488)  loss_giou_aux_0: 0.6895 (0.6791)  loss_vfl_aux_1: 0.7276 (0.7283)  loss_bbox_aux_1: 0.2622 (0.2543)  loss_giou_aux_1: 0.7061 (0.7109)  loss_vfl_aux_2: 0.5519 (0.5560)  loss_bbox_aux_2: 0.2585 (0.2569)  loss_giou_aux_2: 0.7152 (0.7151)  loss_vfl_aux_3: 0.5165 (0.5212)  loss_bbox_aux_3: 0.2426 (0.2487)  loss_giou_aux_3: 0.7161 (0.7070)  loss_vfl_aux_4: 0.5118 (0.5191)  loss_bbox_aux_4: 0.2390 (0.2478)  loss_giou_aux_4: 0.7003 (0.6967)  loss_vfl_dn_0: 0.5203 (0.5217)  loss_bbox_dn_0: 0.1963 (0.2045)  loss_giou_dn_0: 0.6194 (0.6256)  loss_vfl_dn_1: 0.4527 (0.4517)  loss_bbox_dn_1: 0.1702 (0.1791)  loss_giou_dn_1: 0.5648 (0.5703)  loss_vfl_dn_2: 0.4208 (0.4215)  loss_bbox_dn_2: 0.1646 (0.1714)  loss_giou_dn_2: 0.5448 (0.5517)  loss_vfl_dn_3: 0.4138 (0.4147)  loss_bbox_dn_3: 0.1643 (0.1691)  loss_giou_dn_3: 0.5421 (0.5499)  loss_vfl_dn_4: 0.4161 (0.4162)  loss_bbox_dn_4: 0.1644 (0.1688)  loss_giou_dn_4: 0.5405 (0.5475)  loss_vfl_dn_5: 0.4156 (0.4153)  loss_bbox_dn_5: 0.1641 (0.1687)  loss_giou_dn_5: 0.5397 (0.5467)  loss_vfl_enc_0: 0.9297 (0.9418)  loss_bbox_enc_0: 0.2734 (0.2719)  loss_giou_enc_0: 0.7544 (0.7450)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.6049  data: 1.5381  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5277  data: 0.7858  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.5457 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            "best_stat: {'epoch': 72, 'coco_eval_bbox': 0.30148781533657354}\n",
            "Epoch: [73]  [0/8]  eta: 0:00:30  lr: 0.000003  loss: 18.7954 (18.7954)  loss_vfl: 0.5352 (0.5352)  loss_bbox: 0.2631 (0.2631)  loss_giou: 0.6850 (0.6850)  loss_vfl_aux_0: 1.0475 (1.0475)  loss_bbox_aux_0: 0.2669 (0.2669)  loss_giou_aux_0: 0.6958 (0.6958)  loss_vfl_aux_1: 0.7240 (0.7240)  loss_bbox_aux_1: 0.2777 (0.2777)  loss_giou_aux_1: 0.7019 (0.7019)  loss_vfl_aux_2: 0.5622 (0.5622)  loss_bbox_aux_2: 0.2751 (0.2751)  loss_giou_aux_2: 0.7075 (0.7075)  loss_vfl_aux_3: 0.5338 (0.5338)  loss_bbox_aux_3: 0.2722 (0.2722)  loss_giou_aux_3: 0.6986 (0.6986)  loss_vfl_aux_4: 0.5330 (0.5330)  loss_bbox_aux_4: 0.2619 (0.2619)  loss_giou_aux_4: 0.6847 (0.6847)  loss_vfl_dn_0: 0.5236 (0.5236)  loss_bbox_dn_0: 0.2008 (0.2008)  loss_giou_dn_0: 0.6102 (0.6102)  loss_vfl_dn_1: 0.4564 (0.4564)  loss_bbox_dn_1: 0.1814 (0.1814)  loss_giou_dn_1: 0.5589 (0.5589)  loss_vfl_dn_2: 0.4236 (0.4236)  loss_bbox_dn_2: 0.1729 (0.1729)  loss_giou_dn_2: 0.5415 (0.5415)  loss_vfl_dn_3: 0.4162 (0.4162)  loss_bbox_dn_3: 0.1717 (0.1717)  loss_giou_dn_3: 0.5402 (0.5402)  loss_vfl_dn_4: 0.4182 (0.4182)  loss_bbox_dn_4: 0.1710 (0.1710)  loss_giou_dn_4: 0.5357 (0.5357)  loss_vfl_dn_5: 0.4171 (0.4171)  loss_bbox_dn_5: 0.1707 (0.1707)  loss_giou_dn_5: 0.5351 (0.5351)  loss_vfl_enc_0: 0.9478 (0.9478)  loss_bbox_enc_0: 0.3018 (0.3018)  loss_giou_enc_0: 0.7744 (0.7744)  time: 3.8454  data: 3.2686  max mem: 16811\n",
            "Epoch: [73]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.4949 (18.4766)  loss_vfl: 0.5199 (0.5176)  loss_bbox: 0.2320 (0.2407)  loss_giou: 0.6794 (0.6724)  loss_vfl_aux_0: 1.0486 (1.0633)  loss_bbox_aux_0: 0.2633 (0.2429)  loss_giou_aux_0: 0.6791 (0.6644)  loss_vfl_aux_1: 0.6976 (0.7212)  loss_bbox_aux_1: 0.2652 (0.2551)  loss_giou_aux_1: 0.6905 (0.6953)  loss_vfl_aux_2: 0.5622 (0.5686)  loss_bbox_aux_2: 0.2653 (0.2574)  loss_giou_aux_2: 0.6902 (0.6984)  loss_vfl_aux_3: 0.5274 (0.5277)  loss_bbox_aux_3: 0.2382 (0.2458)  loss_giou_aux_3: 0.6863 (0.6866)  loss_vfl_aux_4: 0.5292 (0.5227)  loss_bbox_aux_4: 0.2342 (0.2436)  loss_giou_aux_4: 0.6842 (0.6773)  loss_vfl_dn_0: 0.5234 (0.5235)  loss_bbox_dn_0: 0.2017 (0.2010)  loss_giou_dn_0: 0.6120 (0.6159)  loss_vfl_dn_1: 0.4529 (0.4557)  loss_bbox_dn_1: 0.1777 (0.1766)  loss_giou_dn_1: 0.5577 (0.5595)  loss_vfl_dn_2: 0.4250 (0.4264)  loss_bbox_dn_2: 0.1678 (0.1684)  loss_giou_dn_2: 0.5409 (0.5412)  loss_vfl_dn_3: 0.4164 (0.4202)  loss_bbox_dn_3: 0.1652 (0.1659)  loss_giou_dn_3: 0.5334 (0.5376)  loss_vfl_dn_4: 0.4175 (0.4207)  loss_bbox_dn_4: 0.1640 (0.1659)  loss_giou_dn_4: 0.5318 (0.5352)  loss_vfl_dn_5: 0.4155 (0.4178)  loss_bbox_dn_5: 0.1639 (0.1658)  loss_giou_dn_5: 0.5297 (0.5341)  loss_vfl_enc_0: 0.9293 (0.9422)  loss_bbox_enc_0: 0.2888 (0.2681)  loss_giou_enc_0: 0.7398 (0.7337)  time: 0.9412  data: 0.4252  max mem: 16811\n",
            "Epoch: [73] Total time: 0:00:07 (0.9472 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.4949 (18.4766)  loss_vfl: 0.5199 (0.5176)  loss_bbox: 0.2320 (0.2407)  loss_giou: 0.6794 (0.6724)  loss_vfl_aux_0: 1.0486 (1.0633)  loss_bbox_aux_0: 0.2633 (0.2429)  loss_giou_aux_0: 0.6791 (0.6644)  loss_vfl_aux_1: 0.6976 (0.7212)  loss_bbox_aux_1: 0.2652 (0.2551)  loss_giou_aux_1: 0.6905 (0.6953)  loss_vfl_aux_2: 0.5622 (0.5686)  loss_bbox_aux_2: 0.2653 (0.2574)  loss_giou_aux_2: 0.6902 (0.6984)  loss_vfl_aux_3: 0.5274 (0.5277)  loss_bbox_aux_3: 0.2382 (0.2458)  loss_giou_aux_3: 0.6863 (0.6866)  loss_vfl_aux_4: 0.5292 (0.5227)  loss_bbox_aux_4: 0.2342 (0.2436)  loss_giou_aux_4: 0.6842 (0.6773)  loss_vfl_dn_0: 0.5234 (0.5235)  loss_bbox_dn_0: 0.2017 (0.2010)  loss_giou_dn_0: 0.6120 (0.6159)  loss_vfl_dn_1: 0.4529 (0.4557)  loss_bbox_dn_1: 0.1777 (0.1766)  loss_giou_dn_1: 0.5577 (0.5595)  loss_vfl_dn_2: 0.4250 (0.4264)  loss_bbox_dn_2: 0.1678 (0.1684)  loss_giou_dn_2: 0.5409 (0.5412)  loss_vfl_dn_3: 0.4164 (0.4202)  loss_bbox_dn_3: 0.1652 (0.1659)  loss_giou_dn_3: 0.5334 (0.5376)  loss_vfl_dn_4: 0.4175 (0.4207)  loss_bbox_dn_4: 0.1640 (0.1659)  loss_giou_dn_4: 0.5318 (0.5352)  loss_vfl_dn_5: 0.4155 (0.4178)  loss_bbox_dn_5: 0.1639 (0.1658)  loss_giou_dn_5: 0.5297 (0.5341)  loss_vfl_enc_0: 0.9293 (0.9422)  loss_bbox_enc_0: 0.2888 (0.2681)  loss_giou_enc_0: 0.7398 (0.7337)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4267  data: 1.3653  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4387  data: 0.6990  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4639 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
            "best_stat: {'epoch': 72, 'coco_eval_bbox': 0.30148781533657354}\n",
            "Epoch: [74]  [0/8]  eta: 0:00:14  lr: 0.000003  loss: 18.8746 (18.8746)  loss_vfl: 0.4787 (0.4787)  loss_bbox: 0.2542 (0.2542)  loss_giou: 0.7263 (0.7263)  loss_vfl_aux_0: 0.9696 (0.9696)  loss_bbox_aux_0: 0.3013 (0.3013)  loss_giou_aux_0: 0.7411 (0.7411)  loss_vfl_aux_1: 0.6788 (0.6788)  loss_bbox_aux_1: 0.3073 (0.3073)  loss_giou_aux_1: 0.7652 (0.7652)  loss_vfl_aux_2: 0.5086 (0.5086)  loss_bbox_aux_2: 0.2968 (0.2968)  loss_giou_aux_2: 0.7623 (0.7623)  loss_vfl_aux_3: 0.4777 (0.4777)  loss_bbox_aux_3: 0.2645 (0.2645)  loss_giou_aux_3: 0.7530 (0.7530)  loss_vfl_aux_4: 0.4883 (0.4883)  loss_bbox_aux_4: 0.2585 (0.2585)  loss_giou_aux_4: 0.7253 (0.7253)  loss_vfl_dn_0: 0.5224 (0.5224)  loss_bbox_dn_0: 0.2084 (0.2084)  loss_giou_dn_0: 0.6193 (0.6193)  loss_vfl_dn_1: 0.4616 (0.4616)  loss_bbox_dn_1: 0.1822 (0.1822)  loss_giou_dn_1: 0.5638 (0.5638)  loss_vfl_dn_2: 0.4279 (0.4279)  loss_bbox_dn_2: 0.1751 (0.1751)  loss_giou_dn_2: 0.5448 (0.5448)  loss_vfl_dn_3: 0.4179 (0.4179)  loss_bbox_dn_3: 0.1721 (0.1721)  loss_giou_dn_3: 0.5441 (0.5441)  loss_vfl_dn_4: 0.4187 (0.4187)  loss_bbox_dn_4: 0.1713 (0.1713)  loss_giou_dn_4: 0.5409 (0.5409)  loss_vfl_dn_5: 0.4163 (0.4163)  loss_bbox_dn_5: 0.1709 (0.1709)  loss_giou_dn_5: 0.5395 (0.5395)  loss_vfl_enc_0: 0.8709 (0.8709)  loss_bbox_enc_0: 0.3332 (0.3332)  loss_giou_enc_0: 0.8161 (0.8161)  time: 1.8664  data: 1.2649  max mem: 16811\n",
            "Epoch: [74]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.1494 (18.4607)  loss_vfl: 0.5100 (0.5098)  loss_bbox: 0.2241 (0.2355)  loss_giou: 0.6731 (0.6803)  loss_vfl_aux_0: 1.0537 (1.0687)  loss_bbox_aux_0: 0.2271 (0.2438)  loss_giou_aux_0: 0.6620 (0.6698)  loss_vfl_aux_1: 0.7323 (0.7392)  loss_bbox_aux_1: 0.2331 (0.2557)  loss_giou_aux_1: 0.6886 (0.7071)  loss_vfl_aux_2: 0.5734 (0.5624)  loss_bbox_aux_2: 0.2390 (0.2560)  loss_giou_aux_2: 0.6826 (0.7073)  loss_vfl_aux_3: 0.5168 (0.5190)  loss_bbox_aux_3: 0.2288 (0.2404)  loss_giou_aux_3: 0.6816 (0.6956)  loss_vfl_aux_4: 0.5067 (0.5149)  loss_bbox_aux_4: 0.2329 (0.2386)  loss_giou_aux_4: 0.6799 (0.6837)  loss_vfl_dn_0: 0.5188 (0.5205)  loss_bbox_dn_0: 0.1966 (0.1985)  loss_giou_dn_0: 0.6193 (0.6142)  loss_vfl_dn_1: 0.4528 (0.4565)  loss_bbox_dn_1: 0.1676 (0.1731)  loss_giou_dn_1: 0.5594 (0.5540)  loss_vfl_dn_2: 0.4231 (0.4238)  loss_bbox_dn_2: 0.1608 (0.1663)  loss_giou_dn_2: 0.5425 (0.5369)  loss_vfl_dn_3: 0.4169 (0.4173)  loss_bbox_dn_3: 0.1590 (0.1636)  loss_giou_dn_3: 0.5404 (0.5332)  loss_vfl_dn_4: 0.4179 (0.4181)  loss_bbox_dn_4: 0.1585 (0.1632)  loss_giou_dn_4: 0.5390 (0.5309)  loss_vfl_dn_5: 0.4146 (0.4168)  loss_bbox_dn_5: 0.1583 (0.1630)  loss_giou_dn_5: 0.5390 (0.5300)  loss_vfl_enc_0: 0.9320 (0.9422)  loss_bbox_enc_0: 0.2516 (0.2703)  loss_giou_enc_0: 0.7213 (0.7405)  time: 0.7025  data: 0.1848  max mem: 16811\n",
            "Epoch: [74] Total time: 0:00:05 (0.7078 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.1494 (18.4607)  loss_vfl: 0.5100 (0.5098)  loss_bbox: 0.2241 (0.2355)  loss_giou: 0.6731 (0.6803)  loss_vfl_aux_0: 1.0537 (1.0687)  loss_bbox_aux_0: 0.2271 (0.2438)  loss_giou_aux_0: 0.6620 (0.6698)  loss_vfl_aux_1: 0.7323 (0.7392)  loss_bbox_aux_1: 0.2331 (0.2557)  loss_giou_aux_1: 0.6886 (0.7071)  loss_vfl_aux_2: 0.5734 (0.5624)  loss_bbox_aux_2: 0.2390 (0.2560)  loss_giou_aux_2: 0.6826 (0.7073)  loss_vfl_aux_3: 0.5168 (0.5190)  loss_bbox_aux_3: 0.2288 (0.2404)  loss_giou_aux_3: 0.6816 (0.6956)  loss_vfl_aux_4: 0.5067 (0.5149)  loss_bbox_aux_4: 0.2329 (0.2386)  loss_giou_aux_4: 0.6799 (0.6837)  loss_vfl_dn_0: 0.5188 (0.5205)  loss_bbox_dn_0: 0.1966 (0.1985)  loss_giou_dn_0: 0.6193 (0.6142)  loss_vfl_dn_1: 0.4528 (0.4565)  loss_bbox_dn_1: 0.1676 (0.1731)  loss_giou_dn_1: 0.5594 (0.5540)  loss_vfl_dn_2: 0.4231 (0.4238)  loss_bbox_dn_2: 0.1608 (0.1663)  loss_giou_dn_2: 0.5425 (0.5369)  loss_vfl_dn_3: 0.4169 (0.4173)  loss_bbox_dn_3: 0.1590 (0.1636)  loss_giou_dn_3: 0.5404 (0.5332)  loss_vfl_dn_4: 0.4179 (0.4181)  loss_bbox_dn_4: 0.1585 (0.1632)  loss_giou_dn_4: 0.5390 (0.5309)  loss_vfl_dn_5: 0.4146 (0.4168)  loss_bbox_dn_5: 0.1583 (0.1630)  loss_giou_dn_5: 0.5390 (0.5300)  loss_vfl_enc_0: 0.9320 (0.9422)  loss_bbox_enc_0: 0.2516 (0.2703)  loss_giou_enc_0: 0.7213 (0.7405)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.7114  data: 4.6403  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0814  data: 2.3366  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1169 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
            "best_stat: {'epoch': 74, 'coco_eval_bbox': 0.3028419045408685}\n",
            "Epoch: [75]  [0/8]  eta: 0:00:24  lr: 0.000003  loss: 17.9382 (17.9382)  loss_vfl: 0.5052 (0.5052)  loss_bbox: 0.2255 (0.2255)  loss_giou: 0.6431 (0.6431)  loss_vfl_aux_0: 1.0704 (1.0704)  loss_bbox_aux_0: 0.2283 (0.2283)  loss_giou_aux_0: 0.6200 (0.6200)  loss_vfl_aux_1: 0.7402 (0.7402)  loss_bbox_aux_1: 0.2397 (0.2397)  loss_giou_aux_1: 0.6617 (0.6617)  loss_vfl_aux_2: 0.5692 (0.5692)  loss_bbox_aux_2: 0.2349 (0.2349)  loss_giou_aux_2: 0.6640 (0.6640)  loss_vfl_aux_3: 0.5038 (0.5038)  loss_bbox_aux_3: 0.2383 (0.2383)  loss_giou_aux_3: 0.6590 (0.6590)  loss_vfl_aux_4: 0.5183 (0.5183)  loss_bbox_aux_4: 0.2291 (0.2291)  loss_giou_aux_4: 0.6490 (0.6490)  loss_vfl_dn_0: 0.5212 (0.5212)  loss_bbox_dn_0: 0.1964 (0.1964)  loss_giou_dn_0: 0.5884 (0.5884)  loss_vfl_dn_1: 0.4571 (0.4571)  loss_bbox_dn_1: 0.1686 (0.1686)  loss_giou_dn_1: 0.5282 (0.5282)  loss_vfl_dn_2: 0.4313 (0.4313)  loss_bbox_dn_2: 0.1620 (0.1620)  loss_giou_dn_2: 0.5175 (0.5175)  loss_vfl_dn_3: 0.4250 (0.4250)  loss_bbox_dn_3: 0.1570 (0.1570)  loss_giou_dn_3: 0.5104 (0.5104)  loss_vfl_dn_4: 0.4291 (0.4291)  loss_bbox_dn_4: 0.1570 (0.1570)  loss_giou_dn_4: 0.5069 (0.5069)  loss_vfl_dn_5: 0.4318 (0.4318)  loss_bbox_dn_5: 0.1569 (0.1569)  loss_giou_dn_5: 0.5065 (0.5065)  loss_vfl_enc_0: 0.9369 (0.9369)  loss_bbox_enc_0: 0.2561 (0.2561)  loss_giou_enc_0: 0.6940 (0.6940)  time: 3.0538  data: 2.4762  max mem: 16811\n",
            "Epoch: [75]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.1922 (18.3162)  loss_vfl: 0.5011 (0.5109)  loss_bbox: 0.2362 (0.2364)  loss_giou: 0.6431 (0.6742)  loss_vfl_aux_0: 1.0661 (1.0686)  loss_bbox_aux_0: 0.2370 (0.2372)  loss_giou_aux_0: 0.6310 (0.6475)  loss_vfl_aux_1: 0.7174 (0.7261)  loss_bbox_aux_1: 0.2492 (0.2554)  loss_giou_aux_1: 0.6654 (0.6917)  loss_vfl_aux_2: 0.5575 (0.5599)  loss_bbox_aux_2: 0.2569 (0.2534)  loss_giou_aux_2: 0.6778 (0.6953)  loss_vfl_aux_3: 0.5038 (0.5081)  loss_bbox_aux_3: 0.2466 (0.2426)  loss_giou_aux_3: 0.6682 (0.6883)  loss_vfl_aux_4: 0.5122 (0.5150)  loss_bbox_aux_4: 0.2375 (0.2365)  loss_giou_aux_4: 0.6490 (0.6770)  loss_vfl_dn_0: 0.5189 (0.5191)  loss_bbox_dn_0: 0.1966 (0.1992)  loss_giou_dn_0: 0.6053 (0.6090)  loss_vfl_dn_1: 0.4566 (0.4559)  loss_bbox_dn_1: 0.1693 (0.1722)  loss_giou_dn_1: 0.5474 (0.5509)  loss_vfl_dn_2: 0.4236 (0.4247)  loss_bbox_dn_2: 0.1636 (0.1646)  loss_giou_dn_2: 0.5345 (0.5357)  loss_vfl_dn_3: 0.4148 (0.4165)  loss_bbox_dn_3: 0.1608 (0.1619)  loss_giou_dn_3: 0.5293 (0.5315)  loss_vfl_dn_4: 0.4168 (0.4184)  loss_bbox_dn_4: 0.1597 (0.1616)  loss_giou_dn_4: 0.5264 (0.5282)  loss_vfl_dn_5: 0.4176 (0.4188)  loss_bbox_dn_5: 0.1602 (0.1613)  loss_giou_dn_5: 0.5233 (0.5269)  loss_vfl_enc_0: 0.9369 (0.9495)  loss_bbox_enc_0: 0.2614 (0.2647)  loss_giou_enc_0: 0.7076 (0.7215)  time: 0.8534  data: 0.3341  max mem: 16811\n",
            "Epoch: [75] Total time: 0:00:06 (0.8609 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.1922 (18.3162)  loss_vfl: 0.5011 (0.5109)  loss_bbox: 0.2362 (0.2364)  loss_giou: 0.6431 (0.6742)  loss_vfl_aux_0: 1.0661 (1.0686)  loss_bbox_aux_0: 0.2370 (0.2372)  loss_giou_aux_0: 0.6310 (0.6475)  loss_vfl_aux_1: 0.7174 (0.7261)  loss_bbox_aux_1: 0.2492 (0.2554)  loss_giou_aux_1: 0.6654 (0.6917)  loss_vfl_aux_2: 0.5575 (0.5599)  loss_bbox_aux_2: 0.2569 (0.2534)  loss_giou_aux_2: 0.6778 (0.6953)  loss_vfl_aux_3: 0.5038 (0.5081)  loss_bbox_aux_3: 0.2466 (0.2426)  loss_giou_aux_3: 0.6682 (0.6883)  loss_vfl_aux_4: 0.5122 (0.5150)  loss_bbox_aux_4: 0.2375 (0.2365)  loss_giou_aux_4: 0.6490 (0.6770)  loss_vfl_dn_0: 0.5189 (0.5191)  loss_bbox_dn_0: 0.1966 (0.1992)  loss_giou_dn_0: 0.6053 (0.6090)  loss_vfl_dn_1: 0.4566 (0.4559)  loss_bbox_dn_1: 0.1693 (0.1722)  loss_giou_dn_1: 0.5474 (0.5509)  loss_vfl_dn_2: 0.4236 (0.4247)  loss_bbox_dn_2: 0.1636 (0.1646)  loss_giou_dn_2: 0.5345 (0.5357)  loss_vfl_dn_3: 0.4148 (0.4165)  loss_bbox_dn_3: 0.1608 (0.1619)  loss_giou_dn_3: 0.5293 (0.5315)  loss_vfl_dn_4: 0.4168 (0.4184)  loss_bbox_dn_4: 0.1597 (0.1616)  loss_giou_dn_4: 0.5264 (0.5282)  loss_vfl_dn_5: 0.4176 (0.4188)  loss_bbox_dn_5: 0.1602 (0.1613)  loss_giou_dn_5: 0.5233 (0.5269)  loss_vfl_enc_0: 0.9369 (0.9495)  loss_bbox_enc_0: 0.2614 (0.2647)  loss_giou_enc_0: 0.7076 (0.7215)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.3900  data: 4.3334  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9204  data: 2.1831  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9394 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n",
            "best_stat: {'epoch': 75, 'coco_eval_bbox': 0.3060839889486624}\n",
            "Epoch: [76]  [0/8]  eta: 0:00:23  lr: 0.000003  loss: 18.7899 (18.7899)  loss_vfl: 0.5592 (0.5592)  loss_bbox: 0.2580 (0.2580)  loss_giou: 0.6685 (0.6685)  loss_vfl_aux_0: 1.1364 (1.1364)  loss_bbox_aux_0: 0.2394 (0.2394)  loss_giou_aux_0: 0.6315 (0.6315)  loss_vfl_aux_1: 0.7194 (0.7194)  loss_bbox_aux_1: 0.2654 (0.2654)  loss_giou_aux_1: 0.6986 (0.6986)  loss_vfl_aux_2: 0.6036 (0.6036)  loss_bbox_aux_2: 0.2659 (0.2659)  loss_giou_aux_2: 0.6988 (0.6988)  loss_vfl_aux_3: 0.5581 (0.5581)  loss_bbox_aux_3: 0.2630 (0.2630)  loss_giou_aux_3: 0.6751 (0.6751)  loss_vfl_aux_4: 0.5603 (0.5603)  loss_bbox_aux_4: 0.2594 (0.2594)  loss_giou_aux_4: 0.6730 (0.6730)  loss_vfl_dn_0: 0.5167 (0.5167)  loss_bbox_dn_0: 0.2117 (0.2117)  loss_giou_dn_0: 0.6302 (0.6302)  loss_vfl_dn_1: 0.4548 (0.4548)  loss_bbox_dn_1: 0.1828 (0.1828)  loss_giou_dn_1: 0.5704 (0.5704)  loss_vfl_dn_2: 0.4273 (0.4273)  loss_bbox_dn_2: 0.1699 (0.1699)  loss_giou_dn_2: 0.5448 (0.5448)  loss_vfl_dn_3: 0.4195 (0.4195)  loss_bbox_dn_3: 0.1654 (0.1654)  loss_giou_dn_3: 0.5403 (0.5403)  loss_vfl_dn_4: 0.4235 (0.4235)  loss_bbox_dn_4: 0.1639 (0.1639)  loss_giou_dn_4: 0.5338 (0.5338)  loss_vfl_dn_5: 0.4246 (0.4246)  loss_bbox_dn_5: 0.1634 (0.1634)  loss_giou_dn_5: 0.5316 (0.5316)  loss_vfl_enc_0: 1.0020 (1.0020)  loss_bbox_enc_0: 0.2726 (0.2726)  loss_giou_enc_0: 0.7074 (0.7074)  time: 2.8809  data: 2.3251  max mem: 16811\n",
            "Epoch: [76]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 18.0896 (18.1767)  loss_vfl: 0.5016 (0.5080)  loss_bbox: 0.2231 (0.2332)  loss_giou: 0.6593 (0.6673)  loss_vfl_aux_0: 1.0333 (1.0567)  loss_bbox_aux_0: 0.2394 (0.2367)  loss_giou_aux_0: 0.6315 (0.6458)  loss_vfl_aux_1: 0.6955 (0.7014)  loss_bbox_aux_1: 0.2416 (0.2484)  loss_giou_aux_1: 0.6778 (0.6864)  loss_vfl_aux_2: 0.5602 (0.5673)  loss_bbox_aux_2: 0.2443 (0.2499)  loss_giou_aux_2: 0.6826 (0.6899)  loss_vfl_aux_3: 0.5076 (0.5116)  loss_bbox_aux_3: 0.2331 (0.2373)  loss_giou_aux_3: 0.6715 (0.6769)  loss_vfl_aux_4: 0.5098 (0.5122)  loss_bbox_aux_4: 0.2276 (0.2353)  loss_giou_aux_4: 0.6694 (0.6721)  loss_vfl_dn_0: 0.5156 (0.5170)  loss_bbox_dn_0: 0.1896 (0.1959)  loss_giou_dn_0: 0.6047 (0.6097)  loss_vfl_dn_1: 0.4462 (0.4495)  loss_bbox_dn_1: 0.1624 (0.1711)  loss_giou_dn_1: 0.5454 (0.5519)  loss_vfl_dn_2: 0.4204 (0.4218)  loss_bbox_dn_2: 0.1537 (0.1619)  loss_giou_dn_2: 0.5300 (0.5321)  loss_vfl_dn_3: 0.4117 (0.4135)  loss_bbox_dn_3: 0.1530 (0.1596)  loss_giou_dn_3: 0.5283 (0.5290)  loss_vfl_dn_4: 0.4116 (0.4150)  loss_bbox_dn_4: 0.1531 (0.1590)  loss_giou_dn_4: 0.5251 (0.5263)  loss_vfl_dn_5: 0.4120 (0.4143)  loss_bbox_dn_5: 0.1527 (0.1587)  loss_giou_dn_5: 0.5238 (0.5249)  loss_vfl_enc_0: 0.9389 (0.9458)  loss_bbox_enc_0: 0.2638 (0.2633)  loss_giou_enc_0: 0.6930 (0.7199)  time: 0.8378  data: 0.3264  max mem: 16811\n",
            "Epoch: [76] Total time: 0:00:06 (0.8430 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 18.0896 (18.1767)  loss_vfl: 0.5016 (0.5080)  loss_bbox: 0.2231 (0.2332)  loss_giou: 0.6593 (0.6673)  loss_vfl_aux_0: 1.0333 (1.0567)  loss_bbox_aux_0: 0.2394 (0.2367)  loss_giou_aux_0: 0.6315 (0.6458)  loss_vfl_aux_1: 0.6955 (0.7014)  loss_bbox_aux_1: 0.2416 (0.2484)  loss_giou_aux_1: 0.6778 (0.6864)  loss_vfl_aux_2: 0.5602 (0.5673)  loss_bbox_aux_2: 0.2443 (0.2499)  loss_giou_aux_2: 0.6826 (0.6899)  loss_vfl_aux_3: 0.5076 (0.5116)  loss_bbox_aux_3: 0.2331 (0.2373)  loss_giou_aux_3: 0.6715 (0.6769)  loss_vfl_aux_4: 0.5098 (0.5122)  loss_bbox_aux_4: 0.2276 (0.2353)  loss_giou_aux_4: 0.6694 (0.6721)  loss_vfl_dn_0: 0.5156 (0.5170)  loss_bbox_dn_0: 0.1896 (0.1959)  loss_giou_dn_0: 0.6047 (0.6097)  loss_vfl_dn_1: 0.4462 (0.4495)  loss_bbox_dn_1: 0.1624 (0.1711)  loss_giou_dn_1: 0.5454 (0.5519)  loss_vfl_dn_2: 0.4204 (0.4218)  loss_bbox_dn_2: 0.1537 (0.1619)  loss_giou_dn_2: 0.5300 (0.5321)  loss_vfl_dn_3: 0.4117 (0.4135)  loss_bbox_dn_3: 0.1530 (0.1596)  loss_giou_dn_3: 0.5283 (0.5290)  loss_vfl_dn_4: 0.4116 (0.4150)  loss_bbox_dn_4: 0.1531 (0.1590)  loss_giou_dn_4: 0.5251 (0.5263)  loss_vfl_dn_5: 0.4120 (0.4143)  loss_bbox_dn_5: 0.1527 (0.1587)  loss_giou_dn_5: 0.5238 (0.5249)  loss_vfl_enc_0: 0.9389 (0.9458)  loss_bbox_enc_0: 0.2638 (0.2633)  loss_giou_enc_0: 0.6930 (0.7199)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.2627  data: 2.8690  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3558  data: 1.4519  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3853 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.618\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            "best_stat: {'epoch': 76, 'coco_eval_bbox': 0.30645348558187824}\n",
            "Epoch: [77]  [0/8]  eta: 0:00:26  lr: 0.000003  loss: 19.2196 (19.2196)  loss_vfl: 0.5355 (0.5355)  loss_bbox: 0.2600 (0.2600)  loss_giou: 0.7323 (0.7323)  loss_vfl_aux_0: 1.0264 (1.0264)  loss_bbox_aux_0: 0.2784 (0.2784)  loss_giou_aux_0: 0.7389 (0.7389)  loss_vfl_aux_1: 0.7304 (0.7304)  loss_bbox_aux_1: 0.2646 (0.2646)  loss_giou_aux_1: 0.7395 (0.7395)  loss_vfl_aux_2: 0.6124 (0.6124)  loss_bbox_aux_2: 0.2782 (0.2782)  loss_giou_aux_2: 0.7458 (0.7458)  loss_vfl_aux_3: 0.5461 (0.5461)  loss_bbox_aux_3: 0.2576 (0.2576)  loss_giou_aux_3: 0.7244 (0.7244)  loss_vfl_aux_4: 0.5406 (0.5406)  loss_bbox_aux_4: 0.2583 (0.2583)  loss_giou_aux_4: 0.7347 (0.7347)  loss_vfl_dn_0: 0.5173 (0.5173)  loss_bbox_dn_0: 0.1938 (0.1938)  loss_giou_dn_0: 0.6423 (0.6423)  loss_vfl_dn_1: 0.4594 (0.4594)  loss_bbox_dn_1: 0.1675 (0.1675)  loss_giou_dn_1: 0.5863 (0.5863)  loss_vfl_dn_2: 0.4279 (0.4279)  loss_bbox_dn_2: 0.1614 (0.1614)  loss_giou_dn_2: 0.5741 (0.5741)  loss_vfl_dn_3: 0.4207 (0.4207)  loss_bbox_dn_3: 0.1589 (0.1589)  loss_giou_dn_3: 0.5700 (0.5700)  loss_vfl_dn_4: 0.4232 (0.4232)  loss_bbox_dn_4: 0.1585 (0.1585)  loss_giou_dn_4: 0.5671 (0.5671)  loss_vfl_dn_5: 0.4221 (0.4221)  loss_bbox_dn_5: 0.1582 (0.1582)  loss_giou_dn_5: 0.5653 (0.5653)  loss_vfl_enc_0: 0.9355 (0.9355)  loss_bbox_enc_0: 0.3016 (0.3016)  loss_giou_enc_0: 0.8044 (0.8044)  time: 3.3301  data: 2.7743  max mem: 16811\n",
            "Epoch: [77]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.9545 (18.1377)  loss_vfl: 0.5071 (0.5113)  loss_bbox: 0.2225 (0.2300)  loss_giou: 0.6251 (0.6608)  loss_vfl_aux_0: 1.0264 (1.0544)  loss_bbox_aux_0: 0.2194 (0.2343)  loss_giou_aux_0: 0.5987 (0.6412)  loss_vfl_aux_1: 0.7304 (0.7148)  loss_bbox_aux_1: 0.2457 (0.2490)  loss_giou_aux_1: 0.6457 (0.6792)  loss_vfl_aux_2: 0.5769 (0.5633)  loss_bbox_aux_2: 0.2331 (0.2450)  loss_giou_aux_2: 0.6451 (0.6778)  loss_vfl_aux_3: 0.5233 (0.5166)  loss_bbox_aux_3: 0.2272 (0.2323)  loss_giou_aux_3: 0.6434 (0.6708)  loss_vfl_aux_4: 0.5225 (0.5193)  loss_bbox_aux_4: 0.2255 (0.2302)  loss_giou_aux_4: 0.6277 (0.6629)  loss_vfl_dn_0: 0.5167 (0.5160)  loss_bbox_dn_0: 0.1954 (0.1988)  loss_giou_dn_0: 0.6003 (0.6049)  loss_vfl_dn_1: 0.4475 (0.4471)  loss_bbox_dn_1: 0.1728 (0.1748)  loss_giou_dn_1: 0.5352 (0.5477)  loss_vfl_dn_2: 0.4202 (0.4187)  loss_bbox_dn_2: 0.1655 (0.1666)  loss_giou_dn_2: 0.5193 (0.5310)  loss_vfl_dn_3: 0.4135 (0.4127)  loss_bbox_dn_3: 0.1631 (0.1638)  loss_giou_dn_3: 0.5150 (0.5270)  loss_vfl_dn_4: 0.4141 (0.4151)  loss_bbox_dn_4: 0.1637 (0.1637)  loss_giou_dn_4: 0.5140 (0.5246)  loss_vfl_dn_5: 0.4120 (0.4139)  loss_bbox_dn_5: 0.1637 (0.1635)  loss_giou_dn_5: 0.5125 (0.5235)  loss_vfl_enc_0: 0.9355 (0.9562)  loss_bbox_enc_0: 0.2537 (0.2616)  loss_giou_enc_0: 0.6794 (0.7134)  time: 0.8884  data: 0.3771  max mem: 16811\n",
            "Epoch: [77] Total time: 0:00:07 (0.8955 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.9545 (18.1377)  loss_vfl: 0.5071 (0.5113)  loss_bbox: 0.2225 (0.2300)  loss_giou: 0.6251 (0.6608)  loss_vfl_aux_0: 1.0264 (1.0544)  loss_bbox_aux_0: 0.2194 (0.2343)  loss_giou_aux_0: 0.5987 (0.6412)  loss_vfl_aux_1: 0.7304 (0.7148)  loss_bbox_aux_1: 0.2457 (0.2490)  loss_giou_aux_1: 0.6457 (0.6792)  loss_vfl_aux_2: 0.5769 (0.5633)  loss_bbox_aux_2: 0.2331 (0.2450)  loss_giou_aux_2: 0.6451 (0.6778)  loss_vfl_aux_3: 0.5233 (0.5166)  loss_bbox_aux_3: 0.2272 (0.2323)  loss_giou_aux_3: 0.6434 (0.6708)  loss_vfl_aux_4: 0.5225 (0.5193)  loss_bbox_aux_4: 0.2255 (0.2302)  loss_giou_aux_4: 0.6277 (0.6629)  loss_vfl_dn_0: 0.5167 (0.5160)  loss_bbox_dn_0: 0.1954 (0.1988)  loss_giou_dn_0: 0.6003 (0.6049)  loss_vfl_dn_1: 0.4475 (0.4471)  loss_bbox_dn_1: 0.1728 (0.1748)  loss_giou_dn_1: 0.5352 (0.5477)  loss_vfl_dn_2: 0.4202 (0.4187)  loss_bbox_dn_2: 0.1655 (0.1666)  loss_giou_dn_2: 0.5193 (0.5310)  loss_vfl_dn_3: 0.4135 (0.4127)  loss_bbox_dn_3: 0.1631 (0.1638)  loss_giou_dn_3: 0.5150 (0.5270)  loss_vfl_dn_4: 0.4141 (0.4151)  loss_bbox_dn_4: 0.1637 (0.1637)  loss_giou_dn_4: 0.5140 (0.5246)  loss_vfl_dn_5: 0.4120 (0.4139)  loss_bbox_dn_5: 0.1637 (0.1635)  loss_giou_dn_5: 0.5125 (0.5235)  loss_vfl_enc_0: 0.9355 (0.9562)  loss_bbox_enc_0: 0.2537 (0.2616)  loss_giou_enc_0: 0.6794 (0.7134)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3691  data: 1.3091  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4099  data: 0.6708  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4554 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
            "best_stat: {'epoch': 76, 'coco_eval_bbox': 0.30645348558187824}\n",
            "Epoch: [78]  [0/8]  eta: 0:00:23  lr: 0.000003  loss: 17.7677 (17.7677)  loss_vfl: 0.5378 (0.5378)  loss_bbox: 0.2061 (0.2061)  loss_giou: 0.6021 (0.6021)  loss_vfl_aux_0: 1.0592 (1.0592)  loss_bbox_aux_0: 0.2257 (0.2257)  loss_giou_aux_0: 0.5995 (0.5995)  loss_vfl_aux_1: 0.7364 (0.7364)  loss_bbox_aux_1: 0.2279 (0.2279)  loss_giou_aux_1: 0.6269 (0.6269)  loss_vfl_aux_2: 0.5876 (0.5876)  loss_bbox_aux_2: 0.2300 (0.2300)  loss_giou_aux_2: 0.6232 (0.6232)  loss_vfl_aux_3: 0.5489 (0.5489)  loss_bbox_aux_3: 0.2076 (0.2076)  loss_giou_aux_3: 0.6129 (0.6129)  loss_vfl_aux_4: 0.5472 (0.5472)  loss_bbox_aux_4: 0.2051 (0.2051)  loss_giou_aux_4: 0.6055 (0.6055)  loss_vfl_dn_0: 0.5219 (0.5219)  loss_bbox_dn_0: 0.1964 (0.1964)  loss_giou_dn_0: 0.6030 (0.6030)  loss_vfl_dn_1: 0.4517 (0.4517)  loss_bbox_dn_1: 0.1709 (0.1709)  loss_giou_dn_1: 0.5422 (0.5422)  loss_vfl_dn_2: 0.4251 (0.4251)  loss_bbox_dn_2: 0.1608 (0.1608)  loss_giou_dn_2: 0.5192 (0.5192)  loss_vfl_dn_3: 0.4172 (0.4172)  loss_bbox_dn_3: 0.1580 (0.1580)  loss_giou_dn_3: 0.5142 (0.5142)  loss_vfl_dn_4: 0.4199 (0.4199)  loss_bbox_dn_4: 0.1569 (0.1569)  loss_giou_dn_4: 0.5120 (0.5120)  loss_vfl_dn_5: 0.4165 (0.4165)  loss_bbox_dn_5: 0.1564 (0.1564)  loss_giou_dn_5: 0.5088 (0.5088)  loss_vfl_enc_0: 0.9738 (0.9738)  loss_bbox_enc_0: 0.2657 (0.2657)  loss_giou_enc_0: 0.6870 (0.6870)  time: 2.9365  data: 2.3718  max mem: 16811\n",
            "Epoch: [78]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.7677 (17.9507)  loss_vfl: 0.5001 (0.5022)  loss_bbox: 0.2111 (0.2244)  loss_giou: 0.6342 (0.6564)  loss_vfl_aux_0: 1.0061 (1.0367)  loss_bbox_aux_0: 0.2257 (0.2331)  loss_giou_aux_0: 0.6309 (0.6449)  loss_vfl_aux_1: 0.6840 (0.6942)  loss_bbox_aux_1: 0.2279 (0.2406)  loss_giou_aux_1: 0.6869 (0.6833)  loss_vfl_aux_2: 0.5283 (0.5411)  loss_bbox_aux_2: 0.2347 (0.2419)  loss_giou_aux_2: 0.6816 (0.6834)  loss_vfl_aux_3: 0.5053 (0.5137)  loss_bbox_aux_3: 0.2087 (0.2269)  loss_giou_aux_3: 0.6494 (0.6671)  loss_vfl_aux_4: 0.5124 (0.5115)  loss_bbox_aux_4: 0.2082 (0.2252)  loss_giou_aux_4: 0.6346 (0.6586)  loss_vfl_dn_0: 0.5150 (0.5146)  loss_bbox_dn_0: 0.1964 (0.1899)  loss_giou_dn_0: 0.6030 (0.6034)  loss_vfl_dn_1: 0.4446 (0.4442)  loss_bbox_dn_1: 0.1709 (0.1673)  loss_giou_dn_1: 0.5422 (0.5478)  loss_vfl_dn_2: 0.4224 (0.4179)  loss_bbox_dn_2: 0.1608 (0.1585)  loss_giou_dn_2: 0.5192 (0.5277)  loss_vfl_dn_3: 0.4172 (0.4123)  loss_bbox_dn_3: 0.1580 (0.1565)  loss_giou_dn_3: 0.5142 (0.5245)  loss_vfl_dn_4: 0.4199 (0.4136)  loss_bbox_dn_4: 0.1569 (0.1558)  loss_giou_dn_4: 0.5120 (0.5217)  loss_vfl_dn_5: 0.4165 (0.4125)  loss_bbox_dn_5: 0.1564 (0.1554)  loss_giou_dn_5: 0.5088 (0.5196)  loss_vfl_enc_0: 0.9456 (0.9536)  loss_bbox_enc_0: 0.2519 (0.2552)  loss_giou_enc_0: 0.7131 (0.7134)  time: 0.8367  data: 0.3209  max mem: 16811\n",
            "Epoch: [78] Total time: 0:00:06 (0.8436 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.7677 (17.9507)  loss_vfl: 0.5001 (0.5022)  loss_bbox: 0.2111 (0.2244)  loss_giou: 0.6342 (0.6564)  loss_vfl_aux_0: 1.0061 (1.0367)  loss_bbox_aux_0: 0.2257 (0.2331)  loss_giou_aux_0: 0.6309 (0.6449)  loss_vfl_aux_1: 0.6840 (0.6942)  loss_bbox_aux_1: 0.2279 (0.2406)  loss_giou_aux_1: 0.6869 (0.6833)  loss_vfl_aux_2: 0.5283 (0.5411)  loss_bbox_aux_2: 0.2347 (0.2419)  loss_giou_aux_2: 0.6816 (0.6834)  loss_vfl_aux_3: 0.5053 (0.5137)  loss_bbox_aux_3: 0.2087 (0.2269)  loss_giou_aux_3: 0.6494 (0.6671)  loss_vfl_aux_4: 0.5124 (0.5115)  loss_bbox_aux_4: 0.2082 (0.2252)  loss_giou_aux_4: 0.6346 (0.6586)  loss_vfl_dn_0: 0.5150 (0.5146)  loss_bbox_dn_0: 0.1964 (0.1899)  loss_giou_dn_0: 0.6030 (0.6034)  loss_vfl_dn_1: 0.4446 (0.4442)  loss_bbox_dn_1: 0.1709 (0.1673)  loss_giou_dn_1: 0.5422 (0.5478)  loss_vfl_dn_2: 0.4224 (0.4179)  loss_bbox_dn_2: 0.1608 (0.1585)  loss_giou_dn_2: 0.5192 (0.5277)  loss_vfl_dn_3: 0.4172 (0.4123)  loss_bbox_dn_3: 0.1580 (0.1565)  loss_giou_dn_3: 0.5142 (0.5245)  loss_vfl_dn_4: 0.4199 (0.4136)  loss_bbox_dn_4: 0.1569 (0.1558)  loss_giou_dn_4: 0.5120 (0.5217)  loss_vfl_dn_5: 0.4165 (0.4125)  loss_bbox_dn_5: 0.1564 (0.1554)  loss_giou_dn_5: 0.5088 (0.5196)  loss_vfl_enc_0: 0.9456 (0.9536)  loss_bbox_enc_0: 0.2519 (0.2552)  loss_giou_enc_0: 0.7131 (0.7134)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.7940  data: 4.4092  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1213  data: 2.2212  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1590 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
            "best_stat: {'epoch': 78, 'coco_eval_bbox': 0.30807886749152774}\n",
            "Epoch: [79]  [0/8]  eta: 0:00:24  lr: 0.000003  loss: 17.4865 (17.4865)  loss_vfl: 0.4963 (0.4963)  loss_bbox: 0.1998 (0.1998)  loss_giou: 0.6374 (0.6374)  loss_vfl_aux_0: 1.0427 (1.0427)  loss_bbox_aux_0: 0.2363 (0.2363)  loss_giou_aux_0: 0.6419 (0.6419)  loss_vfl_aux_1: 0.6952 (0.6952)  loss_bbox_aux_1: 0.2400 (0.2400)  loss_giou_aux_1: 0.6717 (0.6717)  loss_vfl_aux_2: 0.5268 (0.5268)  loss_bbox_aux_2: 0.2336 (0.2336)  loss_giou_aux_2: 0.6725 (0.6725)  loss_vfl_aux_3: 0.5099 (0.5099)  loss_bbox_aux_3: 0.2123 (0.2123)  loss_giou_aux_3: 0.6530 (0.6530)  loss_vfl_aux_4: 0.4983 (0.4983)  loss_bbox_aux_4: 0.2063 (0.2063)  loss_giou_aux_4: 0.6399 (0.6399)  loss_vfl_dn_0: 0.5133 (0.5133)  loss_bbox_dn_0: 0.1733 (0.1733)  loss_giou_dn_0: 0.5764 (0.5764)  loss_vfl_dn_1: 0.4376 (0.4376)  loss_bbox_dn_1: 0.1502 (0.1502)  loss_giou_dn_1: 0.5200 (0.5200)  loss_vfl_dn_2: 0.4104 (0.4104)  loss_bbox_dn_2: 0.1419 (0.1419)  loss_giou_dn_2: 0.5007 (0.5007)  loss_vfl_dn_3: 0.4054 (0.4054)  loss_bbox_dn_3: 0.1396 (0.1396)  loss_giou_dn_3: 0.4965 (0.4965)  loss_vfl_dn_4: 0.4048 (0.4048)  loss_bbox_dn_4: 0.1389 (0.1389)  loss_giou_dn_4: 0.4943 (0.4943)  loss_vfl_dn_5: 0.4023 (0.4023)  loss_bbox_dn_5: 0.1385 (0.1385)  loss_giou_dn_5: 0.4927 (0.4927)  loss_vfl_enc_0: 0.9362 (0.9362)  loss_bbox_enc_0: 0.2608 (0.2608)  loss_giou_enc_0: 0.7388 (0.7388)  time: 3.0046  data: 2.4517  max mem: 16811\n",
            "Epoch: [79]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.6093 (18.0005)  loss_vfl: 0.5013 (0.5051)  loss_bbox: 0.2206 (0.2296)  loss_giou: 0.6374 (0.6550)  loss_vfl_aux_0: 1.0294 (1.0480)  loss_bbox_aux_0: 0.2363 (0.2350)  loss_giou_aux_0: 0.6419 (0.6407)  loss_vfl_aux_1: 0.6977 (0.7253)  loss_bbox_aux_1: 0.2452 (0.2543)  loss_giou_aux_1: 0.6717 (0.6849)  loss_vfl_aux_2: 0.5283 (0.5390)  loss_bbox_aux_2: 0.2439 (0.2498)  loss_giou_aux_2: 0.6725 (0.6837)  loss_vfl_aux_3: 0.5113 (0.5170)  loss_bbox_aux_3: 0.2267 (0.2371)  loss_giou_aux_3: 0.6530 (0.6733)  loss_vfl_aux_4: 0.5112 (0.5086)  loss_bbox_aux_4: 0.2177 (0.2323)  loss_giou_aux_4: 0.6399 (0.6573)  loss_vfl_dn_0: 0.5133 (0.5154)  loss_bbox_dn_0: 0.1867 (0.1923)  loss_giou_dn_0: 0.5822 (0.5969)  loss_vfl_dn_1: 0.4434 (0.4488)  loss_bbox_dn_1: 0.1643 (0.1685)  loss_giou_dn_1: 0.5309 (0.5403)  loss_vfl_dn_2: 0.4144 (0.4177)  loss_bbox_dn_2: 0.1547 (0.1596)  loss_giou_dn_2: 0.5111 (0.5206)  loss_vfl_dn_3: 0.4064 (0.4117)  loss_bbox_dn_3: 0.1515 (0.1573)  loss_giou_dn_3: 0.5067 (0.5166)  loss_vfl_dn_4: 0.4078 (0.4125)  loss_bbox_dn_4: 0.1499 (0.1570)  loss_giou_dn_4: 0.5045 (0.5148)  loss_vfl_dn_5: 0.4085 (0.4126)  loss_bbox_dn_5: 0.1505 (0.1569)  loss_giou_dn_5: 0.5023 (0.5142)  loss_vfl_enc_0: 0.9362 (0.9438)  loss_bbox_enc_0: 0.2608 (0.2560)  loss_giou_enc_0: 0.7369 (0.7107)  time: 0.8497  data: 0.3362  max mem: 16811\n",
            "Epoch: [79] Total time: 0:00:06 (0.8591 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.6093 (18.0005)  loss_vfl: 0.5013 (0.5051)  loss_bbox: 0.2206 (0.2296)  loss_giou: 0.6374 (0.6550)  loss_vfl_aux_0: 1.0294 (1.0480)  loss_bbox_aux_0: 0.2363 (0.2350)  loss_giou_aux_0: 0.6419 (0.6407)  loss_vfl_aux_1: 0.6977 (0.7253)  loss_bbox_aux_1: 0.2452 (0.2543)  loss_giou_aux_1: 0.6717 (0.6849)  loss_vfl_aux_2: 0.5283 (0.5390)  loss_bbox_aux_2: 0.2439 (0.2498)  loss_giou_aux_2: 0.6725 (0.6837)  loss_vfl_aux_3: 0.5113 (0.5170)  loss_bbox_aux_3: 0.2267 (0.2371)  loss_giou_aux_3: 0.6530 (0.6733)  loss_vfl_aux_4: 0.5112 (0.5086)  loss_bbox_aux_4: 0.2177 (0.2323)  loss_giou_aux_4: 0.6399 (0.6573)  loss_vfl_dn_0: 0.5133 (0.5154)  loss_bbox_dn_0: 0.1867 (0.1923)  loss_giou_dn_0: 0.5822 (0.5969)  loss_vfl_dn_1: 0.4434 (0.4488)  loss_bbox_dn_1: 0.1643 (0.1685)  loss_giou_dn_1: 0.5309 (0.5403)  loss_vfl_dn_2: 0.4144 (0.4177)  loss_bbox_dn_2: 0.1547 (0.1596)  loss_giou_dn_2: 0.5111 (0.5206)  loss_vfl_dn_3: 0.4064 (0.4117)  loss_bbox_dn_3: 0.1515 (0.1573)  loss_giou_dn_3: 0.5067 (0.5166)  loss_vfl_dn_4: 0.4078 (0.4125)  loss_bbox_dn_4: 0.1499 (0.1570)  loss_giou_dn_4: 0.5045 (0.5148)  loss_vfl_dn_5: 0.4085 (0.4126)  loss_bbox_dn_5: 0.1505 (0.1569)  loss_giou_dn_5: 0.5023 (0.5142)  loss_vfl_enc_0: 0.9362 (0.9438)  loss_bbox_enc_0: 0.2608 (0.2560)  loss_giou_enc_0: 0.7369 (0.7107)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5188  data: 4.4395  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9875  data: 2.2363  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0143 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "best_stat: {'epoch': 79, 'coco_eval_bbox': 0.3092725821576738}\n",
            "Epoch: [80]  [0/8]  eta: 0:00:19  lr: 0.000003  loss: 19.0032 (19.0032)  loss_vfl: 0.5220 (0.5220)  loss_bbox: 0.2540 (0.2540)  loss_giou: 0.7179 (0.7179)  loss_vfl_aux_0: 1.0252 (1.0252)  loss_bbox_aux_0: 0.2924 (0.2924)  loss_giou_aux_0: 0.7335 (0.7335)  loss_vfl_aux_1: 0.7412 (0.7412)  loss_bbox_aux_1: 0.2820 (0.2820)  loss_giou_aux_1: 0.7618 (0.7618)  loss_vfl_aux_2: 0.5656 (0.5656)  loss_bbox_aux_2: 0.2822 (0.2822)  loss_giou_aux_2: 0.7536 (0.7536)  loss_vfl_aux_3: 0.5437 (0.5437)  loss_bbox_aux_3: 0.2612 (0.2612)  loss_giou_aux_3: 0.7376 (0.7376)  loss_vfl_aux_4: 0.5224 (0.5224)  loss_bbox_aux_4: 0.2545 (0.2545)  loss_giou_aux_4: 0.7201 (0.7201)  loss_vfl_dn_0: 0.5126 (0.5126)  loss_bbox_dn_0: 0.1933 (0.1933)  loss_giou_dn_0: 0.6232 (0.6232)  loss_vfl_dn_1: 0.4493 (0.4493)  loss_bbox_dn_1: 0.1676 (0.1676)  loss_giou_dn_1: 0.5629 (0.5629)  loss_vfl_dn_2: 0.4275 (0.4275)  loss_bbox_dn_2: 0.1571 (0.1571)  loss_giou_dn_2: 0.5423 (0.5423)  loss_vfl_dn_3: 0.4188 (0.4188)  loss_bbox_dn_3: 0.1552 (0.1552)  loss_giou_dn_3: 0.5378 (0.5378)  loss_vfl_dn_4: 0.4186 (0.4186)  loss_bbox_dn_4: 0.1553 (0.1553)  loss_giou_dn_4: 0.5368 (0.5368)  loss_vfl_dn_5: 0.4188 (0.4188)  loss_bbox_dn_5: 0.1554 (0.1554)  loss_giou_dn_5: 0.5375 (0.5375)  loss_vfl_enc_0: 0.9439 (0.9439)  loss_bbox_enc_0: 0.3048 (0.3048)  loss_giou_enc_0: 0.8136 (0.8136)  time: 2.4242  data: 1.8755  max mem: 16811\n",
            "Epoch: [80]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.4668 (17.8169)  loss_vfl: 0.4943 (0.4962)  loss_bbox: 0.2242 (0.2231)  loss_giou: 0.6367 (0.6499)  loss_vfl_aux_0: 1.0252 (1.0359)  loss_bbox_aux_0: 0.2299 (0.2367)  loss_giou_aux_0: 0.6369 (0.6412)  loss_vfl_aux_1: 0.7148 (0.7221)  loss_bbox_aux_1: 0.2526 (0.2456)  loss_giou_aux_1: 0.6697 (0.6789)  loss_vfl_aux_2: 0.5369 (0.5367)  loss_bbox_aux_2: 0.2413 (0.2416)  loss_giou_aux_2: 0.6681 (0.6754)  loss_vfl_aux_3: 0.5116 (0.5084)  loss_bbox_aux_3: 0.2343 (0.2313)  loss_giou_aux_3: 0.6527 (0.6636)  loss_vfl_aux_4: 0.4966 (0.4974)  loss_bbox_aux_4: 0.2246 (0.2246)  loss_giou_aux_4: 0.6389 (0.6546)  loss_vfl_dn_0: 0.5151 (0.5154)  loss_bbox_dn_0: 0.1910 (0.1888)  loss_giou_dn_0: 0.5799 (0.5929)  loss_vfl_dn_1: 0.4457 (0.4464)  loss_bbox_dn_1: 0.1649 (0.1638)  loss_giou_dn_1: 0.5253 (0.5330)  loss_vfl_dn_2: 0.4217 (0.4201)  loss_bbox_dn_2: 0.1546 (0.1544)  loss_giou_dn_2: 0.4984 (0.5122)  loss_vfl_dn_3: 0.4130 (0.4127)  loss_bbox_dn_3: 0.1515 (0.1520)  loss_giou_dn_3: 0.4914 (0.5072)  loss_vfl_dn_4: 0.4139 (0.4138)  loss_bbox_dn_4: 0.1516 (0.1514)  loss_giou_dn_4: 0.4881 (0.5053)  loss_vfl_dn_5: 0.4109 (0.4128)  loss_bbox_dn_5: 0.1509 (0.1511)  loss_giou_dn_5: 0.4859 (0.5038)  loss_vfl_enc_0: 0.9439 (0.9487)  loss_bbox_enc_0: 0.2492 (0.2588)  loss_giou_enc_0: 0.7050 (0.7092)  time: 0.7732  data: 0.2634  max mem: 16811\n",
            "Epoch: [80] Total time: 0:00:06 (0.7798 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.4668 (17.8169)  loss_vfl: 0.4943 (0.4962)  loss_bbox: 0.2242 (0.2231)  loss_giou: 0.6367 (0.6499)  loss_vfl_aux_0: 1.0252 (1.0359)  loss_bbox_aux_0: 0.2299 (0.2367)  loss_giou_aux_0: 0.6369 (0.6412)  loss_vfl_aux_1: 0.7148 (0.7221)  loss_bbox_aux_1: 0.2526 (0.2456)  loss_giou_aux_1: 0.6697 (0.6789)  loss_vfl_aux_2: 0.5369 (0.5367)  loss_bbox_aux_2: 0.2413 (0.2416)  loss_giou_aux_2: 0.6681 (0.6754)  loss_vfl_aux_3: 0.5116 (0.5084)  loss_bbox_aux_3: 0.2343 (0.2313)  loss_giou_aux_3: 0.6527 (0.6636)  loss_vfl_aux_4: 0.4966 (0.4974)  loss_bbox_aux_4: 0.2246 (0.2246)  loss_giou_aux_4: 0.6389 (0.6546)  loss_vfl_dn_0: 0.5151 (0.5154)  loss_bbox_dn_0: 0.1910 (0.1888)  loss_giou_dn_0: 0.5799 (0.5929)  loss_vfl_dn_1: 0.4457 (0.4464)  loss_bbox_dn_1: 0.1649 (0.1638)  loss_giou_dn_1: 0.5253 (0.5330)  loss_vfl_dn_2: 0.4217 (0.4201)  loss_bbox_dn_2: 0.1546 (0.1544)  loss_giou_dn_2: 0.4984 (0.5122)  loss_vfl_dn_3: 0.4130 (0.4127)  loss_bbox_dn_3: 0.1515 (0.1520)  loss_giou_dn_3: 0.4914 (0.5072)  loss_vfl_dn_4: 0.4139 (0.4138)  loss_bbox_dn_4: 0.1516 (0.1514)  loss_giou_dn_4: 0.4881 (0.5053)  loss_vfl_dn_5: 0.4109 (0.4128)  loss_bbox_dn_5: 0.1509 (0.1511)  loss_giou_dn_5: 0.4859 (0.5038)  loss_vfl_enc_0: 0.9439 (0.9487)  loss_bbox_enc_0: 0.2492 (0.2588)  loss_giou_enc_0: 0.7050 (0.7092)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4157  data: 4.3620  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9314  data: 2.1973  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9531 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [81]  [0/8]  eta: 0:00:23  lr: 0.000003  loss: 17.0680 (17.0680)  loss_vfl: 0.4759 (0.4759)  loss_bbox: 0.1995 (0.1995)  loss_giou: 0.6266 (0.6266)  loss_vfl_aux_0: 0.9795 (0.9795)  loss_bbox_aux_0: 0.2357 (0.2357)  loss_giou_aux_0: 0.6503 (0.6503)  loss_vfl_aux_1: 0.6514 (0.6514)  loss_bbox_aux_1: 0.2399 (0.2399)  loss_giou_aux_1: 0.6713 (0.6713)  loss_vfl_aux_2: 0.4928 (0.4928)  loss_bbox_aux_2: 0.2207 (0.2207)  loss_giou_aux_2: 0.6705 (0.6705)  loss_vfl_aux_3: 0.4669 (0.4669)  loss_bbox_aux_3: 0.2074 (0.2074)  loss_giou_aux_3: 0.6496 (0.6496)  loss_vfl_aux_4: 0.4777 (0.4777)  loss_bbox_aux_4: 0.1995 (0.1995)  loss_giou_aux_4: 0.6365 (0.6365)  loss_vfl_dn_0: 0.5162 (0.5162)  loss_bbox_dn_0: 0.1653 (0.1653)  loss_giou_dn_0: 0.5532 (0.5532)  loss_vfl_dn_1: 0.4339 (0.4339)  loss_bbox_dn_1: 0.1468 (0.1468)  loss_giou_dn_1: 0.5115 (0.5115)  loss_vfl_dn_2: 0.4088 (0.4088)  loss_bbox_dn_2: 0.1367 (0.1367)  loss_giou_dn_2: 0.4950 (0.4950)  loss_vfl_dn_3: 0.3996 (0.3996)  loss_bbox_dn_3: 0.1351 (0.1351)  loss_giou_dn_3: 0.4895 (0.4895)  loss_vfl_dn_4: 0.3982 (0.3982)  loss_bbox_dn_4: 0.1348 (0.1348)  loss_giou_dn_4: 0.4889 (0.4889)  loss_vfl_dn_5: 0.3962 (0.3962)  loss_bbox_dn_5: 0.1344 (0.1344)  loss_giou_dn_5: 0.4857 (0.4857)  loss_vfl_enc_0: 0.9014 (0.9014)  loss_bbox_enc_0: 0.2592 (0.2592)  loss_giou_enc_0: 0.7256 (0.7256)  time: 2.8985  data: 2.3460  max mem: 16811\n",
            "Epoch: [81]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.5901 (17.6529)  loss_vfl: 0.4888 (0.4938)  loss_bbox: 0.2084 (0.2136)  loss_giou: 0.6266 (0.6392)  loss_vfl_aux_0: 1.0307 (1.0308)  loss_bbox_aux_0: 0.2287 (0.2276)  loss_giou_aux_0: 0.6361 (0.6326)  loss_vfl_aux_1: 0.6898 (0.6905)  loss_bbox_aux_1: 0.2388 (0.2408)  loss_giou_aux_1: 0.6697 (0.6693)  loss_vfl_aux_2: 0.5157 (0.5240)  loss_bbox_aux_2: 0.2335 (0.2345)  loss_giou_aux_2: 0.6676 (0.6684)  loss_vfl_aux_3: 0.4918 (0.4955)  loss_bbox_aux_3: 0.2140 (0.2214)  loss_giou_aux_3: 0.6496 (0.6528)  loss_vfl_aux_4: 0.4965 (0.4966)  loss_bbox_aux_4: 0.2104 (0.2163)  loss_giou_aux_4: 0.6365 (0.6425)  loss_vfl_dn_0: 0.5091 (0.5113)  loss_bbox_dn_0: 0.1855 (0.1889)  loss_giou_dn_0: 0.5886 (0.5920)  loss_vfl_dn_1: 0.4413 (0.4430)  loss_bbox_dn_1: 0.1612 (0.1662)  loss_giou_dn_1: 0.5322 (0.5362)  loss_vfl_dn_2: 0.4189 (0.4188)  loss_bbox_dn_2: 0.1564 (0.1572)  loss_giou_dn_2: 0.5201 (0.5180)  loss_vfl_dn_3: 0.4099 (0.4119)  loss_bbox_dn_3: 0.1552 (0.1551)  loss_giou_dn_3: 0.5154 (0.5138)  loss_vfl_dn_4: 0.4144 (0.4140)  loss_bbox_dn_4: 0.1548 (0.1548)  loss_giou_dn_4: 0.5132 (0.5118)  loss_vfl_dn_5: 0.4113 (0.4123)  loss_bbox_dn_5: 0.1542 (0.1545)  loss_giou_dn_5: 0.5126 (0.5105)  loss_vfl_enc_0: 0.9350 (0.9374)  loss_bbox_enc_0: 0.2530 (0.2515)  loss_giou_enc_0: 0.6994 (0.7035)  time: 0.8314  data: 0.3215  max mem: 16811\n",
            "Epoch: [81] Total time: 0:00:06 (0.8366 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.5901 (17.6529)  loss_vfl: 0.4888 (0.4938)  loss_bbox: 0.2084 (0.2136)  loss_giou: 0.6266 (0.6392)  loss_vfl_aux_0: 1.0307 (1.0308)  loss_bbox_aux_0: 0.2287 (0.2276)  loss_giou_aux_0: 0.6361 (0.6326)  loss_vfl_aux_1: 0.6898 (0.6905)  loss_bbox_aux_1: 0.2388 (0.2408)  loss_giou_aux_1: 0.6697 (0.6693)  loss_vfl_aux_2: 0.5157 (0.5240)  loss_bbox_aux_2: 0.2335 (0.2345)  loss_giou_aux_2: 0.6676 (0.6684)  loss_vfl_aux_3: 0.4918 (0.4955)  loss_bbox_aux_3: 0.2140 (0.2214)  loss_giou_aux_3: 0.6496 (0.6528)  loss_vfl_aux_4: 0.4965 (0.4966)  loss_bbox_aux_4: 0.2104 (0.2163)  loss_giou_aux_4: 0.6365 (0.6425)  loss_vfl_dn_0: 0.5091 (0.5113)  loss_bbox_dn_0: 0.1855 (0.1889)  loss_giou_dn_0: 0.5886 (0.5920)  loss_vfl_dn_1: 0.4413 (0.4430)  loss_bbox_dn_1: 0.1612 (0.1662)  loss_giou_dn_1: 0.5322 (0.5362)  loss_vfl_dn_2: 0.4189 (0.4188)  loss_bbox_dn_2: 0.1564 (0.1572)  loss_giou_dn_2: 0.5201 (0.5180)  loss_vfl_dn_3: 0.4099 (0.4119)  loss_bbox_dn_3: 0.1552 (0.1551)  loss_giou_dn_3: 0.5154 (0.5138)  loss_vfl_dn_4: 0.4144 (0.4140)  loss_bbox_dn_4: 0.1548 (0.1548)  loss_giou_dn_4: 0.5132 (0.5118)  loss_vfl_dn_5: 0.4113 (0.4123)  loss_bbox_dn_5: 0.1542 (0.1545)  loss_giou_dn_5: 0.5126 (0.5105)  loss_vfl_enc_0: 0.9350 (0.9374)  loss_bbox_enc_0: 0.2530 (0.2515)  loss_giou_enc_0: 0.6994 (0.7035)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7466  data: 1.3531  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5967  data: 0.6928  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6354 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [82]  [0/8]  eta: 0:00:33  lr: 0.000003  loss: 17.7391 (17.7391)  loss_vfl: 0.4692 (0.4692)  loss_bbox: 0.2119 (0.2119)  loss_giou: 0.6701 (0.6701)  loss_vfl_aux_0: 1.0002 (1.0002)  loss_bbox_aux_0: 0.2240 (0.2240)  loss_giou_aux_0: 0.6750 (0.6750)  loss_vfl_aux_1: 0.7062 (0.7062)  loss_bbox_aux_1: 0.2338 (0.2338)  loss_giou_aux_1: 0.7126 (0.7126)  loss_vfl_aux_2: 0.5192 (0.5192)  loss_bbox_aux_2: 0.2203 (0.2203)  loss_giou_aux_2: 0.6994 (0.6994)  loss_vfl_aux_3: 0.4742 (0.4742)  loss_bbox_aux_3: 0.2059 (0.2059)  loss_giou_aux_3: 0.6864 (0.6864)  loss_vfl_aux_4: 0.4727 (0.4727)  loss_bbox_aux_4: 0.2139 (0.2139)  loss_giou_aux_4: 0.6716 (0.6716)  loss_vfl_dn_0: 0.5052 (0.5052)  loss_bbox_dn_0: 0.1715 (0.1715)  loss_giou_dn_0: 0.6110 (0.6110)  loss_vfl_dn_1: 0.4347 (0.4347)  loss_bbox_dn_1: 0.1521 (0.1521)  loss_giou_dn_1: 0.5563 (0.5563)  loss_vfl_dn_2: 0.4172 (0.4172)  loss_bbox_dn_2: 0.1448 (0.1448)  loss_giou_dn_2: 0.5354 (0.5354)  loss_vfl_dn_3: 0.4068 (0.4068)  loss_bbox_dn_3: 0.1424 (0.1424)  loss_giou_dn_3: 0.5285 (0.5285)  loss_vfl_dn_4: 0.4072 (0.4072)  loss_bbox_dn_4: 0.1424 (0.1424)  loss_giou_dn_4: 0.5272 (0.5272)  loss_vfl_dn_5: 0.4054 (0.4054)  loss_bbox_dn_5: 0.1419 (0.1419)  loss_giou_dn_5: 0.5257 (0.5257)  loss_vfl_enc_0: 0.9040 (0.9040)  loss_bbox_enc_0: 0.2523 (0.2523)  loss_giou_enc_0: 0.7606 (0.7606)  time: 4.2382  data: 3.7040  max mem: 16811\n",
            "Epoch: [82]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.7391 (17.8111)  loss_vfl: 0.4936 (0.4940)  loss_bbox: 0.2220 (0.2238)  loss_giou: 0.6473 (0.6521)  loss_vfl_aux_0: 1.0504 (1.0393)  loss_bbox_aux_0: 0.2240 (0.2288)  loss_giou_aux_0: 0.6175 (0.6343)  loss_vfl_aux_1: 0.7248 (0.7236)  loss_bbox_aux_1: 0.2367 (0.2479)  loss_giou_aux_1: 0.6546 (0.6760)  loss_vfl_aux_2: 0.5374 (0.5408)  loss_bbox_aux_2: 0.2333 (0.2392)  loss_giou_aux_2: 0.6615 (0.6744)  loss_vfl_aux_3: 0.4932 (0.4985)  loss_bbox_aux_3: 0.2247 (0.2296)  loss_giou_aux_3: 0.6557 (0.6674)  loss_vfl_aux_4: 0.4930 (0.4988)  loss_bbox_aux_4: 0.2198 (0.2243)  loss_giou_aux_4: 0.6482 (0.6543)  loss_vfl_dn_0: 0.5090 (0.5092)  loss_bbox_dn_0: 0.1946 (0.1911)  loss_giou_dn_0: 0.5967 (0.5977)  loss_vfl_dn_1: 0.4404 (0.4407)  loss_bbox_dn_1: 0.1682 (0.1656)  loss_giou_dn_1: 0.5345 (0.5359)  loss_vfl_dn_2: 0.4180 (0.4171)  loss_bbox_dn_2: 0.1596 (0.1574)  loss_giou_dn_2: 0.5152 (0.5169)  loss_vfl_dn_3: 0.4068 (0.4099)  loss_bbox_dn_3: 0.1563 (0.1546)  loss_giou_dn_3: 0.5098 (0.5118)  loss_vfl_dn_4: 0.4075 (0.4117)  loss_bbox_dn_4: 0.1565 (0.1545)  loss_giou_dn_4: 0.5094 (0.5093)  loss_vfl_dn_5: 0.4080 (0.4112)  loss_bbox_dn_5: 0.1563 (0.1544)  loss_giou_dn_5: 0.5085 (0.5088)  loss_vfl_enc_0: 0.9456 (0.9416)  loss_bbox_enc_0: 0.2523 (0.2567)  loss_giou_enc_0: 0.6858 (0.7077)  time: 0.9999  data: 0.4917  max mem: 16811\n",
            "Epoch: [82] Total time: 0:00:08 (1.0080 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.7391 (17.8111)  loss_vfl: 0.4936 (0.4940)  loss_bbox: 0.2220 (0.2238)  loss_giou: 0.6473 (0.6521)  loss_vfl_aux_0: 1.0504 (1.0393)  loss_bbox_aux_0: 0.2240 (0.2288)  loss_giou_aux_0: 0.6175 (0.6343)  loss_vfl_aux_1: 0.7248 (0.7236)  loss_bbox_aux_1: 0.2367 (0.2479)  loss_giou_aux_1: 0.6546 (0.6760)  loss_vfl_aux_2: 0.5374 (0.5408)  loss_bbox_aux_2: 0.2333 (0.2392)  loss_giou_aux_2: 0.6615 (0.6744)  loss_vfl_aux_3: 0.4932 (0.4985)  loss_bbox_aux_3: 0.2247 (0.2296)  loss_giou_aux_3: 0.6557 (0.6674)  loss_vfl_aux_4: 0.4930 (0.4988)  loss_bbox_aux_4: 0.2198 (0.2243)  loss_giou_aux_4: 0.6482 (0.6543)  loss_vfl_dn_0: 0.5090 (0.5092)  loss_bbox_dn_0: 0.1946 (0.1911)  loss_giou_dn_0: 0.5967 (0.5977)  loss_vfl_dn_1: 0.4404 (0.4407)  loss_bbox_dn_1: 0.1682 (0.1656)  loss_giou_dn_1: 0.5345 (0.5359)  loss_vfl_dn_2: 0.4180 (0.4171)  loss_bbox_dn_2: 0.1596 (0.1574)  loss_giou_dn_2: 0.5152 (0.5169)  loss_vfl_dn_3: 0.4068 (0.4099)  loss_bbox_dn_3: 0.1563 (0.1546)  loss_giou_dn_3: 0.5098 (0.5118)  loss_vfl_dn_4: 0.4075 (0.4117)  loss_bbox_dn_4: 0.1565 (0.1545)  loss_giou_dn_4: 0.5094 (0.5093)  loss_vfl_dn_5: 0.4080 (0.4112)  loss_bbox_dn_5: 0.1563 (0.1544)  loss_giou_dn_5: 0.5085 (0.5088)  loss_vfl_enc_0: 0.9456 (0.9416)  loss_bbox_enc_0: 0.2523 (0.2567)  loss_giou_enc_0: 0.6858 (0.7077)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4002  data: 4.3405  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9245  data: 2.1865  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9426 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [83]  [0/8]  eta: 0:00:11  lr: 0.000003  loss: 17.5116 (17.5116)  loss_vfl: 0.5035 (0.5035)  loss_bbox: 0.1987 (0.1987)  loss_giou: 0.6247 (0.6247)  loss_vfl_aux_0: 1.0666 (1.0666)  loss_bbox_aux_0: 0.2044 (0.2044)  loss_giou_aux_0: 0.6231 (0.6231)  loss_vfl_aux_1: 0.7520 (0.7520)  loss_bbox_aux_1: 0.2215 (0.2215)  loss_giou_aux_1: 0.6492 (0.6492)  loss_vfl_aux_2: 0.5474 (0.5474)  loss_bbox_aux_2: 0.2231 (0.2231)  loss_giou_aux_2: 0.6675 (0.6675)  loss_vfl_aux_3: 0.5105 (0.5105)  loss_bbox_aux_3: 0.2124 (0.2124)  loss_giou_aux_3: 0.6563 (0.6563)  loss_vfl_aux_4: 0.5134 (0.5134)  loss_bbox_aux_4: 0.2014 (0.2014)  loss_giou_aux_4: 0.6240 (0.6240)  loss_vfl_dn_0: 0.5224 (0.5224)  loss_bbox_dn_0: 0.1717 (0.1717)  loss_giou_dn_0: 0.5810 (0.5810)  loss_vfl_dn_1: 0.4419 (0.4419)  loss_bbox_dn_1: 0.1523 (0.1523)  loss_giou_dn_1: 0.5307 (0.5307)  loss_vfl_dn_2: 0.4141 (0.4141)  loss_bbox_dn_2: 0.1459 (0.1459)  loss_giou_dn_2: 0.5136 (0.5136)  loss_vfl_dn_3: 0.4084 (0.4084)  loss_bbox_dn_3: 0.1446 (0.1446)  loss_giou_dn_3: 0.5116 (0.5116)  loss_vfl_dn_4: 0.4099 (0.4099)  loss_bbox_dn_4: 0.1451 (0.1451)  loss_giou_dn_4: 0.5108 (0.5108)  loss_vfl_dn_5: 0.4053 (0.4053)  loss_bbox_dn_5: 0.1450 (0.1450)  loss_giou_dn_5: 0.5090 (0.5090)  loss_vfl_enc_0: 0.9363 (0.9363)  loss_bbox_enc_0: 0.2308 (0.2308)  loss_giou_enc_0: 0.6814 (0.6814)  time: 1.4827  data: 0.9152  max mem: 16811\n",
            "Epoch: [83]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.5072 (17.5152)  loss_vfl: 0.4908 (0.4910)  loss_bbox: 0.1987 (0.2113)  loss_giou: 0.6313 (0.6370)  loss_vfl_aux_0: 1.0241 (1.0306)  loss_bbox_aux_0: 0.2105 (0.2253)  loss_giou_aux_0: 0.6308 (0.6288)  loss_vfl_aux_1: 0.6830 (0.6951)  loss_bbox_aux_1: 0.2215 (0.2371)  loss_giou_aux_1: 0.6581 (0.6665)  loss_vfl_aux_2: 0.5341 (0.5262)  loss_bbox_aux_2: 0.2314 (0.2336)  loss_giou_aux_2: 0.6675 (0.6646)  loss_vfl_aux_3: 0.4923 (0.4946)  loss_bbox_aux_3: 0.2124 (0.2206)  loss_giou_aux_3: 0.6563 (0.6565)  loss_vfl_aux_4: 0.4951 (0.4963)  loss_bbox_aux_4: 0.2073 (0.2156)  loss_giou_aux_4: 0.6340 (0.6405)  loss_vfl_dn_0: 0.5117 (0.5127)  loss_bbox_dn_0: 0.1768 (0.1834)  loss_giou_dn_0: 0.5810 (0.5825)  loss_vfl_dn_1: 0.4410 (0.4415)  loss_bbox_dn_1: 0.1523 (0.1601)  loss_giou_dn_1: 0.5164 (0.5245)  loss_vfl_dn_2: 0.4141 (0.4144)  loss_bbox_dn_2: 0.1459 (0.1520)  loss_giou_dn_2: 0.4998 (0.5065)  loss_vfl_dn_3: 0.4082 (0.4095)  loss_bbox_dn_3: 0.1446 (0.1505)  loss_giou_dn_3: 0.4952 (0.5042)  loss_vfl_dn_4: 0.4099 (0.4115)  loss_bbox_dn_4: 0.1451 (0.1497)  loss_giou_dn_4: 0.4912 (0.5009)  loss_vfl_dn_5: 0.4074 (0.4089)  loss_bbox_dn_5: 0.1450 (0.1495)  loss_giou_dn_5: 0.4904 (0.5000)  loss_vfl_enc_0: 0.9302 (0.9343)  loss_bbox_enc_0: 0.2399 (0.2474)  loss_giou_enc_0: 0.6998 (0.7000)  time: 0.6666  data: 0.1439  max mem: 16811\n",
            "Epoch: [83] Total time: 0:00:05 (0.6744 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.5072 (17.5152)  loss_vfl: 0.4908 (0.4910)  loss_bbox: 0.1987 (0.2113)  loss_giou: 0.6313 (0.6370)  loss_vfl_aux_0: 1.0241 (1.0306)  loss_bbox_aux_0: 0.2105 (0.2253)  loss_giou_aux_0: 0.6308 (0.6288)  loss_vfl_aux_1: 0.6830 (0.6951)  loss_bbox_aux_1: 0.2215 (0.2371)  loss_giou_aux_1: 0.6581 (0.6665)  loss_vfl_aux_2: 0.5341 (0.5262)  loss_bbox_aux_2: 0.2314 (0.2336)  loss_giou_aux_2: 0.6675 (0.6646)  loss_vfl_aux_3: 0.4923 (0.4946)  loss_bbox_aux_3: 0.2124 (0.2206)  loss_giou_aux_3: 0.6563 (0.6565)  loss_vfl_aux_4: 0.4951 (0.4963)  loss_bbox_aux_4: 0.2073 (0.2156)  loss_giou_aux_4: 0.6340 (0.6405)  loss_vfl_dn_0: 0.5117 (0.5127)  loss_bbox_dn_0: 0.1768 (0.1834)  loss_giou_dn_0: 0.5810 (0.5825)  loss_vfl_dn_1: 0.4410 (0.4415)  loss_bbox_dn_1: 0.1523 (0.1601)  loss_giou_dn_1: 0.5164 (0.5245)  loss_vfl_dn_2: 0.4141 (0.4144)  loss_bbox_dn_2: 0.1459 (0.1520)  loss_giou_dn_2: 0.4998 (0.5065)  loss_vfl_dn_3: 0.4082 (0.4095)  loss_bbox_dn_3: 0.1446 (0.1505)  loss_giou_dn_3: 0.4952 (0.5042)  loss_vfl_dn_4: 0.4099 (0.4115)  loss_bbox_dn_4: 0.1451 (0.1497)  loss_giou_dn_4: 0.4912 (0.5009)  loss_vfl_dn_5: 0.4074 (0.4089)  loss_bbox_dn_5: 0.1450 (0.1495)  loss_giou_dn_5: 0.4904 (0.5000)  loss_vfl_enc_0: 0.9302 (0.9343)  loss_bbox_enc_0: 0.2399 (0.2474)  loss_giou_enc_0: 0.6998 (0.7000)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.0889  data: 3.6991  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7699  data: 1.8666  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.7901 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [84]  [0/8]  eta: 0:00:11  lr: 0.000003  loss: 16.9013 (16.9013)  loss_vfl: 0.4996 (0.4996)  loss_bbox: 0.1924 (0.1924)  loss_giou: 0.5993 (0.5993)  loss_vfl_aux_0: 1.0370 (1.0370)  loss_bbox_aux_0: 0.2056 (0.2056)  loss_giou_aux_0: 0.5913 (0.5913)  loss_vfl_aux_1: 0.6713 (0.6713)  loss_bbox_aux_1: 0.2048 (0.2048)  loss_giou_aux_1: 0.6194 (0.6194)  loss_vfl_aux_2: 0.5186 (0.5186)  loss_bbox_aux_2: 0.2071 (0.2071)  loss_giou_aux_2: 0.6233 (0.6233)  loss_vfl_aux_3: 0.4977 (0.4977)  loss_bbox_aux_3: 0.1959 (0.1959)  loss_giou_aux_3: 0.6100 (0.6100)  loss_vfl_aux_4: 0.4995 (0.4995)  loss_bbox_aux_4: 0.1937 (0.1937)  loss_giou_aux_4: 0.6027 (0.6027)  loss_vfl_dn_0: 0.5150 (0.5150)  loss_bbox_dn_0: 0.1730 (0.1730)  loss_giou_dn_0: 0.5627 (0.5627)  loss_vfl_dn_1: 0.4424 (0.4424)  loss_bbox_dn_1: 0.1475 (0.1475)  loss_giou_dn_1: 0.5042 (0.5042)  loss_vfl_dn_2: 0.4153 (0.4153)  loss_bbox_dn_2: 0.1432 (0.1432)  loss_giou_dn_2: 0.4933 (0.4933)  loss_vfl_dn_3: 0.4059 (0.4059)  loss_bbox_dn_3: 0.1405 (0.1405)  loss_giou_dn_3: 0.4892 (0.4892)  loss_vfl_dn_4: 0.4099 (0.4099)  loss_bbox_dn_4: 0.1403 (0.1403)  loss_giou_dn_4: 0.4862 (0.4862)  loss_vfl_dn_5: 0.4055 (0.4055)  loss_bbox_dn_5: 0.1398 (0.1398)  loss_giou_dn_5: 0.4843 (0.4843)  loss_vfl_enc_0: 0.9522 (0.9522)  loss_bbox_enc_0: 0.2242 (0.2242)  loss_giou_enc_0: 0.6576 (0.6576)  time: 1.3849  data: 0.8191  max mem: 16811\n",
            "Epoch: [84]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.2578 (17.4710)  loss_vfl: 0.4958 (0.4926)  loss_bbox: 0.2069 (0.2102)  loss_giou: 0.6297 (0.6284)  loss_vfl_aux_0: 1.0155 (1.0345)  loss_bbox_aux_0: 0.2188 (0.2223)  loss_giou_aux_0: 0.6068 (0.6256)  loss_vfl_aux_1: 0.6713 (0.6788)  loss_bbox_aux_1: 0.2279 (0.2343)  loss_giou_aux_1: 0.6387 (0.6577)  loss_vfl_aux_2: 0.5186 (0.5257)  loss_bbox_aux_2: 0.2246 (0.2308)  loss_giou_aux_2: 0.6361 (0.6538)  loss_vfl_aux_3: 0.4927 (0.4889)  loss_bbox_aux_3: 0.2141 (0.2187)  loss_giou_aux_3: 0.6454 (0.6448)  loss_vfl_aux_4: 0.4990 (0.4952)  loss_bbox_aux_4: 0.2071 (0.2142)  loss_giou_aux_4: 0.6306 (0.6332)  loss_vfl_dn_0: 0.5100 (0.5107)  loss_bbox_dn_0: 0.1857 (0.1894)  loss_giou_dn_0: 0.5885 (0.5877)  loss_vfl_dn_1: 0.4398 (0.4416)  loss_bbox_dn_1: 0.1623 (0.1651)  loss_giou_dn_1: 0.5205 (0.5256)  loss_vfl_dn_2: 0.4153 (0.4156)  loss_bbox_dn_2: 0.1531 (0.1571)  loss_giou_dn_2: 0.5033 (0.5087)  loss_vfl_dn_3: 0.4059 (0.4087)  loss_bbox_dn_3: 0.1519 (0.1545)  loss_giou_dn_3: 0.4995 (0.5048)  loss_vfl_dn_4: 0.4099 (0.4095)  loss_bbox_dn_4: 0.1524 (0.1541)  loss_giou_dn_4: 0.4945 (0.5022)  loss_vfl_dn_5: 0.4055 (0.4081)  loss_bbox_dn_5: 0.1522 (0.1539)  loss_giou_dn_5: 0.4953 (0.5012)  loss_vfl_enc_0: 0.9280 (0.9384)  loss_bbox_enc_0: 0.2454 (0.2482)  loss_giou_enc_0: 0.6803 (0.6962)  time: 0.6516  data: 0.1338  max mem: 16811\n",
            "Epoch: [84] Total time: 0:00:05 (0.6574 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.2578 (17.4710)  loss_vfl: 0.4958 (0.4926)  loss_bbox: 0.2069 (0.2102)  loss_giou: 0.6297 (0.6284)  loss_vfl_aux_0: 1.0155 (1.0345)  loss_bbox_aux_0: 0.2188 (0.2223)  loss_giou_aux_0: 0.6068 (0.6256)  loss_vfl_aux_1: 0.6713 (0.6788)  loss_bbox_aux_1: 0.2279 (0.2343)  loss_giou_aux_1: 0.6387 (0.6577)  loss_vfl_aux_2: 0.5186 (0.5257)  loss_bbox_aux_2: 0.2246 (0.2308)  loss_giou_aux_2: 0.6361 (0.6538)  loss_vfl_aux_3: 0.4927 (0.4889)  loss_bbox_aux_3: 0.2141 (0.2187)  loss_giou_aux_3: 0.6454 (0.6448)  loss_vfl_aux_4: 0.4990 (0.4952)  loss_bbox_aux_4: 0.2071 (0.2142)  loss_giou_aux_4: 0.6306 (0.6332)  loss_vfl_dn_0: 0.5100 (0.5107)  loss_bbox_dn_0: 0.1857 (0.1894)  loss_giou_dn_0: 0.5885 (0.5877)  loss_vfl_dn_1: 0.4398 (0.4416)  loss_bbox_dn_1: 0.1623 (0.1651)  loss_giou_dn_1: 0.5205 (0.5256)  loss_vfl_dn_2: 0.4153 (0.4156)  loss_bbox_dn_2: 0.1531 (0.1571)  loss_giou_dn_2: 0.5033 (0.5087)  loss_vfl_dn_3: 0.4059 (0.4087)  loss_bbox_dn_3: 0.1519 (0.1545)  loss_giou_dn_3: 0.4995 (0.5048)  loss_vfl_dn_4: 0.4099 (0.4095)  loss_bbox_dn_4: 0.1524 (0.1541)  loss_giou_dn_4: 0.4945 (0.5022)  loss_vfl_dn_5: 0.4055 (0.4081)  loss_bbox_dn_5: 0.1522 (0.1539)  loss_giou_dn_5: 0.4953 (0.5012)  loss_vfl_enc_0: 0.9280 (0.9384)  loss_bbox_enc_0: 0.2454 (0.2482)  loss_giou_enc_0: 0.6803 (0.6962)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.9070  data: 1.8393  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6794  data: 0.9359  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6974 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [85]  [0/8]  eta: 0:00:13  lr: 0.000003  loss: 18.4417 (18.4417)  loss_vfl: 0.5161 (0.5161)  loss_bbox: 0.2395 (0.2395)  loss_giou: 0.6696 (0.6696)  loss_vfl_aux_0: 1.0204 (1.0204)  loss_bbox_aux_0: 0.2344 (0.2344)  loss_giou_aux_0: 0.6526 (0.6526)  loss_vfl_aux_1: 0.7102 (0.7102)  loss_bbox_aux_1: 0.2548 (0.2548)  loss_giou_aux_1: 0.6983 (0.6983)  loss_vfl_aux_2: 0.5546 (0.5546)  loss_bbox_aux_2: 0.2671 (0.2671)  loss_giou_aux_2: 0.7131 (0.7131)  loss_vfl_aux_3: 0.5157 (0.5157)  loss_bbox_aux_3: 0.2607 (0.2607)  loss_giou_aux_3: 0.6963 (0.6963)  loss_vfl_aux_4: 0.5183 (0.5183)  loss_bbox_aux_4: 0.2441 (0.2441)  loss_giou_aux_4: 0.6784 (0.6784)  loss_vfl_dn_0: 0.5061 (0.5061)  loss_bbox_dn_0: 0.2237 (0.2237)  loss_giou_dn_0: 0.6294 (0.6294)  loss_vfl_dn_1: 0.4452 (0.4452)  loss_bbox_dn_1: 0.1929 (0.1929)  loss_giou_dn_1: 0.5671 (0.5671)  loss_vfl_dn_2: 0.4194 (0.4194)  loss_bbox_dn_2: 0.1797 (0.1797)  loss_giou_dn_2: 0.5435 (0.5435)  loss_vfl_dn_3: 0.4181 (0.4181)  loss_bbox_dn_3: 0.1736 (0.1736)  loss_giou_dn_3: 0.5363 (0.5363)  loss_vfl_dn_4: 0.4172 (0.4172)  loss_bbox_dn_4: 0.1733 (0.1733)  loss_giou_dn_4: 0.5338 (0.5338)  loss_vfl_dn_5: 0.4158 (0.4158)  loss_bbox_dn_5: 0.1734 (0.1734)  loss_giou_dn_5: 0.5342 (0.5342)  loss_vfl_enc_0: 0.9361 (0.9361)  loss_bbox_enc_0: 0.2589 (0.2589)  loss_giou_enc_0: 0.7200 (0.7200)  time: 1.7179  data: 1.1647  max mem: 16811\n",
            "Epoch: [85]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.4042 (17.4043)  loss_vfl: 0.4967 (0.4976)  loss_bbox: 0.2077 (0.2065)  loss_giou: 0.6180 (0.6211)  loss_vfl_aux_0: 1.0186 (1.0419)  loss_bbox_aux_0: 0.2288 (0.2181)  loss_giou_aux_0: 0.6319 (0.6115)  loss_vfl_aux_1: 0.7083 (0.7152)  loss_bbox_aux_1: 0.2325 (0.2281)  loss_giou_aux_1: 0.6402 (0.6466)  loss_vfl_aux_2: 0.5284 (0.5351)  loss_bbox_aux_2: 0.2247 (0.2258)  loss_giou_aux_2: 0.6298 (0.6450)  loss_vfl_aux_3: 0.4987 (0.4984)  loss_bbox_aux_3: 0.2127 (0.2153)  loss_giou_aux_3: 0.6217 (0.6359)  loss_vfl_aux_4: 0.4982 (0.4999)  loss_bbox_aux_4: 0.2092 (0.2107)  loss_giou_aux_4: 0.6225 (0.6269)  loss_vfl_dn_0: 0.5107 (0.5111)  loss_bbox_dn_0: 0.1799 (0.1846)  loss_giou_dn_0: 0.5789 (0.5791)  loss_vfl_dn_1: 0.4430 (0.4433)  loss_bbox_dn_1: 0.1558 (0.1615)  loss_giou_dn_1: 0.5257 (0.5230)  loss_vfl_dn_2: 0.4159 (0.4166)  loss_bbox_dn_2: 0.1458 (0.1526)  loss_giou_dn_2: 0.5080 (0.5043)  loss_vfl_dn_3: 0.4118 (0.4118)  loss_bbox_dn_3: 0.1437 (0.1495)  loss_giou_dn_3: 0.5051 (0.5002)  loss_vfl_dn_4: 0.4130 (0.4121)  loss_bbox_dn_4: 0.1436 (0.1494)  loss_giou_dn_4: 0.5027 (0.4981)  loss_vfl_dn_5: 0.4131 (0.4119)  loss_bbox_dn_5: 0.1434 (0.1492)  loss_giou_dn_5: 0.5008 (0.4971)  loss_vfl_enc_0: 0.9361 (0.9399)  loss_bbox_enc_0: 0.2589 (0.2436)  loss_giou_enc_0: 0.7007 (0.6858)  time: 0.6878  data: 0.1751  max mem: 16811\n",
            "Epoch: [85] Total time: 0:00:05 (0.6952 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.4042 (17.4043)  loss_vfl: 0.4967 (0.4976)  loss_bbox: 0.2077 (0.2065)  loss_giou: 0.6180 (0.6211)  loss_vfl_aux_0: 1.0186 (1.0419)  loss_bbox_aux_0: 0.2288 (0.2181)  loss_giou_aux_0: 0.6319 (0.6115)  loss_vfl_aux_1: 0.7083 (0.7152)  loss_bbox_aux_1: 0.2325 (0.2281)  loss_giou_aux_1: 0.6402 (0.6466)  loss_vfl_aux_2: 0.5284 (0.5351)  loss_bbox_aux_2: 0.2247 (0.2258)  loss_giou_aux_2: 0.6298 (0.6450)  loss_vfl_aux_3: 0.4987 (0.4984)  loss_bbox_aux_3: 0.2127 (0.2153)  loss_giou_aux_3: 0.6217 (0.6359)  loss_vfl_aux_4: 0.4982 (0.4999)  loss_bbox_aux_4: 0.2092 (0.2107)  loss_giou_aux_4: 0.6225 (0.6269)  loss_vfl_dn_0: 0.5107 (0.5111)  loss_bbox_dn_0: 0.1799 (0.1846)  loss_giou_dn_0: 0.5789 (0.5791)  loss_vfl_dn_1: 0.4430 (0.4433)  loss_bbox_dn_1: 0.1558 (0.1615)  loss_giou_dn_1: 0.5257 (0.5230)  loss_vfl_dn_2: 0.4159 (0.4166)  loss_bbox_dn_2: 0.1458 (0.1526)  loss_giou_dn_2: 0.5080 (0.5043)  loss_vfl_dn_3: 0.4118 (0.4118)  loss_bbox_dn_3: 0.1437 (0.1495)  loss_giou_dn_3: 0.5051 (0.5002)  loss_vfl_dn_4: 0.4130 (0.4121)  loss_bbox_dn_4: 0.1436 (0.1494)  loss_giou_dn_4: 0.5027 (0.4981)  loss_vfl_dn_5: 0.4131 (0.4119)  loss_bbox_dn_5: 0.1434 (0.1492)  loss_giou_dn_5: 0.5008 (0.4971)  loss_vfl_enc_0: 0.9361 (0.9399)  loss_bbox_enc_0: 0.2589 (0.2436)  loss_giou_enc_0: 0.7007 (0.6858)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7464  data: 1.3494  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5983  data: 0.6910  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3339 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [86]  [0/8]  eta: 0:00:11  lr: 0.000003  loss: 17.9218 (17.9218)  loss_vfl: 0.5362 (0.5362)  loss_bbox: 0.2277 (0.2277)  loss_giou: 0.6236 (0.6236)  loss_vfl_aux_0: 1.0949 (1.0949)  loss_bbox_aux_0: 0.2528 (0.2528)  loss_giou_aux_0: 0.6511 (0.6511)  loss_vfl_aux_1: 0.7768 (0.7768)  loss_bbox_aux_1: 0.2458 (0.2458)  loss_giou_aux_1: 0.6570 (0.6570)  loss_vfl_aux_2: 0.5602 (0.5602)  loss_bbox_aux_2: 0.2413 (0.2413)  loss_giou_aux_2: 0.6614 (0.6614)  loss_vfl_aux_3: 0.5496 (0.5496)  loss_bbox_aux_3: 0.2201 (0.2201)  loss_giou_aux_3: 0.6339 (0.6339)  loss_vfl_aux_4: 0.5342 (0.5342)  loss_bbox_aux_4: 0.2371 (0.2371)  loss_giou_aux_4: 0.6332 (0.6332)  loss_vfl_dn_0: 0.5031 (0.5031)  loss_bbox_dn_0: 0.1971 (0.1971)  loss_giou_dn_0: 0.5700 (0.5700)  loss_vfl_dn_1: 0.4287 (0.4287)  loss_bbox_dn_1: 0.1741 (0.1741)  loss_giou_dn_1: 0.5251 (0.5251)  loss_vfl_dn_2: 0.4078 (0.4078)  loss_bbox_dn_2: 0.1555 (0.1555)  loss_giou_dn_2: 0.4942 (0.4942)  loss_vfl_dn_3: 0.4020 (0.4020)  loss_bbox_dn_3: 0.1537 (0.1537)  loss_giou_dn_3: 0.4904 (0.4904)  loss_vfl_dn_4: 0.4052 (0.4052)  loss_bbox_dn_4: 0.1527 (0.1527)  loss_giou_dn_4: 0.4895 (0.4895)  loss_vfl_dn_5: 0.4020 (0.4020)  loss_bbox_dn_5: 0.1519 (0.1519)  loss_giou_dn_5: 0.4861 (0.4861)  loss_vfl_enc_0: 0.9889 (0.9889)  loss_bbox_enc_0: 0.2712 (0.2712)  loss_giou_enc_0: 0.7358 (0.7358)  time: 1.4495  data: 0.9147  max mem: 16811\n",
            "Epoch: [86]  [7/8]  eta: 0:00:00  lr: 0.000003  loss: 17.4211 (17.3850)  loss_vfl: 0.4946 (0.5013)  loss_bbox: 0.1975 (0.2027)  loss_giou: 0.6079 (0.6095)  loss_vfl_aux_0: 1.0616 (1.0617)  loss_bbox_aux_0: 0.2099 (0.2210)  loss_giou_aux_0: 0.6127 (0.6109)  loss_vfl_aux_1: 0.7205 (0.7281)  loss_bbox_aux_1: 0.2254 (0.2313)  loss_giou_aux_1: 0.6519 (0.6464)  loss_vfl_aux_2: 0.5260 (0.5318)  loss_bbox_aux_2: 0.2202 (0.2211)  loss_giou_aux_2: 0.6481 (0.6430)  loss_vfl_aux_3: 0.4944 (0.5028)  loss_bbox_aux_3: 0.2109 (0.2080)  loss_giou_aux_3: 0.6329 (0.6280)  loss_vfl_aux_4: 0.4944 (0.5042)  loss_bbox_aux_4: 0.2001 (0.2048)  loss_giou_aux_4: 0.6069 (0.6137)  loss_vfl_dn_0: 0.5064 (0.5065)  loss_bbox_dn_0: 0.1829 (0.1873)  loss_giou_dn_0: 0.5755 (0.5820)  loss_vfl_dn_1: 0.4336 (0.4378)  loss_bbox_dn_1: 0.1564 (0.1614)  loss_giou_dn_1: 0.5251 (0.5250)  loss_vfl_dn_2: 0.4097 (0.4152)  loss_bbox_dn_2: 0.1469 (0.1523)  loss_giou_dn_2: 0.4942 (0.5029)  loss_vfl_dn_3: 0.4046 (0.4097)  loss_bbox_dn_3: 0.1457 (0.1497)  loss_giou_dn_3: 0.4904 (0.4987)  loss_vfl_dn_4: 0.4052 (0.4098)  loss_bbox_dn_4: 0.1460 (0.1496)  loss_giou_dn_4: 0.4895 (0.4972)  loss_vfl_dn_5: 0.4045 (0.4098)  loss_bbox_dn_5: 0.1458 (0.1494)  loss_giou_dn_5: 0.4861 (0.4957)  loss_vfl_enc_0: 0.9322 (0.9348)  loss_bbox_enc_0: 0.2442 (0.2473)  loss_giou_enc_0: 0.6967 (0.6924)  time: 0.6509  data: 0.1401  max mem: 16811\n",
            "Epoch: [86] Total time: 0:00:05 (0.6596 s / it)\n",
            "Averaged stats: lr: 0.000003  loss: 17.4211 (17.3850)  loss_vfl: 0.4946 (0.5013)  loss_bbox: 0.1975 (0.2027)  loss_giou: 0.6079 (0.6095)  loss_vfl_aux_0: 1.0616 (1.0617)  loss_bbox_aux_0: 0.2099 (0.2210)  loss_giou_aux_0: 0.6127 (0.6109)  loss_vfl_aux_1: 0.7205 (0.7281)  loss_bbox_aux_1: 0.2254 (0.2313)  loss_giou_aux_1: 0.6519 (0.6464)  loss_vfl_aux_2: 0.5260 (0.5318)  loss_bbox_aux_2: 0.2202 (0.2211)  loss_giou_aux_2: 0.6481 (0.6430)  loss_vfl_aux_3: 0.4944 (0.5028)  loss_bbox_aux_3: 0.2109 (0.2080)  loss_giou_aux_3: 0.6329 (0.6280)  loss_vfl_aux_4: 0.4944 (0.5042)  loss_bbox_aux_4: 0.2001 (0.2048)  loss_giou_aux_4: 0.6069 (0.6137)  loss_vfl_dn_0: 0.5064 (0.5065)  loss_bbox_dn_0: 0.1829 (0.1873)  loss_giou_dn_0: 0.5755 (0.5820)  loss_vfl_dn_1: 0.4336 (0.4378)  loss_bbox_dn_1: 0.1564 (0.1614)  loss_giou_dn_1: 0.5251 (0.5250)  loss_vfl_dn_2: 0.4097 (0.4152)  loss_bbox_dn_2: 0.1469 (0.1523)  loss_giou_dn_2: 0.4942 (0.5029)  loss_vfl_dn_3: 0.4046 (0.4097)  loss_bbox_dn_3: 0.1457 (0.1497)  loss_giou_dn_3: 0.4904 (0.4987)  loss_vfl_dn_4: 0.4052 (0.4098)  loss_bbox_dn_4: 0.1460 (0.1496)  loss_giou_dn_4: 0.4895 (0.4972)  loss_vfl_dn_5: 0.4045 (0.4098)  loss_bbox_dn_5: 0.1458 (0.1494)  loss_giou_dn_5: 0.4861 (0.4957)  loss_vfl_enc_0: 0.9322 (0.9348)  loss_bbox_enc_0: 0.2442 (0.2473)  loss_giou_enc_0: 0.6967 (0.6924)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.3973  data: 4.3348  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9241  data: 2.1836  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9420 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.631\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [87]  [0/8]  eta: 0:00:10  lr: 0.000003  loss: 18.2708 (18.2708)  loss_vfl: 0.4843 (0.4843)  loss_bbox: 0.2378 (0.2378)  loss_giou: 0.6754 (0.6754)  loss_vfl_aux_0: 1.0834 (1.0834)  loss_bbox_aux_0: 0.2780 (0.2780)  loss_giou_aux_0: 0.6903 (0.6903)  loss_vfl_aux_1: 0.7079 (0.7079)  loss_bbox_aux_1: 0.2963 (0.2963)  loss_giou_aux_1: 0.7348 (0.7348)  loss_vfl_aux_2: 0.5136 (0.5136)  loss_bbox_aux_2: 0.2755 (0.2755)  loss_giou_aux_2: 0.7107 (0.7107)  loss_vfl_aux_3: 0.4884 (0.4884)  loss_bbox_aux_3: 0.2539 (0.2539)  loss_giou_aux_3: 0.6978 (0.6978)  loss_vfl_aux_4: 0.4978 (0.4978)  loss_bbox_aux_4: 0.2365 (0.2365)  loss_giou_aux_4: 0.6739 (0.6739)  loss_vfl_dn_0: 0.4977 (0.4977)  loss_bbox_dn_0: 0.1912 (0.1912)  loss_giou_dn_0: 0.5853 (0.5853)  loss_vfl_dn_1: 0.4281 (0.4281)  loss_bbox_dn_1: 0.1709 (0.1709)  loss_giou_dn_1: 0.5362 (0.5362)  loss_vfl_dn_2: 0.4070 (0.4070)  loss_bbox_dn_2: 0.1592 (0.1592)  loss_giou_dn_2: 0.5116 (0.5116)  loss_vfl_dn_3: 0.4019 (0.4019)  loss_bbox_dn_3: 0.1578 (0.1578)  loss_giou_dn_3: 0.5101 (0.5101)  loss_vfl_dn_4: 0.4042 (0.4042)  loss_bbox_dn_4: 0.1583 (0.1583)  loss_giou_dn_4: 0.5074 (0.5074)  loss_vfl_dn_5: 0.4008 (0.4008)  loss_bbox_dn_5: 0.1585 (0.1585)  loss_giou_dn_5: 0.5076 (0.5076)  loss_vfl_enc_0: 0.9667 (0.9667)  loss_bbox_enc_0: 0.3100 (0.3100)  loss_giou_enc_0: 0.7639 (0.7639)  time: 1.3714  data: 0.8134  max mem: 16811\n",
            "Epoch: [87]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 17.1026 (17.2286)  loss_vfl: 0.4911 (0.4993)  loss_bbox: 0.1999 (0.2045)  loss_giou: 0.6007 (0.6089)  loss_vfl_aux_0: 1.0261 (1.0617)  loss_bbox_aux_0: 0.2077 (0.2161)  loss_giou_aux_0: 0.5916 (0.6030)  loss_vfl_aux_1: 0.6817 (0.6924)  loss_bbox_aux_1: 0.2210 (0.2318)  loss_giou_aux_1: 0.6265 (0.6487)  loss_vfl_aux_2: 0.5136 (0.5207)  loss_bbox_aux_2: 0.2169 (0.2224)  loss_giou_aux_2: 0.6261 (0.6405)  loss_vfl_aux_3: 0.4884 (0.4969)  loss_bbox_aux_3: 0.2070 (0.2089)  loss_giou_aux_3: 0.6203 (0.6242)  loss_vfl_aux_4: 0.4964 (0.5059)  loss_bbox_aux_4: 0.2030 (0.2058)  loss_giou_aux_4: 0.6013 (0.6105)  loss_vfl_dn_0: 0.5030 (0.5042)  loss_bbox_dn_0: 0.1827 (0.1839)  loss_giou_dn_0: 0.5663 (0.5728)  loss_vfl_dn_1: 0.4284 (0.4324)  loss_bbox_dn_1: 0.1582 (0.1602)  loss_giou_dn_1: 0.5163 (0.5180)  loss_vfl_dn_2: 0.4070 (0.4082)  loss_bbox_dn_2: 0.1505 (0.1517)  loss_giou_dn_2: 0.4900 (0.4977)  loss_vfl_dn_3: 0.4019 (0.4031)  loss_bbox_dn_3: 0.1477 (0.1490)  loss_giou_dn_3: 0.4888 (0.4945)  loss_vfl_dn_4: 0.4042 (0.4040)  loss_bbox_dn_4: 0.1463 (0.1484)  loss_giou_dn_4: 0.4872 (0.4916)  loss_vfl_dn_5: 0.4008 (0.4037)  loss_bbox_dn_5: 0.1459 (0.1482)  loss_giou_dn_5: 0.4863 (0.4906)  loss_vfl_enc_0: 0.9284 (0.9399)  loss_bbox_enc_0: 0.2409 (0.2427)  loss_giou_enc_0: 0.6708 (0.6815)  time: 0.6483  data: 0.1314  max mem: 16811\n",
            "Epoch: [87] Total time: 0:00:05 (0.6561 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 17.1026 (17.2286)  loss_vfl: 0.4911 (0.4993)  loss_bbox: 0.1999 (0.2045)  loss_giou: 0.6007 (0.6089)  loss_vfl_aux_0: 1.0261 (1.0617)  loss_bbox_aux_0: 0.2077 (0.2161)  loss_giou_aux_0: 0.5916 (0.6030)  loss_vfl_aux_1: 0.6817 (0.6924)  loss_bbox_aux_1: 0.2210 (0.2318)  loss_giou_aux_1: 0.6265 (0.6487)  loss_vfl_aux_2: 0.5136 (0.5207)  loss_bbox_aux_2: 0.2169 (0.2224)  loss_giou_aux_2: 0.6261 (0.6405)  loss_vfl_aux_3: 0.4884 (0.4969)  loss_bbox_aux_3: 0.2070 (0.2089)  loss_giou_aux_3: 0.6203 (0.6242)  loss_vfl_aux_4: 0.4964 (0.5059)  loss_bbox_aux_4: 0.2030 (0.2058)  loss_giou_aux_4: 0.6013 (0.6105)  loss_vfl_dn_0: 0.5030 (0.5042)  loss_bbox_dn_0: 0.1827 (0.1839)  loss_giou_dn_0: 0.5663 (0.5728)  loss_vfl_dn_1: 0.4284 (0.4324)  loss_bbox_dn_1: 0.1582 (0.1602)  loss_giou_dn_1: 0.5163 (0.5180)  loss_vfl_dn_2: 0.4070 (0.4082)  loss_bbox_dn_2: 0.1505 (0.1517)  loss_giou_dn_2: 0.4900 (0.4977)  loss_vfl_dn_3: 0.4019 (0.4031)  loss_bbox_dn_3: 0.1477 (0.1490)  loss_giou_dn_3: 0.4888 (0.4945)  loss_vfl_dn_4: 0.4042 (0.4040)  loss_bbox_dn_4: 0.1463 (0.1484)  loss_giou_dn_4: 0.4872 (0.4916)  loss_vfl_dn_5: 0.4008 (0.4037)  loss_bbox_dn_5: 0.1459 (0.1482)  loss_giou_dn_5: 0.4863 (0.4906)  loss_vfl_enc_0: 0.9284 (0.9399)  loss_bbox_enc_0: 0.2409 (0.2427)  loss_giou_enc_0: 0.6708 (0.6815)\n",
            "Test:  [0/2]  eta: 0:00:07    time: 3.7276  data: 2.6580  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.0894  data: 1.3460  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.1072 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [88]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 17.5818 (17.5818)  loss_vfl: 0.5089 (0.5089)  loss_bbox: 0.2049 (0.2049)  loss_giou: 0.6420 (0.6420)  loss_vfl_aux_0: 1.0103 (1.0103)  loss_bbox_aux_0: 0.2320 (0.2320)  loss_giou_aux_0: 0.6794 (0.6794)  loss_vfl_aux_1: 0.6773 (0.6773)  loss_bbox_aux_1: 0.2271 (0.2271)  loss_giou_aux_1: 0.6873 (0.6873)  loss_vfl_aux_2: 0.5212 (0.5212)  loss_bbox_aux_2: 0.2235 (0.2235)  loss_giou_aux_2: 0.6808 (0.6808)  loss_vfl_aux_3: 0.4930 (0.4930)  loss_bbox_aux_3: 0.2148 (0.2148)  loss_giou_aux_3: 0.6724 (0.6724)  loss_vfl_aux_4: 0.5094 (0.5094)  loss_bbox_aux_4: 0.2094 (0.2094)  loss_giou_aux_4: 0.6487 (0.6487)  loss_vfl_dn_0: 0.5047 (0.5047)  loss_bbox_dn_0: 0.1747 (0.1747)  loss_giou_dn_0: 0.5734 (0.5734)  loss_vfl_dn_1: 0.4381 (0.4381)  loss_bbox_dn_1: 0.1539 (0.1539)  loss_giou_dn_1: 0.5261 (0.5261)  loss_vfl_dn_2: 0.4116 (0.4116)  loss_bbox_dn_2: 0.1475 (0.1475)  loss_giou_dn_2: 0.5108 (0.5108)  loss_vfl_dn_3: 0.4083 (0.4083)  loss_bbox_dn_3: 0.1461 (0.1461)  loss_giou_dn_3: 0.5097 (0.5097)  loss_vfl_dn_4: 0.4078 (0.4078)  loss_bbox_dn_4: 0.1455 (0.1455)  loss_giou_dn_4: 0.5071 (0.5071)  loss_vfl_dn_5: 0.4091 (0.4091)  loss_bbox_dn_5: 0.1455 (0.1455)  loss_giou_dn_5: 0.5066 (0.5066)  loss_vfl_enc_0: 0.9129 (0.9129)  loss_bbox_enc_0: 0.2498 (0.2498)  loss_giou_enc_0: 0.7501 (0.7501)  time: 1.5065  data: 0.9498  max mem: 16811\n",
            "Epoch: [88]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.9956 (17.2035)  loss_vfl: 0.4927 (0.4965)  loss_bbox: 0.1996 (0.2017)  loss_giou: 0.6051 (0.6020)  loss_vfl_aux_0: 1.0269 (1.0496)  loss_bbox_aux_0: 0.2189 (0.2190)  loss_giou_aux_0: 0.6008 (0.6072)  loss_vfl_aux_1: 0.6716 (0.6804)  loss_bbox_aux_1: 0.2246 (0.2255)  loss_giou_aux_1: 0.6372 (0.6403)  loss_vfl_aux_2: 0.5139 (0.5184)  loss_bbox_aux_2: 0.2235 (0.2236)  loss_giou_aux_2: 0.6224 (0.6319)  loss_vfl_aux_3: 0.4930 (0.4928)  loss_bbox_aux_3: 0.2060 (0.2079)  loss_giou_aux_3: 0.6151 (0.6244)  loss_vfl_aux_4: 0.4971 (0.4984)  loss_bbox_aux_4: 0.2063 (0.2047)  loss_giou_aux_4: 0.6120 (0.6063)  loss_vfl_dn_0: 0.5023 (0.5031)  loss_bbox_dn_0: 0.1758 (0.1829)  loss_giou_dn_0: 0.5734 (0.5776)  loss_vfl_dn_1: 0.4309 (0.4351)  loss_bbox_dn_1: 0.1539 (0.1581)  loss_giou_dn_1: 0.5145 (0.5198)  loss_vfl_dn_2: 0.4096 (0.4118)  loss_bbox_dn_2: 0.1475 (0.1504)  loss_giou_dn_2: 0.5001 (0.5029)  loss_vfl_dn_3: 0.4075 (0.4068)  loss_bbox_dn_3: 0.1461 (0.1478)  loss_giou_dn_3: 0.4958 (0.4989)  loss_vfl_dn_4: 0.4078 (0.4073)  loss_bbox_dn_4: 0.1455 (0.1471)  loss_giou_dn_4: 0.4940 (0.4965)  loss_vfl_dn_5: 0.4091 (0.4079)  loss_bbox_dn_5: 0.1455 (0.1468)  loss_giou_dn_5: 0.4922 (0.4953)  loss_vfl_enc_0: 0.9368 (0.9482)  loss_bbox_enc_0: 0.2407 (0.2443)  loss_giou_enc_0: 0.6742 (0.6846)  time: 0.6549  data: 0.1398  max mem: 16811\n",
            "Epoch: [88] Total time: 0:00:05 (0.6614 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.9956 (17.2035)  loss_vfl: 0.4927 (0.4965)  loss_bbox: 0.1996 (0.2017)  loss_giou: 0.6051 (0.6020)  loss_vfl_aux_0: 1.0269 (1.0496)  loss_bbox_aux_0: 0.2189 (0.2190)  loss_giou_aux_0: 0.6008 (0.6072)  loss_vfl_aux_1: 0.6716 (0.6804)  loss_bbox_aux_1: 0.2246 (0.2255)  loss_giou_aux_1: 0.6372 (0.6403)  loss_vfl_aux_2: 0.5139 (0.5184)  loss_bbox_aux_2: 0.2235 (0.2236)  loss_giou_aux_2: 0.6224 (0.6319)  loss_vfl_aux_3: 0.4930 (0.4928)  loss_bbox_aux_3: 0.2060 (0.2079)  loss_giou_aux_3: 0.6151 (0.6244)  loss_vfl_aux_4: 0.4971 (0.4984)  loss_bbox_aux_4: 0.2063 (0.2047)  loss_giou_aux_4: 0.6120 (0.6063)  loss_vfl_dn_0: 0.5023 (0.5031)  loss_bbox_dn_0: 0.1758 (0.1829)  loss_giou_dn_0: 0.5734 (0.5776)  loss_vfl_dn_1: 0.4309 (0.4351)  loss_bbox_dn_1: 0.1539 (0.1581)  loss_giou_dn_1: 0.5145 (0.5198)  loss_vfl_dn_2: 0.4096 (0.4118)  loss_bbox_dn_2: 0.1475 (0.1504)  loss_giou_dn_2: 0.5001 (0.5029)  loss_vfl_dn_3: 0.4075 (0.4068)  loss_bbox_dn_3: 0.1461 (0.1478)  loss_giou_dn_3: 0.4958 (0.4989)  loss_vfl_dn_4: 0.4078 (0.4073)  loss_bbox_dn_4: 0.1455 (0.1471)  loss_giou_dn_4: 0.4940 (0.4965)  loss_vfl_dn_5: 0.4091 (0.4079)  loss_bbox_dn_5: 0.1455 (0.1468)  loss_giou_dn_5: 0.4922 (0.4953)  loss_vfl_enc_0: 0.9368 (0.9482)  loss_bbox_enc_0: 0.2407 (0.2443)  loss_giou_enc_0: 0.6742 (0.6846)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4435  data: 4.3748  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9484  data: 2.2039  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9668 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [89]  [0/8]  eta: 0:00:13  lr: 0.000004  loss: 17.8809 (17.8809)  loss_vfl: 0.4665 (0.4665)  loss_bbox: 0.2423 (0.2423)  loss_giou: 0.6798 (0.6798)  loss_vfl_aux_0: 1.0608 (1.0608)  loss_bbox_aux_0: 0.2742 (0.2742)  loss_giou_aux_0: 0.6556 (0.6556)  loss_vfl_aux_1: 0.6468 (0.6468)  loss_bbox_aux_1: 0.2906 (0.2906)  loss_giou_aux_1: 0.7030 (0.7030)  loss_vfl_aux_2: 0.4999 (0.4999)  loss_bbox_aux_2: 0.2725 (0.2725)  loss_giou_aux_2: 0.7039 (0.7039)  loss_vfl_aux_3: 0.4750 (0.4750)  loss_bbox_aux_3: 0.2558 (0.2558)  loss_giou_aux_3: 0.7034 (0.7034)  loss_vfl_aux_4: 0.4777 (0.4777)  loss_bbox_aux_4: 0.2448 (0.2448)  loss_giou_aux_4: 0.6829 (0.6829)  loss_vfl_dn_0: 0.5128 (0.5128)  loss_bbox_dn_0: 0.1843 (0.1843)  loss_giou_dn_0: 0.5454 (0.5454)  loss_vfl_dn_1: 0.4393 (0.4393)  loss_bbox_dn_1: 0.1661 (0.1661)  loss_giou_dn_1: 0.5010 (0.5010)  loss_vfl_dn_2: 0.4097 (0.4097)  loss_bbox_dn_2: 0.1573 (0.1573)  loss_giou_dn_2: 0.4854 (0.4854)  loss_vfl_dn_3: 0.4027 (0.4027)  loss_bbox_dn_3: 0.1552 (0.1552)  loss_giou_dn_3: 0.4848 (0.4848)  loss_vfl_dn_4: 0.4042 (0.4042)  loss_bbox_dn_4: 0.1542 (0.1542)  loss_giou_dn_4: 0.4821 (0.4821)  loss_vfl_dn_5: 0.4045 (0.4045)  loss_bbox_dn_5: 0.1542 (0.1542)  loss_giou_dn_5: 0.4825 (0.4825)  loss_vfl_enc_0: 0.9768 (0.9768)  loss_bbox_enc_0: 0.2980 (0.2980)  loss_giou_enc_0: 0.7447 (0.7447)  time: 1.7250  data: 0.8905  max mem: 16811\n",
            "Epoch: [89]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.9917 (17.0948)  loss_vfl: 0.4734 (0.4875)  loss_bbox: 0.1915 (0.2008)  loss_giou: 0.5928 (0.6049)  loss_vfl_aux_0: 1.0454 (1.0532)  loss_bbox_aux_0: 0.2011 (0.2049)  loss_giou_aux_0: 0.6146 (0.5912)  loss_vfl_aux_1: 0.6868 (0.6874)  loss_bbox_aux_1: 0.2118 (0.2242)  loss_giou_aux_1: 0.6379 (0.6324)  loss_vfl_aux_2: 0.5257 (0.5347)  loss_bbox_aux_2: 0.2023 (0.2159)  loss_giou_aux_2: 0.6357 (0.6292)  loss_vfl_aux_3: 0.4948 (0.5067)  loss_bbox_aux_3: 0.1934 (0.2038)  loss_giou_aux_3: 0.5996 (0.6158)  loss_vfl_aux_4: 0.4862 (0.4957)  loss_bbox_aux_4: 0.1917 (0.2023)  loss_giou_aux_4: 0.5934 (0.6088)  loss_vfl_dn_0: 0.5016 (0.5036)  loss_bbox_dn_0: 0.1772 (0.1784)  loss_giou_dn_0: 0.5716 (0.5704)  loss_vfl_dn_1: 0.4351 (0.4353)  loss_bbox_dn_1: 0.1495 (0.1556)  loss_giou_dn_1: 0.5118 (0.5148)  loss_vfl_dn_2: 0.4118 (0.4124)  loss_bbox_dn_2: 0.1410 (0.1473)  loss_giou_dn_2: 0.4906 (0.4962)  loss_vfl_dn_3: 0.4051 (0.4057)  loss_bbox_dn_3: 0.1384 (0.1452)  loss_giou_dn_3: 0.4869 (0.4918)  loss_vfl_dn_4: 0.4053 (0.4059)  loss_bbox_dn_4: 0.1374 (0.1445)  loss_giou_dn_4: 0.4831 (0.4893)  loss_vfl_dn_5: 0.4045 (0.4048)  loss_bbox_dn_5: 0.1371 (0.1442)  loss_giou_dn_5: 0.4825 (0.4881)  loss_vfl_enc_0: 0.9554 (0.9602)  loss_bbox_enc_0: 0.2267 (0.2312)  loss_giou_enc_0: 0.6802 (0.6705)  time: 0.6864  data: 0.1380  max mem: 16811\n",
            "Epoch: [89] Total time: 0:00:05 (0.6947 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.9917 (17.0948)  loss_vfl: 0.4734 (0.4875)  loss_bbox: 0.1915 (0.2008)  loss_giou: 0.5928 (0.6049)  loss_vfl_aux_0: 1.0454 (1.0532)  loss_bbox_aux_0: 0.2011 (0.2049)  loss_giou_aux_0: 0.6146 (0.5912)  loss_vfl_aux_1: 0.6868 (0.6874)  loss_bbox_aux_1: 0.2118 (0.2242)  loss_giou_aux_1: 0.6379 (0.6324)  loss_vfl_aux_2: 0.5257 (0.5347)  loss_bbox_aux_2: 0.2023 (0.2159)  loss_giou_aux_2: 0.6357 (0.6292)  loss_vfl_aux_3: 0.4948 (0.5067)  loss_bbox_aux_3: 0.1934 (0.2038)  loss_giou_aux_3: 0.5996 (0.6158)  loss_vfl_aux_4: 0.4862 (0.4957)  loss_bbox_aux_4: 0.1917 (0.2023)  loss_giou_aux_4: 0.5934 (0.6088)  loss_vfl_dn_0: 0.5016 (0.5036)  loss_bbox_dn_0: 0.1772 (0.1784)  loss_giou_dn_0: 0.5716 (0.5704)  loss_vfl_dn_1: 0.4351 (0.4353)  loss_bbox_dn_1: 0.1495 (0.1556)  loss_giou_dn_1: 0.5118 (0.5148)  loss_vfl_dn_2: 0.4118 (0.4124)  loss_bbox_dn_2: 0.1410 (0.1473)  loss_giou_dn_2: 0.4906 (0.4962)  loss_vfl_dn_3: 0.4051 (0.4057)  loss_bbox_dn_3: 0.1384 (0.1452)  loss_giou_dn_3: 0.4869 (0.4918)  loss_vfl_dn_4: 0.4053 (0.4059)  loss_bbox_dn_4: 0.1374 (0.1445)  loss_giou_dn_4: 0.4831 (0.4893)  loss_vfl_dn_5: 0.4045 (0.4048)  loss_bbox_dn_5: 0.1371 (0.1442)  loss_giou_dn_5: 0.4825 (0.4881)  loss_vfl_enc_0: 0.9554 (0.9602)  loss_bbox_enc_0: 0.2267 (0.2312)  loss_giou_enc_0: 0.6802 (0.6705)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4571  data: 1.3425  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4604  data: 0.6885  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4857 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [90]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 17.2475 (17.2475)  loss_vfl: 0.5016 (0.5016)  loss_bbox: 0.1835 (0.1835)  loss_giou: 0.5969 (0.5969)  loss_vfl_aux_0: 0.9935 (0.9935)  loss_bbox_aux_0: 0.2191 (0.2191)  loss_giou_aux_0: 0.6441 (0.6441)  loss_vfl_aux_1: 0.6677 (0.6677)  loss_bbox_aux_1: 0.2197 (0.2197)  loss_giou_aux_1: 0.6693 (0.6693)  loss_vfl_aux_2: 0.5228 (0.5228)  loss_bbox_aux_2: 0.2048 (0.2048)  loss_giou_aux_2: 0.6553 (0.6553)  loss_vfl_aux_3: 0.4967 (0.4967)  loss_bbox_aux_3: 0.1941 (0.1941)  loss_giou_aux_3: 0.6283 (0.6283)  loss_vfl_aux_4: 0.5121 (0.5121)  loss_bbox_aux_4: 0.1841 (0.1841)  loss_giou_aux_4: 0.6025 (0.6025)  loss_vfl_dn_0: 0.5033 (0.5033)  loss_bbox_dn_0: 0.1759 (0.1759)  loss_giou_dn_0: 0.5830 (0.5830)  loss_vfl_dn_1: 0.4417 (0.4417)  loss_bbox_dn_1: 0.1586 (0.1586)  loss_giou_dn_1: 0.5321 (0.5321)  loss_vfl_dn_2: 0.4206 (0.4206)  loss_bbox_dn_2: 0.1480 (0.1480)  loss_giou_dn_2: 0.5121 (0.5121)  loss_vfl_dn_3: 0.4125 (0.4125)  loss_bbox_dn_3: 0.1473 (0.1473)  loss_giou_dn_3: 0.5093 (0.5093)  loss_vfl_dn_4: 0.4133 (0.4133)  loss_bbox_dn_4: 0.1452 (0.1452)  loss_giou_dn_4: 0.5051 (0.5051)  loss_vfl_dn_5: 0.4113 (0.4113)  loss_bbox_dn_5: 0.1450 (0.1450)  loss_giou_dn_5: 0.5042 (0.5042)  loss_vfl_enc_0: 0.9201 (0.9201)  loss_bbox_enc_0: 0.2415 (0.2415)  loss_giou_enc_0: 0.7210 (0.7210)  time: 1.5122  data: 0.9661  max mem: 16811\n",
            "Epoch: [90]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 17.1843 (17.0554)  loss_vfl: 0.4846 (0.4883)  loss_bbox: 0.1953 (0.1987)  loss_giou: 0.6122 (0.6018)  loss_vfl_aux_0: 1.0205 (1.0339)  loss_bbox_aux_0: 0.1964 (0.2064)  loss_giou_aux_0: 0.6057 (0.5947)  loss_vfl_aux_1: 0.6677 (0.6823)  loss_bbox_aux_1: 0.2172 (0.2193)  loss_giou_aux_1: 0.6460 (0.6310)  loss_vfl_aux_2: 0.5262 (0.5350)  loss_bbox_aux_2: 0.2009 (0.2135)  loss_giou_aux_2: 0.6360 (0.6256)  loss_vfl_aux_3: 0.4959 (0.5017)  loss_bbox_aux_3: 0.1942 (0.2051)  loss_giou_aux_3: 0.6269 (0.6173)  loss_vfl_aux_4: 0.4918 (0.4934)  loss_bbox_aux_4: 0.1944 (0.2013)  loss_giou_aux_4: 0.6110 (0.6051)  loss_vfl_dn_0: 0.5033 (0.5029)  loss_bbox_dn_0: 0.1759 (0.1808)  loss_giou_dn_0: 0.5715 (0.5763)  loss_vfl_dn_1: 0.4356 (0.4378)  loss_bbox_dn_1: 0.1567 (0.1574)  loss_giou_dn_1: 0.5166 (0.5178)  loss_vfl_dn_2: 0.4105 (0.4111)  loss_bbox_dn_2: 0.1480 (0.1483)  loss_giou_dn_2: 0.4974 (0.4977)  loss_vfl_dn_3: 0.4017 (0.4035)  loss_bbox_dn_3: 0.1454 (0.1470)  loss_giou_dn_3: 0.4920 (0.4951)  loss_vfl_dn_4: 0.4042 (0.4041)  loss_bbox_dn_4: 0.1443 (0.1463)  loss_giou_dn_4: 0.4896 (0.4931)  loss_vfl_dn_5: 0.3998 (0.4022)  loss_bbox_dn_5: 0.1441 (0.1460)  loss_giou_dn_5: 0.4903 (0.4916)  loss_vfl_enc_0: 0.9242 (0.9408)  loss_bbox_enc_0: 0.2190 (0.2310)  loss_giou_enc_0: 0.6620 (0.6699)  time: 0.6554  data: 0.1419  max mem: 16811\n",
            "Epoch: [90] Total time: 0:00:05 (0.6608 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 17.1843 (17.0554)  loss_vfl: 0.4846 (0.4883)  loss_bbox: 0.1953 (0.1987)  loss_giou: 0.6122 (0.6018)  loss_vfl_aux_0: 1.0205 (1.0339)  loss_bbox_aux_0: 0.1964 (0.2064)  loss_giou_aux_0: 0.6057 (0.5947)  loss_vfl_aux_1: 0.6677 (0.6823)  loss_bbox_aux_1: 0.2172 (0.2193)  loss_giou_aux_1: 0.6460 (0.6310)  loss_vfl_aux_2: 0.5262 (0.5350)  loss_bbox_aux_2: 0.2009 (0.2135)  loss_giou_aux_2: 0.6360 (0.6256)  loss_vfl_aux_3: 0.4959 (0.5017)  loss_bbox_aux_3: 0.1942 (0.2051)  loss_giou_aux_3: 0.6269 (0.6173)  loss_vfl_aux_4: 0.4918 (0.4934)  loss_bbox_aux_4: 0.1944 (0.2013)  loss_giou_aux_4: 0.6110 (0.6051)  loss_vfl_dn_0: 0.5033 (0.5029)  loss_bbox_dn_0: 0.1759 (0.1808)  loss_giou_dn_0: 0.5715 (0.5763)  loss_vfl_dn_1: 0.4356 (0.4378)  loss_bbox_dn_1: 0.1567 (0.1574)  loss_giou_dn_1: 0.5166 (0.5178)  loss_vfl_dn_2: 0.4105 (0.4111)  loss_bbox_dn_2: 0.1480 (0.1483)  loss_giou_dn_2: 0.4974 (0.4977)  loss_vfl_dn_3: 0.4017 (0.4035)  loss_bbox_dn_3: 0.1454 (0.1470)  loss_giou_dn_3: 0.4920 (0.4951)  loss_vfl_dn_4: 0.4042 (0.4041)  loss_bbox_dn_4: 0.1443 (0.1463)  loss_giou_dn_4: 0.4896 (0.4931)  loss_vfl_dn_5: 0.3998 (0.4022)  loss_bbox_dn_5: 0.1441 (0.1460)  loss_giou_dn_5: 0.4903 (0.4916)  loss_vfl_enc_0: 0.9242 (0.9408)  loss_bbox_enc_0: 0.2190 (0.2310)  loss_giou_enc_0: 0.6620 (0.6699)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.0741  data: 1.6675  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.7629  data: 0.8506  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.7839 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [91]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.7862 (16.7862)  loss_vfl: 0.4911 (0.4911)  loss_bbox: 0.1824 (0.1824)  loss_giou: 0.5767 (0.5767)  loss_vfl_aux_0: 1.0155 (1.0155)  loss_bbox_aux_0: 0.2031 (0.2031)  loss_giou_aux_0: 0.5925 (0.5925)  loss_vfl_aux_1: 0.6836 (0.6836)  loss_bbox_aux_1: 0.2043 (0.2043)  loss_giou_aux_1: 0.6374 (0.6374)  loss_vfl_aux_2: 0.5185 (0.5185)  loss_bbox_aux_2: 0.1981 (0.1981)  loss_giou_aux_2: 0.6148 (0.6148)  loss_vfl_aux_3: 0.5009 (0.5009)  loss_bbox_aux_3: 0.1856 (0.1856)  loss_giou_aux_3: 0.5924 (0.5924)  loss_vfl_aux_4: 0.4949 (0.4949)  loss_bbox_aux_4: 0.1824 (0.1824)  loss_giou_aux_4: 0.5742 (0.5742)  loss_vfl_dn_0: 0.5034 (0.5034)  loss_bbox_dn_0: 0.1779 (0.1779)  loss_giou_dn_0: 0.5796 (0.5796)  loss_vfl_dn_1: 0.4269 (0.4269)  loss_bbox_dn_1: 0.1531 (0.1531)  loss_giou_dn_1: 0.5235 (0.5235)  loss_vfl_dn_2: 0.4043 (0.4043)  loss_bbox_dn_2: 0.1449 (0.1449)  loss_giou_dn_2: 0.5009 (0.5009)  loss_vfl_dn_3: 0.3967 (0.3967)  loss_bbox_dn_3: 0.1424 (0.1424)  loss_giou_dn_3: 0.4928 (0.4928)  loss_vfl_dn_4: 0.3969 (0.3969)  loss_bbox_dn_4: 0.1420 (0.1420)  loss_giou_dn_4: 0.4898 (0.4898)  loss_vfl_dn_5: 0.3968 (0.3968)  loss_bbox_dn_5: 0.1418 (0.1418)  loss_giou_dn_5: 0.4887 (0.4887)  loss_vfl_enc_0: 0.9458 (0.9458)  loss_bbox_enc_0: 0.2286 (0.2286)  loss_giou_enc_0: 0.6607 (0.6607)  time: 1.5642  data: 0.9745  max mem: 16811\n",
            "Epoch: [91]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.8279 (17.0279)  loss_vfl: 0.4911 (0.4886)  loss_bbox: 0.1875 (0.2021)  loss_giou: 0.5805 (0.5998)  loss_vfl_aux_0: 1.0288 (1.0293)  loss_bbox_aux_0: 0.2015 (0.2104)  loss_giou_aux_0: 0.5850 (0.5965)  loss_vfl_aux_1: 0.6836 (0.6965)  loss_bbox_aux_1: 0.2060 (0.2196)  loss_giou_aux_1: 0.6130 (0.6263)  loss_vfl_aux_2: 0.5185 (0.5234)  loss_bbox_aux_2: 0.2060 (0.2146)  loss_giou_aux_2: 0.6148 (0.6220)  loss_vfl_aux_3: 0.5009 (0.4967)  loss_bbox_aux_3: 0.1942 (0.2069)  loss_giou_aux_3: 0.5978 (0.6118)  loss_vfl_aux_4: 0.4934 (0.4927)  loss_bbox_aux_4: 0.1880 (0.2018)  loss_giou_aux_4: 0.5815 (0.6007)  loss_vfl_dn_0: 0.4999 (0.5009)  loss_bbox_dn_0: 0.1782 (0.1806)  loss_giou_dn_0: 0.5645 (0.5707)  loss_vfl_dn_1: 0.4349 (0.4375)  loss_bbox_dn_1: 0.1566 (0.1584)  loss_giou_dn_1: 0.5067 (0.5164)  loss_vfl_dn_2: 0.4115 (0.4128)  loss_bbox_dn_2: 0.1488 (0.1494)  loss_giou_dn_2: 0.4862 (0.4959)  loss_vfl_dn_3: 0.4040 (0.4049)  loss_bbox_dn_3: 0.1455 (0.1465)  loss_giou_dn_3: 0.4792 (0.4891)  loss_vfl_dn_4: 0.4048 (0.4051)  loss_bbox_dn_4: 0.1456 (0.1466)  loss_giou_dn_4: 0.4781 (0.4878)  loss_vfl_dn_5: 0.4047 (0.4053)  loss_bbox_dn_5: 0.1455 (0.1466)  loss_giou_dn_5: 0.4782 (0.4877)  loss_vfl_enc_0: 0.9345 (0.9307)  loss_bbox_enc_0: 0.2286 (0.2395)  loss_giou_enc_0: 0.6607 (0.6757)  time: 0.6612  data: 0.1422  max mem: 16811\n",
            "Epoch: [91] Total time: 0:00:05 (0.6697 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.8279 (17.0279)  loss_vfl: 0.4911 (0.4886)  loss_bbox: 0.1875 (0.2021)  loss_giou: 0.5805 (0.5998)  loss_vfl_aux_0: 1.0288 (1.0293)  loss_bbox_aux_0: 0.2015 (0.2104)  loss_giou_aux_0: 0.5850 (0.5965)  loss_vfl_aux_1: 0.6836 (0.6965)  loss_bbox_aux_1: 0.2060 (0.2196)  loss_giou_aux_1: 0.6130 (0.6263)  loss_vfl_aux_2: 0.5185 (0.5234)  loss_bbox_aux_2: 0.2060 (0.2146)  loss_giou_aux_2: 0.6148 (0.6220)  loss_vfl_aux_3: 0.5009 (0.4967)  loss_bbox_aux_3: 0.1942 (0.2069)  loss_giou_aux_3: 0.5978 (0.6118)  loss_vfl_aux_4: 0.4934 (0.4927)  loss_bbox_aux_4: 0.1880 (0.2018)  loss_giou_aux_4: 0.5815 (0.6007)  loss_vfl_dn_0: 0.4999 (0.5009)  loss_bbox_dn_0: 0.1782 (0.1806)  loss_giou_dn_0: 0.5645 (0.5707)  loss_vfl_dn_1: 0.4349 (0.4375)  loss_bbox_dn_1: 0.1566 (0.1584)  loss_giou_dn_1: 0.5067 (0.5164)  loss_vfl_dn_2: 0.4115 (0.4128)  loss_bbox_dn_2: 0.1488 (0.1494)  loss_giou_dn_2: 0.4862 (0.4959)  loss_vfl_dn_3: 0.4040 (0.4049)  loss_bbox_dn_3: 0.1455 (0.1465)  loss_giou_dn_3: 0.4792 (0.4891)  loss_vfl_dn_4: 0.4048 (0.4051)  loss_bbox_dn_4: 0.1456 (0.1466)  loss_giou_dn_4: 0.4781 (0.4878)  loss_vfl_dn_5: 0.4047 (0.4053)  loss_bbox_dn_5: 0.1455 (0.1466)  loss_giou_dn_5: 0.4782 (0.4877)  loss_vfl_enc_0: 0.9345 (0.9307)  loss_bbox_enc_0: 0.2286 (0.2395)  loss_giou_enc_0: 0.6607 (0.6757)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4727  data: 1.4123  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4651  data: 0.7226  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4832 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [92]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 16.7224 (16.7224)  loss_vfl: 0.4904 (0.4904)  loss_bbox: 0.1774 (0.1774)  loss_giou: 0.6057 (0.6057)  loss_vfl_aux_0: 1.0096 (1.0096)  loss_bbox_aux_0: 0.1894 (0.1894)  loss_giou_aux_0: 0.6014 (0.6014)  loss_vfl_aux_1: 0.6987 (0.6987)  loss_bbox_aux_1: 0.1931 (0.1931)  loss_giou_aux_1: 0.6257 (0.6257)  loss_vfl_aux_2: 0.5133 (0.5133)  loss_bbox_aux_2: 0.2002 (0.2002)  loss_giou_aux_2: 0.6301 (0.6301)  loss_vfl_aux_3: 0.4911 (0.4911)  loss_bbox_aux_3: 0.1823 (0.1823)  loss_giou_aux_3: 0.6105 (0.6105)  loss_vfl_aux_4: 0.4867 (0.4867)  loss_bbox_aux_4: 0.1801 (0.1801)  loss_giou_aux_4: 0.6043 (0.6043)  loss_vfl_dn_0: 0.4983 (0.4983)  loss_bbox_dn_0: 0.1672 (0.1672)  loss_giou_dn_0: 0.5893 (0.5893)  loss_vfl_dn_1: 0.4383 (0.4383)  loss_bbox_dn_1: 0.1400 (0.1400)  loss_giou_dn_1: 0.5199 (0.5199)  loss_vfl_dn_2: 0.4098 (0.4098)  loss_bbox_dn_2: 0.1295 (0.1295)  loss_giou_dn_2: 0.4923 (0.4923)  loss_vfl_dn_3: 0.4006 (0.4006)  loss_bbox_dn_3: 0.1264 (0.1264)  loss_giou_dn_3: 0.4898 (0.4898)  loss_vfl_dn_4: 0.4039 (0.4039)  loss_bbox_dn_4: 0.1263 (0.1263)  loss_giou_dn_4: 0.4878 (0.4878)  loss_vfl_dn_5: 0.4021 (0.4021)  loss_bbox_dn_5: 0.1260 (0.1260)  loss_giou_dn_5: 0.4866 (0.4866)  loss_vfl_enc_0: 0.9154 (0.9154)  loss_bbox_enc_0: 0.2115 (0.2115)  loss_giou_enc_0: 0.6713 (0.6713)  time: 1.4163  data: 0.8683  max mem: 16811\n",
            "Epoch: [92]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.7619 (16.8879)  loss_vfl: 0.4863 (0.4875)  loss_bbox: 0.2010 (0.1981)  loss_giou: 0.5876 (0.5963)  loss_vfl_aux_0: 1.0174 (1.0238)  loss_bbox_aux_0: 0.1978 (0.2072)  loss_giou_aux_0: 0.5823 (0.5929)  loss_vfl_aux_1: 0.6746 (0.6758)  loss_bbox_aux_1: 0.2155 (0.2205)  loss_giou_aux_1: 0.6186 (0.6245)  loss_vfl_aux_2: 0.5107 (0.5068)  loss_bbox_aux_2: 0.2106 (0.2130)  loss_giou_aux_2: 0.6100 (0.6218)  loss_vfl_aux_3: 0.4886 (0.4882)  loss_bbox_aux_3: 0.2026 (0.2026)  loss_giou_aux_3: 0.6048 (0.6110)  loss_vfl_aux_4: 0.4881 (0.4905)  loss_bbox_aux_4: 0.2004 (0.1991)  loss_giou_aux_4: 0.5916 (0.5997)  loss_vfl_dn_0: 0.5003 (0.5011)  loss_bbox_dn_0: 0.1772 (0.1798)  loss_giou_dn_0: 0.5616 (0.5675)  loss_vfl_dn_1: 0.4355 (0.4370)  loss_bbox_dn_1: 0.1532 (0.1556)  loss_giou_dn_1: 0.4974 (0.5089)  loss_vfl_dn_2: 0.4098 (0.4119)  loss_bbox_dn_2: 0.1450 (0.1458)  loss_giou_dn_2: 0.4793 (0.4889)  loss_vfl_dn_3: 0.4039 (0.4047)  loss_bbox_dn_3: 0.1450 (0.1440)  loss_giou_dn_3: 0.4763 (0.4859)  loss_vfl_dn_4: 0.4039 (0.4060)  loss_bbox_dn_4: 0.1448 (0.1437)  loss_giou_dn_4: 0.4751 (0.4834)  loss_vfl_dn_5: 0.4021 (0.4042)  loss_bbox_dn_5: 0.1442 (0.1433)  loss_giou_dn_5: 0.4723 (0.4814)  loss_vfl_enc_0: 0.9254 (0.9397)  loss_bbox_enc_0: 0.2242 (0.2323)  loss_giou_enc_0: 0.6565 (0.6635)  time: 0.6542  data: 0.1377  max mem: 16811\n",
            "Epoch: [92] Total time: 0:00:05 (0.6596 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.7619 (16.8879)  loss_vfl: 0.4863 (0.4875)  loss_bbox: 0.2010 (0.1981)  loss_giou: 0.5876 (0.5963)  loss_vfl_aux_0: 1.0174 (1.0238)  loss_bbox_aux_0: 0.1978 (0.2072)  loss_giou_aux_0: 0.5823 (0.5929)  loss_vfl_aux_1: 0.6746 (0.6758)  loss_bbox_aux_1: 0.2155 (0.2205)  loss_giou_aux_1: 0.6186 (0.6245)  loss_vfl_aux_2: 0.5107 (0.5068)  loss_bbox_aux_2: 0.2106 (0.2130)  loss_giou_aux_2: 0.6100 (0.6218)  loss_vfl_aux_3: 0.4886 (0.4882)  loss_bbox_aux_3: 0.2026 (0.2026)  loss_giou_aux_3: 0.6048 (0.6110)  loss_vfl_aux_4: 0.4881 (0.4905)  loss_bbox_aux_4: 0.2004 (0.1991)  loss_giou_aux_4: 0.5916 (0.5997)  loss_vfl_dn_0: 0.5003 (0.5011)  loss_bbox_dn_0: 0.1772 (0.1798)  loss_giou_dn_0: 0.5616 (0.5675)  loss_vfl_dn_1: 0.4355 (0.4370)  loss_bbox_dn_1: 0.1532 (0.1556)  loss_giou_dn_1: 0.4974 (0.5089)  loss_vfl_dn_2: 0.4098 (0.4119)  loss_bbox_dn_2: 0.1450 (0.1458)  loss_giou_dn_2: 0.4793 (0.4889)  loss_vfl_dn_3: 0.4039 (0.4047)  loss_bbox_dn_3: 0.1450 (0.1440)  loss_giou_dn_3: 0.4763 (0.4859)  loss_vfl_dn_4: 0.4039 (0.4060)  loss_bbox_dn_4: 0.1448 (0.1437)  loss_giou_dn_4: 0.4751 (0.4834)  loss_vfl_dn_5: 0.4021 (0.4042)  loss_bbox_dn_5: 0.1442 (0.1433)  loss_giou_dn_5: 0.4723 (0.4814)  loss_vfl_enc_0: 0.9254 (0.9397)  loss_bbox_enc_0: 0.2242 (0.2323)  loss_giou_enc_0: 0.6565 (0.6635)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.7317  data: 4.2782  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.0932  data: 2.1562  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1323 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [93]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.8306 (16.8306)  loss_vfl: 0.4807 (0.4807)  loss_bbox: 0.1830 (0.1830)  loss_giou: 0.6159 (0.6159)  loss_vfl_aux_0: 0.9842 (0.9842)  loss_bbox_aux_0: 0.1806 (0.1806)  loss_giou_aux_0: 0.5852 (0.5852)  loss_vfl_aux_1: 0.6472 (0.6472)  loss_bbox_aux_1: 0.1995 (0.1995)  loss_giou_aux_1: 0.6339 (0.6339)  loss_vfl_aux_2: 0.5097 (0.5097)  loss_bbox_aux_2: 0.2002 (0.2002)  loss_giou_aux_2: 0.6386 (0.6386)  loss_vfl_aux_3: 0.4822 (0.4822)  loss_bbox_aux_3: 0.1940 (0.1940)  loss_giou_aux_3: 0.6285 (0.6285)  loss_vfl_aux_4: 0.4841 (0.4841)  loss_bbox_aux_4: 0.1867 (0.1867)  loss_giou_aux_4: 0.6157 (0.6157)  loss_vfl_dn_0: 0.5067 (0.5067)  loss_bbox_dn_0: 0.1697 (0.1697)  loss_giou_dn_0: 0.5931 (0.5931)  loss_vfl_dn_1: 0.4485 (0.4485)  loss_bbox_dn_1: 0.1444 (0.1444)  loss_giou_dn_1: 0.5271 (0.5271)  loss_vfl_dn_2: 0.4223 (0.4223)  loss_bbox_dn_2: 0.1391 (0.1391)  loss_giou_dn_2: 0.5103 (0.5103)  loss_vfl_dn_3: 0.4153 (0.4153)  loss_bbox_dn_3: 0.1381 (0.1381)  loss_giou_dn_3: 0.5056 (0.5056)  loss_vfl_dn_4: 0.4166 (0.4166)  loss_bbox_dn_4: 0.1387 (0.1387)  loss_giou_dn_4: 0.5047 (0.5047)  loss_vfl_dn_5: 0.4154 (0.4154)  loss_bbox_dn_5: 0.1385 (0.1385)  loss_giou_dn_5: 0.5039 (0.5039)  loss_vfl_enc_0: 0.8733 (0.8733)  loss_bbox_enc_0: 0.2037 (0.2037)  loss_giou_enc_0: 0.6657 (0.6657)  time: 1.5089  data: 0.9404  max mem: 16811\n",
            "Epoch: [93]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.8979 (16.9259)  loss_vfl: 0.4807 (0.4862)  loss_bbox: 0.1928 (0.1944)  loss_giou: 0.6004 (0.5995)  loss_vfl_aux_0: 1.0307 (1.0335)  loss_bbox_aux_0: 0.2136 (0.2113)  loss_giou_aux_0: 0.5863 (0.5919)  loss_vfl_aux_1: 0.6585 (0.6658)  loss_bbox_aux_1: 0.2232 (0.2241)  loss_giou_aux_1: 0.6339 (0.6267)  loss_vfl_aux_2: 0.5161 (0.5166)  loss_bbox_aux_2: 0.2158 (0.2159)  loss_giou_aux_2: 0.6260 (0.6275)  loss_vfl_aux_3: 0.4914 (0.4927)  loss_bbox_aux_3: 0.2040 (0.2036)  loss_giou_aux_3: 0.6127 (0.6133)  loss_vfl_aux_4: 0.4892 (0.4925)  loss_bbox_aux_4: 0.1922 (0.1975)  loss_giou_aux_4: 0.6011 (0.6013)  loss_vfl_dn_0: 0.4969 (0.4995)  loss_bbox_dn_0: 0.1777 (0.1795)  loss_giou_dn_0: 0.5721 (0.5715)  loss_vfl_dn_1: 0.4333 (0.4351)  loss_bbox_dn_1: 0.1502 (0.1540)  loss_giou_dn_1: 0.5069 (0.5105)  loss_vfl_dn_2: 0.4108 (0.4120)  loss_bbox_dn_2: 0.1409 (0.1451)  loss_giou_dn_2: 0.4858 (0.4902)  loss_vfl_dn_3: 0.4028 (0.4052)  loss_bbox_dn_3: 0.1388 (0.1429)  loss_giou_dn_3: 0.4843 (0.4859)  loss_vfl_dn_4: 0.4054 (0.4052)  loss_bbox_dn_4: 0.1387 (0.1425)  loss_giou_dn_4: 0.4829 (0.4836)  loss_vfl_dn_5: 0.4028 (0.4042)  loss_bbox_dn_5: 0.1385 (0.1424)  loss_giou_dn_5: 0.4830 (0.4830)  loss_vfl_enc_0: 0.9377 (0.9355)  loss_bbox_enc_0: 0.2320 (0.2362)  loss_giou_enc_0: 0.6657 (0.6676)  time: 0.6584  data: 0.1429  max mem: 16811\n",
            "Epoch: [93] Total time: 0:00:05 (0.6658 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.8979 (16.9259)  loss_vfl: 0.4807 (0.4862)  loss_bbox: 0.1928 (0.1944)  loss_giou: 0.6004 (0.5995)  loss_vfl_aux_0: 1.0307 (1.0335)  loss_bbox_aux_0: 0.2136 (0.2113)  loss_giou_aux_0: 0.5863 (0.5919)  loss_vfl_aux_1: 0.6585 (0.6658)  loss_bbox_aux_1: 0.2232 (0.2241)  loss_giou_aux_1: 0.6339 (0.6267)  loss_vfl_aux_2: 0.5161 (0.5166)  loss_bbox_aux_2: 0.2158 (0.2159)  loss_giou_aux_2: 0.6260 (0.6275)  loss_vfl_aux_3: 0.4914 (0.4927)  loss_bbox_aux_3: 0.2040 (0.2036)  loss_giou_aux_3: 0.6127 (0.6133)  loss_vfl_aux_4: 0.4892 (0.4925)  loss_bbox_aux_4: 0.1922 (0.1975)  loss_giou_aux_4: 0.6011 (0.6013)  loss_vfl_dn_0: 0.4969 (0.4995)  loss_bbox_dn_0: 0.1777 (0.1795)  loss_giou_dn_0: 0.5721 (0.5715)  loss_vfl_dn_1: 0.4333 (0.4351)  loss_bbox_dn_1: 0.1502 (0.1540)  loss_giou_dn_1: 0.5069 (0.5105)  loss_vfl_dn_2: 0.4108 (0.4120)  loss_bbox_dn_2: 0.1409 (0.1451)  loss_giou_dn_2: 0.4858 (0.4902)  loss_vfl_dn_3: 0.4028 (0.4052)  loss_bbox_dn_3: 0.1388 (0.1429)  loss_giou_dn_3: 0.4843 (0.4859)  loss_vfl_dn_4: 0.4054 (0.4052)  loss_bbox_dn_4: 0.1387 (0.1425)  loss_giou_dn_4: 0.4829 (0.4836)  loss_vfl_dn_5: 0.4028 (0.4042)  loss_bbox_dn_5: 0.1385 (0.1424)  loss_giou_dn_5: 0.4830 (0.4830)  loss_vfl_enc_0: 0.9377 (0.9355)  loss_bbox_enc_0: 0.2320 (0.2362)  loss_giou_enc_0: 0.6657 (0.6676)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4559  data: 1.3834  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4545  data: 0.7086  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4728 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            "best_stat: {'epoch': 80, 'coco_eval_bbox': 0.31102631360012806}\n",
            "Epoch: [94]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 17.3918 (17.3918)  loss_vfl: 0.4797 (0.4797)  loss_bbox: 0.2029 (0.2029)  loss_giou: 0.6249 (0.6249)  loss_vfl_aux_0: 0.9749 (0.9749)  loss_bbox_aux_0: 0.2123 (0.2123)  loss_giou_aux_0: 0.6286 (0.6286)  loss_vfl_aux_1: 0.6518 (0.6518)  loss_bbox_aux_1: 0.2330 (0.2330)  loss_giou_aux_1: 0.6623 (0.6623)  loss_vfl_aux_2: 0.5329 (0.5329)  loss_bbox_aux_2: 0.2170 (0.2170)  loss_giou_aux_2: 0.6513 (0.6513)  loss_vfl_aux_3: 0.4978 (0.4978)  loss_bbox_aux_3: 0.2159 (0.2159)  loss_giou_aux_3: 0.6471 (0.6471)  loss_vfl_aux_4: 0.4955 (0.4955)  loss_bbox_aux_4: 0.2097 (0.2097)  loss_giou_aux_4: 0.6229 (0.6229)  loss_vfl_dn_0: 0.5013 (0.5013)  loss_bbox_dn_0: 0.1856 (0.1856)  loss_giou_dn_0: 0.5897 (0.5897)  loss_vfl_dn_1: 0.4410 (0.4410)  loss_bbox_dn_1: 0.1674 (0.1674)  loss_giou_dn_1: 0.5420 (0.5420)  loss_vfl_dn_2: 0.4300 (0.4300)  loss_bbox_dn_2: 0.1568 (0.1568)  loss_giou_dn_2: 0.5188 (0.5188)  loss_vfl_dn_3: 0.4231 (0.4231)  loss_bbox_dn_3: 0.1566 (0.1566)  loss_giou_dn_3: 0.5190 (0.5190)  loss_vfl_dn_4: 0.4204 (0.4204)  loss_bbox_dn_4: 0.1567 (0.1567)  loss_giou_dn_4: 0.5185 (0.5185)  loss_vfl_dn_5: 0.4172 (0.4172)  loss_bbox_dn_5: 0.1562 (0.1562)  loss_giou_dn_5: 0.5167 (0.5167)  loss_vfl_enc_0: 0.9035 (0.9035)  loss_bbox_enc_0: 0.2244 (0.2244)  loss_giou_enc_0: 0.6862 (0.6862)  time: 1.5013  data: 0.9402  max mem: 16811\n",
            "Epoch: [94]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.6102 (16.7508)  loss_vfl: 0.4797 (0.4845)  loss_bbox: 0.1896 (0.1921)  loss_giou: 0.5711 (0.5816)  loss_vfl_aux_0: 1.0192 (1.0293)  loss_bbox_aux_0: 0.1977 (0.2047)  loss_giou_aux_0: 0.5606 (0.5803)  loss_vfl_aux_1: 0.6519 (0.6719)  loss_bbox_aux_1: 0.2086 (0.2156)  loss_giou_aux_1: 0.5825 (0.6139)  loss_vfl_aux_2: 0.5151 (0.5187)  loss_bbox_aux_2: 0.2104 (0.2092)  loss_giou_aux_2: 0.5949 (0.6094)  loss_vfl_aux_3: 0.4885 (0.4902)  loss_bbox_aux_3: 0.1986 (0.2016)  loss_giou_aux_3: 0.5829 (0.5995)  loss_vfl_aux_4: 0.4923 (0.4925)  loss_bbox_aux_4: 0.1909 (0.1942)  loss_giou_aux_4: 0.5725 (0.5850)  loss_vfl_dn_0: 0.4964 (0.4978)  loss_bbox_dn_0: 0.1757 (0.1754)  loss_giou_dn_0: 0.5612 (0.5650)  loss_vfl_dn_1: 0.4305 (0.4320)  loss_bbox_dn_1: 0.1515 (0.1533)  loss_giou_dn_1: 0.5048 (0.5109)  loss_vfl_dn_2: 0.4063 (0.4091)  loss_bbox_dn_2: 0.1421 (0.1437)  loss_giou_dn_2: 0.4829 (0.4870)  loss_vfl_dn_3: 0.3976 (0.4009)  loss_bbox_dn_3: 0.1405 (0.1428)  loss_giou_dn_3: 0.4806 (0.4850)  loss_vfl_dn_4: 0.3998 (0.4019)  loss_bbox_dn_4: 0.1393 (0.1423)  loss_giou_dn_4: 0.4814 (0.4828)  loss_vfl_dn_5: 0.3992 (0.4010)  loss_bbox_dn_5: 0.1396 (0.1422)  loss_giou_dn_5: 0.4800 (0.4819)  loss_vfl_enc_0: 0.9271 (0.9350)  loss_bbox_enc_0: 0.2244 (0.2275)  loss_giou_enc_0: 0.6444 (0.6591)  time: 0.6556  data: 0.1419  max mem: 16811\n",
            "Epoch: [94] Total time: 0:00:05 (0.6612 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.6102 (16.7508)  loss_vfl: 0.4797 (0.4845)  loss_bbox: 0.1896 (0.1921)  loss_giou: 0.5711 (0.5816)  loss_vfl_aux_0: 1.0192 (1.0293)  loss_bbox_aux_0: 0.1977 (0.2047)  loss_giou_aux_0: 0.5606 (0.5803)  loss_vfl_aux_1: 0.6519 (0.6719)  loss_bbox_aux_1: 0.2086 (0.2156)  loss_giou_aux_1: 0.5825 (0.6139)  loss_vfl_aux_2: 0.5151 (0.5187)  loss_bbox_aux_2: 0.2104 (0.2092)  loss_giou_aux_2: 0.5949 (0.6094)  loss_vfl_aux_3: 0.4885 (0.4902)  loss_bbox_aux_3: 0.1986 (0.2016)  loss_giou_aux_3: 0.5829 (0.5995)  loss_vfl_aux_4: 0.4923 (0.4925)  loss_bbox_aux_4: 0.1909 (0.1942)  loss_giou_aux_4: 0.5725 (0.5850)  loss_vfl_dn_0: 0.4964 (0.4978)  loss_bbox_dn_0: 0.1757 (0.1754)  loss_giou_dn_0: 0.5612 (0.5650)  loss_vfl_dn_1: 0.4305 (0.4320)  loss_bbox_dn_1: 0.1515 (0.1533)  loss_giou_dn_1: 0.5048 (0.5109)  loss_vfl_dn_2: 0.4063 (0.4091)  loss_bbox_dn_2: 0.1421 (0.1437)  loss_giou_dn_2: 0.4829 (0.4870)  loss_vfl_dn_3: 0.3976 (0.4009)  loss_bbox_dn_3: 0.1405 (0.1428)  loss_giou_dn_3: 0.4806 (0.4850)  loss_vfl_dn_4: 0.3998 (0.4019)  loss_bbox_dn_4: 0.1393 (0.1423)  loss_giou_dn_4: 0.4814 (0.4828)  loss_vfl_dn_5: 0.3992 (0.4010)  loss_bbox_dn_5: 0.1396 (0.1422)  loss_giou_dn_5: 0.4800 (0.4819)  loss_vfl_enc_0: 0.9271 (0.9350)  loss_bbox_enc_0: 0.2244 (0.2275)  loss_giou_enc_0: 0.6444 (0.6591)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.7850  data: 4.3821  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1177  data: 2.2081  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1387 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
            "best_stat: {'epoch': 94, 'coco_eval_bbox': 0.31461822633462877}\n",
            "Epoch: [95]  [0/8]  eta: 0:00:24  lr: 0.000004  loss: 16.6887 (16.6887)  loss_vfl: 0.5187 (0.5187)  loss_bbox: 0.1680 (0.1680)  loss_giou: 0.5691 (0.5691)  loss_vfl_aux_0: 1.1403 (1.1403)  loss_bbox_aux_0: 0.1658 (0.1658)  loss_giou_aux_0: 0.5434 (0.5434)  loss_vfl_aux_1: 0.7214 (0.7214)  loss_bbox_aux_1: 0.1888 (0.1888)  loss_giou_aux_1: 0.5972 (0.5972)  loss_vfl_aux_2: 0.5538 (0.5538)  loss_bbox_aux_2: 0.1756 (0.1756)  loss_giou_aux_2: 0.5938 (0.5938)  loss_vfl_aux_3: 0.5292 (0.5292)  loss_bbox_aux_3: 0.1717 (0.1717)  loss_giou_aux_3: 0.5855 (0.5855)  loss_vfl_aux_4: 0.5229 (0.5229)  loss_bbox_aux_4: 0.1701 (0.1701)  loss_giou_aux_4: 0.5772 (0.5772)  loss_vfl_dn_0: 0.4902 (0.4902)  loss_bbox_dn_0: 0.1616 (0.1616)  loss_giou_dn_0: 0.5564 (0.5564)  loss_vfl_dn_1: 0.4263 (0.4263)  loss_bbox_dn_1: 0.1376 (0.1376)  loss_giou_dn_1: 0.5057 (0.5057)  loss_vfl_dn_2: 0.4035 (0.4035)  loss_bbox_dn_2: 0.1325 (0.1325)  loss_giou_dn_2: 0.4901 (0.4901)  loss_vfl_dn_3: 0.3954 (0.3954)  loss_bbox_dn_3: 0.1317 (0.1317)  loss_giou_dn_3: 0.4906 (0.4906)  loss_vfl_dn_4: 0.3948 (0.3948)  loss_bbox_dn_4: 0.1317 (0.1317)  loss_giou_dn_4: 0.4893 (0.4893)  loss_vfl_dn_5: 0.3931 (0.3931)  loss_bbox_dn_5: 0.1315 (0.1315)  loss_giou_dn_5: 0.4877 (0.4877)  loss_vfl_enc_0: 1.0035 (1.0035)  loss_bbox_enc_0: 0.2087 (0.2087)  loss_giou_enc_0: 0.6340 (0.6340)  time: 3.0739  data: 2.4881  max mem: 16811\n",
            "Epoch: [95]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.6859 (16.6829)  loss_vfl: 0.4796 (0.4876)  loss_bbox: 0.1825 (0.1878)  loss_giou: 0.5734 (0.5748)  loss_vfl_aux_0: 1.0083 (1.0372)  loss_bbox_aux_0: 0.1956 (0.1971)  loss_giou_aux_0: 0.5792 (0.5754)  loss_vfl_aux_1: 0.6405 (0.6549)  loss_bbox_aux_1: 0.2048 (0.2097)  loss_giou_aux_1: 0.6040 (0.6100)  loss_vfl_aux_2: 0.4976 (0.5129)  loss_bbox_aux_2: 0.2057 (0.2035)  loss_giou_aux_2: 0.6054 (0.6070)  loss_vfl_aux_3: 0.4792 (0.4939)  loss_bbox_aux_3: 0.1899 (0.1914)  loss_giou_aux_3: 0.5962 (0.5876)  loss_vfl_aux_4: 0.4785 (0.4906)  loss_bbox_aux_4: 0.1816 (0.1887)  loss_giou_aux_4: 0.5788 (0.5782)  loss_vfl_dn_0: 0.4967 (0.4965)  loss_bbox_dn_0: 0.1812 (0.1768)  loss_giou_dn_0: 0.5569 (0.5621)  loss_vfl_dn_1: 0.4290 (0.4335)  loss_bbox_dn_1: 0.1566 (0.1547)  loss_giou_dn_1: 0.5057 (0.5081)  loss_vfl_dn_2: 0.4072 (0.4126)  loss_bbox_dn_2: 0.1455 (0.1460)  loss_giou_dn_2: 0.4901 (0.4887)  loss_vfl_dn_3: 0.4026 (0.4050)  loss_bbox_dn_3: 0.1428 (0.1438)  loss_giou_dn_3: 0.4882 (0.4843)  loss_vfl_dn_4: 0.4026 (0.4059)  loss_bbox_dn_4: 0.1428 (0.1436)  loss_giou_dn_4: 0.4849 (0.4829)  loss_vfl_dn_5: 0.4041 (0.4065)  loss_bbox_dn_5: 0.1425 (0.1435)  loss_giou_dn_5: 0.4840 (0.4822)  loss_vfl_enc_0: 0.9090 (0.9344)  loss_bbox_enc_0: 0.2189 (0.2276)  loss_giou_enc_0: 0.6495 (0.6557)  time: 0.8582  data: 0.3318  max mem: 16811\n",
            "Epoch: [95] Total time: 0:00:06 (0.8658 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.6859 (16.6829)  loss_vfl: 0.4796 (0.4876)  loss_bbox: 0.1825 (0.1878)  loss_giou: 0.5734 (0.5748)  loss_vfl_aux_0: 1.0083 (1.0372)  loss_bbox_aux_0: 0.1956 (0.1971)  loss_giou_aux_0: 0.5792 (0.5754)  loss_vfl_aux_1: 0.6405 (0.6549)  loss_bbox_aux_1: 0.2048 (0.2097)  loss_giou_aux_1: 0.6040 (0.6100)  loss_vfl_aux_2: 0.4976 (0.5129)  loss_bbox_aux_2: 0.2057 (0.2035)  loss_giou_aux_2: 0.6054 (0.6070)  loss_vfl_aux_3: 0.4792 (0.4939)  loss_bbox_aux_3: 0.1899 (0.1914)  loss_giou_aux_3: 0.5962 (0.5876)  loss_vfl_aux_4: 0.4785 (0.4906)  loss_bbox_aux_4: 0.1816 (0.1887)  loss_giou_aux_4: 0.5788 (0.5782)  loss_vfl_dn_0: 0.4967 (0.4965)  loss_bbox_dn_0: 0.1812 (0.1768)  loss_giou_dn_0: 0.5569 (0.5621)  loss_vfl_dn_1: 0.4290 (0.4335)  loss_bbox_dn_1: 0.1566 (0.1547)  loss_giou_dn_1: 0.5057 (0.5081)  loss_vfl_dn_2: 0.4072 (0.4126)  loss_bbox_dn_2: 0.1455 (0.1460)  loss_giou_dn_2: 0.4901 (0.4887)  loss_vfl_dn_3: 0.4026 (0.4050)  loss_bbox_dn_3: 0.1428 (0.1438)  loss_giou_dn_3: 0.4882 (0.4843)  loss_vfl_dn_4: 0.4026 (0.4059)  loss_bbox_dn_4: 0.1428 (0.1436)  loss_giou_dn_4: 0.4849 (0.4829)  loss_vfl_dn_5: 0.4041 (0.4065)  loss_bbox_dn_5: 0.1425 (0.1435)  loss_giou_dn_5: 0.4840 (0.4822)  loss_vfl_enc_0: 0.9090 (0.9344)  loss_bbox_enc_0: 0.2189 (0.2276)  loss_giou_enc_0: 0.6495 (0.6557)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5061  data: 4.4256  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9849  data: 2.2298  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0144 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "best_stat: {'epoch': 94, 'coco_eval_bbox': 0.31461822633462877}\n",
            "Epoch: [96]  [0/8]  eta: 0:00:13  lr: 0.000004  loss: 16.8901 (16.8901)  loss_vfl: 0.4975 (0.4975)  loss_bbox: 0.2049 (0.2049)  loss_giou: 0.5861 (0.5861)  loss_vfl_aux_0: 1.0059 (1.0059)  loss_bbox_aux_0: 0.2142 (0.2142)  loss_giou_aux_0: 0.5889 (0.5889)  loss_vfl_aux_1: 0.6547 (0.6547)  loss_bbox_aux_1: 0.2249 (0.2249)  loss_giou_aux_1: 0.6194 (0.6194)  loss_vfl_aux_2: 0.5315 (0.5315)  loss_bbox_aux_2: 0.2202 (0.2202)  loss_giou_aux_2: 0.6094 (0.6094)  loss_vfl_aux_3: 0.4975 (0.4975)  loss_bbox_aux_3: 0.2089 (0.2089)  loss_giou_aux_3: 0.6010 (0.6010)  loss_vfl_aux_4: 0.4900 (0.4900)  loss_bbox_aux_4: 0.2079 (0.2079)  loss_giou_aux_4: 0.5929 (0.5929)  loss_vfl_dn_0: 0.4850 (0.4850)  loss_bbox_dn_0: 0.1880 (0.1880)  loss_giou_dn_0: 0.5656 (0.5656)  loss_vfl_dn_1: 0.4201 (0.4201)  loss_bbox_dn_1: 0.1688 (0.1688)  loss_giou_dn_1: 0.5111 (0.5111)  loss_vfl_dn_2: 0.4035 (0.4035)  loss_bbox_dn_2: 0.1584 (0.1584)  loss_giou_dn_2: 0.4890 (0.4890)  loss_vfl_dn_3: 0.3929 (0.3929)  loss_bbox_dn_3: 0.1575 (0.1575)  loss_giou_dn_3: 0.4870 (0.4870)  loss_vfl_dn_4: 0.3920 (0.3920)  loss_bbox_dn_4: 0.1579 (0.1579)  loss_giou_dn_4: 0.4846 (0.4846)  loss_vfl_dn_5: 0.3909 (0.3909)  loss_bbox_dn_5: 0.1576 (0.1576)  loss_giou_dn_5: 0.4830 (0.4830)  loss_vfl_enc_0: 0.9176 (0.9176)  loss_bbox_enc_0: 0.2473 (0.2473)  loss_giou_enc_0: 0.6767 (0.6767)  time: 1.6494  data: 1.0695  max mem: 16811\n",
            "Epoch: [96]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.7299 (16.6337)  loss_vfl: 0.4946 (0.4910)  loss_bbox: 0.1904 (0.1893)  loss_giou: 0.5847 (0.5681)  loss_vfl_aux_0: 1.0301 (1.0367)  loss_bbox_aux_0: 0.1968 (0.2006)  loss_giou_aux_0: 0.5698 (0.5657)  loss_vfl_aux_1: 0.6547 (0.6647)  loss_bbox_aux_1: 0.2084 (0.2113)  loss_giou_aux_1: 0.6130 (0.6044)  loss_vfl_aux_2: 0.5315 (0.5315)  loss_bbox_aux_2: 0.1917 (0.2028)  loss_giou_aux_2: 0.6017 (0.5921)  loss_vfl_aux_3: 0.4957 (0.4925)  loss_bbox_aux_3: 0.1955 (0.1941)  loss_giou_aux_3: 0.5996 (0.5848)  loss_vfl_aux_4: 0.4900 (0.4935)  loss_bbox_aux_4: 0.1839 (0.1893)  loss_giou_aux_4: 0.5905 (0.5723)  loss_vfl_dn_0: 0.4903 (0.4960)  loss_bbox_dn_0: 0.1788 (0.1778)  loss_giou_dn_0: 0.5656 (0.5641)  loss_vfl_dn_1: 0.4317 (0.4335)  loss_bbox_dn_1: 0.1515 (0.1537)  loss_giou_dn_1: 0.5104 (0.5054)  loss_vfl_dn_2: 0.4119 (0.4123)  loss_bbox_dn_2: 0.1419 (0.1447)  loss_giou_dn_2: 0.4890 (0.4855)  loss_vfl_dn_3: 0.4043 (0.4035)  loss_bbox_dn_3: 0.1396 (0.1425)  loss_giou_dn_3: 0.4848 (0.4806)  loss_vfl_dn_4: 0.4042 (0.4042)  loss_bbox_dn_4: 0.1374 (0.1420)  loss_giou_dn_4: 0.4814 (0.4777)  loss_vfl_dn_5: 0.4020 (0.4030)  loss_bbox_dn_5: 0.1370 (0.1416)  loss_giou_dn_5: 0.4793 (0.4760)  loss_vfl_enc_0: 0.9357 (0.9318)  loss_bbox_enc_0: 0.2180 (0.2258)  loss_giou_enc_0: 0.6478 (0.6468)  time: 0.6745  data: 0.1543  max mem: 16811\n",
            "Epoch: [96] Total time: 0:00:05 (0.6825 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.7299 (16.6337)  loss_vfl: 0.4946 (0.4910)  loss_bbox: 0.1904 (0.1893)  loss_giou: 0.5847 (0.5681)  loss_vfl_aux_0: 1.0301 (1.0367)  loss_bbox_aux_0: 0.1968 (0.2006)  loss_giou_aux_0: 0.5698 (0.5657)  loss_vfl_aux_1: 0.6547 (0.6647)  loss_bbox_aux_1: 0.2084 (0.2113)  loss_giou_aux_1: 0.6130 (0.6044)  loss_vfl_aux_2: 0.5315 (0.5315)  loss_bbox_aux_2: 0.1917 (0.2028)  loss_giou_aux_2: 0.6017 (0.5921)  loss_vfl_aux_3: 0.4957 (0.4925)  loss_bbox_aux_3: 0.1955 (0.1941)  loss_giou_aux_3: 0.5996 (0.5848)  loss_vfl_aux_4: 0.4900 (0.4935)  loss_bbox_aux_4: 0.1839 (0.1893)  loss_giou_aux_4: 0.5905 (0.5723)  loss_vfl_dn_0: 0.4903 (0.4960)  loss_bbox_dn_0: 0.1788 (0.1778)  loss_giou_dn_0: 0.5656 (0.5641)  loss_vfl_dn_1: 0.4317 (0.4335)  loss_bbox_dn_1: 0.1515 (0.1537)  loss_giou_dn_1: 0.5104 (0.5054)  loss_vfl_dn_2: 0.4119 (0.4123)  loss_bbox_dn_2: 0.1419 (0.1447)  loss_giou_dn_2: 0.4890 (0.4855)  loss_vfl_dn_3: 0.4043 (0.4035)  loss_bbox_dn_3: 0.1396 (0.1425)  loss_giou_dn_3: 0.4848 (0.4806)  loss_vfl_dn_4: 0.4042 (0.4042)  loss_bbox_dn_4: 0.1374 (0.1420)  loss_giou_dn_4: 0.4814 (0.4777)  loss_vfl_dn_5: 0.4020 (0.4030)  loss_bbox_dn_5: 0.1370 (0.1416)  loss_giou_dn_5: 0.4793 (0.4760)  loss_vfl_enc_0: 0.9357 (0.9318)  loss_bbox_enc_0: 0.2180 (0.2258)  loss_giou_enc_0: 0.6478 (0.6468)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4579  data: 1.3785  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4535  data: 0.7057  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4789 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [97]  [0/8]  eta: 0:00:31  lr: 0.000004  loss: 16.9234 (16.9234)  loss_vfl: 0.4827 (0.4827)  loss_bbox: 0.1935 (0.1935)  loss_giou: 0.6095 (0.6095)  loss_vfl_aux_0: 0.9698 (0.9698)  loss_bbox_aux_0: 0.1933 (0.1933)  loss_giou_aux_0: 0.5884 (0.5884)  loss_vfl_aux_1: 0.6520 (0.6520)  loss_bbox_aux_1: 0.2049 (0.2049)  loss_giou_aux_1: 0.6235 (0.6235)  loss_vfl_aux_2: 0.5219 (0.5219)  loss_bbox_aux_2: 0.2037 (0.2037)  loss_giou_aux_2: 0.6243 (0.6243)  loss_vfl_aux_3: 0.4937 (0.4937)  loss_bbox_aux_3: 0.1965 (0.1965)  loss_giou_aux_3: 0.6091 (0.6091)  loss_vfl_aux_4: 0.4862 (0.4862)  loss_bbox_aux_4: 0.1923 (0.1923)  loss_giou_aux_4: 0.6110 (0.6110)  loss_vfl_dn_0: 0.5037 (0.5037)  loss_bbox_dn_0: 0.1842 (0.1842)  loss_giou_dn_0: 0.5983 (0.5983)  loss_vfl_dn_1: 0.4433 (0.4433)  loss_bbox_dn_1: 0.1555 (0.1555)  loss_giou_dn_1: 0.5417 (0.5417)  loss_vfl_dn_2: 0.4236 (0.4236)  loss_bbox_dn_2: 0.1484 (0.1484)  loss_giou_dn_2: 0.5222 (0.5222)  loss_vfl_dn_3: 0.4129 (0.4129)  loss_bbox_dn_3: 0.1445 (0.1445)  loss_giou_dn_3: 0.5130 (0.5130)  loss_vfl_dn_4: 0.4131 (0.4131)  loss_bbox_dn_4: 0.1454 (0.1454)  loss_giou_dn_4: 0.5107 (0.5107)  loss_vfl_dn_5: 0.4122 (0.4122)  loss_bbox_dn_5: 0.1450 (0.1450)  loss_giou_dn_5: 0.5099 (0.5099)  loss_vfl_enc_0: 0.8665 (0.8665)  loss_bbox_enc_0: 0.2109 (0.2109)  loss_giou_enc_0: 0.6624 (0.6624)  time: 3.9181  data: 3.3611  max mem: 16811\n",
            "Epoch: [97]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.4061 (16.4634)  loss_vfl: 0.4810 (0.4808)  loss_bbox: 0.1891 (0.1845)  loss_giou: 0.5579 (0.5672)  loss_vfl_aux_0: 1.0396 (1.0385)  loss_bbox_aux_0: 0.1933 (0.1986)  loss_giou_aux_0: 0.5742 (0.5712)  loss_vfl_aux_1: 0.6759 (0.6763)  loss_bbox_aux_1: 0.2080 (0.2098)  loss_giou_aux_1: 0.6055 (0.6050)  loss_vfl_aux_2: 0.5194 (0.5166)  loss_bbox_aux_2: 0.2037 (0.2009)  loss_giou_aux_2: 0.5966 (0.5940)  loss_vfl_aux_3: 0.4746 (0.4817)  loss_bbox_aux_3: 0.1950 (0.1917)  loss_giou_aux_3: 0.5835 (0.5843)  loss_vfl_aux_4: 0.4860 (0.4859)  loss_bbox_aux_4: 0.1910 (0.1854)  loss_giou_aux_4: 0.5701 (0.5711)  loss_vfl_dn_0: 0.4961 (0.4970)  loss_bbox_dn_0: 0.1694 (0.1714)  loss_giou_dn_0: 0.5464 (0.5510)  loss_vfl_dn_1: 0.4301 (0.4324)  loss_bbox_dn_1: 0.1471 (0.1474)  loss_giou_dn_1: 0.4814 (0.4942)  loss_vfl_dn_2: 0.4023 (0.4074)  loss_bbox_dn_2: 0.1398 (0.1395)  loss_giou_dn_2: 0.4605 (0.4739)  loss_vfl_dn_3: 0.3929 (0.3988)  loss_bbox_dn_3: 0.1369 (0.1374)  loss_giou_dn_3: 0.4550 (0.4687)  loss_vfl_dn_4: 0.3926 (0.3991)  loss_bbox_dn_4: 0.1362 (0.1370)  loss_giou_dn_4: 0.4513 (0.4655)  loss_vfl_dn_5: 0.3925 (0.3984)  loss_bbox_dn_5: 0.1357 (0.1367)  loss_giou_dn_5: 0.4511 (0.4645)  loss_vfl_enc_0: 0.9165 (0.9281)  loss_bbox_enc_0: 0.2194 (0.2227)  loss_giou_enc_0: 0.6526 (0.6487)  time: 0.9500  data: 0.4366  max mem: 16811\n",
            "Epoch: [97] Total time: 0:00:07 (0.9554 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.4061 (16.4634)  loss_vfl: 0.4810 (0.4808)  loss_bbox: 0.1891 (0.1845)  loss_giou: 0.5579 (0.5672)  loss_vfl_aux_0: 1.0396 (1.0385)  loss_bbox_aux_0: 0.1933 (0.1986)  loss_giou_aux_0: 0.5742 (0.5712)  loss_vfl_aux_1: 0.6759 (0.6763)  loss_bbox_aux_1: 0.2080 (0.2098)  loss_giou_aux_1: 0.6055 (0.6050)  loss_vfl_aux_2: 0.5194 (0.5166)  loss_bbox_aux_2: 0.2037 (0.2009)  loss_giou_aux_2: 0.5966 (0.5940)  loss_vfl_aux_3: 0.4746 (0.4817)  loss_bbox_aux_3: 0.1950 (0.1917)  loss_giou_aux_3: 0.5835 (0.5843)  loss_vfl_aux_4: 0.4860 (0.4859)  loss_bbox_aux_4: 0.1910 (0.1854)  loss_giou_aux_4: 0.5701 (0.5711)  loss_vfl_dn_0: 0.4961 (0.4970)  loss_bbox_dn_0: 0.1694 (0.1714)  loss_giou_dn_0: 0.5464 (0.5510)  loss_vfl_dn_1: 0.4301 (0.4324)  loss_bbox_dn_1: 0.1471 (0.1474)  loss_giou_dn_1: 0.4814 (0.4942)  loss_vfl_dn_2: 0.4023 (0.4074)  loss_bbox_dn_2: 0.1398 (0.1395)  loss_giou_dn_2: 0.4605 (0.4739)  loss_vfl_dn_3: 0.3929 (0.3988)  loss_bbox_dn_3: 0.1369 (0.1374)  loss_giou_dn_3: 0.4550 (0.4687)  loss_vfl_dn_4: 0.3926 (0.3991)  loss_bbox_dn_4: 0.1362 (0.1370)  loss_giou_dn_4: 0.4513 (0.4655)  loss_vfl_dn_5: 0.3925 (0.3984)  loss_bbox_dn_5: 0.1357 (0.1367)  loss_giou_dn_5: 0.4511 (0.4645)  loss_vfl_enc_0: 0.9165 (0.9281)  loss_bbox_enc_0: 0.2194 (0.2227)  loss_giou_enc_0: 0.6526 (0.6487)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4679  data: 1.3910  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6376  data: 0.7124  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6692 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [98]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 16.1884 (16.1884)  loss_vfl: 0.4651 (0.4651)  loss_bbox: 0.1798 (0.1798)  loss_giou: 0.5462 (0.5462)  loss_vfl_aux_0: 1.0380 (1.0380)  loss_bbox_aux_0: 0.1928 (0.1928)  loss_giou_aux_0: 0.5536 (0.5536)  loss_vfl_aux_1: 0.6671 (0.6671)  loss_bbox_aux_1: 0.1986 (0.1986)  loss_giou_aux_1: 0.5823 (0.5823)  loss_vfl_aux_2: 0.4980 (0.4980)  loss_bbox_aux_2: 0.1990 (0.1990)  loss_giou_aux_2: 0.5781 (0.5781)  loss_vfl_aux_3: 0.4661 (0.4661)  loss_bbox_aux_3: 0.1905 (0.1905)  loss_giou_aux_3: 0.5734 (0.5734)  loss_vfl_aux_4: 0.4736 (0.4736)  loss_bbox_aux_4: 0.1800 (0.1800)  loss_giou_aux_4: 0.5519 (0.5519)  loss_vfl_dn_0: 0.4930 (0.4930)  loss_bbox_dn_0: 0.1762 (0.1762)  loss_giou_dn_0: 0.5538 (0.5538)  loss_vfl_dn_1: 0.4331 (0.4331)  loss_bbox_dn_1: 0.1502 (0.1502)  loss_giou_dn_1: 0.4877 (0.4877)  loss_vfl_dn_2: 0.4096 (0.4096)  loss_bbox_dn_2: 0.1392 (0.1392)  loss_giou_dn_2: 0.4644 (0.4644)  loss_vfl_dn_3: 0.3983 (0.3983)  loss_bbox_dn_3: 0.1368 (0.1368)  loss_giou_dn_3: 0.4593 (0.4593)  loss_vfl_dn_4: 0.4014 (0.4014)  loss_bbox_dn_4: 0.1371 (0.1371)  loss_giou_dn_4: 0.4578 (0.4578)  loss_vfl_dn_5: 0.3999 (0.3999)  loss_bbox_dn_5: 0.1369 (0.1369)  loss_giou_dn_5: 0.4565 (0.4565)  loss_vfl_enc_0: 0.9077 (0.9077)  loss_bbox_enc_0: 0.2238 (0.2238)  loss_giou_enc_0: 0.6313 (0.6313)  time: 1.4741  data: 0.9228  max mem: 16811\n",
            "Epoch: [98]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.2919 (16.4188)  loss_vfl: 0.4798 (0.4875)  loss_bbox: 0.1730 (0.1765)  loss_giou: 0.5476 (0.5561)  loss_vfl_aux_0: 1.0351 (1.0361)  loss_bbox_aux_0: 0.1862 (0.1941)  loss_giou_aux_0: 0.5483 (0.5640)  loss_vfl_aux_1: 0.6671 (0.6693)  loss_bbox_aux_1: 0.1979 (0.2024)  loss_giou_aux_1: 0.5777 (0.5939)  loss_vfl_aux_2: 0.5262 (0.5251)  loss_bbox_aux_2: 0.1907 (0.1937)  loss_giou_aux_2: 0.5710 (0.5824)  loss_vfl_aux_3: 0.4827 (0.4915)  loss_bbox_aux_3: 0.1792 (0.1851)  loss_giou_aux_3: 0.5605 (0.5746)  loss_vfl_aux_4: 0.4885 (0.4935)  loss_bbox_aux_4: 0.1749 (0.1771)  loss_giou_aux_4: 0.5508 (0.5601)  loss_vfl_dn_0: 0.4922 (0.4929)  loss_bbox_dn_0: 0.1762 (0.1739)  loss_giou_dn_0: 0.5538 (0.5587)  loss_vfl_dn_1: 0.4302 (0.4310)  loss_bbox_dn_1: 0.1502 (0.1501)  loss_giou_dn_1: 0.4877 (0.4968)  loss_vfl_dn_2: 0.4054 (0.4076)  loss_bbox_dn_2: 0.1392 (0.1413)  loss_giou_dn_2: 0.4652 (0.4766)  loss_vfl_dn_3: 0.3992 (0.3994)  loss_bbox_dn_3: 0.1368 (0.1392)  loss_giou_dn_3: 0.4619 (0.4721)  loss_vfl_dn_4: 0.4010 (0.4003)  loss_bbox_dn_4: 0.1371 (0.1387)  loss_giou_dn_4: 0.4619 (0.4701)  loss_vfl_dn_5: 0.3999 (0.3993)  loss_bbox_dn_5: 0.1369 (0.1385)  loss_giou_dn_5: 0.4607 (0.4690)  loss_vfl_enc_0: 0.9350 (0.9324)  loss_bbox_enc_0: 0.2062 (0.2201)  loss_giou_enc_0: 0.6322 (0.6481)  time: 0.6583  data: 0.1451  max mem: 16811\n",
            "Epoch: [98] Total time: 0:00:05 (0.6659 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.2919 (16.4188)  loss_vfl: 0.4798 (0.4875)  loss_bbox: 0.1730 (0.1765)  loss_giou: 0.5476 (0.5561)  loss_vfl_aux_0: 1.0351 (1.0361)  loss_bbox_aux_0: 0.1862 (0.1941)  loss_giou_aux_0: 0.5483 (0.5640)  loss_vfl_aux_1: 0.6671 (0.6693)  loss_bbox_aux_1: 0.1979 (0.2024)  loss_giou_aux_1: 0.5777 (0.5939)  loss_vfl_aux_2: 0.5262 (0.5251)  loss_bbox_aux_2: 0.1907 (0.1937)  loss_giou_aux_2: 0.5710 (0.5824)  loss_vfl_aux_3: 0.4827 (0.4915)  loss_bbox_aux_3: 0.1792 (0.1851)  loss_giou_aux_3: 0.5605 (0.5746)  loss_vfl_aux_4: 0.4885 (0.4935)  loss_bbox_aux_4: 0.1749 (0.1771)  loss_giou_aux_4: 0.5508 (0.5601)  loss_vfl_dn_0: 0.4922 (0.4929)  loss_bbox_dn_0: 0.1762 (0.1739)  loss_giou_dn_0: 0.5538 (0.5587)  loss_vfl_dn_1: 0.4302 (0.4310)  loss_bbox_dn_1: 0.1502 (0.1501)  loss_giou_dn_1: 0.4877 (0.4968)  loss_vfl_dn_2: 0.4054 (0.4076)  loss_bbox_dn_2: 0.1392 (0.1413)  loss_giou_dn_2: 0.4652 (0.4766)  loss_vfl_dn_3: 0.3992 (0.3994)  loss_bbox_dn_3: 0.1368 (0.1392)  loss_giou_dn_3: 0.4619 (0.4721)  loss_vfl_dn_4: 0.4010 (0.4003)  loss_bbox_dn_4: 0.1371 (0.1387)  loss_giou_dn_4: 0.4619 (0.4701)  loss_vfl_dn_5: 0.3999 (0.3993)  loss_bbox_dn_5: 0.1369 (0.1385)  loss_giou_dn_5: 0.4607 (0.4690)  loss_vfl_enc_0: 0.9350 (0.9324)  loss_bbox_enc_0: 0.2062 (0.2201)  loss_giou_enc_0: 0.6322 (0.6481)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.9310  data: 1.8462  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6912  data: 0.9397  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.7095 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [99]  [0/8]  eta: 0:00:23  lr: 0.000004  loss: 17.3570 (17.3570)  loss_vfl: 0.4570 (0.4570)  loss_bbox: 0.2223 (0.2223)  loss_giou: 0.6234 (0.6234)  loss_vfl_aux_0: 1.0097 (1.0097)  loss_bbox_aux_0: 0.2358 (0.2358)  loss_giou_aux_0: 0.6245 (0.6245)  loss_vfl_aux_1: 0.6543 (0.6543)  loss_bbox_aux_1: 0.2382 (0.2382)  loss_giou_aux_1: 0.6481 (0.6481)  loss_vfl_aux_2: 0.4919 (0.4919)  loss_bbox_aux_2: 0.2323 (0.2323)  loss_giou_aux_2: 0.6461 (0.6461)  loss_vfl_aux_3: 0.4591 (0.4591)  loss_bbox_aux_3: 0.2316 (0.2316)  loss_giou_aux_3: 0.6381 (0.6381)  loss_vfl_aux_4: 0.4526 (0.4526)  loss_bbox_aux_4: 0.2247 (0.2247)  loss_giou_aux_4: 0.6314 (0.6314)  loss_vfl_dn_0: 0.4837 (0.4837)  loss_bbox_dn_0: 0.1982 (0.1982)  loss_giou_dn_0: 0.5935 (0.5935)  loss_vfl_dn_1: 0.4323 (0.4323)  loss_bbox_dn_1: 0.1786 (0.1786)  loss_giou_dn_1: 0.5441 (0.5441)  loss_vfl_dn_2: 0.4085 (0.4085)  loss_bbox_dn_2: 0.1675 (0.1675)  loss_giou_dn_2: 0.5279 (0.5279)  loss_vfl_dn_3: 0.3986 (0.3986)  loss_bbox_dn_3: 0.1650 (0.1650)  loss_giou_dn_3: 0.5222 (0.5222)  loss_vfl_dn_4: 0.4005 (0.4005)  loss_bbox_dn_4: 0.1656 (0.1656)  loss_giou_dn_4: 0.5207 (0.5207)  loss_vfl_dn_5: 0.4019 (0.4019)  loss_bbox_dn_5: 0.1657 (0.1657)  loss_giou_dn_5: 0.5210 (0.5210)  loss_vfl_enc_0: 0.9088 (0.9088)  loss_bbox_enc_0: 0.2534 (0.2534)  loss_giou_enc_0: 0.6783 (0.6783)  time: 2.9082  data: 2.3132  max mem: 16811\n",
            "Epoch: [99]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 16.1268 (16.2626)  loss_vfl: 0.4668 (0.4763)  loss_bbox: 0.1767 (0.1817)  loss_giou: 0.5529 (0.5580)  loss_vfl_aux_0: 1.0213 (1.0454)  loss_bbox_aux_0: 0.1759 (0.1889)  loss_giou_aux_0: 0.5451 (0.5512)  loss_vfl_aux_1: 0.6543 (0.6681)  loss_bbox_aux_1: 0.1901 (0.2006)  loss_giou_aux_1: 0.5783 (0.5881)  loss_vfl_aux_2: 0.4919 (0.5022)  loss_bbox_aux_2: 0.1917 (0.1951)  loss_giou_aux_2: 0.5725 (0.5810)  loss_vfl_aux_3: 0.4743 (0.4818)  loss_bbox_aux_3: 0.1788 (0.1882)  loss_giou_aux_3: 0.5607 (0.5718)  loss_vfl_aux_4: 0.4759 (0.4812)  loss_bbox_aux_4: 0.1743 (0.1820)  loss_giou_aux_4: 0.5507 (0.5621)  loss_vfl_dn_0: 0.4922 (0.4935)  loss_bbox_dn_0: 0.1608 (0.1671)  loss_giou_dn_0: 0.5318 (0.5442)  loss_vfl_dn_1: 0.4307 (0.4307)  loss_bbox_dn_1: 0.1382 (0.1463)  loss_giou_dn_1: 0.4685 (0.4897)  loss_vfl_dn_2: 0.4003 (0.4045)  loss_bbox_dn_2: 0.1287 (0.1375)  loss_giou_dn_2: 0.4504 (0.4705)  loss_vfl_dn_3: 0.3955 (0.3970)  loss_bbox_dn_3: 0.1289 (0.1356)  loss_giou_dn_3: 0.4510 (0.4661)  loss_vfl_dn_4: 0.3955 (0.3981)  loss_bbox_dn_4: 0.1294 (0.1355)  loss_giou_dn_4: 0.4512 (0.4643)  loss_vfl_dn_5: 0.3944 (0.3975)  loss_bbox_dn_5: 0.1293 (0.1353)  loss_giou_dn_5: 0.4497 (0.4631)  loss_vfl_enc_0: 0.9291 (0.9315)  loss_bbox_enc_0: 0.2080 (0.2158)  loss_giou_enc_0: 0.6284 (0.6348)  time: 0.8345  data: 0.3146  max mem: 16811\n",
            "Epoch: [99] Total time: 0:00:06 (0.8421 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 16.1268 (16.2626)  loss_vfl: 0.4668 (0.4763)  loss_bbox: 0.1767 (0.1817)  loss_giou: 0.5529 (0.5580)  loss_vfl_aux_0: 1.0213 (1.0454)  loss_bbox_aux_0: 0.1759 (0.1889)  loss_giou_aux_0: 0.5451 (0.5512)  loss_vfl_aux_1: 0.6543 (0.6681)  loss_bbox_aux_1: 0.1901 (0.2006)  loss_giou_aux_1: 0.5783 (0.5881)  loss_vfl_aux_2: 0.4919 (0.5022)  loss_bbox_aux_2: 0.1917 (0.1951)  loss_giou_aux_2: 0.5725 (0.5810)  loss_vfl_aux_3: 0.4743 (0.4818)  loss_bbox_aux_3: 0.1788 (0.1882)  loss_giou_aux_3: 0.5607 (0.5718)  loss_vfl_aux_4: 0.4759 (0.4812)  loss_bbox_aux_4: 0.1743 (0.1820)  loss_giou_aux_4: 0.5507 (0.5621)  loss_vfl_dn_0: 0.4922 (0.4935)  loss_bbox_dn_0: 0.1608 (0.1671)  loss_giou_dn_0: 0.5318 (0.5442)  loss_vfl_dn_1: 0.4307 (0.4307)  loss_bbox_dn_1: 0.1382 (0.1463)  loss_giou_dn_1: 0.4685 (0.4897)  loss_vfl_dn_2: 0.4003 (0.4045)  loss_bbox_dn_2: 0.1287 (0.1375)  loss_giou_dn_2: 0.4504 (0.4705)  loss_vfl_dn_3: 0.3955 (0.3970)  loss_bbox_dn_3: 0.1289 (0.1356)  loss_giou_dn_3: 0.4510 (0.4661)  loss_vfl_dn_4: 0.3955 (0.3981)  loss_bbox_dn_4: 0.1294 (0.1355)  loss_giou_dn_4: 0.4512 (0.4643)  loss_vfl_dn_5: 0.3944 (0.3975)  loss_bbox_dn_5: 0.1293 (0.1353)  loss_giou_dn_5: 0.4497 (0.4631)  loss_vfl_enc_0: 0.9291 (0.9315)  loss_bbox_enc_0: 0.2080 (0.2158)  loss_giou_enc_0: 0.6284 (0.6348)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.8874  data: 1.8265  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.8405  data: 0.9295  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.8623 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [100]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 15.9574 (15.9574)  loss_vfl: 0.4745 (0.4745)  loss_bbox: 0.1662 (0.1662)  loss_giou: 0.5233 (0.5233)  loss_vfl_aux_0: 1.0823 (1.0823)  loss_bbox_aux_0: 0.1995 (0.1995)  loss_giou_aux_0: 0.5421 (0.5421)  loss_vfl_aux_1: 0.6818 (0.6818)  loss_bbox_aux_1: 0.2071 (0.2071)  loss_giou_aux_1: 0.5661 (0.5661)  loss_vfl_aux_2: 0.5125 (0.5125)  loss_bbox_aux_2: 0.1765 (0.1765)  loss_giou_aux_2: 0.5494 (0.5494)  loss_vfl_aux_3: 0.4794 (0.4794)  loss_bbox_aux_3: 0.1697 (0.1697)  loss_giou_aux_3: 0.5419 (0.5419)  loss_vfl_aux_4: 0.4807 (0.4807)  loss_bbox_aux_4: 0.1675 (0.1675)  loss_giou_aux_4: 0.5306 (0.5306)  loss_vfl_dn_0: 0.4917 (0.4917)  loss_bbox_dn_0: 0.1670 (0.1670)  loss_giou_dn_0: 0.5189 (0.5189)  loss_vfl_dn_1: 0.4286 (0.4286)  loss_bbox_dn_1: 0.1418 (0.1418)  loss_giou_dn_1: 0.4627 (0.4627)  loss_vfl_dn_2: 0.4052 (0.4052)  loss_bbox_dn_2: 0.1329 (0.1329)  loss_giou_dn_2: 0.4457 (0.4457)  loss_vfl_dn_3: 0.3971 (0.3971)  loss_bbox_dn_3: 0.1309 (0.1309)  loss_giou_dn_3: 0.4442 (0.4442)  loss_vfl_dn_4: 0.3970 (0.3970)  loss_bbox_dn_4: 0.1303 (0.1303)  loss_giou_dn_4: 0.4418 (0.4418)  loss_vfl_dn_5: 0.3974 (0.3974)  loss_bbox_dn_5: 0.1300 (0.1300)  loss_giou_dn_5: 0.4406 (0.4406)  loss_vfl_enc_0: 0.9645 (0.9645)  loss_bbox_enc_0: 0.2241 (0.2241)  loss_giou_enc_0: 0.6139 (0.6139)  time: 1.4634  data: 0.9161  max mem: 16811\n",
            "Epoch: [100]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.9790 (16.0800)  loss_vfl: 0.4693 (0.4693)  loss_bbox: 0.1747 (0.1731)  loss_giou: 0.5430 (0.5458)  loss_vfl_aux_0: 1.0349 (1.0321)  loss_bbox_aux_0: 0.1818 (0.1851)  loss_giou_aux_0: 0.5430 (0.5546)  loss_vfl_aux_1: 0.6442 (0.6577)  loss_bbox_aux_1: 0.1904 (0.1956)  loss_giou_aux_1: 0.5735 (0.5802)  loss_vfl_aux_2: 0.5006 (0.5117)  loss_bbox_aux_2: 0.1814 (0.1846)  loss_giou_aux_2: 0.5576 (0.5684)  loss_vfl_aux_3: 0.4750 (0.4769)  loss_bbox_aux_3: 0.1760 (0.1785)  loss_giou_aux_3: 0.5550 (0.5638)  loss_vfl_aux_4: 0.4738 (0.4742)  loss_bbox_aux_4: 0.1738 (0.1739)  loss_giou_aux_4: 0.5419 (0.5492)  loss_vfl_dn_0: 0.4929 (0.4928)  loss_bbox_dn_0: 0.1651 (0.1645)  loss_giou_dn_0: 0.5343 (0.5428)  loss_vfl_dn_1: 0.4275 (0.4276)  loss_bbox_dn_1: 0.1418 (0.1427)  loss_giou_dn_1: 0.4741 (0.4866)  loss_vfl_dn_2: 0.4052 (0.4047)  loss_bbox_dn_2: 0.1329 (0.1339)  loss_giou_dn_2: 0.4571 (0.4669)  loss_vfl_dn_3: 0.3971 (0.3973)  loss_bbox_dn_3: 0.1309 (0.1324)  loss_giou_dn_3: 0.4522 (0.4636)  loss_vfl_dn_4: 0.3970 (0.3980)  loss_bbox_dn_4: 0.1303 (0.1319)  loss_giou_dn_4: 0.4497 (0.4613)  loss_vfl_dn_5: 0.3974 (0.3966)  loss_bbox_dn_5: 0.1300 (0.1317)  loss_giou_dn_5: 0.4480 (0.4601)  loss_vfl_enc_0: 0.9352 (0.9238)  loss_bbox_enc_0: 0.2114 (0.2114)  loss_giou_enc_0: 0.6242 (0.6346)  time: 0.6581  data: 0.1401  max mem: 16811\n",
            "Epoch: [100] Total time: 0:00:05 (0.6661 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.9790 (16.0800)  loss_vfl: 0.4693 (0.4693)  loss_bbox: 0.1747 (0.1731)  loss_giou: 0.5430 (0.5458)  loss_vfl_aux_0: 1.0349 (1.0321)  loss_bbox_aux_0: 0.1818 (0.1851)  loss_giou_aux_0: 0.5430 (0.5546)  loss_vfl_aux_1: 0.6442 (0.6577)  loss_bbox_aux_1: 0.1904 (0.1956)  loss_giou_aux_1: 0.5735 (0.5802)  loss_vfl_aux_2: 0.5006 (0.5117)  loss_bbox_aux_2: 0.1814 (0.1846)  loss_giou_aux_2: 0.5576 (0.5684)  loss_vfl_aux_3: 0.4750 (0.4769)  loss_bbox_aux_3: 0.1760 (0.1785)  loss_giou_aux_3: 0.5550 (0.5638)  loss_vfl_aux_4: 0.4738 (0.4742)  loss_bbox_aux_4: 0.1738 (0.1739)  loss_giou_aux_4: 0.5419 (0.5492)  loss_vfl_dn_0: 0.4929 (0.4928)  loss_bbox_dn_0: 0.1651 (0.1645)  loss_giou_dn_0: 0.5343 (0.5428)  loss_vfl_dn_1: 0.4275 (0.4276)  loss_bbox_dn_1: 0.1418 (0.1427)  loss_giou_dn_1: 0.4741 (0.4866)  loss_vfl_dn_2: 0.4052 (0.4047)  loss_bbox_dn_2: 0.1329 (0.1339)  loss_giou_dn_2: 0.4571 (0.4669)  loss_vfl_dn_3: 0.3971 (0.3973)  loss_bbox_dn_3: 0.1309 (0.1324)  loss_giou_dn_3: 0.4522 (0.4636)  loss_vfl_dn_4: 0.3970 (0.3980)  loss_bbox_dn_4: 0.1303 (0.1319)  loss_giou_dn_4: 0.4497 (0.4613)  loss_vfl_dn_5: 0.3974 (0.3966)  loss_bbox_dn_5: 0.1300 (0.1317)  loss_giou_dn_5: 0.4480 (0.4601)  loss_vfl_enc_0: 0.9352 (0.9238)  loss_bbox_enc_0: 0.2114 (0.2114)  loss_giou_enc_0: 0.6242 (0.6346)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.4265  data: 3.3310  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.4385  data: 1.6825  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.4721 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [101]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.2586 (16.2586)  loss_vfl: 0.4701 (0.4701)  loss_bbox: 0.1723 (0.1723)  loss_giou: 0.5532 (0.5532)  loss_vfl_aux_0: 1.0352 (1.0352)  loss_bbox_aux_0: 0.1889 (0.1889)  loss_giou_aux_0: 0.5476 (0.5476)  loss_vfl_aux_1: 0.6482 (0.6482)  loss_bbox_aux_1: 0.1950 (0.1950)  loss_giou_aux_1: 0.5884 (0.5884)  loss_vfl_aux_2: 0.5075 (0.5075)  loss_bbox_aux_2: 0.1909 (0.1909)  loss_giou_aux_2: 0.5723 (0.5723)  loss_vfl_aux_3: 0.4853 (0.4853)  loss_bbox_aux_3: 0.1805 (0.1805)  loss_giou_aux_3: 0.5679 (0.5679)  loss_vfl_aux_4: 0.4766 (0.4766)  loss_bbox_aux_4: 0.1741 (0.1741)  loss_giou_aux_4: 0.5541 (0.5541)  loss_vfl_dn_0: 0.4879 (0.4879)  loss_bbox_dn_0: 0.1829 (0.1829)  loss_giou_dn_0: 0.5577 (0.5577)  loss_vfl_dn_1: 0.4364 (0.4364)  loss_bbox_dn_1: 0.1585 (0.1585)  loss_giou_dn_1: 0.4968 (0.4968)  loss_vfl_dn_2: 0.4065 (0.4065)  loss_bbox_dn_2: 0.1464 (0.1464)  loss_giou_dn_2: 0.4740 (0.4740)  loss_vfl_dn_3: 0.3973 (0.3973)  loss_bbox_dn_3: 0.1432 (0.1432)  loss_giou_dn_3: 0.4686 (0.4686)  loss_vfl_dn_4: 0.3963 (0.3963)  loss_bbox_dn_4: 0.1415 (0.1415)  loss_giou_dn_4: 0.4648 (0.4648)  loss_vfl_dn_5: 0.3940 (0.3940)  loss_bbox_dn_5: 0.1411 (0.1411)  loss_giou_dn_5: 0.4638 (0.4638)  loss_vfl_enc_0: 0.9450 (0.9450)  loss_bbox_enc_0: 0.2152 (0.2152)  loss_giou_enc_0: 0.6328 (0.6328)  time: 1.5189  data: 0.9014  max mem: 16811\n",
            "Epoch: [101]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.9782 (16.2028)  loss_vfl: 0.4788 (0.4848)  loss_bbox: 0.1723 (0.1745)  loss_giou: 0.5303 (0.5494)  loss_vfl_aux_0: 1.0352 (1.0398)  loss_bbox_aux_0: 0.1907 (0.1926)  loss_giou_aux_0: 0.5294 (0.5547)  loss_vfl_aux_1: 0.6482 (0.6452)  loss_bbox_aux_1: 0.1950 (0.1979)  loss_giou_aux_1: 0.5593 (0.5829)  loss_vfl_aux_2: 0.5094 (0.5150)  loss_bbox_aux_2: 0.1864 (0.1881)  loss_giou_aux_2: 0.5518 (0.5657)  loss_vfl_aux_3: 0.4802 (0.4863)  loss_bbox_aux_3: 0.1805 (0.1831)  loss_giou_aux_3: 0.5443 (0.5637)  loss_vfl_aux_4: 0.4766 (0.4824)  loss_bbox_aux_4: 0.1741 (0.1740)  loss_giou_aux_4: 0.5298 (0.5510)  loss_vfl_dn_0: 0.4902 (0.4908)  loss_bbox_dn_0: 0.1671 (0.1715)  loss_giou_dn_0: 0.5336 (0.5499)  loss_vfl_dn_1: 0.4262 (0.4273)  loss_bbox_dn_1: 0.1431 (0.1480)  loss_giou_dn_1: 0.4754 (0.4907)  loss_vfl_dn_2: 0.4053 (0.4035)  loss_bbox_dn_2: 0.1367 (0.1395)  loss_giou_dn_2: 0.4578 (0.4722)  loss_vfl_dn_3: 0.3973 (0.3982)  loss_bbox_dn_3: 0.1347 (0.1373)  loss_giou_dn_3: 0.4528 (0.4675)  loss_vfl_dn_4: 0.3966 (0.3981)  loss_bbox_dn_4: 0.1345 (0.1369)  loss_giou_dn_4: 0.4512 (0.4648)  loss_vfl_dn_5: 0.3978 (0.3987)  loss_bbox_dn_5: 0.1343 (0.1366)  loss_giou_dn_5: 0.4491 (0.4633)  loss_vfl_enc_0: 0.9189 (0.9277)  loss_bbox_enc_0: 0.2152 (0.2157)  loss_giou_enc_0: 0.6104 (0.6336)  time: 0.6704  data: 0.1419  max mem: 16811\n",
            "Epoch: [101] Total time: 0:00:05 (0.6798 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.9782 (16.2028)  loss_vfl: 0.4788 (0.4848)  loss_bbox: 0.1723 (0.1745)  loss_giou: 0.5303 (0.5494)  loss_vfl_aux_0: 1.0352 (1.0398)  loss_bbox_aux_0: 0.1907 (0.1926)  loss_giou_aux_0: 0.5294 (0.5547)  loss_vfl_aux_1: 0.6482 (0.6452)  loss_bbox_aux_1: 0.1950 (0.1979)  loss_giou_aux_1: 0.5593 (0.5829)  loss_vfl_aux_2: 0.5094 (0.5150)  loss_bbox_aux_2: 0.1864 (0.1881)  loss_giou_aux_2: 0.5518 (0.5657)  loss_vfl_aux_3: 0.4802 (0.4863)  loss_bbox_aux_3: 0.1805 (0.1831)  loss_giou_aux_3: 0.5443 (0.5637)  loss_vfl_aux_4: 0.4766 (0.4824)  loss_bbox_aux_4: 0.1741 (0.1740)  loss_giou_aux_4: 0.5298 (0.5510)  loss_vfl_dn_0: 0.4902 (0.4908)  loss_bbox_dn_0: 0.1671 (0.1715)  loss_giou_dn_0: 0.5336 (0.5499)  loss_vfl_dn_1: 0.4262 (0.4273)  loss_bbox_dn_1: 0.1431 (0.1480)  loss_giou_dn_1: 0.4754 (0.4907)  loss_vfl_dn_2: 0.4053 (0.4035)  loss_bbox_dn_2: 0.1367 (0.1395)  loss_giou_dn_2: 0.4578 (0.4722)  loss_vfl_dn_3: 0.3973 (0.3982)  loss_bbox_dn_3: 0.1347 (0.1373)  loss_giou_dn_3: 0.4528 (0.4675)  loss_vfl_dn_4: 0.3966 (0.3981)  loss_bbox_dn_4: 0.1345 (0.1369)  loss_giou_dn_4: 0.4512 (0.4648)  loss_vfl_dn_5: 0.3978 (0.3987)  loss_bbox_dn_5: 0.1343 (0.1366)  loss_giou_dn_5: 0.4491 (0.4633)  loss_vfl_enc_0: 0.9189 (0.9277)  loss_bbox_enc_0: 0.2152 (0.2157)  loss_giou_enc_0: 0.6104 (0.6336)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4330  data: 1.3274  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6136  data: 0.6804  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6348 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.633\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [102]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.2241 (16.2241)  loss_vfl: 0.4695 (0.4695)  loss_bbox: 0.1808 (0.1808)  loss_giou: 0.5615 (0.5615)  loss_vfl_aux_0: 1.0172 (1.0172)  loss_bbox_aux_0: 0.2066 (0.2066)  loss_giou_aux_0: 0.5662 (0.5662)  loss_vfl_aux_1: 0.6267 (0.6267)  loss_bbox_aux_1: 0.2080 (0.2080)  loss_giou_aux_1: 0.5991 (0.5991)  loss_vfl_aux_2: 0.5104 (0.5104)  loss_bbox_aux_2: 0.2025 (0.2025)  loss_giou_aux_2: 0.5875 (0.5875)  loss_vfl_aux_3: 0.4733 (0.4733)  loss_bbox_aux_3: 0.1878 (0.1878)  loss_giou_aux_3: 0.5781 (0.5781)  loss_vfl_aux_4: 0.4673 (0.4673)  loss_bbox_aux_4: 0.1832 (0.1832)  loss_giou_aux_4: 0.5641 (0.5641)  loss_vfl_dn_0: 0.4904 (0.4904)  loss_bbox_dn_0: 0.1731 (0.1731)  loss_giou_dn_0: 0.5386 (0.5386)  loss_vfl_dn_1: 0.4221 (0.4221)  loss_bbox_dn_1: 0.1483 (0.1483)  loss_giou_dn_1: 0.4810 (0.4810)  loss_vfl_dn_2: 0.4013 (0.4013)  loss_bbox_dn_2: 0.1395 (0.1395)  loss_giou_dn_2: 0.4602 (0.4602)  loss_vfl_dn_3: 0.3977 (0.3977)  loss_bbox_dn_3: 0.1381 (0.1381)  loss_giou_dn_3: 0.4573 (0.4573)  loss_vfl_dn_4: 0.3962 (0.3962)  loss_bbox_dn_4: 0.1376 (0.1376)  loss_giou_dn_4: 0.4551 (0.4551)  loss_vfl_dn_5: 0.3983 (0.3983)  loss_bbox_dn_5: 0.1372 (0.1372)  loss_giou_dn_5: 0.4547 (0.4547)  loss_vfl_enc_0: 0.9209 (0.9209)  loss_bbox_enc_0: 0.2337 (0.2337)  loss_giou_enc_0: 0.6530 (0.6530)  time: 1.5553  data: 0.9822  max mem: 16811\n",
            "Epoch: [102]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.9367 (16.0409)  loss_vfl: 0.4724 (0.4815)  loss_bbox: 0.1744 (0.1718)  loss_giou: 0.5301 (0.5383)  loss_vfl_aux_0: 1.0172 (1.0320)  loss_bbox_aux_0: 0.1861 (0.1878)  loss_giou_aux_0: 0.5448 (0.5466)  loss_vfl_aux_1: 0.6209 (0.6341)  loss_bbox_aux_1: 0.1887 (0.1968)  loss_giou_aux_1: 0.5745 (0.5774)  loss_vfl_aux_2: 0.5106 (0.5102)  loss_bbox_aux_2: 0.1852 (0.1888)  loss_giou_aux_2: 0.5595 (0.5651)  loss_vfl_aux_3: 0.4883 (0.4874)  loss_bbox_aux_3: 0.1727 (0.1771)  loss_giou_aux_3: 0.5455 (0.5527)  loss_vfl_aux_4: 0.4817 (0.4825)  loss_bbox_aux_4: 0.1746 (0.1729)  loss_giou_aux_4: 0.5325 (0.5401)  loss_vfl_dn_0: 0.4904 (0.4917)  loss_bbox_dn_0: 0.1667 (0.1671)  loss_giou_dn_0: 0.5331 (0.5387)  loss_vfl_dn_1: 0.4221 (0.4276)  loss_bbox_dn_1: 0.1451 (0.1451)  loss_giou_dn_1: 0.4775 (0.4821)  loss_vfl_dn_2: 0.4013 (0.4054)  loss_bbox_dn_2: 0.1356 (0.1364)  loss_giou_dn_2: 0.4600 (0.4624)  loss_vfl_dn_3: 0.3986 (0.4002)  loss_bbox_dn_3: 0.1360 (0.1351)  loss_giou_dn_3: 0.4573 (0.4597)  loss_vfl_dn_4: 0.3970 (0.3993)  loss_bbox_dn_4: 0.1361 (0.1345)  loss_giou_dn_4: 0.4531 (0.4573)  loss_vfl_dn_5: 0.3955 (0.3991)  loss_bbox_dn_5: 0.1360 (0.1343)  loss_giou_dn_5: 0.4515 (0.4559)  loss_vfl_enc_0: 0.9209 (0.9284)  loss_bbox_enc_0: 0.2044 (0.2121)  loss_giou_enc_0: 0.6325 (0.6252)  time: 0.6609  data: 0.1430  max mem: 16811\n",
            "Epoch: [102] Total time: 0:00:05 (0.6751 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.9367 (16.0409)  loss_vfl: 0.4724 (0.4815)  loss_bbox: 0.1744 (0.1718)  loss_giou: 0.5301 (0.5383)  loss_vfl_aux_0: 1.0172 (1.0320)  loss_bbox_aux_0: 0.1861 (0.1878)  loss_giou_aux_0: 0.5448 (0.5466)  loss_vfl_aux_1: 0.6209 (0.6341)  loss_bbox_aux_1: 0.1887 (0.1968)  loss_giou_aux_1: 0.5745 (0.5774)  loss_vfl_aux_2: 0.5106 (0.5102)  loss_bbox_aux_2: 0.1852 (0.1888)  loss_giou_aux_2: 0.5595 (0.5651)  loss_vfl_aux_3: 0.4883 (0.4874)  loss_bbox_aux_3: 0.1727 (0.1771)  loss_giou_aux_3: 0.5455 (0.5527)  loss_vfl_aux_4: 0.4817 (0.4825)  loss_bbox_aux_4: 0.1746 (0.1729)  loss_giou_aux_4: 0.5325 (0.5401)  loss_vfl_dn_0: 0.4904 (0.4917)  loss_bbox_dn_0: 0.1667 (0.1671)  loss_giou_dn_0: 0.5331 (0.5387)  loss_vfl_dn_1: 0.4221 (0.4276)  loss_bbox_dn_1: 0.1451 (0.1451)  loss_giou_dn_1: 0.4775 (0.4821)  loss_vfl_dn_2: 0.4013 (0.4054)  loss_bbox_dn_2: 0.1356 (0.1364)  loss_giou_dn_2: 0.4600 (0.4624)  loss_vfl_dn_3: 0.3986 (0.4002)  loss_bbox_dn_3: 0.1360 (0.1351)  loss_giou_dn_3: 0.4573 (0.4597)  loss_vfl_dn_4: 0.3970 (0.3993)  loss_bbox_dn_4: 0.1361 (0.1345)  loss_giou_dn_4: 0.4531 (0.4573)  loss_vfl_dn_5: 0.3955 (0.3991)  loss_bbox_dn_5: 0.1360 (0.1343)  loss_giou_dn_5: 0.4515 (0.4559)  loss_vfl_enc_0: 0.9209 (0.9284)  loss_bbox_enc_0: 0.2044 (0.2121)  loss_giou_enc_0: 0.6325 (0.6252)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4778  data: 4.4166  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9662  data: 2.2250  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9879 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [103]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.8320 (16.8320)  loss_vfl: 0.4648 (0.4648)  loss_bbox: 0.1867 (0.1867)  loss_giou: 0.5853 (0.5853)  loss_vfl_aux_0: 0.9798 (0.9798)  loss_bbox_aux_0: 0.2232 (0.2232)  loss_giou_aux_0: 0.6261 (0.6261)  loss_vfl_aux_1: 0.6050 (0.6050)  loss_bbox_aux_1: 0.2302 (0.2302)  loss_giou_aux_1: 0.6461 (0.6461)  loss_vfl_aux_2: 0.5016 (0.5016)  loss_bbox_aux_2: 0.2113 (0.2113)  loss_giou_aux_2: 0.6189 (0.6189)  loss_vfl_aux_3: 0.4833 (0.4833)  loss_bbox_aux_3: 0.1957 (0.1957)  loss_giou_aux_3: 0.5977 (0.5977)  loss_vfl_aux_4: 0.4735 (0.4735)  loss_bbox_aux_4: 0.1886 (0.1886)  loss_giou_aux_4: 0.5867 (0.5867)  loss_vfl_dn_0: 0.5002 (0.5002)  loss_bbox_dn_0: 0.1751 (0.1751)  loss_giou_dn_0: 0.5705 (0.5705)  loss_vfl_dn_1: 0.4427 (0.4427)  loss_bbox_dn_1: 0.1503 (0.1503)  loss_giou_dn_1: 0.5129 (0.5129)  loss_vfl_dn_2: 0.4202 (0.4202)  loss_bbox_dn_2: 0.1449 (0.1449)  loss_giou_dn_2: 0.4987 (0.4987)  loss_vfl_dn_3: 0.4140 (0.4140)  loss_bbox_dn_3: 0.1437 (0.1437)  loss_giou_dn_3: 0.4938 (0.4938)  loss_vfl_dn_4: 0.4143 (0.4143)  loss_bbox_dn_4: 0.1427 (0.1427)  loss_giou_dn_4: 0.4919 (0.4919)  loss_vfl_dn_5: 0.4116 (0.4116)  loss_bbox_dn_5: 0.1425 (0.1425)  loss_giou_dn_5: 0.4900 (0.4900)  loss_vfl_enc_0: 0.8973 (0.8973)  loss_bbox_enc_0: 0.2543 (0.2543)  loss_giou_enc_0: 0.7159 (0.7159)  time: 1.5170  data: 0.9609  max mem: 16811\n",
            "Epoch: [103]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.9829 (16.0362)  loss_vfl: 0.4704 (0.4734)  loss_bbox: 0.1717 (0.1720)  loss_giou: 0.5328 (0.5402)  loss_vfl_aux_0: 1.0209 (1.0246)  loss_bbox_aux_0: 0.1820 (0.1885)  loss_giou_aux_0: 0.5471 (0.5524)  loss_vfl_aux_1: 0.6361 (0.6413)  loss_bbox_aux_1: 0.1937 (0.1970)  loss_giou_aux_1: 0.5636 (0.5778)  loss_vfl_aux_2: 0.4969 (0.5001)  loss_bbox_aux_2: 0.1870 (0.1866)  loss_giou_aux_2: 0.5619 (0.5651)  loss_vfl_aux_3: 0.4833 (0.4838)  loss_bbox_aux_3: 0.1779 (0.1777)  loss_giou_aux_3: 0.5448 (0.5539)  loss_vfl_aux_4: 0.4776 (0.4799)  loss_bbox_aux_4: 0.1742 (0.1726)  loss_giou_aux_4: 0.5320 (0.5428)  loss_vfl_dn_0: 0.4933 (0.4935)  loss_bbox_dn_0: 0.1607 (0.1655)  loss_giou_dn_0: 0.5362 (0.5427)  loss_vfl_dn_1: 0.4211 (0.4265)  loss_bbox_dn_1: 0.1367 (0.1438)  loss_giou_dn_1: 0.4782 (0.4854)  loss_vfl_dn_2: 0.3993 (0.4048)  loss_bbox_dn_2: 0.1291 (0.1361)  loss_giou_dn_2: 0.4571 (0.4652)  loss_vfl_dn_3: 0.3923 (0.3982)  loss_bbox_dn_3: 0.1267 (0.1339)  loss_giou_dn_3: 0.4522 (0.4599)  loss_vfl_dn_4: 0.3927 (0.3987)  loss_bbox_dn_4: 0.1264 (0.1333)  loss_giou_dn_4: 0.4508 (0.4577)  loss_vfl_dn_5: 0.3924 (0.3974)  loss_bbox_dn_5: 0.1262 (0.1332)  loss_giou_dn_5: 0.4509 (0.4564)  loss_vfl_enc_0: 0.9350 (0.9276)  loss_bbox_enc_0: 0.2104 (0.2153)  loss_giou_enc_0: 0.6257 (0.6314)  time: 0.6596  data: 0.1436  max mem: 16811\n",
            "Epoch: [103] Total time: 0:00:05 (0.6672 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.9829 (16.0362)  loss_vfl: 0.4704 (0.4734)  loss_bbox: 0.1717 (0.1720)  loss_giou: 0.5328 (0.5402)  loss_vfl_aux_0: 1.0209 (1.0246)  loss_bbox_aux_0: 0.1820 (0.1885)  loss_giou_aux_0: 0.5471 (0.5524)  loss_vfl_aux_1: 0.6361 (0.6413)  loss_bbox_aux_1: 0.1937 (0.1970)  loss_giou_aux_1: 0.5636 (0.5778)  loss_vfl_aux_2: 0.4969 (0.5001)  loss_bbox_aux_2: 0.1870 (0.1866)  loss_giou_aux_2: 0.5619 (0.5651)  loss_vfl_aux_3: 0.4833 (0.4838)  loss_bbox_aux_3: 0.1779 (0.1777)  loss_giou_aux_3: 0.5448 (0.5539)  loss_vfl_aux_4: 0.4776 (0.4799)  loss_bbox_aux_4: 0.1742 (0.1726)  loss_giou_aux_4: 0.5320 (0.5428)  loss_vfl_dn_0: 0.4933 (0.4935)  loss_bbox_dn_0: 0.1607 (0.1655)  loss_giou_dn_0: 0.5362 (0.5427)  loss_vfl_dn_1: 0.4211 (0.4265)  loss_bbox_dn_1: 0.1367 (0.1438)  loss_giou_dn_1: 0.4782 (0.4854)  loss_vfl_dn_2: 0.3993 (0.4048)  loss_bbox_dn_2: 0.1291 (0.1361)  loss_giou_dn_2: 0.4571 (0.4652)  loss_vfl_dn_3: 0.3923 (0.3982)  loss_bbox_dn_3: 0.1267 (0.1339)  loss_giou_dn_3: 0.4522 (0.4599)  loss_vfl_dn_4: 0.3927 (0.3987)  loss_bbox_dn_4: 0.1264 (0.1333)  loss_giou_dn_4: 0.4508 (0.4577)  loss_vfl_dn_5: 0.3924 (0.3974)  loss_bbox_dn_5: 0.1262 (0.1332)  loss_giou_dn_5: 0.4509 (0.4564)  loss_vfl_enc_0: 0.9350 (0.9276)  loss_bbox_enc_0: 0.2104 (0.2153)  loss_giou_enc_0: 0.6257 (0.6314)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.0811  data: 3.6624  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7673  data: 1.8474  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.7917 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [104]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 16.3921 (16.3921)  loss_vfl: 0.4870 (0.4870)  loss_bbox: 0.1689 (0.1689)  loss_giou: 0.5521 (0.5521)  loss_vfl_aux_0: 1.0049 (1.0049)  loss_bbox_aux_0: 0.1791 (0.1791)  loss_giou_aux_0: 0.5780 (0.5780)  loss_vfl_aux_1: 0.6397 (0.6397)  loss_bbox_aux_1: 0.2023 (0.2023)  loss_giou_aux_1: 0.6108 (0.6108)  loss_vfl_aux_2: 0.4880 (0.4880)  loss_bbox_aux_2: 0.1936 (0.1936)  loss_giou_aux_2: 0.5944 (0.5944)  loss_vfl_aux_3: 0.4823 (0.4823)  loss_bbox_aux_3: 0.1826 (0.1826)  loss_giou_aux_3: 0.5809 (0.5809)  loss_vfl_aux_4: 0.4980 (0.4980)  loss_bbox_aux_4: 0.1660 (0.1660)  loss_giou_aux_4: 0.5540 (0.5540)  loss_vfl_dn_0: 0.4884 (0.4884)  loss_bbox_dn_0: 0.1717 (0.1717)  loss_giou_dn_0: 0.5729 (0.5729)  loss_vfl_dn_1: 0.4324 (0.4324)  loss_bbox_dn_1: 0.1514 (0.1514)  loss_giou_dn_1: 0.5164 (0.5164)  loss_vfl_dn_2: 0.4089 (0.4089)  loss_bbox_dn_2: 0.1413 (0.1413)  loss_giou_dn_2: 0.4887 (0.4887)  loss_vfl_dn_3: 0.3972 (0.3972)  loss_bbox_dn_3: 0.1408 (0.1408)  loss_giou_dn_3: 0.4878 (0.4878)  loss_vfl_dn_4: 0.3989 (0.3989)  loss_bbox_dn_4: 0.1404 (0.1404)  loss_giou_dn_4: 0.4862 (0.4862)  loss_vfl_dn_5: 0.3964 (0.3964)  loss_bbox_dn_5: 0.1402 (0.1402)  loss_giou_dn_5: 0.4855 (0.4855)  loss_vfl_enc_0: 0.9087 (0.9087)  loss_bbox_enc_0: 0.2132 (0.2132)  loss_giou_enc_0: 0.6622 (0.6622)  time: 1.4509  data: 0.8870  max mem: 16811\n",
            "Epoch: [104]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.6505 (15.8864)  loss_vfl: 0.4693 (0.4760)  loss_bbox: 0.1609 (0.1638)  loss_giou: 0.5194 (0.5297)  loss_vfl_aux_0: 1.0206 (1.0298)  loss_bbox_aux_0: 0.1791 (0.1819)  loss_giou_aux_0: 0.5338 (0.5407)  loss_vfl_aux_1: 0.6504 (0.6476)  loss_bbox_aux_1: 0.1852 (0.1897)  loss_giou_aux_1: 0.5617 (0.5689)  loss_vfl_aux_2: 0.4960 (0.5035)  loss_bbox_aux_2: 0.1706 (0.1783)  loss_giou_aux_2: 0.5514 (0.5539)  loss_vfl_aux_3: 0.4773 (0.4800)  loss_bbox_aux_3: 0.1635 (0.1693)  loss_giou_aux_3: 0.5291 (0.5449)  loss_vfl_aux_4: 0.4729 (0.4826)  loss_bbox_aux_4: 0.1626 (0.1642)  loss_giou_aux_4: 0.5261 (0.5334)  loss_vfl_dn_0: 0.4869 (0.4887)  loss_bbox_dn_0: 0.1586 (0.1626)  loss_giou_dn_0: 0.5350 (0.5417)  loss_vfl_dn_1: 0.4231 (0.4248)  loss_bbox_dn_1: 0.1338 (0.1404)  loss_giou_dn_1: 0.4726 (0.4835)  loss_vfl_dn_2: 0.4019 (0.4031)  loss_bbox_dn_2: 0.1269 (0.1326)  loss_giou_dn_2: 0.4534 (0.4634)  loss_vfl_dn_3: 0.3971 (0.3968)  loss_bbox_dn_3: 0.1268 (0.1314)  loss_giou_dn_3: 0.4506 (0.4599)  loss_vfl_dn_4: 0.3987 (0.3971)  loss_bbox_dn_4: 0.1257 (0.1309)  loss_giou_dn_4: 0.4492 (0.4578)  loss_vfl_dn_5: 0.3964 (0.3959)  loss_bbox_dn_5: 0.1254 (0.1306)  loss_giou_dn_5: 0.4470 (0.4563)  loss_vfl_enc_0: 0.9265 (0.9249)  loss_bbox_enc_0: 0.2096 (0.2055)  loss_giou_enc_0: 0.6237 (0.6206)  time: 0.6620  data: 0.1416  max mem: 16811\n",
            "Epoch: [104] Total time: 0:00:05 (0.6700 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.6505 (15.8864)  loss_vfl: 0.4693 (0.4760)  loss_bbox: 0.1609 (0.1638)  loss_giou: 0.5194 (0.5297)  loss_vfl_aux_0: 1.0206 (1.0298)  loss_bbox_aux_0: 0.1791 (0.1819)  loss_giou_aux_0: 0.5338 (0.5407)  loss_vfl_aux_1: 0.6504 (0.6476)  loss_bbox_aux_1: 0.1852 (0.1897)  loss_giou_aux_1: 0.5617 (0.5689)  loss_vfl_aux_2: 0.4960 (0.5035)  loss_bbox_aux_2: 0.1706 (0.1783)  loss_giou_aux_2: 0.5514 (0.5539)  loss_vfl_aux_3: 0.4773 (0.4800)  loss_bbox_aux_3: 0.1635 (0.1693)  loss_giou_aux_3: 0.5291 (0.5449)  loss_vfl_aux_4: 0.4729 (0.4826)  loss_bbox_aux_4: 0.1626 (0.1642)  loss_giou_aux_4: 0.5261 (0.5334)  loss_vfl_dn_0: 0.4869 (0.4887)  loss_bbox_dn_0: 0.1586 (0.1626)  loss_giou_dn_0: 0.5350 (0.5417)  loss_vfl_dn_1: 0.4231 (0.4248)  loss_bbox_dn_1: 0.1338 (0.1404)  loss_giou_dn_1: 0.4726 (0.4835)  loss_vfl_dn_2: 0.4019 (0.4031)  loss_bbox_dn_2: 0.1269 (0.1326)  loss_giou_dn_2: 0.4534 (0.4634)  loss_vfl_dn_3: 0.3971 (0.3968)  loss_bbox_dn_3: 0.1268 (0.1314)  loss_giou_dn_3: 0.4506 (0.4599)  loss_vfl_dn_4: 0.3987 (0.3971)  loss_bbox_dn_4: 0.1257 (0.1309)  loss_giou_dn_4: 0.4492 (0.4578)  loss_vfl_dn_5: 0.3964 (0.3959)  loss_bbox_dn_5: 0.1254 (0.1306)  loss_giou_dn_5: 0.4470 (0.4563)  loss_vfl_enc_0: 0.9265 (0.9249)  loss_bbox_enc_0: 0.2096 (0.2055)  loss_giou_enc_0: 0.6237 (0.6206)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.5992  data: 3.5246  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.5278  data: 1.7793  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.5483 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [105]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 16.5750 (16.5750)  loss_vfl: 0.4759 (0.4759)  loss_bbox: 0.1918 (0.1918)  loss_giou: 0.5537 (0.5537)  loss_vfl_aux_0: 0.9940 (0.9940)  loss_bbox_aux_0: 0.2072 (0.2072)  loss_giou_aux_0: 0.5728 (0.5728)  loss_vfl_aux_1: 0.6128 (0.6128)  loss_bbox_aux_1: 0.2301 (0.2301)  loss_giou_aux_1: 0.6053 (0.6053)  loss_vfl_aux_2: 0.4792 (0.4792)  loss_bbox_aux_2: 0.2162 (0.2162)  loss_giou_aux_2: 0.5991 (0.5991)  loss_vfl_aux_3: 0.4702 (0.4702)  loss_bbox_aux_3: 0.1972 (0.1972)  loss_giou_aux_3: 0.5675 (0.5675)  loss_vfl_aux_4: 0.4781 (0.4781)  loss_bbox_aux_4: 0.1919 (0.1919)  loss_giou_aux_4: 0.5546 (0.5546)  loss_vfl_dn_0: 0.4915 (0.4915)  loss_bbox_dn_0: 0.1939 (0.1939)  loss_giou_dn_0: 0.5701 (0.5701)  loss_vfl_dn_1: 0.4347 (0.4347)  loss_bbox_dn_1: 0.1713 (0.1713)  loss_giou_dn_1: 0.5142 (0.5142)  loss_vfl_dn_2: 0.4145 (0.4145)  loss_bbox_dn_2: 0.1609 (0.1609)  loss_giou_dn_2: 0.4936 (0.4936)  loss_vfl_dn_3: 0.4062 (0.4062)  loss_bbox_dn_3: 0.1592 (0.1592)  loss_giou_dn_3: 0.4910 (0.4910)  loss_vfl_dn_4: 0.4077 (0.4077)  loss_bbox_dn_4: 0.1578 (0.1578)  loss_giou_dn_4: 0.4886 (0.4886)  loss_vfl_dn_5: 0.4071 (0.4071)  loss_bbox_dn_5: 0.1571 (0.1571)  loss_giou_dn_5: 0.4862 (0.4862)  loss_vfl_enc_0: 0.8971 (0.8971)  loss_bbox_enc_0: 0.2384 (0.2384)  loss_giou_enc_0: 0.6363 (0.6363)  time: 1.4383  data: 0.8699  max mem: 16811\n",
            "Epoch: [105]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.7615 (15.9329)  loss_vfl: 0.4759 (0.4677)  loss_bbox: 0.1677 (0.1744)  loss_giou: 0.5537 (0.5425)  loss_vfl_aux_0: 1.0274 (1.0323)  loss_bbox_aux_0: 0.1857 (0.1887)  loss_giou_aux_0: 0.5361 (0.5438)  loss_vfl_aux_1: 0.6222 (0.6216)  loss_bbox_aux_1: 0.1901 (0.1954)  loss_giou_aux_1: 0.5708 (0.5730)  loss_vfl_aux_2: 0.5014 (0.5016)  loss_bbox_aux_2: 0.1784 (0.1867)  loss_giou_aux_2: 0.5585 (0.5610)  loss_vfl_aux_3: 0.4702 (0.4740)  loss_bbox_aux_3: 0.1710 (0.1784)  loss_giou_aux_3: 0.5562 (0.5510)  loss_vfl_aux_4: 0.4781 (0.4721)  loss_bbox_aux_4: 0.1654 (0.1737)  loss_giou_aux_4: 0.5512 (0.5442)  loss_vfl_dn_0: 0.4857 (0.4861)  loss_bbox_dn_0: 0.1629 (0.1639)  loss_giou_dn_0: 0.5326 (0.5413)  loss_vfl_dn_1: 0.4187 (0.4200)  loss_bbox_dn_1: 0.1417 (0.1436)  loss_giou_dn_1: 0.4811 (0.4843)  loss_vfl_dn_2: 0.3997 (0.4004)  loss_bbox_dn_2: 0.1342 (0.1349)  loss_giou_dn_2: 0.4620 (0.4648)  loss_vfl_dn_3: 0.3956 (0.3960)  loss_bbox_dn_3: 0.1303 (0.1333)  loss_giou_dn_3: 0.4577 (0.4610)  loss_vfl_dn_4: 0.3982 (0.3968)  loss_bbox_dn_4: 0.1310 (0.1331)  loss_giou_dn_4: 0.4569 (0.4593)  loss_vfl_dn_5: 0.3959 (0.3966)  loss_bbox_dn_5: 0.1308 (0.1329)  loss_giou_dn_5: 0.4582 (0.4584)  loss_vfl_enc_0: 0.9081 (0.9059)  loss_bbox_enc_0: 0.2186 (0.2159)  loss_giou_enc_0: 0.6082 (0.6226)  time: 0.6558  data: 0.1393  max mem: 16811\n",
            "Epoch: [105] Total time: 0:00:05 (0.6637 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.7615 (15.9329)  loss_vfl: 0.4759 (0.4677)  loss_bbox: 0.1677 (0.1744)  loss_giou: 0.5537 (0.5425)  loss_vfl_aux_0: 1.0274 (1.0323)  loss_bbox_aux_0: 0.1857 (0.1887)  loss_giou_aux_0: 0.5361 (0.5438)  loss_vfl_aux_1: 0.6222 (0.6216)  loss_bbox_aux_1: 0.1901 (0.1954)  loss_giou_aux_1: 0.5708 (0.5730)  loss_vfl_aux_2: 0.5014 (0.5016)  loss_bbox_aux_2: 0.1784 (0.1867)  loss_giou_aux_2: 0.5585 (0.5610)  loss_vfl_aux_3: 0.4702 (0.4740)  loss_bbox_aux_3: 0.1710 (0.1784)  loss_giou_aux_3: 0.5562 (0.5510)  loss_vfl_aux_4: 0.4781 (0.4721)  loss_bbox_aux_4: 0.1654 (0.1737)  loss_giou_aux_4: 0.5512 (0.5442)  loss_vfl_dn_0: 0.4857 (0.4861)  loss_bbox_dn_0: 0.1629 (0.1639)  loss_giou_dn_0: 0.5326 (0.5413)  loss_vfl_dn_1: 0.4187 (0.4200)  loss_bbox_dn_1: 0.1417 (0.1436)  loss_giou_dn_1: 0.4811 (0.4843)  loss_vfl_dn_2: 0.3997 (0.4004)  loss_bbox_dn_2: 0.1342 (0.1349)  loss_giou_dn_2: 0.4620 (0.4648)  loss_vfl_dn_3: 0.3956 (0.3960)  loss_bbox_dn_3: 0.1303 (0.1333)  loss_giou_dn_3: 0.4577 (0.4610)  loss_vfl_dn_4: 0.3982 (0.3968)  loss_bbox_dn_4: 0.1310 (0.1331)  loss_giou_dn_4: 0.4569 (0.4593)  loss_vfl_dn_5: 0.3959 (0.3966)  loss_bbox_dn_5: 0.1308 (0.1329)  loss_giou_dn_5: 0.4582 (0.4584)  loss_vfl_enc_0: 0.9081 (0.9059)  loss_bbox_enc_0: 0.2186 (0.2159)  loss_giou_enc_0: 0.6082 (0.6226)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7212  data: 1.3138  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5863  data: 0.6731  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6156 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [106]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 15.3928 (15.3928)  loss_vfl: 0.4280 (0.4280)  loss_bbox: 0.1675 (0.1675)  loss_giou: 0.5082 (0.5082)  loss_vfl_aux_0: 0.9910 (0.9910)  loss_bbox_aux_0: 0.1779 (0.1779)  loss_giou_aux_0: 0.4984 (0.4984)  loss_vfl_aux_1: 0.5885 (0.5885)  loss_bbox_aux_1: 0.1905 (0.1905)  loss_giou_aux_1: 0.5297 (0.5297)  loss_vfl_aux_2: 0.4750 (0.4750)  loss_bbox_aux_2: 0.1784 (0.1784)  loss_giou_aux_2: 0.5160 (0.5160)  loss_vfl_aux_3: 0.4369 (0.4369)  loss_bbox_aux_3: 0.1743 (0.1743)  loss_giou_aux_3: 0.5213 (0.5213)  loss_vfl_aux_4: 0.4302 (0.4302)  loss_bbox_aux_4: 0.1670 (0.1670)  loss_giou_aux_4: 0.5102 (0.5102)  loss_vfl_dn_0: 0.4885 (0.4885)  loss_bbox_dn_0: 0.1787 (0.1787)  loss_giou_dn_0: 0.5506 (0.5506)  loss_vfl_dn_1: 0.4213 (0.4213)  loss_bbox_dn_1: 0.1521 (0.1521)  loss_giou_dn_1: 0.4899 (0.4899)  loss_vfl_dn_2: 0.4051 (0.4051)  loss_bbox_dn_2: 0.1402 (0.1402)  loss_giou_dn_2: 0.4650 (0.4650)  loss_vfl_dn_3: 0.3993 (0.3993)  loss_bbox_dn_3: 0.1368 (0.1368)  loss_giou_dn_3: 0.4576 (0.4576)  loss_vfl_dn_4: 0.3977 (0.3977)  loss_bbox_dn_4: 0.1354 (0.1354)  loss_giou_dn_4: 0.4520 (0.4520)  loss_vfl_dn_5: 0.3954 (0.3954)  loss_bbox_dn_5: 0.1352 (0.1352)  loss_giou_dn_5: 0.4508 (0.4508)  loss_vfl_enc_0: 0.8854 (0.8854)  loss_bbox_enc_0: 0.1950 (0.1950)  loss_giou_enc_0: 0.5714 (0.5714)  time: 1.4195  data: 0.8614  max mem: 16811\n",
            "Epoch: [106]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.8149 (15.8413)  loss_vfl: 0.4635 (0.4674)  loss_bbox: 0.1656 (0.1650)  loss_giou: 0.5176 (0.5358)  loss_vfl_aux_0: 1.0087 (1.0148)  loss_bbox_aux_0: 0.1779 (0.1838)  loss_giou_aux_0: 0.5132 (0.5451)  loss_vfl_aux_1: 0.6273 (0.6206)  loss_bbox_aux_1: 0.1905 (0.1913)  loss_giou_aux_1: 0.5511 (0.5752)  loss_vfl_aux_2: 0.5037 (0.5047)  loss_bbox_aux_2: 0.1836 (0.1827)  loss_giou_aux_2: 0.5480 (0.5610)  loss_vfl_aux_3: 0.4719 (0.4755)  loss_bbox_aux_3: 0.1697 (0.1724)  loss_giou_aux_3: 0.5343 (0.5519)  loss_vfl_aux_4: 0.4725 (0.4733)  loss_bbox_aux_4: 0.1670 (0.1671)  loss_giou_aux_4: 0.5186 (0.5394)  loss_vfl_dn_0: 0.4871 (0.4881)  loss_bbox_dn_0: 0.1647 (0.1658)  loss_giou_dn_0: 0.5506 (0.5423)  loss_vfl_dn_1: 0.4235 (0.4224)  loss_bbox_dn_1: 0.1401 (0.1422)  loss_giou_dn_1: 0.4847 (0.4801)  loss_vfl_dn_2: 0.4045 (0.4025)  loss_bbox_dn_2: 0.1311 (0.1334)  loss_giou_dn_2: 0.4650 (0.4596)  loss_vfl_dn_3: 0.3973 (0.3947)  loss_bbox_dn_3: 0.1296 (0.1312)  loss_giou_dn_3: 0.4576 (0.4541)  loss_vfl_dn_4: 0.3966 (0.3944)  loss_bbox_dn_4: 0.1294 (0.1306)  loss_giou_dn_4: 0.4520 (0.4514)  loss_vfl_dn_5: 0.3954 (0.3932)  loss_bbox_dn_5: 0.1292 (0.1305)  loss_giou_dn_5: 0.4508 (0.4505)  loss_vfl_enc_0: 0.8988 (0.9081)  loss_bbox_enc_0: 0.1992 (0.2120)  loss_giou_enc_0: 0.5811 (0.6273)  time: 0.6567  data: 0.1384  max mem: 16811\n",
            "Epoch: [106] Total time: 0:00:05 (0.6640 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.8149 (15.8413)  loss_vfl: 0.4635 (0.4674)  loss_bbox: 0.1656 (0.1650)  loss_giou: 0.5176 (0.5358)  loss_vfl_aux_0: 1.0087 (1.0148)  loss_bbox_aux_0: 0.1779 (0.1838)  loss_giou_aux_0: 0.5132 (0.5451)  loss_vfl_aux_1: 0.6273 (0.6206)  loss_bbox_aux_1: 0.1905 (0.1913)  loss_giou_aux_1: 0.5511 (0.5752)  loss_vfl_aux_2: 0.5037 (0.5047)  loss_bbox_aux_2: 0.1836 (0.1827)  loss_giou_aux_2: 0.5480 (0.5610)  loss_vfl_aux_3: 0.4719 (0.4755)  loss_bbox_aux_3: 0.1697 (0.1724)  loss_giou_aux_3: 0.5343 (0.5519)  loss_vfl_aux_4: 0.4725 (0.4733)  loss_bbox_aux_4: 0.1670 (0.1671)  loss_giou_aux_4: 0.5186 (0.5394)  loss_vfl_dn_0: 0.4871 (0.4881)  loss_bbox_dn_0: 0.1647 (0.1658)  loss_giou_dn_0: 0.5506 (0.5423)  loss_vfl_dn_1: 0.4235 (0.4224)  loss_bbox_dn_1: 0.1401 (0.1422)  loss_giou_dn_1: 0.4847 (0.4801)  loss_vfl_dn_2: 0.4045 (0.4025)  loss_bbox_dn_2: 0.1311 (0.1334)  loss_giou_dn_2: 0.4650 (0.4596)  loss_vfl_dn_3: 0.3973 (0.3947)  loss_bbox_dn_3: 0.1296 (0.1312)  loss_giou_dn_3: 0.4576 (0.4541)  loss_vfl_dn_4: 0.3966 (0.3944)  loss_bbox_dn_4: 0.1294 (0.1306)  loss_giou_dn_4: 0.4520 (0.4514)  loss_vfl_dn_5: 0.3954 (0.3932)  loss_bbox_dn_5: 0.1292 (0.1305)  loss_giou_dn_5: 0.4508 (0.4505)  loss_vfl_enc_0: 0.8988 (0.9081)  loss_bbox_enc_0: 0.1992 (0.2120)  loss_giou_enc_0: 0.5811 (0.6273)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5047  data: 4.4252  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9783  data: 2.2294  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0057 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.631\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [107]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.0255 (16.0255)  loss_vfl: 0.4761 (0.4761)  loss_bbox: 0.1786 (0.1786)  loss_giou: 0.5275 (0.5275)  loss_vfl_aux_0: 1.0309 (1.0309)  loss_bbox_aux_0: 0.2052 (0.2052)  loss_giou_aux_0: 0.5349 (0.5349)  loss_vfl_aux_1: 0.6715 (0.6715)  loss_bbox_aux_1: 0.2115 (0.2115)  loss_giou_aux_1: 0.5764 (0.5764)  loss_vfl_aux_2: 0.5028 (0.5028)  loss_bbox_aux_2: 0.2015 (0.2015)  loss_giou_aux_2: 0.5565 (0.5565)  loss_vfl_aux_3: 0.4783 (0.4783)  loss_bbox_aux_3: 0.1838 (0.1838)  loss_giou_aux_3: 0.5504 (0.5504)  loss_vfl_aux_4: 0.4790 (0.4790)  loss_bbox_aux_4: 0.1785 (0.1785)  loss_giou_aux_4: 0.5312 (0.5312)  loss_vfl_dn_0: 0.4850 (0.4850)  loss_bbox_dn_0: 0.1695 (0.1695)  loss_giou_dn_0: 0.5435 (0.5435)  loss_vfl_dn_1: 0.4277 (0.4277)  loss_bbox_dn_1: 0.1462 (0.1462)  loss_giou_dn_1: 0.4753 (0.4753)  loss_vfl_dn_2: 0.4025 (0.4025)  loss_bbox_dn_2: 0.1389 (0.1389)  loss_giou_dn_2: 0.4580 (0.4580)  loss_vfl_dn_3: 0.3948 (0.3948)  loss_bbox_dn_3: 0.1367 (0.1367)  loss_giou_dn_3: 0.4533 (0.4533)  loss_vfl_dn_4: 0.3943 (0.3943)  loss_bbox_dn_4: 0.1362 (0.1362)  loss_giou_dn_4: 0.4495 (0.4495)  loss_vfl_dn_5: 0.3922 (0.3922)  loss_bbox_dn_5: 0.1362 (0.1362)  loss_giou_dn_5: 0.4476 (0.4476)  loss_vfl_enc_0: 0.9174 (0.9174)  loss_bbox_enc_0: 0.2335 (0.2335)  loss_giou_enc_0: 0.6126 (0.6126)  time: 1.5072  data: 0.9629  max mem: 16811\n",
            "Epoch: [107]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.9678 (15.7779)  loss_vfl: 0.4531 (0.4571)  loss_bbox: 0.1729 (0.1743)  loss_giou: 0.5275 (0.5338)  loss_vfl_aux_0: 1.0309 (1.0366)  loss_bbox_aux_0: 0.1831 (0.1882)  loss_giou_aux_0: 0.5349 (0.5417)  loss_vfl_aux_1: 0.6385 (0.6430)  loss_bbox_aux_1: 0.1910 (0.1978)  loss_giou_aux_1: 0.5581 (0.5661)  loss_vfl_aux_2: 0.4942 (0.4955)  loss_bbox_aux_2: 0.1907 (0.1865)  loss_giou_aux_2: 0.5565 (0.5581)  loss_vfl_aux_3: 0.4604 (0.4663)  loss_bbox_aux_3: 0.1772 (0.1770)  loss_giou_aux_3: 0.5504 (0.5482)  loss_vfl_aux_4: 0.4588 (0.4645)  loss_bbox_aux_4: 0.1688 (0.1719)  loss_giou_aux_4: 0.5312 (0.5348)  loss_vfl_dn_0: 0.4887 (0.4886)  loss_bbox_dn_0: 0.1630 (0.1624)  loss_giou_dn_0: 0.5236 (0.5313)  loss_vfl_dn_1: 0.4262 (0.4252)  loss_bbox_dn_1: 0.1368 (0.1390)  loss_giou_dn_1: 0.4624 (0.4681)  loss_vfl_dn_2: 0.3973 (0.4012)  loss_bbox_dn_2: 0.1292 (0.1306)  loss_giou_dn_2: 0.4429 (0.4489)  loss_vfl_dn_3: 0.3929 (0.3945)  loss_bbox_dn_3: 0.1255 (0.1286)  loss_giou_dn_3: 0.4391 (0.4441)  loss_vfl_dn_4: 0.3933 (0.3944)  loss_bbox_dn_4: 0.1265 (0.1282)  loss_giou_dn_4: 0.4368 (0.4416)  loss_vfl_dn_5: 0.3922 (0.3938)  loss_bbox_dn_5: 0.1262 (0.1280)  loss_giou_dn_5: 0.4354 (0.4400)  loss_vfl_enc_0: 0.9118 (0.9083)  loss_bbox_enc_0: 0.2018 (0.2156)  loss_giou_enc_0: 0.6126 (0.6241)  time: 0.6641  data: 0.1469  max mem: 16811\n",
            "Epoch: [107] Total time: 0:00:05 (0.6714 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.9678 (15.7779)  loss_vfl: 0.4531 (0.4571)  loss_bbox: 0.1729 (0.1743)  loss_giou: 0.5275 (0.5338)  loss_vfl_aux_0: 1.0309 (1.0366)  loss_bbox_aux_0: 0.1831 (0.1882)  loss_giou_aux_0: 0.5349 (0.5417)  loss_vfl_aux_1: 0.6385 (0.6430)  loss_bbox_aux_1: 0.1910 (0.1978)  loss_giou_aux_1: 0.5581 (0.5661)  loss_vfl_aux_2: 0.4942 (0.4955)  loss_bbox_aux_2: 0.1907 (0.1865)  loss_giou_aux_2: 0.5565 (0.5581)  loss_vfl_aux_3: 0.4604 (0.4663)  loss_bbox_aux_3: 0.1772 (0.1770)  loss_giou_aux_3: 0.5504 (0.5482)  loss_vfl_aux_4: 0.4588 (0.4645)  loss_bbox_aux_4: 0.1688 (0.1719)  loss_giou_aux_4: 0.5312 (0.5348)  loss_vfl_dn_0: 0.4887 (0.4886)  loss_bbox_dn_0: 0.1630 (0.1624)  loss_giou_dn_0: 0.5236 (0.5313)  loss_vfl_dn_1: 0.4262 (0.4252)  loss_bbox_dn_1: 0.1368 (0.1390)  loss_giou_dn_1: 0.4624 (0.4681)  loss_vfl_dn_2: 0.3973 (0.4012)  loss_bbox_dn_2: 0.1292 (0.1306)  loss_giou_dn_2: 0.4429 (0.4489)  loss_vfl_dn_3: 0.3929 (0.3945)  loss_bbox_dn_3: 0.1255 (0.1286)  loss_giou_dn_3: 0.4391 (0.4441)  loss_vfl_dn_4: 0.3933 (0.3944)  loss_bbox_dn_4: 0.1265 (0.1282)  loss_giou_dn_4: 0.4368 (0.4416)  loss_vfl_dn_5: 0.3922 (0.3938)  loss_bbox_dn_5: 0.1262 (0.1280)  loss_giou_dn_5: 0.4354 (0.4400)  loss_vfl_enc_0: 0.9118 (0.9083)  loss_bbox_enc_0: 0.2018 (0.2156)  loss_giou_enc_0: 0.6126 (0.6241)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4465  data: 1.3750  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4485  data: 0.7038  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4670 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [108]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 15.7150 (15.7150)  loss_vfl: 0.4811 (0.4811)  loss_bbox: 0.1629 (0.1629)  loss_giou: 0.5002 (0.5002)  loss_vfl_aux_0: 1.0298 (1.0298)  loss_bbox_aux_0: 0.1863 (0.1863)  loss_giou_aux_0: 0.5158 (0.5158)  loss_vfl_aux_1: 0.6541 (0.6541)  loss_bbox_aux_1: 0.1971 (0.1971)  loss_giou_aux_1: 0.5473 (0.5473)  loss_vfl_aux_2: 0.5123 (0.5123)  loss_bbox_aux_2: 0.1751 (0.1751)  loss_giou_aux_2: 0.5274 (0.5274)  loss_vfl_aux_3: 0.4828 (0.4828)  loss_bbox_aux_3: 0.1707 (0.1707)  loss_giou_aux_3: 0.5168 (0.5168)  loss_vfl_aux_4: 0.4831 (0.4831)  loss_bbox_aux_4: 0.1645 (0.1645)  loss_giou_aux_4: 0.5026 (0.5026)  loss_vfl_dn_0: 0.4947 (0.4947)  loss_bbox_dn_0: 0.1713 (0.1713)  loss_giou_dn_0: 0.5393 (0.5393)  loss_vfl_dn_1: 0.4317 (0.4317)  loss_bbox_dn_1: 0.1486 (0.1486)  loss_giou_dn_1: 0.4709 (0.4709)  loss_vfl_dn_2: 0.4052 (0.4052)  loss_bbox_dn_2: 0.1385 (0.1385)  loss_giou_dn_2: 0.4519 (0.4519)  loss_vfl_dn_3: 0.3984 (0.3984)  loss_bbox_dn_3: 0.1363 (0.1363)  loss_giou_dn_3: 0.4453 (0.4453)  loss_vfl_dn_4: 0.3971 (0.3971)  loss_bbox_dn_4: 0.1363 (0.1363)  loss_giou_dn_4: 0.4444 (0.4444)  loss_vfl_dn_5: 0.3998 (0.3998)  loss_bbox_dn_5: 0.1358 (0.1358)  loss_giou_dn_5: 0.4420 (0.4420)  loss_vfl_enc_0: 0.9011 (0.9011)  loss_bbox_enc_0: 0.2102 (0.2102)  loss_giou_enc_0: 0.6064 (0.6064)  time: 1.4079  data: 0.8568  max mem: 16811\n",
            "Epoch: [108]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.7150 (15.7697)  loss_vfl: 0.4794 (0.4858)  loss_bbox: 0.1682 (0.1614)  loss_giou: 0.5002 (0.5176)  loss_vfl_aux_0: 1.0151 (1.0294)  loss_bbox_aux_0: 0.1742 (0.1812)  loss_giou_aux_0: 0.5158 (0.5380)  loss_vfl_aux_1: 0.6443 (0.6523)  loss_bbox_aux_1: 0.1967 (0.1931)  loss_giou_aux_1: 0.5473 (0.5668)  loss_vfl_aux_2: 0.4980 (0.5044)  loss_bbox_aux_2: 0.1751 (0.1782)  loss_giou_aux_2: 0.5274 (0.5469)  loss_vfl_aux_3: 0.4828 (0.4814)  loss_bbox_aux_3: 0.1707 (0.1678)  loss_giou_aux_3: 0.5168 (0.5348)  loss_vfl_aux_4: 0.4774 (0.4851)  loss_bbox_aux_4: 0.1680 (0.1625)  loss_giou_aux_4: 0.5026 (0.5202)  loss_vfl_dn_0: 0.4863 (0.4870)  loss_bbox_dn_0: 0.1619 (0.1610)  loss_giou_dn_0: 0.5278 (0.5287)  loss_vfl_dn_1: 0.4268 (0.4252)  loss_bbox_dn_1: 0.1436 (0.1400)  loss_giou_dn_1: 0.4709 (0.4737)  loss_vfl_dn_2: 0.4012 (0.4019)  loss_bbox_dn_2: 0.1334 (0.1314)  loss_giou_dn_2: 0.4519 (0.4533)  loss_vfl_dn_3: 0.3947 (0.3956)  loss_bbox_dn_3: 0.1328 (0.1298)  loss_giou_dn_3: 0.4453 (0.4495)  loss_vfl_dn_4: 0.3957 (0.3963)  loss_bbox_dn_4: 0.1326 (0.1293)  loss_giou_dn_4: 0.4444 (0.4467)  loss_vfl_dn_5: 0.3954 (0.3970)  loss_bbox_dn_5: 0.1322 (0.1290)  loss_giou_dn_5: 0.4420 (0.4451)  loss_vfl_enc_0: 0.9002 (0.9142)  loss_bbox_enc_0: 0.2046 (0.2077)  loss_giou_enc_0: 0.6064 (0.6203)  time: 0.6509  data: 0.1357  max mem: 16811\n",
            "Epoch: [108] Total time: 0:00:05 (0.6576 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.7150 (15.7697)  loss_vfl: 0.4794 (0.4858)  loss_bbox: 0.1682 (0.1614)  loss_giou: 0.5002 (0.5176)  loss_vfl_aux_0: 1.0151 (1.0294)  loss_bbox_aux_0: 0.1742 (0.1812)  loss_giou_aux_0: 0.5158 (0.5380)  loss_vfl_aux_1: 0.6443 (0.6523)  loss_bbox_aux_1: 0.1967 (0.1931)  loss_giou_aux_1: 0.5473 (0.5668)  loss_vfl_aux_2: 0.4980 (0.5044)  loss_bbox_aux_2: 0.1751 (0.1782)  loss_giou_aux_2: 0.5274 (0.5469)  loss_vfl_aux_3: 0.4828 (0.4814)  loss_bbox_aux_3: 0.1707 (0.1678)  loss_giou_aux_3: 0.5168 (0.5348)  loss_vfl_aux_4: 0.4774 (0.4851)  loss_bbox_aux_4: 0.1680 (0.1625)  loss_giou_aux_4: 0.5026 (0.5202)  loss_vfl_dn_0: 0.4863 (0.4870)  loss_bbox_dn_0: 0.1619 (0.1610)  loss_giou_dn_0: 0.5278 (0.5287)  loss_vfl_dn_1: 0.4268 (0.4252)  loss_bbox_dn_1: 0.1436 (0.1400)  loss_giou_dn_1: 0.4709 (0.4737)  loss_vfl_dn_2: 0.4012 (0.4019)  loss_bbox_dn_2: 0.1334 (0.1314)  loss_giou_dn_2: 0.4519 (0.4533)  loss_vfl_dn_3: 0.3947 (0.3956)  loss_bbox_dn_3: 0.1328 (0.1298)  loss_giou_dn_3: 0.4453 (0.4495)  loss_vfl_dn_4: 0.3957 (0.3963)  loss_bbox_dn_4: 0.1326 (0.1293)  loss_giou_dn_4: 0.4444 (0.4467)  loss_vfl_dn_5: 0.3954 (0.3970)  loss_bbox_dn_5: 0.1322 (0.1290)  loss_giou_dn_5: 0.4420 (0.4451)  loss_vfl_enc_0: 0.9002 (0.9142)  loss_bbox_enc_0: 0.2046 (0.2077)  loss_giou_enc_0: 0.6064 (0.6203)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3935  data: 1.3321  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4226  data: 0.6828  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4461 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [109]  [0/8]  eta: 0:00:12  lr: 0.000004  loss: 16.4953 (16.4953)  loss_vfl: 0.4856 (0.4856)  loss_bbox: 0.1953 (0.1953)  loss_giou: 0.5526 (0.5526)  loss_vfl_aux_0: 0.9997 (0.9997)  loss_bbox_aux_0: 0.2168 (0.2168)  loss_giou_aux_0: 0.5813 (0.5813)  loss_vfl_aux_1: 0.6331 (0.6331)  loss_bbox_aux_1: 0.2269 (0.2269)  loss_giou_aux_1: 0.5951 (0.5951)  loss_vfl_aux_2: 0.5048 (0.5048)  loss_bbox_aux_2: 0.2020 (0.2020)  loss_giou_aux_2: 0.5853 (0.5853)  loss_vfl_aux_3: 0.4825 (0.4825)  loss_bbox_aux_3: 0.1970 (0.1970)  loss_giou_aux_3: 0.5744 (0.5744)  loss_vfl_aux_4: 0.4849 (0.4849)  loss_bbox_aux_4: 0.1948 (0.1948)  loss_giou_aux_4: 0.5643 (0.5643)  loss_vfl_dn_0: 0.4913 (0.4913)  loss_bbox_dn_0: 0.1768 (0.1768)  loss_giou_dn_0: 0.5689 (0.5689)  loss_vfl_dn_1: 0.4279 (0.4279)  loss_bbox_dn_1: 0.1548 (0.1548)  loss_giou_dn_1: 0.5097 (0.5097)  loss_vfl_dn_2: 0.4063 (0.4063)  loss_bbox_dn_2: 0.1447 (0.1447)  loss_giou_dn_2: 0.4859 (0.4859)  loss_vfl_dn_3: 0.4000 (0.4000)  loss_bbox_dn_3: 0.1416 (0.1416)  loss_giou_dn_3: 0.4790 (0.4790)  loss_vfl_dn_4: 0.4030 (0.4030)  loss_bbox_dn_4: 0.1414 (0.1414)  loss_giou_dn_4: 0.4754 (0.4754)  loss_vfl_dn_5: 0.4039 (0.4039)  loss_bbox_dn_5: 0.1408 (0.1408)  loss_giou_dn_5: 0.4732 (0.4732)  loss_vfl_enc_0: 0.9018 (0.9018)  loss_bbox_enc_0: 0.2410 (0.2410)  loss_giou_enc_0: 0.6514 (0.6514)  time: 1.5158  data: 0.9598  max mem: 16811\n",
            "Epoch: [109]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.6784 (15.8143)  loss_vfl: 0.4629 (0.4711)  loss_bbox: 0.1607 (0.1734)  loss_giou: 0.5270 (0.5316)  loss_vfl_aux_0: 1.0126 (1.0240)  loss_bbox_aux_0: 0.1988 (0.1888)  loss_giou_aux_0: 0.5658 (0.5386)  loss_vfl_aux_1: 0.6161 (0.6186)  loss_bbox_aux_1: 0.2072 (0.1989)  loss_giou_aux_1: 0.5951 (0.5707)  loss_vfl_aux_2: 0.4928 (0.4920)  loss_bbox_aux_2: 0.1866 (0.1866)  loss_giou_aux_2: 0.5635 (0.5551)  loss_vfl_aux_3: 0.4700 (0.4716)  loss_bbox_aux_3: 0.1687 (0.1792)  loss_giou_aux_3: 0.5499 (0.5454)  loss_vfl_aux_4: 0.4668 (0.4749)  loss_bbox_aux_4: 0.1655 (0.1747)  loss_giou_aux_4: 0.5325 (0.5360)  loss_vfl_dn_0: 0.4828 (0.4847)  loss_bbox_dn_0: 0.1602 (0.1646)  loss_giou_dn_0: 0.5513 (0.5367)  loss_vfl_dn_1: 0.4213 (0.4214)  loss_bbox_dn_1: 0.1410 (0.1424)  loss_giou_dn_1: 0.4858 (0.4780)  loss_vfl_dn_2: 0.4000 (0.3993)  loss_bbox_dn_2: 0.1288 (0.1333)  loss_giou_dn_2: 0.4648 (0.4567)  loss_vfl_dn_3: 0.3912 (0.3920)  loss_bbox_dn_3: 0.1273 (0.1314)  loss_giou_dn_3: 0.4591 (0.4524)  loss_vfl_dn_4: 0.3922 (0.3934)  loss_bbox_dn_4: 0.1263 (0.1311)  loss_giou_dn_4: 0.4566 (0.4509)  loss_vfl_dn_5: 0.3896 (0.3922)  loss_bbox_dn_5: 0.1264 (0.1309)  loss_giou_dn_5: 0.4535 (0.4499)  loss_vfl_enc_0: 0.8908 (0.9098)  loss_bbox_enc_0: 0.2249 (0.2161)  loss_giou_enc_0: 0.6395 (0.6159)  time: 0.6544  data: 0.1402  max mem: 16811\n",
            "Epoch: [109] Total time: 0:00:05 (0.6596 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.6784 (15.8143)  loss_vfl: 0.4629 (0.4711)  loss_bbox: 0.1607 (0.1734)  loss_giou: 0.5270 (0.5316)  loss_vfl_aux_0: 1.0126 (1.0240)  loss_bbox_aux_0: 0.1988 (0.1888)  loss_giou_aux_0: 0.5658 (0.5386)  loss_vfl_aux_1: 0.6161 (0.6186)  loss_bbox_aux_1: 0.2072 (0.1989)  loss_giou_aux_1: 0.5951 (0.5707)  loss_vfl_aux_2: 0.4928 (0.4920)  loss_bbox_aux_2: 0.1866 (0.1866)  loss_giou_aux_2: 0.5635 (0.5551)  loss_vfl_aux_3: 0.4700 (0.4716)  loss_bbox_aux_3: 0.1687 (0.1792)  loss_giou_aux_3: 0.5499 (0.5454)  loss_vfl_aux_4: 0.4668 (0.4749)  loss_bbox_aux_4: 0.1655 (0.1747)  loss_giou_aux_4: 0.5325 (0.5360)  loss_vfl_dn_0: 0.4828 (0.4847)  loss_bbox_dn_0: 0.1602 (0.1646)  loss_giou_dn_0: 0.5513 (0.5367)  loss_vfl_dn_1: 0.4213 (0.4214)  loss_bbox_dn_1: 0.1410 (0.1424)  loss_giou_dn_1: 0.4858 (0.4780)  loss_vfl_dn_2: 0.4000 (0.3993)  loss_bbox_dn_2: 0.1288 (0.1333)  loss_giou_dn_2: 0.4648 (0.4567)  loss_vfl_dn_3: 0.3912 (0.3920)  loss_bbox_dn_3: 0.1273 (0.1314)  loss_giou_dn_3: 0.4591 (0.4524)  loss_vfl_dn_4: 0.3922 (0.3934)  loss_bbox_dn_4: 0.1263 (0.1311)  loss_giou_dn_4: 0.4566 (0.4509)  loss_vfl_dn_5: 0.3896 (0.3922)  loss_bbox_dn_5: 0.1264 (0.1309)  loss_giou_dn_5: 0.4535 (0.4499)  loss_vfl_enc_0: 0.8908 (0.9098)  loss_bbox_enc_0: 0.2249 (0.2161)  loss_giou_enc_0: 0.6395 (0.6159)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4814  data: 4.4153  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9655  data: 2.2238  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0013 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            "best_stat: {'epoch': 96, 'coco_eval_bbox': 0.31622345517055667}\n",
            "Epoch: [110]  [0/8]  eta: 0:00:11  lr: 0.000004  loss: 16.2121 (16.2121)  loss_vfl: 0.4562 (0.4562)  loss_bbox: 0.1844 (0.1844)  loss_giou: 0.5474 (0.5474)  loss_vfl_aux_0: 0.9520 (0.9520)  loss_bbox_aux_0: 0.2347 (0.2347)  loss_giou_aux_0: 0.6137 (0.6137)  loss_vfl_aux_1: 0.5888 (0.5888)  loss_bbox_aux_1: 0.2253 (0.2253)  loss_giou_aux_1: 0.6185 (0.6185)  loss_vfl_aux_2: 0.4898 (0.4898)  loss_bbox_aux_2: 0.2025 (0.2025)  loss_giou_aux_2: 0.5817 (0.5817)  loss_vfl_aux_3: 0.4710 (0.4710)  loss_bbox_aux_3: 0.1896 (0.1896)  loss_giou_aux_3: 0.5661 (0.5661)  loss_vfl_aux_4: 0.4671 (0.4671)  loss_bbox_aux_4: 0.1833 (0.1833)  loss_giou_aux_4: 0.5494 (0.5494)  loss_vfl_dn_0: 0.4882 (0.4882)  loss_bbox_dn_0: 0.1718 (0.1718)  loss_giou_dn_0: 0.5636 (0.5636)  loss_vfl_dn_1: 0.4303 (0.4303)  loss_bbox_dn_1: 0.1486 (0.1486)  loss_giou_dn_1: 0.5006 (0.5006)  loss_vfl_dn_2: 0.4035 (0.4035)  loss_bbox_dn_2: 0.1340 (0.1340)  loss_giou_dn_2: 0.4693 (0.4693)  loss_vfl_dn_3: 0.3965 (0.3965)  loss_bbox_dn_3: 0.1315 (0.1315)  loss_giou_dn_3: 0.4651 (0.4651)  loss_vfl_dn_4: 0.3961 (0.3961)  loss_bbox_dn_4: 0.1310 (0.1310)  loss_giou_dn_4: 0.4621 (0.4621)  loss_vfl_dn_5: 0.3932 (0.3932)  loss_bbox_dn_5: 0.1305 (0.1305)  loss_giou_dn_5: 0.4600 (0.4600)  loss_vfl_enc_0: 0.8647 (0.8647)  loss_bbox_enc_0: 0.2551 (0.2551)  loss_giou_enc_0: 0.6950 (0.6950)  time: 1.4871  data: 0.9465  max mem: 16811\n",
            "Epoch: [110]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.8783 (15.7450)  loss_vfl: 0.4652 (0.4769)  loss_bbox: 0.1611 (0.1621)  loss_giou: 0.5230 (0.5184)  loss_vfl_aux_0: 1.0310 (1.0328)  loss_bbox_aux_0: 0.1775 (0.1820)  loss_giou_aux_0: 0.5445 (0.5379)  loss_vfl_aux_1: 0.6103 (0.6353)  loss_bbox_aux_1: 0.1923 (0.1908)  loss_giou_aux_1: 0.5681 (0.5666)  loss_vfl_aux_2: 0.4924 (0.5081)  loss_bbox_aux_2: 0.1654 (0.1769)  loss_giou_aux_2: 0.5431 (0.5490)  loss_vfl_aux_3: 0.4710 (0.4902)  loss_bbox_aux_3: 0.1599 (0.1682)  loss_giou_aux_3: 0.5384 (0.5355)  loss_vfl_aux_4: 0.4710 (0.4871)  loss_bbox_aux_4: 0.1607 (0.1626)  loss_giou_aux_4: 0.5251 (0.5223)  loss_vfl_dn_0: 0.4856 (0.4848)  loss_bbox_dn_0: 0.1571 (0.1595)  loss_giou_dn_0: 0.5225 (0.5282)  loss_vfl_dn_1: 0.4242 (0.4241)  loss_bbox_dn_1: 0.1374 (0.1383)  loss_giou_dn_1: 0.4764 (0.4733)  loss_vfl_dn_2: 0.4010 (0.4013)  loss_bbox_dn_2: 0.1286 (0.1289)  loss_giou_dn_2: 0.4572 (0.4509)  loss_vfl_dn_3: 0.3953 (0.3955)  loss_bbox_dn_3: 0.1280 (0.1278)  loss_giou_dn_3: 0.4557 (0.4475)  loss_vfl_dn_4: 0.3949 (0.3951)  loss_bbox_dn_4: 0.1274 (0.1270)  loss_giou_dn_4: 0.4501 (0.4444)  loss_vfl_dn_5: 0.3932 (0.3942)  loss_bbox_dn_5: 0.1274 (0.1269)  loss_giou_dn_5: 0.4494 (0.4439)  loss_vfl_enc_0: 0.9205 (0.9112)  loss_bbox_enc_0: 0.2110 (0.2119)  loss_giou_enc_0: 0.6352 (0.6276)  time: 0.6601  data: 0.1437  max mem: 16811\n",
            "Epoch: [110] Total time: 0:00:05 (0.6690 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.8783 (15.7450)  loss_vfl: 0.4652 (0.4769)  loss_bbox: 0.1611 (0.1621)  loss_giou: 0.5230 (0.5184)  loss_vfl_aux_0: 1.0310 (1.0328)  loss_bbox_aux_0: 0.1775 (0.1820)  loss_giou_aux_0: 0.5445 (0.5379)  loss_vfl_aux_1: 0.6103 (0.6353)  loss_bbox_aux_1: 0.1923 (0.1908)  loss_giou_aux_1: 0.5681 (0.5666)  loss_vfl_aux_2: 0.4924 (0.5081)  loss_bbox_aux_2: 0.1654 (0.1769)  loss_giou_aux_2: 0.5431 (0.5490)  loss_vfl_aux_3: 0.4710 (0.4902)  loss_bbox_aux_3: 0.1599 (0.1682)  loss_giou_aux_3: 0.5384 (0.5355)  loss_vfl_aux_4: 0.4710 (0.4871)  loss_bbox_aux_4: 0.1607 (0.1626)  loss_giou_aux_4: 0.5251 (0.5223)  loss_vfl_dn_0: 0.4856 (0.4848)  loss_bbox_dn_0: 0.1571 (0.1595)  loss_giou_dn_0: 0.5225 (0.5282)  loss_vfl_dn_1: 0.4242 (0.4241)  loss_bbox_dn_1: 0.1374 (0.1383)  loss_giou_dn_1: 0.4764 (0.4733)  loss_vfl_dn_2: 0.4010 (0.4013)  loss_bbox_dn_2: 0.1286 (0.1289)  loss_giou_dn_2: 0.4572 (0.4509)  loss_vfl_dn_3: 0.3953 (0.3955)  loss_bbox_dn_3: 0.1280 (0.1278)  loss_giou_dn_3: 0.4557 (0.4475)  loss_vfl_dn_4: 0.3949 (0.3951)  loss_bbox_dn_4: 0.1274 (0.1270)  loss_giou_dn_4: 0.4501 (0.4444)  loss_vfl_dn_5: 0.3932 (0.3942)  loss_bbox_dn_5: 0.1274 (0.1269)  loss_giou_dn_5: 0.4494 (0.4439)  loss_vfl_enc_0: 0.9205 (0.9112)  loss_bbox_enc_0: 0.2110 (0.2119)  loss_giou_enc_0: 0.6352 (0.6276)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.0847  data: 4.0221  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7698  data: 2.0276  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.7970 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n",
            "best_stat: {'epoch': 110, 'coco_eval_bbox': 0.3163821799972117}\n",
            "Epoch: [111]  [0/8]  eta: 0:00:24  lr: 0.000004  loss: 15.5972 (15.5972)  loss_vfl: 0.4579 (0.4579)  loss_bbox: 0.1657 (0.1657)  loss_giou: 0.5281 (0.5281)  loss_vfl_aux_0: 0.9906 (0.9906)  loss_bbox_aux_0: 0.1829 (0.1829)  loss_giou_aux_0: 0.5444 (0.5444)  loss_vfl_aux_1: 0.6195 (0.6195)  loss_bbox_aux_1: 0.1860 (0.1860)  loss_giou_aux_1: 0.5719 (0.5719)  loss_vfl_aux_2: 0.4824 (0.4824)  loss_bbox_aux_2: 0.1793 (0.1793)  loss_giou_aux_2: 0.5607 (0.5607)  loss_vfl_aux_3: 0.4577 (0.4577)  loss_bbox_aux_3: 0.1717 (0.1717)  loss_giou_aux_3: 0.5400 (0.5400)  loss_vfl_aux_4: 0.4582 (0.4582)  loss_bbox_aux_4: 0.1677 (0.1677)  loss_giou_aux_4: 0.5342 (0.5342)  loss_vfl_dn_0: 0.4917 (0.4917)  loss_bbox_dn_0: 0.1571 (0.1571)  loss_giou_dn_0: 0.5263 (0.5263)  loss_vfl_dn_1: 0.4262 (0.4262)  loss_bbox_dn_1: 0.1378 (0.1378)  loss_giou_dn_1: 0.4764 (0.4764)  loss_vfl_dn_2: 0.4035 (0.4035)  loss_bbox_dn_2: 0.1304 (0.1304)  loss_giou_dn_2: 0.4504 (0.4504)  loss_vfl_dn_3: 0.3939 (0.3939)  loss_bbox_dn_3: 0.1303 (0.1303)  loss_giou_dn_3: 0.4485 (0.4485)  loss_vfl_dn_4: 0.3938 (0.3938)  loss_bbox_dn_4: 0.1280 (0.1280)  loss_giou_dn_4: 0.4426 (0.4426)  loss_vfl_dn_5: 0.3920 (0.3920)  loss_bbox_dn_5: 0.1277 (0.1277)  loss_giou_dn_5: 0.4417 (0.4417)  loss_vfl_enc_0: 0.8918 (0.8918)  loss_bbox_enc_0: 0.1982 (0.1982)  loss_giou_enc_0: 0.6097 (0.6097)  time: 3.0427  data: 2.4852  max mem: 16811\n",
            "Epoch: [111]  [7/8]  eta: 0:00:00  lr: 0.000004  loss: 15.6067 (15.6797)  loss_vfl: 0.4627 (0.4670)  loss_bbox: 0.1653 (0.1642)  loss_giou: 0.5247 (0.5294)  loss_vfl_aux_0: 1.0106 (1.0146)  loss_bbox_aux_0: 0.1829 (0.1897)  loss_giou_aux_0: 0.5444 (0.5423)  loss_vfl_aux_1: 0.6195 (0.6164)  loss_bbox_aux_1: 0.1885 (0.1943)  loss_giou_aux_1: 0.5705 (0.5683)  loss_vfl_aux_2: 0.4888 (0.4943)  loss_bbox_aux_2: 0.1793 (0.1822)  loss_giou_aux_2: 0.5512 (0.5553)  loss_vfl_aux_3: 0.4602 (0.4703)  loss_bbox_aux_3: 0.1707 (0.1713)  loss_giou_aux_3: 0.5383 (0.5472)  loss_vfl_aux_4: 0.4594 (0.4705)  loss_bbox_aux_4: 0.1672 (0.1656)  loss_giou_aux_4: 0.5283 (0.5327)  loss_vfl_dn_0: 0.4821 (0.4860)  loss_bbox_dn_0: 0.1548 (0.1590)  loss_giou_dn_0: 0.5233 (0.5262)  loss_vfl_dn_1: 0.4223 (0.4242)  loss_bbox_dn_1: 0.1312 (0.1354)  loss_giou_dn_1: 0.4548 (0.4679)  loss_vfl_dn_2: 0.4035 (0.4040)  loss_bbox_dn_2: 0.1260 (0.1287)  loss_giou_dn_2: 0.4402 (0.4484)  loss_vfl_dn_3: 0.3939 (0.3951)  loss_bbox_dn_3: 0.1249 (0.1270)  loss_giou_dn_3: 0.4345 (0.4436)  loss_vfl_dn_4: 0.3938 (0.3953)  loss_bbox_dn_4: 0.1247 (0.1266)  loss_giou_dn_4: 0.4342 (0.4417)  loss_vfl_dn_5: 0.3920 (0.3949)  loss_bbox_dn_5: 0.1242 (0.1263)  loss_giou_dn_5: 0.4310 (0.4403)  loss_vfl_enc_0: 0.8918 (0.8960)  loss_bbox_enc_0: 0.2125 (0.2139)  loss_giou_enc_0: 0.6149 (0.6234)  time: 0.8444  data: 0.3295  max mem: 16811\n",
            "Epoch: [111] Total time: 0:00:06 (0.8519 s / it)\n",
            "Averaged stats: lr: 0.000004  loss: 15.6067 (15.6797)  loss_vfl: 0.4627 (0.4670)  loss_bbox: 0.1653 (0.1642)  loss_giou: 0.5247 (0.5294)  loss_vfl_aux_0: 1.0106 (1.0146)  loss_bbox_aux_0: 0.1829 (0.1897)  loss_giou_aux_0: 0.5444 (0.5423)  loss_vfl_aux_1: 0.6195 (0.6164)  loss_bbox_aux_1: 0.1885 (0.1943)  loss_giou_aux_1: 0.5705 (0.5683)  loss_vfl_aux_2: 0.4888 (0.4943)  loss_bbox_aux_2: 0.1793 (0.1822)  loss_giou_aux_2: 0.5512 (0.5553)  loss_vfl_aux_3: 0.4602 (0.4703)  loss_bbox_aux_3: 0.1707 (0.1713)  loss_giou_aux_3: 0.5383 (0.5472)  loss_vfl_aux_4: 0.4594 (0.4705)  loss_bbox_aux_4: 0.1672 (0.1656)  loss_giou_aux_4: 0.5283 (0.5327)  loss_vfl_dn_0: 0.4821 (0.4860)  loss_bbox_dn_0: 0.1548 (0.1590)  loss_giou_dn_0: 0.5233 (0.5262)  loss_vfl_dn_1: 0.4223 (0.4242)  loss_bbox_dn_1: 0.1312 (0.1354)  loss_giou_dn_1: 0.4548 (0.4679)  loss_vfl_dn_2: 0.4035 (0.4040)  loss_bbox_dn_2: 0.1260 (0.1287)  loss_giou_dn_2: 0.4402 (0.4484)  loss_vfl_dn_3: 0.3939 (0.3951)  loss_bbox_dn_3: 0.1249 (0.1270)  loss_giou_dn_3: 0.4345 (0.4436)  loss_vfl_dn_4: 0.3938 (0.3953)  loss_bbox_dn_4: 0.1247 (0.1266)  loss_giou_dn_4: 0.4342 (0.4417)  loss_vfl_dn_5: 0.3920 (0.3949)  loss_bbox_dn_5: 0.1242 (0.1263)  loss_giou_dn_5: 0.4310 (0.4403)  loss_vfl_enc_0: 0.8918 (0.8960)  loss_bbox_enc_0: 0.2125 (0.2139)  loss_giou_enc_0: 0.6149 (0.6234)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5142  data: 4.4417  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9873  data: 2.2371  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0151 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [112]  [0/8]  eta: 0:00:24  lr: 0.000004  loss: 14.9322 (14.9322)  loss_vfl: 0.4546 (0.4546)  loss_bbox: 0.1446 (0.1446)  loss_giou: 0.4862 (0.4862)  loss_vfl_aux_0: 1.0718 (1.0718)  loss_bbox_aux_0: 0.1567 (0.1567)  loss_giou_aux_0: 0.4825 (0.4825)  loss_vfl_aux_1: 0.5858 (0.5858)  loss_bbox_aux_1: 0.1656 (0.1656)  loss_giou_aux_1: 0.5229 (0.5229)  loss_vfl_aux_2: 0.4723 (0.4723)  loss_bbox_aux_2: 0.1577 (0.1577)  loss_giou_aux_2: 0.5164 (0.5164)  loss_vfl_aux_3: 0.4526 (0.4526)  loss_bbox_aux_3: 0.1489 (0.1489)  loss_giou_aux_3: 0.5073 (0.5073)  loss_vfl_aux_4: 0.4513 (0.4513)  loss_bbox_aux_4: 0.1449 (0.1449)  loss_giou_aux_4: 0.4882 (0.4882)  loss_vfl_dn_0: 0.4766 (0.4766)  loss_bbox_dn_0: 0.1577 (0.1577)  loss_giou_dn_0: 0.5004 (0.5004)  loss_vfl_dn_1: 0.4139 (0.4139)  loss_bbox_dn_1: 0.1311 (0.1311)  loss_giou_dn_1: 0.4393 (0.4393)  loss_vfl_dn_2: 0.3970 (0.3970)  loss_bbox_dn_2: 0.1223 (0.1223)  loss_giou_dn_2: 0.4182 (0.4182)  loss_vfl_dn_3: 0.3881 (0.3881)  loss_bbox_dn_3: 0.1212 (0.1212)  loss_giou_dn_3: 0.4146 (0.4146)  loss_vfl_dn_4: 0.3884 (0.3884)  loss_bbox_dn_4: 0.1207 (0.1207)  loss_giou_dn_4: 0.4117 (0.4117)  loss_vfl_dn_5: 0.3884 (0.3884)  loss_bbox_dn_5: 0.1203 (0.1203)  loss_giou_dn_5: 0.4115 (0.4115)  loss_vfl_enc_0: 0.9246 (0.9246)  loss_bbox_enc_0: 0.1886 (0.1886)  loss_giou_enc_0: 0.5871 (0.5871)  time: 3.0826  data: 2.5261  max mem: 16811\n",
            "Epoch: [112]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 15.5327 (15.4709)  loss_vfl: 0.4602 (0.4659)  loss_bbox: 0.1553 (0.1588)  loss_giou: 0.5064 (0.5137)  loss_vfl_aux_0: 1.0087 (1.0155)  loss_bbox_aux_0: 0.1751 (0.1794)  loss_giou_aux_0: 0.5201 (0.5298)  loss_vfl_aux_1: 0.6038 (0.6172)  loss_bbox_aux_1: 0.1785 (0.1836)  loss_giou_aux_1: 0.5343 (0.5532)  loss_vfl_aux_2: 0.4914 (0.4913)  loss_bbox_aux_2: 0.1607 (0.1694)  loss_giou_aux_2: 0.5202 (0.5364)  loss_vfl_aux_3: 0.4640 (0.4693)  loss_bbox_aux_3: 0.1532 (0.1618)  loss_giou_aux_3: 0.5201 (0.5254)  loss_vfl_aux_4: 0.4603 (0.4651)  loss_bbox_aux_4: 0.1516 (0.1592)  loss_giou_aux_4: 0.5094 (0.5157)  loss_vfl_dn_0: 0.4838 (0.4848)  loss_bbox_dn_0: 0.1577 (0.1604)  loss_giou_dn_0: 0.5173 (0.5245)  loss_vfl_dn_1: 0.4189 (0.4214)  loss_bbox_dn_1: 0.1313 (0.1359)  loss_giou_dn_1: 0.4565 (0.4631)  loss_vfl_dn_2: 0.3970 (0.4005)  loss_bbox_dn_2: 0.1250 (0.1281)  loss_giou_dn_2: 0.4364 (0.4450)  loss_vfl_dn_3: 0.3915 (0.3935)  loss_bbox_dn_3: 0.1233 (0.1263)  loss_giou_dn_3: 0.4341 (0.4404)  loss_vfl_dn_4: 0.3923 (0.3931)  loss_bbox_dn_4: 0.1233 (0.1261)  loss_giou_dn_4: 0.4325 (0.4385)  loss_vfl_dn_5: 0.3919 (0.3929)  loss_bbox_dn_5: 0.1229 (0.1259)  loss_giou_dn_5: 0.4325 (0.4376)  loss_vfl_enc_0: 0.9145 (0.9053)  loss_bbox_enc_0: 0.1897 (0.2051)  loss_giou_enc_0: 0.5960 (0.6116)  time: 0.8460  data: 0.3322  max mem: 16811\n",
            "Epoch: [112] Total time: 0:00:06 (0.8526 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 15.5327 (15.4709)  loss_vfl: 0.4602 (0.4659)  loss_bbox: 0.1553 (0.1588)  loss_giou: 0.5064 (0.5137)  loss_vfl_aux_0: 1.0087 (1.0155)  loss_bbox_aux_0: 0.1751 (0.1794)  loss_giou_aux_0: 0.5201 (0.5298)  loss_vfl_aux_1: 0.6038 (0.6172)  loss_bbox_aux_1: 0.1785 (0.1836)  loss_giou_aux_1: 0.5343 (0.5532)  loss_vfl_aux_2: 0.4914 (0.4913)  loss_bbox_aux_2: 0.1607 (0.1694)  loss_giou_aux_2: 0.5202 (0.5364)  loss_vfl_aux_3: 0.4640 (0.4693)  loss_bbox_aux_3: 0.1532 (0.1618)  loss_giou_aux_3: 0.5201 (0.5254)  loss_vfl_aux_4: 0.4603 (0.4651)  loss_bbox_aux_4: 0.1516 (0.1592)  loss_giou_aux_4: 0.5094 (0.5157)  loss_vfl_dn_0: 0.4838 (0.4848)  loss_bbox_dn_0: 0.1577 (0.1604)  loss_giou_dn_0: 0.5173 (0.5245)  loss_vfl_dn_1: 0.4189 (0.4214)  loss_bbox_dn_1: 0.1313 (0.1359)  loss_giou_dn_1: 0.4565 (0.4631)  loss_vfl_dn_2: 0.3970 (0.4005)  loss_bbox_dn_2: 0.1250 (0.1281)  loss_giou_dn_2: 0.4364 (0.4450)  loss_vfl_dn_3: 0.3915 (0.3935)  loss_bbox_dn_3: 0.1233 (0.1263)  loss_giou_dn_3: 0.4341 (0.4404)  loss_vfl_dn_4: 0.3923 (0.3931)  loss_bbox_dn_4: 0.1233 (0.1261)  loss_giou_dn_4: 0.4325 (0.4385)  loss_vfl_dn_5: 0.3919 (0.3929)  loss_bbox_dn_5: 0.1229 (0.1259)  loss_giou_dn_5: 0.4325 (0.4376)  loss_vfl_enc_0: 0.9145 (0.9053)  loss_bbox_enc_0: 0.1897 (0.2051)  loss_giou_enc_0: 0.5960 (0.6116)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7375  data: 1.3356  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5951  data: 0.6842  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6269 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [113]  [0/8]  eta: 0:00:30  lr: 0.000005  loss: 15.1530 (15.1530)  loss_vfl: 0.4658 (0.4658)  loss_bbox: 0.1370 (0.1370)  loss_giou: 0.4911 (0.4911)  loss_vfl_aux_0: 0.9945 (0.9945)  loss_bbox_aux_0: 0.1431 (0.1431)  loss_giou_aux_0: 0.4920 (0.4920)  loss_vfl_aux_1: 0.6089 (0.6089)  loss_bbox_aux_1: 0.1568 (0.1568)  loss_giou_aux_1: 0.5280 (0.5280)  loss_vfl_aux_2: 0.4885 (0.4885)  loss_bbox_aux_2: 0.1460 (0.1460)  loss_giou_aux_2: 0.5109 (0.5109)  loss_vfl_aux_3: 0.4715 (0.4715)  loss_bbox_aux_3: 0.1408 (0.1408)  loss_giou_aux_3: 0.5024 (0.5024)  loss_vfl_aux_4: 0.4676 (0.4676)  loss_bbox_aux_4: 0.1386 (0.1386)  loss_giou_aux_4: 0.4917 (0.4917)  loss_vfl_dn_0: 0.4883 (0.4883)  loss_bbox_dn_0: 0.1515 (0.1515)  loss_giou_dn_0: 0.5398 (0.5398)  loss_vfl_dn_1: 0.4292 (0.4292)  loss_bbox_dn_1: 0.1315 (0.1315)  loss_giou_dn_1: 0.4785 (0.4785)  loss_vfl_dn_2: 0.4094 (0.4094)  loss_bbox_dn_2: 0.1257 (0.1257)  loss_giou_dn_2: 0.4582 (0.4582)  loss_vfl_dn_3: 0.4022 (0.4022)  loss_bbox_dn_3: 0.1236 (0.1236)  loss_giou_dn_3: 0.4551 (0.4551)  loss_vfl_dn_4: 0.4010 (0.4010)  loss_bbox_dn_4: 0.1241 (0.1241)  loss_giou_dn_4: 0.4533 (0.4533)  loss_vfl_dn_5: 0.4011 (0.4011)  loss_bbox_dn_5: 0.1242 (0.1242)  loss_giou_dn_5: 0.4544 (0.4544)  loss_vfl_enc_0: 0.8765 (0.8765)  loss_bbox_enc_0: 0.1700 (0.1700)  loss_giou_enc_0: 0.5801 (0.5801)  time: 3.8037  data: 3.2278  max mem: 16811\n",
            "Epoch: [113]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 15.1481 (15.3669)  loss_vfl: 0.4553 (0.4552)  loss_bbox: 0.1495 (0.1562)  loss_giou: 0.4979 (0.5106)  loss_vfl_aux_0: 1.0247 (1.0186)  loss_bbox_aux_0: 0.1686 (0.1791)  loss_giou_aux_0: 0.4957 (0.5238)  loss_vfl_aux_1: 0.6089 (0.6162)  loss_bbox_aux_1: 0.1847 (0.1865)  loss_giou_aux_1: 0.5280 (0.5483)  loss_vfl_aux_2: 0.4752 (0.4802)  loss_bbox_aux_2: 0.1718 (0.1754)  loss_giou_aux_2: 0.5158 (0.5359)  loss_vfl_aux_3: 0.4589 (0.4661)  loss_bbox_aux_3: 0.1630 (0.1628)  loss_giou_aux_3: 0.5146 (0.5242)  loss_vfl_aux_4: 0.4572 (0.4585)  loss_bbox_aux_4: 0.1503 (0.1563)  loss_giou_aux_4: 0.5002 (0.5121)  loss_vfl_dn_0: 0.4799 (0.4806)  loss_bbox_dn_0: 0.1567 (0.1576)  loss_giou_dn_0: 0.5160 (0.5215)  loss_vfl_dn_1: 0.4132 (0.4155)  loss_bbox_dn_1: 0.1331 (0.1354)  loss_giou_dn_1: 0.4563 (0.4618)  loss_vfl_dn_2: 0.3950 (0.3951)  loss_bbox_dn_2: 0.1257 (0.1271)  loss_giou_dn_2: 0.4308 (0.4421)  loss_vfl_dn_3: 0.3869 (0.3893)  loss_bbox_dn_3: 0.1236 (0.1254)  loss_giou_dn_3: 0.4274 (0.4381)  loss_vfl_dn_4: 0.3880 (0.3889)  loss_bbox_dn_4: 0.1230 (0.1247)  loss_giou_dn_4: 0.4235 (0.4347)  loss_vfl_dn_5: 0.3866 (0.3886)  loss_bbox_dn_5: 0.1233 (0.1247)  loss_giou_dn_5: 0.4219 (0.4346)  loss_vfl_enc_0: 0.9110 (0.8989)  loss_bbox_enc_0: 0.1909 (0.2071)  loss_giou_enc_0: 0.5947 (0.6091)  time: 0.9439  data: 0.4282  max mem: 16811\n",
            "Epoch: [113] Total time: 0:00:07 (0.9490 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 15.1481 (15.3669)  loss_vfl: 0.4553 (0.4552)  loss_bbox: 0.1495 (0.1562)  loss_giou: 0.4979 (0.5106)  loss_vfl_aux_0: 1.0247 (1.0186)  loss_bbox_aux_0: 0.1686 (0.1791)  loss_giou_aux_0: 0.4957 (0.5238)  loss_vfl_aux_1: 0.6089 (0.6162)  loss_bbox_aux_1: 0.1847 (0.1865)  loss_giou_aux_1: 0.5280 (0.5483)  loss_vfl_aux_2: 0.4752 (0.4802)  loss_bbox_aux_2: 0.1718 (0.1754)  loss_giou_aux_2: 0.5158 (0.5359)  loss_vfl_aux_3: 0.4589 (0.4661)  loss_bbox_aux_3: 0.1630 (0.1628)  loss_giou_aux_3: 0.5146 (0.5242)  loss_vfl_aux_4: 0.4572 (0.4585)  loss_bbox_aux_4: 0.1503 (0.1563)  loss_giou_aux_4: 0.5002 (0.5121)  loss_vfl_dn_0: 0.4799 (0.4806)  loss_bbox_dn_0: 0.1567 (0.1576)  loss_giou_dn_0: 0.5160 (0.5215)  loss_vfl_dn_1: 0.4132 (0.4155)  loss_bbox_dn_1: 0.1331 (0.1354)  loss_giou_dn_1: 0.4563 (0.4618)  loss_vfl_dn_2: 0.3950 (0.3951)  loss_bbox_dn_2: 0.1257 (0.1271)  loss_giou_dn_2: 0.4308 (0.4421)  loss_vfl_dn_3: 0.3869 (0.3893)  loss_bbox_dn_3: 0.1236 (0.1254)  loss_giou_dn_3: 0.4274 (0.4381)  loss_vfl_dn_4: 0.3880 (0.3889)  loss_bbox_dn_4: 0.1230 (0.1247)  loss_giou_dn_4: 0.4235 (0.4347)  loss_vfl_dn_5: 0.3866 (0.3886)  loss_bbox_dn_5: 0.1233 (0.1247)  loss_giou_dn_5: 0.4219 (0.4346)  loss_vfl_enc_0: 0.9110 (0.8989)  loss_bbox_enc_0: 0.1909 (0.2071)  loss_giou_enc_0: 0.5947 (0.6091)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4799  data: 4.4095  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9657  data: 2.2210  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9967 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [114]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.9402 (14.9402)  loss_vfl: 0.4370 (0.4370)  loss_bbox: 0.1525 (0.1525)  loss_giou: 0.5060 (0.5060)  loss_vfl_aux_0: 0.9766 (0.9766)  loss_bbox_aux_0: 0.1591 (0.1591)  loss_giou_aux_0: 0.5167 (0.5167)  loss_vfl_aux_1: 0.5639 (0.5639)  loss_bbox_aux_1: 0.1730 (0.1730)  loss_giou_aux_1: 0.5518 (0.5518)  loss_vfl_aux_2: 0.4650 (0.4650)  loss_bbox_aux_2: 0.1588 (0.1588)  loss_giou_aux_2: 0.5200 (0.5200)  loss_vfl_aux_3: 0.4444 (0.4444)  loss_bbox_aux_3: 0.1556 (0.1556)  loss_giou_aux_3: 0.5169 (0.5169)  loss_vfl_aux_4: 0.4446 (0.4446)  loss_bbox_aux_4: 0.1494 (0.1494)  loss_giou_aux_4: 0.5041 (0.5041)  loss_vfl_dn_0: 0.4871 (0.4871)  loss_bbox_dn_0: 0.1553 (0.1553)  loss_giou_dn_0: 0.5053 (0.5053)  loss_vfl_dn_1: 0.4200 (0.4200)  loss_bbox_dn_1: 0.1324 (0.1324)  loss_giou_dn_1: 0.4481 (0.4481)  loss_vfl_dn_2: 0.3963 (0.3963)  loss_bbox_dn_2: 0.1236 (0.1236)  loss_giou_dn_2: 0.4264 (0.4264)  loss_vfl_dn_3: 0.3895 (0.3895)  loss_bbox_dn_3: 0.1241 (0.1241)  loss_giou_dn_3: 0.4265 (0.4265)  loss_vfl_dn_4: 0.3872 (0.3872)  loss_bbox_dn_4: 0.1243 (0.1243)  loss_giou_dn_4: 0.4247 (0.4247)  loss_vfl_dn_5: 0.3880 (0.3880)  loss_bbox_dn_5: 0.1244 (0.1244)  loss_giou_dn_5: 0.4256 (0.4256)  loss_vfl_enc_0: 0.8794 (0.8794)  loss_bbox_enc_0: 0.1826 (0.1826)  loss_giou_enc_0: 0.5737 (0.5737)  time: 1.4340  data: 0.8601  max mem: 16811\n",
            "Epoch: [114]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 15.3353 (15.3303)  loss_vfl: 0.4584 (0.4610)  loss_bbox: 0.1525 (0.1559)  loss_giou: 0.4990 (0.5024)  loss_vfl_aux_0: 1.0118 (1.0190)  loss_bbox_aux_0: 0.1657 (0.1760)  loss_giou_aux_0: 0.5274 (0.5229)  loss_vfl_aux_1: 0.6050 (0.6023)  loss_bbox_aux_1: 0.1855 (0.1877)  loss_giou_aux_1: 0.5437 (0.5443)  loss_vfl_aux_2: 0.4878 (0.4894)  loss_bbox_aux_2: 0.1602 (0.1673)  loss_giou_aux_2: 0.5200 (0.5228)  loss_vfl_aux_3: 0.4650 (0.4713)  loss_bbox_aux_3: 0.1556 (0.1616)  loss_giou_aux_3: 0.5167 (0.5163)  loss_vfl_aux_4: 0.4608 (0.4670)  loss_bbox_aux_4: 0.1494 (0.1571)  loss_giou_aux_4: 0.5032 (0.5052)  loss_vfl_dn_0: 0.4854 (0.4845)  loss_bbox_dn_0: 0.1553 (0.1589)  loss_giou_dn_0: 0.5132 (0.5195)  loss_vfl_dn_1: 0.4191 (0.4185)  loss_bbox_dn_1: 0.1324 (0.1373)  loss_giou_dn_1: 0.4590 (0.4631)  loss_vfl_dn_2: 0.3963 (0.3957)  loss_bbox_dn_2: 0.1236 (0.1288)  loss_giou_dn_2: 0.4413 (0.4420)  loss_vfl_dn_3: 0.3895 (0.3898)  loss_bbox_dn_3: 0.1241 (0.1269)  loss_giou_dn_3: 0.4370 (0.4376)  loss_vfl_dn_4: 0.3875 (0.3893)  loss_bbox_dn_4: 0.1243 (0.1262)  loss_giou_dn_4: 0.4337 (0.4350)  loss_vfl_dn_5: 0.3880 (0.3880)  loss_bbox_dn_5: 0.1244 (0.1260)  loss_giou_dn_5: 0.4321 (0.4342)  loss_vfl_enc_0: 0.8794 (0.8913)  loss_bbox_enc_0: 0.1935 (0.2024)  loss_giou_enc_0: 0.5944 (0.6059)  time: 0.6511  data: 0.1366  max mem: 16811\n",
            "Epoch: [114] Total time: 0:00:05 (0.6593 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 15.3353 (15.3303)  loss_vfl: 0.4584 (0.4610)  loss_bbox: 0.1525 (0.1559)  loss_giou: 0.4990 (0.5024)  loss_vfl_aux_0: 1.0118 (1.0190)  loss_bbox_aux_0: 0.1657 (0.1760)  loss_giou_aux_0: 0.5274 (0.5229)  loss_vfl_aux_1: 0.6050 (0.6023)  loss_bbox_aux_1: 0.1855 (0.1877)  loss_giou_aux_1: 0.5437 (0.5443)  loss_vfl_aux_2: 0.4878 (0.4894)  loss_bbox_aux_2: 0.1602 (0.1673)  loss_giou_aux_2: 0.5200 (0.5228)  loss_vfl_aux_3: 0.4650 (0.4713)  loss_bbox_aux_3: 0.1556 (0.1616)  loss_giou_aux_3: 0.5167 (0.5163)  loss_vfl_aux_4: 0.4608 (0.4670)  loss_bbox_aux_4: 0.1494 (0.1571)  loss_giou_aux_4: 0.5032 (0.5052)  loss_vfl_dn_0: 0.4854 (0.4845)  loss_bbox_dn_0: 0.1553 (0.1589)  loss_giou_dn_0: 0.5132 (0.5195)  loss_vfl_dn_1: 0.4191 (0.4185)  loss_bbox_dn_1: 0.1324 (0.1373)  loss_giou_dn_1: 0.4590 (0.4631)  loss_vfl_dn_2: 0.3963 (0.3957)  loss_bbox_dn_2: 0.1236 (0.1288)  loss_giou_dn_2: 0.4413 (0.4420)  loss_vfl_dn_3: 0.3895 (0.3898)  loss_bbox_dn_3: 0.1241 (0.1269)  loss_giou_dn_3: 0.4370 (0.4376)  loss_vfl_dn_4: 0.3875 (0.3893)  loss_bbox_dn_4: 0.1243 (0.1262)  loss_giou_dn_4: 0.4337 (0.4350)  loss_vfl_dn_5: 0.3880 (0.3880)  loss_bbox_dn_5: 0.1244 (0.1260)  loss_giou_dn_5: 0.4321 (0.4342)  loss_vfl_enc_0: 0.8794 (0.8913)  loss_bbox_enc_0: 0.1935 (0.2024)  loss_giou_enc_0: 0.5944 (0.6059)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.2640  data: 1.8014  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.8601  data: 0.9171  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.8928 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [115]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 15.3789 (15.3789)  loss_vfl: 0.4578 (0.4578)  loss_bbox: 0.1599 (0.1599)  loss_giou: 0.4921 (0.4921)  loss_vfl_aux_0: 0.9758 (0.9758)  loss_bbox_aux_0: 0.1773 (0.1773)  loss_giou_aux_0: 0.5023 (0.5023)  loss_vfl_aux_1: 0.6145 (0.6145)  loss_bbox_aux_1: 0.1817 (0.1817)  loss_giou_aux_1: 0.5149 (0.5149)  loss_vfl_aux_2: 0.4970 (0.4970)  loss_bbox_aux_2: 0.1618 (0.1618)  loss_giou_aux_2: 0.4948 (0.4948)  loss_vfl_aux_3: 0.4714 (0.4714)  loss_bbox_aux_3: 0.1652 (0.1652)  loss_giou_aux_3: 0.4995 (0.4995)  loss_vfl_aux_4: 0.4600 (0.4600)  loss_bbox_aux_4: 0.1649 (0.1649)  loss_giou_aux_4: 0.5002 (0.5002)  loss_vfl_dn_0: 0.5014 (0.5014)  loss_bbox_dn_0: 0.1736 (0.1736)  loss_giou_dn_0: 0.5262 (0.5262)  loss_vfl_dn_1: 0.4427 (0.4427)  loss_bbox_dn_1: 0.1479 (0.1479)  loss_giou_dn_1: 0.4697 (0.4697)  loss_vfl_dn_2: 0.4122 (0.4122)  loss_bbox_dn_2: 0.1385 (0.1385)  loss_giou_dn_2: 0.4479 (0.4479)  loss_vfl_dn_3: 0.4087 (0.4087)  loss_bbox_dn_3: 0.1370 (0.1370)  loss_giou_dn_3: 0.4447 (0.4447)  loss_vfl_dn_4: 0.4076 (0.4076)  loss_bbox_dn_4: 0.1353 (0.1353)  loss_giou_dn_4: 0.4397 (0.4397)  loss_vfl_dn_5: 0.4061 (0.4061)  loss_bbox_dn_5: 0.1351 (0.1351)  loss_giou_dn_5: 0.4394 (0.4394)  loss_vfl_enc_0: 0.8863 (0.8863)  loss_bbox_enc_0: 0.2048 (0.2048)  loss_giou_enc_0: 0.5831 (0.5831)  time: 1.4907  data: 0.9406  max mem: 16811\n",
            "Epoch: [115]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 15.2800 (15.1984)  loss_vfl: 0.4559 (0.4567)  loss_bbox: 0.1528 (0.1523)  loss_giou: 0.4921 (0.4981)  loss_vfl_aux_0: 0.9895 (0.9886)  loss_bbox_aux_0: 0.1774 (0.1753)  loss_giou_aux_0: 0.5057 (0.5186)  loss_vfl_aux_1: 0.6231 (0.6212)  loss_bbox_aux_1: 0.1817 (0.1808)  loss_giou_aux_1: 0.5260 (0.5399)  loss_vfl_aux_2: 0.4761 (0.4826)  loss_bbox_aux_2: 0.1653 (0.1639)  loss_giou_aux_2: 0.5130 (0.5230)  loss_vfl_aux_3: 0.4674 (0.4684)  loss_bbox_aux_3: 0.1592 (0.1578)  loss_giou_aux_3: 0.5050 (0.5124)  loss_vfl_aux_4: 0.4571 (0.4598)  loss_bbox_aux_4: 0.1571 (0.1531)  loss_giou_aux_4: 0.4972 (0.5014)  loss_vfl_dn_0: 0.4808 (0.4833)  loss_bbox_dn_0: 0.1448 (0.1546)  loss_giou_dn_0: 0.5146 (0.5173)  loss_vfl_dn_1: 0.4142 (0.4185)  loss_bbox_dn_1: 0.1227 (0.1321)  loss_giou_dn_1: 0.4551 (0.4585)  loss_vfl_dn_2: 0.3898 (0.3945)  loss_bbox_dn_2: 0.1164 (0.1237)  loss_giou_dn_2: 0.4348 (0.4376)  loss_vfl_dn_3: 0.3829 (0.3882)  loss_bbox_dn_3: 0.1150 (0.1217)  loss_giou_dn_3: 0.4294 (0.4328)  loss_vfl_dn_4: 0.3837 (0.3875)  loss_bbox_dn_4: 0.1138 (0.1209)  loss_giou_dn_4: 0.4251 (0.4296)  loss_vfl_dn_5: 0.3838 (0.3860)  loss_bbox_dn_5: 0.1137 (0.1207)  loss_giou_dn_5: 0.4235 (0.4284)  loss_vfl_enc_0: 0.9010 (0.9054)  loss_bbox_enc_0: 0.2034 (0.2011)  loss_giou_enc_0: 0.6003 (0.6022)  time: 0.7185  data: 0.1424  max mem: 16811\n",
            "Epoch: [115] Total time: 0:00:05 (0.7238 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 15.2800 (15.1984)  loss_vfl: 0.4559 (0.4567)  loss_bbox: 0.1528 (0.1523)  loss_giou: 0.4921 (0.4981)  loss_vfl_aux_0: 0.9895 (0.9886)  loss_bbox_aux_0: 0.1774 (0.1753)  loss_giou_aux_0: 0.5057 (0.5186)  loss_vfl_aux_1: 0.6231 (0.6212)  loss_bbox_aux_1: 0.1817 (0.1808)  loss_giou_aux_1: 0.5260 (0.5399)  loss_vfl_aux_2: 0.4761 (0.4826)  loss_bbox_aux_2: 0.1653 (0.1639)  loss_giou_aux_2: 0.5130 (0.5230)  loss_vfl_aux_3: 0.4674 (0.4684)  loss_bbox_aux_3: 0.1592 (0.1578)  loss_giou_aux_3: 0.5050 (0.5124)  loss_vfl_aux_4: 0.4571 (0.4598)  loss_bbox_aux_4: 0.1571 (0.1531)  loss_giou_aux_4: 0.4972 (0.5014)  loss_vfl_dn_0: 0.4808 (0.4833)  loss_bbox_dn_0: 0.1448 (0.1546)  loss_giou_dn_0: 0.5146 (0.5173)  loss_vfl_dn_1: 0.4142 (0.4185)  loss_bbox_dn_1: 0.1227 (0.1321)  loss_giou_dn_1: 0.4551 (0.4585)  loss_vfl_dn_2: 0.3898 (0.3945)  loss_bbox_dn_2: 0.1164 (0.1237)  loss_giou_dn_2: 0.4348 (0.4376)  loss_vfl_dn_3: 0.3829 (0.3882)  loss_bbox_dn_3: 0.1150 (0.1217)  loss_giou_dn_3: 0.4294 (0.4328)  loss_vfl_dn_4: 0.3837 (0.3875)  loss_bbox_dn_4: 0.1138 (0.1209)  loss_giou_dn_4: 0.4251 (0.4296)  loss_vfl_dn_5: 0.3838 (0.3860)  loss_bbox_dn_5: 0.1137 (0.1207)  loss_giou_dn_5: 0.4235 (0.4284)  loss_vfl_enc_0: 0.9010 (0.9054)  loss_bbox_enc_0: 0.2034 (0.2011)  loss_giou_enc_0: 0.6003 (0.6022)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.8698  data: 3.8070  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.6584  data: 1.9198  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.6793 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [116]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 15.7063 (15.7063)  loss_vfl: 0.4367 (0.4367)  loss_bbox: 0.1723 (0.1723)  loss_giou: 0.5652 (0.5652)  loss_vfl_aux_0: 0.9529 (0.9529)  loss_bbox_aux_0: 0.2148 (0.2148)  loss_giou_aux_0: 0.5891 (0.5891)  loss_vfl_aux_1: 0.5703 (0.5703)  loss_bbox_aux_1: 0.2096 (0.2096)  loss_giou_aux_1: 0.6161 (0.6161)  loss_vfl_aux_2: 0.4485 (0.4485)  loss_bbox_aux_2: 0.1971 (0.1971)  loss_giou_aux_2: 0.6004 (0.6004)  loss_vfl_aux_3: 0.4375 (0.4375)  loss_bbox_aux_3: 0.1836 (0.1836)  loss_giou_aux_3: 0.5856 (0.5856)  loss_vfl_aux_4: 0.4391 (0.4391)  loss_bbox_aux_4: 0.1731 (0.1731)  loss_giou_aux_4: 0.5667 (0.5667)  loss_vfl_dn_0: 0.4745 (0.4745)  loss_bbox_dn_0: 0.1522 (0.1522)  loss_giou_dn_0: 0.5211 (0.5211)  loss_vfl_dn_1: 0.4136 (0.4136)  loss_bbox_dn_1: 0.1281 (0.1281)  loss_giou_dn_1: 0.4682 (0.4682)  loss_vfl_dn_2: 0.3872 (0.3872)  loss_bbox_dn_2: 0.1212 (0.1212)  loss_giou_dn_2: 0.4531 (0.4531)  loss_vfl_dn_3: 0.3800 (0.3800)  loss_bbox_dn_3: 0.1197 (0.1197)  loss_giou_dn_3: 0.4513 (0.4513)  loss_vfl_dn_4: 0.3798 (0.3798)  loss_bbox_dn_4: 0.1187 (0.1187)  loss_giou_dn_4: 0.4486 (0.4486)  loss_vfl_dn_5: 0.3781 (0.3781)  loss_bbox_dn_5: 0.1184 (0.1184)  loss_giou_dn_5: 0.4470 (0.4470)  loss_vfl_enc_0: 0.8896 (0.8896)  loss_bbox_enc_0: 0.2373 (0.2373)  loss_giou_enc_0: 0.6598 (0.6598)  time: 1.4688  data: 0.9229  max mem: 16811\n",
            "Epoch: [116]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 15.3303 (15.3131)  loss_vfl: 0.4593 (0.4615)  loss_bbox: 0.1506 (0.1526)  loss_giou: 0.4906 (0.4950)  loss_vfl_aux_0: 0.9786 (0.9946)  loss_bbox_aux_0: 0.1576 (0.1755)  loss_giou_aux_0: 0.5277 (0.5195)  loss_vfl_aux_1: 0.6235 (0.6189)  loss_bbox_aux_1: 0.1758 (0.1850)  loss_giou_aux_1: 0.5524 (0.5405)  loss_vfl_aux_2: 0.4875 (0.4834)  loss_bbox_aux_2: 0.1677 (0.1710)  loss_giou_aux_2: 0.5289 (0.5254)  loss_vfl_aux_3: 0.4649 (0.4708)  loss_bbox_aux_3: 0.1546 (0.1589)  loss_giou_aux_3: 0.5077 (0.5086)  loss_vfl_aux_4: 0.4594 (0.4644)  loss_bbox_aux_4: 0.1491 (0.1532)  loss_giou_aux_4: 0.4912 (0.4960)  loss_vfl_dn_0: 0.4822 (0.4828)  loss_bbox_dn_0: 0.1540 (0.1590)  loss_giou_dn_0: 0.5086 (0.5191)  loss_vfl_dn_1: 0.4173 (0.4205)  loss_bbox_dn_1: 0.1375 (0.1381)  loss_giou_dn_1: 0.4532 (0.4633)  loss_vfl_dn_2: 0.3973 (0.3977)  loss_bbox_dn_2: 0.1329 (0.1302)  loss_giou_dn_2: 0.4365 (0.4444)  loss_vfl_dn_3: 0.3906 (0.3911)  loss_bbox_dn_3: 0.1316 (0.1284)  loss_giou_dn_3: 0.4322 (0.4399)  loss_vfl_dn_4: 0.3906 (0.3913)  loss_bbox_dn_4: 0.1300 (0.1281)  loss_giou_dn_4: 0.4310 (0.4372)  loss_vfl_dn_5: 0.3924 (0.3919)  loss_bbox_dn_5: 0.1302 (0.1278)  loss_giou_dn_5: 0.4304 (0.4362)  loss_vfl_enc_0: 0.8896 (0.8984)  loss_bbox_enc_0: 0.1886 (0.2084)  loss_giou_enc_0: 0.5969 (0.6047)  time: 0.6528  data: 0.1426  max mem: 16811\n",
            "Epoch: [116] Total time: 0:00:05 (0.6594 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 15.3303 (15.3131)  loss_vfl: 0.4593 (0.4615)  loss_bbox: 0.1506 (0.1526)  loss_giou: 0.4906 (0.4950)  loss_vfl_aux_0: 0.9786 (0.9946)  loss_bbox_aux_0: 0.1576 (0.1755)  loss_giou_aux_0: 0.5277 (0.5195)  loss_vfl_aux_1: 0.6235 (0.6189)  loss_bbox_aux_1: 0.1758 (0.1850)  loss_giou_aux_1: 0.5524 (0.5405)  loss_vfl_aux_2: 0.4875 (0.4834)  loss_bbox_aux_2: 0.1677 (0.1710)  loss_giou_aux_2: 0.5289 (0.5254)  loss_vfl_aux_3: 0.4649 (0.4708)  loss_bbox_aux_3: 0.1546 (0.1589)  loss_giou_aux_3: 0.5077 (0.5086)  loss_vfl_aux_4: 0.4594 (0.4644)  loss_bbox_aux_4: 0.1491 (0.1532)  loss_giou_aux_4: 0.4912 (0.4960)  loss_vfl_dn_0: 0.4822 (0.4828)  loss_bbox_dn_0: 0.1540 (0.1590)  loss_giou_dn_0: 0.5086 (0.5191)  loss_vfl_dn_1: 0.4173 (0.4205)  loss_bbox_dn_1: 0.1375 (0.1381)  loss_giou_dn_1: 0.4532 (0.4633)  loss_vfl_dn_2: 0.3973 (0.3977)  loss_bbox_dn_2: 0.1329 (0.1302)  loss_giou_dn_2: 0.4365 (0.4444)  loss_vfl_dn_3: 0.3906 (0.3911)  loss_bbox_dn_3: 0.1316 (0.1284)  loss_giou_dn_3: 0.4322 (0.4399)  loss_vfl_dn_4: 0.3906 (0.3913)  loss_bbox_dn_4: 0.1300 (0.1281)  loss_giou_dn_4: 0.4310 (0.4372)  loss_vfl_dn_5: 0.3924 (0.3919)  loss_bbox_dn_5: 0.1302 (0.1278)  loss_giou_dn_5: 0.4304 (0.4362)  loss_vfl_enc_0: 0.8896 (0.8984)  loss_bbox_enc_0: 0.1886 (0.2084)  loss_giou_enc_0: 0.5969 (0.6047)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4566  data: 1.3506  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4576  data: 0.6927  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4770 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [117]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.7771 (14.7771)  loss_vfl: 0.4800 (0.4800)  loss_bbox: 0.1431 (0.1431)  loss_giou: 0.4711 (0.4711)  loss_vfl_aux_0: 1.0157 (1.0157)  loss_bbox_aux_0: 0.1409 (0.1409)  loss_giou_aux_0: 0.4760 (0.4760)  loss_vfl_aux_1: 0.6430 (0.6430)  loss_bbox_aux_1: 0.1520 (0.1520)  loss_giou_aux_1: 0.5034 (0.5034)  loss_vfl_aux_2: 0.5153 (0.5153)  loss_bbox_aux_2: 0.1513 (0.1513)  loss_giou_aux_2: 0.5022 (0.5022)  loss_vfl_aux_3: 0.5000 (0.5000)  loss_bbox_aux_3: 0.1457 (0.1457)  loss_giou_aux_3: 0.4940 (0.4940)  loss_vfl_aux_4: 0.4809 (0.4809)  loss_bbox_aux_4: 0.1461 (0.1461)  loss_giou_aux_4: 0.4748 (0.4748)  loss_vfl_dn_0: 0.4780 (0.4780)  loss_bbox_dn_0: 0.1423 (0.1423)  loss_giou_dn_0: 0.4928 (0.4928)  loss_vfl_dn_1: 0.4139 (0.4139)  loss_bbox_dn_1: 0.1184 (0.1184)  loss_giou_dn_1: 0.4273 (0.4273)  loss_vfl_dn_2: 0.3943 (0.3943)  loss_bbox_dn_2: 0.1103 (0.1103)  loss_giou_dn_2: 0.4053 (0.4053)  loss_vfl_dn_3: 0.3874 (0.3874)  loss_bbox_dn_3: 0.1098 (0.1098)  loss_giou_dn_3: 0.4020 (0.4020)  loss_vfl_dn_4: 0.3860 (0.3860)  loss_bbox_dn_4: 0.1096 (0.1096)  loss_giou_dn_4: 0.3989 (0.3989)  loss_vfl_dn_5: 0.3839 (0.3839)  loss_bbox_dn_5: 0.1093 (0.1093)  loss_giou_dn_5: 0.3966 (0.3966)  loss_vfl_enc_0: 0.9442 (0.9442)  loss_bbox_enc_0: 0.1712 (0.1712)  loss_giou_enc_0: 0.5600 (0.5600)  time: 1.4726  data: 0.9202  max mem: 16811\n",
            "Epoch: [117]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.8780 (15.1016)  loss_vfl: 0.4664 (0.4624)  loss_bbox: 0.1521 (0.1533)  loss_giou: 0.4925 (0.4950)  loss_vfl_aux_0: 0.9875 (0.9891)  loss_bbox_aux_0: 0.1659 (0.1667)  loss_giou_aux_0: 0.5035 (0.5130)  loss_vfl_aux_1: 0.5939 (0.6060)  loss_bbox_aux_1: 0.1737 (0.1721)  loss_giou_aux_1: 0.5190 (0.5291)  loss_vfl_aux_2: 0.4813 (0.4896)  loss_bbox_aux_2: 0.1677 (0.1656)  loss_giou_aux_2: 0.5092 (0.5173)  loss_vfl_aux_3: 0.4678 (0.4677)  loss_bbox_aux_3: 0.1587 (0.1597)  loss_giou_aux_3: 0.5108 (0.5102)  loss_vfl_aux_4: 0.4664 (0.4631)  loss_bbox_aux_4: 0.1531 (0.1538)  loss_giou_aux_4: 0.4942 (0.4976)  loss_vfl_dn_0: 0.4774 (0.4786)  loss_bbox_dn_0: 0.1464 (0.1525)  loss_giou_dn_0: 0.4963 (0.5112)  loss_vfl_dn_1: 0.4139 (0.4141)  loss_bbox_dn_1: 0.1252 (0.1310)  loss_giou_dn_1: 0.4446 (0.4542)  loss_vfl_dn_2: 0.3940 (0.3944)  loss_bbox_dn_2: 0.1171 (0.1222)  loss_giou_dn_2: 0.4227 (0.4329)  loss_vfl_dn_3: 0.3874 (0.3880)  loss_bbox_dn_3: 0.1149 (0.1209)  loss_giou_dn_3: 0.4170 (0.4292)  loss_vfl_dn_4: 0.3860 (0.3879)  loss_bbox_dn_4: 0.1150 (0.1203)  loss_giou_dn_4: 0.4151 (0.4266)  loss_vfl_dn_5: 0.3839 (0.3868)  loss_bbox_dn_5: 0.1145 (0.1200)  loss_giou_dn_5: 0.4139 (0.4244)  loss_vfl_enc_0: 0.8971 (0.9023)  loss_bbox_enc_0: 0.1917 (0.1944)  loss_giou_enc_0: 0.6014 (0.5988)  time: 0.6539  data: 0.1405  max mem: 16811\n",
            "Epoch: [117] Total time: 0:00:05 (0.6592 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.8780 (15.1016)  loss_vfl: 0.4664 (0.4624)  loss_bbox: 0.1521 (0.1533)  loss_giou: 0.4925 (0.4950)  loss_vfl_aux_0: 0.9875 (0.9891)  loss_bbox_aux_0: 0.1659 (0.1667)  loss_giou_aux_0: 0.5035 (0.5130)  loss_vfl_aux_1: 0.5939 (0.6060)  loss_bbox_aux_1: 0.1737 (0.1721)  loss_giou_aux_1: 0.5190 (0.5291)  loss_vfl_aux_2: 0.4813 (0.4896)  loss_bbox_aux_2: 0.1677 (0.1656)  loss_giou_aux_2: 0.5092 (0.5173)  loss_vfl_aux_3: 0.4678 (0.4677)  loss_bbox_aux_3: 0.1587 (0.1597)  loss_giou_aux_3: 0.5108 (0.5102)  loss_vfl_aux_4: 0.4664 (0.4631)  loss_bbox_aux_4: 0.1531 (0.1538)  loss_giou_aux_4: 0.4942 (0.4976)  loss_vfl_dn_0: 0.4774 (0.4786)  loss_bbox_dn_0: 0.1464 (0.1525)  loss_giou_dn_0: 0.4963 (0.5112)  loss_vfl_dn_1: 0.4139 (0.4141)  loss_bbox_dn_1: 0.1252 (0.1310)  loss_giou_dn_1: 0.4446 (0.4542)  loss_vfl_dn_2: 0.3940 (0.3944)  loss_bbox_dn_2: 0.1171 (0.1222)  loss_giou_dn_2: 0.4227 (0.4329)  loss_vfl_dn_3: 0.3874 (0.3880)  loss_bbox_dn_3: 0.1149 (0.1209)  loss_giou_dn_3: 0.4170 (0.4292)  loss_vfl_dn_4: 0.3860 (0.3879)  loss_bbox_dn_4: 0.1150 (0.1203)  loss_giou_dn_4: 0.4151 (0.4266)  loss_vfl_dn_5: 0.3839 (0.3868)  loss_bbox_dn_5: 0.1145 (0.1200)  loss_giou_dn_5: 0.4139 (0.4244)  loss_vfl_enc_0: 0.8971 (0.9023)  loss_bbox_enc_0: 0.1917 (0.1944)  loss_giou_enc_0: 0.6014 (0.5988)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4209  data: 4.3495  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9383  data: 2.1920  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9607 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [118]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 15.3954 (15.3954)  loss_vfl: 0.4445 (0.4445)  loss_bbox: 0.1552 (0.1552)  loss_giou: 0.4977 (0.4977)  loss_vfl_aux_0: 0.9920 (0.9920)  loss_bbox_aux_0: 0.1728 (0.1728)  loss_giou_aux_0: 0.5040 (0.5040)  loss_vfl_aux_1: 0.6044 (0.6044)  loss_bbox_aux_1: 0.1954 (0.1954)  loss_giou_aux_1: 0.5476 (0.5476)  loss_vfl_aux_2: 0.4878 (0.4878)  loss_bbox_aux_2: 0.1743 (0.1743)  loss_giou_aux_2: 0.5264 (0.5264)  loss_vfl_aux_3: 0.4573 (0.4573)  loss_bbox_aux_3: 0.1570 (0.1570)  loss_giou_aux_3: 0.5151 (0.5151)  loss_vfl_aux_4: 0.4563 (0.4563)  loss_bbox_aux_4: 0.1543 (0.1543)  loss_giou_aux_4: 0.4976 (0.4976)  loss_vfl_dn_0: 0.5032 (0.5032)  loss_bbox_dn_0: 0.1644 (0.1644)  loss_giou_dn_0: 0.5224 (0.5224)  loss_vfl_dn_1: 0.4258 (0.4258)  loss_bbox_dn_1: 0.1486 (0.1486)  loss_giou_dn_1: 0.4785 (0.4785)  loss_vfl_dn_2: 0.4027 (0.4027)  loss_bbox_dn_2: 0.1402 (0.1402)  loss_giou_dn_2: 0.4583 (0.4583)  loss_vfl_dn_3: 0.3958 (0.3958)  loss_bbox_dn_3: 0.1361 (0.1361)  loss_giou_dn_3: 0.4513 (0.4513)  loss_vfl_dn_4: 0.3971 (0.3971)  loss_bbox_dn_4: 0.1354 (0.1354)  loss_giou_dn_4: 0.4473 (0.4473)  loss_vfl_dn_5: 0.3966 (0.3966)  loss_bbox_dn_5: 0.1354 (0.1354)  loss_giou_dn_5: 0.4474 (0.4474)  loss_vfl_enc_0: 0.8881 (0.8881)  loss_bbox_enc_0: 0.1933 (0.1933)  loss_giou_enc_0: 0.5879 (0.5879)  time: 1.4463  data: 0.8654  max mem: 16811\n",
            "Epoch: [118]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.9880 (15.0996)  loss_vfl: 0.4445 (0.4513)  loss_bbox: 0.1463 (0.1499)  loss_giou: 0.4844 (0.4889)  loss_vfl_aux_0: 0.9518 (0.9808)  loss_bbox_aux_0: 0.1713 (0.1754)  loss_giou_aux_0: 0.5043 (0.5142)  loss_vfl_aux_1: 0.6152 (0.6203)  loss_bbox_aux_1: 0.1778 (0.1802)  loss_giou_aux_1: 0.5231 (0.5318)  loss_vfl_aux_2: 0.4731 (0.4783)  loss_bbox_aux_2: 0.1599 (0.1634)  loss_giou_aux_2: 0.5099 (0.5128)  loss_vfl_aux_3: 0.4530 (0.4591)  loss_bbox_aux_3: 0.1491 (0.1539)  loss_giou_aux_3: 0.5007 (0.5011)  loss_vfl_aux_4: 0.4516 (0.4570)  loss_bbox_aux_4: 0.1511 (0.1511)  loss_giou_aux_4: 0.4875 (0.4911)  loss_vfl_dn_0: 0.4832 (0.4849)  loss_bbox_dn_0: 0.1554 (0.1553)  loss_giou_dn_0: 0.5118 (0.5138)  loss_vfl_dn_1: 0.4215 (0.4191)  loss_bbox_dn_1: 0.1320 (0.1336)  loss_giou_dn_1: 0.4528 (0.4580)  loss_vfl_dn_2: 0.3948 (0.3965)  loss_bbox_dn_2: 0.1189 (0.1250)  loss_giou_dn_2: 0.4294 (0.4363)  loss_vfl_dn_3: 0.3875 (0.3899)  loss_bbox_dn_3: 0.1177 (0.1228)  loss_giou_dn_3: 0.4267 (0.4314)  loss_vfl_dn_4: 0.3896 (0.3910)  loss_bbox_dn_4: 0.1179 (0.1218)  loss_giou_dn_4: 0.4250 (0.4281)  loss_vfl_dn_5: 0.3883 (0.3899)  loss_bbox_dn_5: 0.1178 (0.1215)  loss_giou_dn_5: 0.4233 (0.4267)  loss_vfl_enc_0: 0.8816 (0.8926)  loss_bbox_enc_0: 0.1951 (0.2014)  loss_giou_enc_0: 0.5879 (0.5996)  time: 0.6929  data: 0.1776  max mem: 16811\n",
            "Epoch: [118] Total time: 0:00:05 (0.6989 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.9880 (15.0996)  loss_vfl: 0.4445 (0.4513)  loss_bbox: 0.1463 (0.1499)  loss_giou: 0.4844 (0.4889)  loss_vfl_aux_0: 0.9518 (0.9808)  loss_bbox_aux_0: 0.1713 (0.1754)  loss_giou_aux_0: 0.5043 (0.5142)  loss_vfl_aux_1: 0.6152 (0.6203)  loss_bbox_aux_1: 0.1778 (0.1802)  loss_giou_aux_1: 0.5231 (0.5318)  loss_vfl_aux_2: 0.4731 (0.4783)  loss_bbox_aux_2: 0.1599 (0.1634)  loss_giou_aux_2: 0.5099 (0.5128)  loss_vfl_aux_3: 0.4530 (0.4591)  loss_bbox_aux_3: 0.1491 (0.1539)  loss_giou_aux_3: 0.5007 (0.5011)  loss_vfl_aux_4: 0.4516 (0.4570)  loss_bbox_aux_4: 0.1511 (0.1511)  loss_giou_aux_4: 0.4875 (0.4911)  loss_vfl_dn_0: 0.4832 (0.4849)  loss_bbox_dn_0: 0.1554 (0.1553)  loss_giou_dn_0: 0.5118 (0.5138)  loss_vfl_dn_1: 0.4215 (0.4191)  loss_bbox_dn_1: 0.1320 (0.1336)  loss_giou_dn_1: 0.4528 (0.4580)  loss_vfl_dn_2: 0.3948 (0.3965)  loss_bbox_dn_2: 0.1189 (0.1250)  loss_giou_dn_2: 0.4294 (0.4363)  loss_vfl_dn_3: 0.3875 (0.3899)  loss_bbox_dn_3: 0.1177 (0.1228)  loss_giou_dn_3: 0.4267 (0.4314)  loss_vfl_dn_4: 0.3896 (0.3910)  loss_bbox_dn_4: 0.1179 (0.1218)  loss_giou_dn_4: 0.4250 (0.4281)  loss_vfl_dn_5: 0.3883 (0.3899)  loss_bbox_dn_5: 0.1178 (0.1215)  loss_giou_dn_5: 0.4233 (0.4267)  loss_vfl_enc_0: 0.8816 (0.8926)  loss_bbox_enc_0: 0.1951 (0.2014)  loss_giou_enc_0: 0.5879 (0.5996)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.3405  data: 3.2303  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3965  data: 1.6315  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.4176 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [119]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 15.9398 (15.9398)  loss_vfl: 0.4679 (0.4679)  loss_bbox: 0.1706 (0.1706)  loss_giou: 0.5546 (0.5546)  loss_vfl_aux_0: 0.9458 (0.9458)  loss_bbox_aux_0: 0.1998 (0.1998)  loss_giou_aux_0: 0.5654 (0.5654)  loss_vfl_aux_1: 0.6111 (0.6111)  loss_bbox_aux_1: 0.1968 (0.1968)  loss_giou_aux_1: 0.5746 (0.5746)  loss_vfl_aux_2: 0.4820 (0.4820)  loss_bbox_aux_2: 0.1930 (0.1930)  loss_giou_aux_2: 0.5703 (0.5703)  loss_vfl_aux_3: 0.4596 (0.4596)  loss_bbox_aux_3: 0.1908 (0.1908)  loss_giou_aux_3: 0.5770 (0.5770)  loss_vfl_aux_4: 0.4695 (0.4695)  loss_bbox_aux_4: 0.1862 (0.1862)  loss_giou_aux_4: 0.5680 (0.5680)  loss_vfl_dn_0: 0.4892 (0.4892)  loss_bbox_dn_0: 0.1609 (0.1609)  loss_giou_dn_0: 0.5526 (0.5526)  loss_vfl_dn_1: 0.4249 (0.4249)  loss_bbox_dn_1: 0.1380 (0.1380)  loss_giou_dn_1: 0.4928 (0.4928)  loss_vfl_dn_2: 0.4066 (0.4066)  loss_bbox_dn_2: 0.1273 (0.1273)  loss_giou_dn_2: 0.4645 (0.4645)  loss_vfl_dn_3: 0.3958 (0.3958)  loss_bbox_dn_3: 0.1272 (0.1272)  loss_giou_dn_3: 0.4611 (0.4611)  loss_vfl_dn_4: 0.4000 (0.4000)  loss_bbox_dn_4: 0.1264 (0.1264)  loss_giou_dn_4: 0.4585 (0.4585)  loss_vfl_dn_5: 0.3957 (0.3957)  loss_bbox_dn_5: 0.1262 (0.1262)  loss_giou_dn_5: 0.4574 (0.4574)  loss_vfl_enc_0: 0.8778 (0.8778)  loss_bbox_enc_0: 0.2219 (0.2219)  loss_giou_enc_0: 0.6522 (0.6522)  time: 1.4622  data: 0.9043  max mem: 16811\n",
            "Epoch: [119]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.9555 (15.1839)  loss_vfl: 0.4488 (0.4583)  loss_bbox: 0.1505 (0.1529)  loss_giou: 0.4905 (0.4946)  loss_vfl_aux_0: 0.9553 (0.9795)  loss_bbox_aux_0: 0.1699 (0.1755)  loss_giou_aux_0: 0.4947 (0.5180)  loss_vfl_aux_1: 0.6056 (0.6221)  loss_bbox_aux_1: 0.1722 (0.1781)  loss_giou_aux_1: 0.5296 (0.5356)  loss_vfl_aux_2: 0.4791 (0.4855)  loss_bbox_aux_2: 0.1628 (0.1667)  loss_giou_aux_2: 0.5102 (0.5223)  loss_vfl_aux_3: 0.4556 (0.4616)  loss_bbox_aux_3: 0.1605 (0.1606)  loss_giou_aux_3: 0.4967 (0.5103)  loss_vfl_aux_4: 0.4569 (0.4641)  loss_bbox_aux_4: 0.1508 (0.1560)  loss_giou_aux_4: 0.4943 (0.4995)  loss_vfl_dn_0: 0.4875 (0.4856)  loss_bbox_dn_0: 0.1523 (0.1539)  loss_giou_dn_0: 0.5080 (0.5134)  loss_vfl_dn_1: 0.4189 (0.4182)  loss_bbox_dn_1: 0.1301 (0.1321)  loss_giou_dn_1: 0.4538 (0.4571)  loss_vfl_dn_2: 0.3965 (0.3969)  loss_bbox_dn_2: 0.1230 (0.1242)  loss_giou_dn_2: 0.4339 (0.4376)  loss_vfl_dn_3: 0.3906 (0.3897)  loss_bbox_dn_3: 0.1199 (0.1221)  loss_giou_dn_3: 0.4258 (0.4315)  loss_vfl_dn_4: 0.3927 (0.3914)  loss_bbox_dn_4: 0.1204 (0.1215)  loss_giou_dn_4: 0.4232 (0.4288)  loss_vfl_dn_5: 0.3910 (0.3893)  loss_bbox_dn_5: 0.1201 (0.1213)  loss_giou_dn_5: 0.4203 (0.4278)  loss_vfl_enc_0: 0.8866 (0.8955)  loss_bbox_enc_0: 0.1957 (0.2015)  loss_giou_enc_0: 0.5865 (0.6037)  time: 0.6514  data: 0.1378  max mem: 16811\n",
            "Epoch: [119] Total time: 0:00:05 (0.6565 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.9555 (15.1839)  loss_vfl: 0.4488 (0.4583)  loss_bbox: 0.1505 (0.1529)  loss_giou: 0.4905 (0.4946)  loss_vfl_aux_0: 0.9553 (0.9795)  loss_bbox_aux_0: 0.1699 (0.1755)  loss_giou_aux_0: 0.4947 (0.5180)  loss_vfl_aux_1: 0.6056 (0.6221)  loss_bbox_aux_1: 0.1722 (0.1781)  loss_giou_aux_1: 0.5296 (0.5356)  loss_vfl_aux_2: 0.4791 (0.4855)  loss_bbox_aux_2: 0.1628 (0.1667)  loss_giou_aux_2: 0.5102 (0.5223)  loss_vfl_aux_3: 0.4556 (0.4616)  loss_bbox_aux_3: 0.1605 (0.1606)  loss_giou_aux_3: 0.4967 (0.5103)  loss_vfl_aux_4: 0.4569 (0.4641)  loss_bbox_aux_4: 0.1508 (0.1560)  loss_giou_aux_4: 0.4943 (0.4995)  loss_vfl_dn_0: 0.4875 (0.4856)  loss_bbox_dn_0: 0.1523 (0.1539)  loss_giou_dn_0: 0.5080 (0.5134)  loss_vfl_dn_1: 0.4189 (0.4182)  loss_bbox_dn_1: 0.1301 (0.1321)  loss_giou_dn_1: 0.4538 (0.4571)  loss_vfl_dn_2: 0.3965 (0.3969)  loss_bbox_dn_2: 0.1230 (0.1242)  loss_giou_dn_2: 0.4339 (0.4376)  loss_vfl_dn_3: 0.3906 (0.3897)  loss_bbox_dn_3: 0.1199 (0.1221)  loss_giou_dn_3: 0.4258 (0.4315)  loss_vfl_dn_4: 0.3927 (0.3914)  loss_bbox_dn_4: 0.1204 (0.1215)  loss_giou_dn_4: 0.4232 (0.4288)  loss_vfl_dn_5: 0.3910 (0.3893)  loss_bbox_dn_5: 0.1201 (0.1213)  loss_giou_dn_5: 0.4203 (0.4278)  loss_vfl_enc_0: 0.8866 (0.8955)  loss_bbox_enc_0: 0.1957 (0.2015)  loss_giou_enc_0: 0.5865 (0.6037)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7410  data: 1.3290  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5999  data: 0.6807  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6293 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [120]  [0/8]  eta: 0:00:14  lr: 0.000005  loss: 15.5912 (15.5912)  loss_vfl: 0.4791 (0.4791)  loss_bbox: 0.1664 (0.1664)  loss_giou: 0.5017 (0.5017)  loss_vfl_aux_0: 0.9878 (0.9878)  loss_bbox_aux_0: 0.1918 (0.1918)  loss_giou_aux_0: 0.5363 (0.5363)  loss_vfl_aux_1: 0.6431 (0.6431)  loss_bbox_aux_1: 0.1995 (0.1995)  loss_giou_aux_1: 0.5570 (0.5570)  loss_vfl_aux_2: 0.4994 (0.4994)  loss_bbox_aux_2: 0.1765 (0.1765)  loss_giou_aux_2: 0.5295 (0.5295)  loss_vfl_aux_3: 0.4754 (0.4754)  loss_bbox_aux_3: 0.1724 (0.1724)  loss_giou_aux_3: 0.5216 (0.5216)  loss_vfl_aux_4: 0.4790 (0.4790)  loss_bbox_aux_4: 0.1671 (0.1671)  loss_giou_aux_4: 0.5034 (0.5034)  loss_vfl_dn_0: 0.4728 (0.4728)  loss_bbox_dn_0: 0.1710 (0.1710)  loss_giou_dn_0: 0.5309 (0.5309)  loss_vfl_dn_1: 0.4172 (0.4172)  loss_bbox_dn_1: 0.1463 (0.1463)  loss_giou_dn_1: 0.4671 (0.4671)  loss_vfl_dn_2: 0.3990 (0.3990)  loss_bbox_dn_2: 0.1367 (0.1367)  loss_giou_dn_2: 0.4442 (0.4442)  loss_vfl_dn_3: 0.3934 (0.3934)  loss_bbox_dn_3: 0.1330 (0.1330)  loss_giou_dn_3: 0.4377 (0.4377)  loss_vfl_dn_4: 0.3911 (0.3911)  loss_bbox_dn_4: 0.1325 (0.1325)  loss_giou_dn_4: 0.4347 (0.4347)  loss_vfl_dn_5: 0.3898 (0.3898)  loss_bbox_dn_5: 0.1323 (0.1323)  loss_giou_dn_5: 0.4324 (0.4324)  loss_vfl_enc_0: 0.9136 (0.9136)  loss_bbox_enc_0: 0.2136 (0.2136)  loss_giou_enc_0: 0.6152 (0.6152)  time: 1.8584  data: 1.3017  max mem: 16811\n",
            "Epoch: [120]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 15.0308 (15.1206)  loss_vfl: 0.4569 (0.4597)  loss_bbox: 0.1505 (0.1540)  loss_giou: 0.4890 (0.4906)  loss_vfl_aux_0: 0.9820 (0.9885)  loss_bbox_aux_0: 0.1682 (0.1771)  loss_giou_aux_0: 0.5111 (0.5117)  loss_vfl_aux_1: 0.5992 (0.5998)  loss_bbox_aux_1: 0.1764 (0.1827)  loss_giou_aux_1: 0.5284 (0.5290)  loss_vfl_aux_2: 0.4732 (0.4802)  loss_bbox_aux_2: 0.1578 (0.1664)  loss_giou_aux_2: 0.5103 (0.5143)  loss_vfl_aux_3: 0.4593 (0.4605)  loss_bbox_aux_3: 0.1530 (0.1587)  loss_giou_aux_3: 0.5007 (0.5045)  loss_vfl_aux_4: 0.4588 (0.4618)  loss_bbox_aux_4: 0.1513 (0.1542)  loss_giou_aux_4: 0.4918 (0.4924)  loss_vfl_dn_0: 0.4742 (0.4801)  loss_bbox_dn_0: 0.1567 (0.1591)  loss_giou_dn_0: 0.5085 (0.5176)  loss_vfl_dn_1: 0.4122 (0.4147)  loss_bbox_dn_1: 0.1284 (0.1350)  loss_giou_dn_1: 0.4479 (0.4547)  loss_vfl_dn_2: 0.3976 (0.3962)  loss_bbox_dn_2: 0.1230 (0.1264)  loss_giou_dn_2: 0.4297 (0.4352)  loss_vfl_dn_3: 0.3934 (0.3922)  loss_bbox_dn_3: 0.1196 (0.1240)  loss_giou_dn_3: 0.4244 (0.4294)  loss_vfl_dn_4: 0.3911 (0.3923)  loss_bbox_dn_4: 0.1201 (0.1239)  loss_giou_dn_4: 0.4231 (0.4274)  loss_vfl_dn_5: 0.3898 (0.3912)  loss_bbox_dn_5: 0.1196 (0.1236)  loss_giou_dn_5: 0.4213 (0.4254)  loss_vfl_enc_0: 0.8708 (0.8892)  loss_bbox_enc_0: 0.1929 (0.2023)  loss_giou_enc_0: 0.5958 (0.5943)  time: 0.7022  data: 0.1871  max mem: 16811\n",
            "Epoch: [120] Total time: 0:00:05 (0.7074 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 15.0308 (15.1206)  loss_vfl: 0.4569 (0.4597)  loss_bbox: 0.1505 (0.1540)  loss_giou: 0.4890 (0.4906)  loss_vfl_aux_0: 0.9820 (0.9885)  loss_bbox_aux_0: 0.1682 (0.1771)  loss_giou_aux_0: 0.5111 (0.5117)  loss_vfl_aux_1: 0.5992 (0.5998)  loss_bbox_aux_1: 0.1764 (0.1827)  loss_giou_aux_1: 0.5284 (0.5290)  loss_vfl_aux_2: 0.4732 (0.4802)  loss_bbox_aux_2: 0.1578 (0.1664)  loss_giou_aux_2: 0.5103 (0.5143)  loss_vfl_aux_3: 0.4593 (0.4605)  loss_bbox_aux_3: 0.1530 (0.1587)  loss_giou_aux_3: 0.5007 (0.5045)  loss_vfl_aux_4: 0.4588 (0.4618)  loss_bbox_aux_4: 0.1513 (0.1542)  loss_giou_aux_4: 0.4918 (0.4924)  loss_vfl_dn_0: 0.4742 (0.4801)  loss_bbox_dn_0: 0.1567 (0.1591)  loss_giou_dn_0: 0.5085 (0.5176)  loss_vfl_dn_1: 0.4122 (0.4147)  loss_bbox_dn_1: 0.1284 (0.1350)  loss_giou_dn_1: 0.4479 (0.4547)  loss_vfl_dn_2: 0.3976 (0.3962)  loss_bbox_dn_2: 0.1230 (0.1264)  loss_giou_dn_2: 0.4297 (0.4352)  loss_vfl_dn_3: 0.3934 (0.3922)  loss_bbox_dn_3: 0.1196 (0.1240)  loss_giou_dn_3: 0.4244 (0.4294)  loss_vfl_dn_4: 0.3911 (0.3923)  loss_bbox_dn_4: 0.1201 (0.1239)  loss_giou_dn_4: 0.4231 (0.4274)  loss_vfl_dn_5: 0.3898 (0.3912)  loss_bbox_dn_5: 0.1196 (0.1236)  loss_giou_dn_5: 0.4213 (0.4254)  loss_vfl_enc_0: 0.8708 (0.8892)  loss_bbox_enc_0: 0.1929 (0.2023)  loss_giou_enc_0: 0.5958 (0.5943)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3916  data: 1.3183  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4212  data: 0.6754  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4468 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [121]  [0/8]  eta: 0:00:34  lr: 0.000005  loss: 15.2386 (15.2386)  loss_vfl: 0.4588 (0.4588)  loss_bbox: 0.1620 (0.1620)  loss_giou: 0.5007 (0.5007)  loss_vfl_aux_0: 0.9673 (0.9673)  loss_bbox_aux_0: 0.1860 (0.1860)  loss_giou_aux_0: 0.5296 (0.5296)  loss_vfl_aux_1: 0.5824 (0.5824)  loss_bbox_aux_1: 0.1897 (0.1897)  loss_giou_aux_1: 0.5477 (0.5477)  loss_vfl_aux_2: 0.4870 (0.4870)  loss_bbox_aux_2: 0.1725 (0.1725)  loss_giou_aux_2: 0.5188 (0.5188)  loss_vfl_aux_3: 0.4728 (0.4728)  loss_bbox_aux_3: 0.1634 (0.1634)  loss_giou_aux_3: 0.5081 (0.5081)  loss_vfl_aux_4: 0.4642 (0.4642)  loss_bbox_aux_4: 0.1613 (0.1613)  loss_giou_aux_4: 0.5022 (0.5022)  loss_vfl_dn_0: 0.4883 (0.4883)  loss_bbox_dn_0: 0.1561 (0.1561)  loss_giou_dn_0: 0.5181 (0.5181)  loss_vfl_dn_1: 0.4236 (0.4236)  loss_bbox_dn_1: 0.1330 (0.1330)  loss_giou_dn_1: 0.4587 (0.4587)  loss_vfl_dn_2: 0.3993 (0.3993)  loss_bbox_dn_2: 0.1245 (0.1245)  loss_giou_dn_2: 0.4402 (0.4402)  loss_vfl_dn_3: 0.3929 (0.3929)  loss_bbox_dn_3: 0.1224 (0.1224)  loss_giou_dn_3: 0.4348 (0.4348)  loss_vfl_dn_4: 0.3934 (0.3934)  loss_bbox_dn_4: 0.1222 (0.1222)  loss_giou_dn_4: 0.4319 (0.4319)  loss_vfl_dn_5: 0.3912 (0.3912)  loss_bbox_dn_5: 0.1219 (0.1219)  loss_giou_dn_5: 0.4306 (0.4306)  loss_vfl_enc_0: 0.8692 (0.8692)  loss_bbox_enc_0: 0.2078 (0.2078)  loss_giou_enc_0: 0.6042 (0.6042)  time: 4.2509  data: 3.6873  max mem: 16811\n",
            "Epoch: [121]  [7/8]  eta: 0:00:01  lr: 0.000005  loss: 14.7629 (14.9968)  loss_vfl: 0.4492 (0.4493)  loss_bbox: 0.1508 (0.1522)  loss_giou: 0.4656 (0.4904)  loss_vfl_aux_0: 1.0020 (0.9962)  loss_bbox_aux_0: 0.1784 (0.1715)  loss_giou_aux_0: 0.5191 (0.5139)  loss_vfl_aux_1: 0.5896 (0.6047)  loss_bbox_aux_1: 0.1789 (0.1778)  loss_giou_aux_1: 0.5074 (0.5272)  loss_vfl_aux_2: 0.4819 (0.4796)  loss_bbox_aux_2: 0.1600 (0.1657)  loss_giou_aux_2: 0.4928 (0.5134)  loss_vfl_aux_3: 0.4683 (0.4633)  loss_bbox_aux_3: 0.1560 (0.1556)  loss_giou_aux_3: 0.4795 (0.5012)  loss_vfl_aux_4: 0.4642 (0.4564)  loss_bbox_aux_4: 0.1499 (0.1510)  loss_giou_aux_4: 0.4657 (0.4906)  loss_vfl_dn_0: 0.4778 (0.4802)  loss_bbox_dn_0: 0.1551 (0.1522)  loss_giou_dn_0: 0.5019 (0.5064)  loss_vfl_dn_1: 0.4121 (0.4134)  loss_bbox_dn_1: 0.1293 (0.1308)  loss_giou_dn_1: 0.4456 (0.4476)  loss_vfl_dn_2: 0.3911 (0.3924)  loss_bbox_dn_2: 0.1229 (0.1224)  loss_giou_dn_2: 0.4293 (0.4288)  loss_vfl_dn_3: 0.3917 (0.3875)  loss_bbox_dn_3: 0.1200 (0.1206)  loss_giou_dn_3: 0.4227 (0.4235)  loss_vfl_dn_4: 0.3901 (0.3867)  loss_bbox_dn_4: 0.1200 (0.1202)  loss_giou_dn_4: 0.4187 (0.4213)  loss_vfl_dn_5: 0.3875 (0.3855)  loss_bbox_dn_5: 0.1194 (0.1198)  loss_giou_dn_5: 0.4165 (0.4196)  loss_vfl_enc_0: 0.8711 (0.8846)  loss_bbox_enc_0: 0.2039 (0.1975)  loss_giou_enc_0: 0.5889 (0.5954)  time: 1.0025  data: 0.4899  max mem: 16811\n",
            "Epoch: [121] Total time: 0:00:08 (1.0080 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.7629 (14.9968)  loss_vfl: 0.4492 (0.4493)  loss_bbox: 0.1508 (0.1522)  loss_giou: 0.4656 (0.4904)  loss_vfl_aux_0: 1.0020 (0.9962)  loss_bbox_aux_0: 0.1784 (0.1715)  loss_giou_aux_0: 0.5191 (0.5139)  loss_vfl_aux_1: 0.5896 (0.6047)  loss_bbox_aux_1: 0.1789 (0.1778)  loss_giou_aux_1: 0.5074 (0.5272)  loss_vfl_aux_2: 0.4819 (0.4796)  loss_bbox_aux_2: 0.1600 (0.1657)  loss_giou_aux_2: 0.4928 (0.5134)  loss_vfl_aux_3: 0.4683 (0.4633)  loss_bbox_aux_3: 0.1560 (0.1556)  loss_giou_aux_3: 0.4795 (0.5012)  loss_vfl_aux_4: 0.4642 (0.4564)  loss_bbox_aux_4: 0.1499 (0.1510)  loss_giou_aux_4: 0.4657 (0.4906)  loss_vfl_dn_0: 0.4778 (0.4802)  loss_bbox_dn_0: 0.1551 (0.1522)  loss_giou_dn_0: 0.5019 (0.5064)  loss_vfl_dn_1: 0.4121 (0.4134)  loss_bbox_dn_1: 0.1293 (0.1308)  loss_giou_dn_1: 0.4456 (0.4476)  loss_vfl_dn_2: 0.3911 (0.3924)  loss_bbox_dn_2: 0.1229 (0.1224)  loss_giou_dn_2: 0.4293 (0.4288)  loss_vfl_dn_3: 0.3917 (0.3875)  loss_bbox_dn_3: 0.1200 (0.1206)  loss_giou_dn_3: 0.4227 (0.4235)  loss_vfl_dn_4: 0.3901 (0.3867)  loss_bbox_dn_4: 0.1200 (0.1202)  loss_giou_dn_4: 0.4187 (0.4213)  loss_vfl_dn_5: 0.3875 (0.3855)  loss_bbox_dn_5: 0.1194 (0.1198)  loss_giou_dn_5: 0.4165 (0.4196)  loss_vfl_enc_0: 0.8711 (0.8846)  loss_bbox_enc_0: 0.2039 (0.1975)  loss_giou_enc_0: 0.5889 (0.5954)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8525  data: 4.4598  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1509  data: 2.2463  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1805 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            "best_stat: {'epoch': 111, 'coco_eval_bbox': 0.31813083760649197}\n",
            "Epoch: [122]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.8402 (14.8402)  loss_vfl: 0.4610 (0.4610)  loss_bbox: 0.1481 (0.1481)  loss_giou: 0.4629 (0.4629)  loss_vfl_aux_0: 1.0859 (1.0859)  loss_bbox_aux_0: 0.1708 (0.1708)  loss_giou_aux_0: 0.4783 (0.4783)  loss_vfl_aux_1: 0.6103 (0.6103)  loss_bbox_aux_1: 0.1761 (0.1761)  loss_giou_aux_1: 0.5075 (0.5075)  loss_vfl_aux_2: 0.4772 (0.4772)  loss_bbox_aux_2: 0.1705 (0.1705)  loss_giou_aux_2: 0.5013 (0.5013)  loss_vfl_aux_3: 0.4675 (0.4675)  loss_bbox_aux_3: 0.1545 (0.1545)  loss_giou_aux_3: 0.4706 (0.4706)  loss_vfl_aux_4: 0.4655 (0.4655)  loss_bbox_aux_4: 0.1481 (0.1481)  loss_giou_aux_4: 0.4620 (0.4620)  loss_vfl_dn_0: 0.4752 (0.4752)  loss_bbox_dn_0: 0.1513 (0.1513)  loss_giou_dn_0: 0.4919 (0.4919)  loss_vfl_dn_1: 0.4094 (0.4094)  loss_bbox_dn_1: 0.1279 (0.1279)  loss_giou_dn_1: 0.4316 (0.4316)  loss_vfl_dn_2: 0.3860 (0.3860)  loss_bbox_dn_2: 0.1204 (0.1204)  loss_giou_dn_2: 0.4132 (0.4132)  loss_vfl_dn_3: 0.3795 (0.3795)  loss_bbox_dn_3: 0.1186 (0.1186)  loss_giou_dn_3: 0.4088 (0.4088)  loss_vfl_dn_4: 0.3780 (0.3780)  loss_bbox_dn_4: 0.1183 (0.1183)  loss_giou_dn_4: 0.4063 (0.4063)  loss_vfl_dn_5: 0.3774 (0.3774)  loss_bbox_dn_5: 0.1180 (0.1180)  loss_giou_dn_5: 0.4058 (0.4058)  loss_vfl_enc_0: 0.9476 (0.9476)  loss_bbox_enc_0: 0.1894 (0.1894)  loss_giou_enc_0: 0.5672 (0.5672)  time: 1.4233  data: 0.8565  max mem: 16811\n",
            "Epoch: [122]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.8402 (14.9597)  loss_vfl: 0.4516 (0.4550)  loss_bbox: 0.1481 (0.1501)  loss_giou: 0.4823 (0.4819)  loss_vfl_aux_0: 0.9953 (1.0092)  loss_bbox_aux_0: 0.1695 (0.1680)  loss_giou_aux_0: 0.4843 (0.5010)  loss_vfl_aux_1: 0.6060 (0.6078)  loss_bbox_aux_1: 0.1727 (0.1743)  loss_giou_aux_1: 0.5075 (0.5210)  loss_vfl_aux_2: 0.4800 (0.4864)  loss_bbox_aux_2: 0.1666 (0.1651)  loss_giou_aux_2: 0.5013 (0.5103)  loss_vfl_aux_3: 0.4637 (0.4724)  loss_bbox_aux_3: 0.1545 (0.1563)  loss_giou_aux_3: 0.4918 (0.4920)  loss_vfl_aux_4: 0.4530 (0.4605)  loss_bbox_aux_4: 0.1481 (0.1497)  loss_giou_aux_4: 0.4851 (0.4833)  loss_vfl_dn_0: 0.4752 (0.4768)  loss_bbox_dn_0: 0.1513 (0.1536)  loss_giou_dn_0: 0.4987 (0.5038)  loss_vfl_dn_1: 0.4141 (0.4147)  loss_bbox_dn_1: 0.1279 (0.1312)  loss_giou_dn_1: 0.4492 (0.4456)  loss_vfl_dn_2: 0.3952 (0.3940)  loss_bbox_dn_2: 0.1204 (0.1219)  loss_giou_dn_2: 0.4172 (0.4238)  loss_vfl_dn_3: 0.3884 (0.3877)  loss_bbox_dn_3: 0.1186 (0.1200)  loss_giou_dn_3: 0.4125 (0.4197)  loss_vfl_dn_4: 0.3871 (0.3868)  loss_bbox_dn_4: 0.1183 (0.1195)  loss_giou_dn_4: 0.4123 (0.4174)  loss_vfl_dn_5: 0.3859 (0.3856)  loss_bbox_dn_5: 0.1180 (0.1192)  loss_giou_dn_5: 0.4099 (0.4162)  loss_vfl_enc_0: 0.9001 (0.8994)  loss_bbox_enc_0: 0.1894 (0.1928)  loss_giou_enc_0: 0.5676 (0.5855)  time: 0.6500  data: 0.1357  max mem: 16811\n",
            "Epoch: [122] Total time: 0:00:05 (0.6568 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.8402 (14.9597)  loss_vfl: 0.4516 (0.4550)  loss_bbox: 0.1481 (0.1501)  loss_giou: 0.4823 (0.4819)  loss_vfl_aux_0: 0.9953 (1.0092)  loss_bbox_aux_0: 0.1695 (0.1680)  loss_giou_aux_0: 0.4843 (0.5010)  loss_vfl_aux_1: 0.6060 (0.6078)  loss_bbox_aux_1: 0.1727 (0.1743)  loss_giou_aux_1: 0.5075 (0.5210)  loss_vfl_aux_2: 0.4800 (0.4864)  loss_bbox_aux_2: 0.1666 (0.1651)  loss_giou_aux_2: 0.5013 (0.5103)  loss_vfl_aux_3: 0.4637 (0.4724)  loss_bbox_aux_3: 0.1545 (0.1563)  loss_giou_aux_3: 0.4918 (0.4920)  loss_vfl_aux_4: 0.4530 (0.4605)  loss_bbox_aux_4: 0.1481 (0.1497)  loss_giou_aux_4: 0.4851 (0.4833)  loss_vfl_dn_0: 0.4752 (0.4768)  loss_bbox_dn_0: 0.1513 (0.1536)  loss_giou_dn_0: 0.4987 (0.5038)  loss_vfl_dn_1: 0.4141 (0.4147)  loss_bbox_dn_1: 0.1279 (0.1312)  loss_giou_dn_1: 0.4492 (0.4456)  loss_vfl_dn_2: 0.3952 (0.3940)  loss_bbox_dn_2: 0.1204 (0.1219)  loss_giou_dn_2: 0.4172 (0.4238)  loss_vfl_dn_3: 0.3884 (0.3877)  loss_bbox_dn_3: 0.1186 (0.1200)  loss_giou_dn_3: 0.4125 (0.4197)  loss_vfl_dn_4: 0.3871 (0.3868)  loss_bbox_dn_4: 0.1183 (0.1195)  loss_giou_dn_4: 0.4123 (0.4174)  loss_vfl_dn_5: 0.3859 (0.3856)  loss_bbox_dn_5: 0.1180 (0.1192)  loss_giou_dn_5: 0.4099 (0.4162)  loss_vfl_enc_0: 0.9001 (0.8994)  loss_bbox_enc_0: 0.1894 (0.1928)  loss_giou_enc_0: 0.5676 (0.5855)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.3991  data: 4.3392  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9229  data: 2.1859  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9419 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592\n",
            "best_stat: {'epoch': 122, 'coco_eval_bbox': 0.31819654853515383}\n",
            "Epoch: [123]  [0/8]  eta: 0:00:18  lr: 0.000005  loss: 16.0387 (16.0387)  loss_vfl: 0.4737 (0.4737)  loss_bbox: 0.1728 (0.1728)  loss_giou: 0.5442 (0.5442)  loss_vfl_aux_0: 0.9102 (0.9102)  loss_bbox_aux_0: 0.2286 (0.2286)  loss_giou_aux_0: 0.6083 (0.6083)  loss_vfl_aux_1: 0.5734 (0.5734)  loss_bbox_aux_1: 0.2251 (0.2251)  loss_giou_aux_1: 0.6157 (0.6157)  loss_vfl_aux_2: 0.4852 (0.4852)  loss_bbox_aux_2: 0.1943 (0.1943)  loss_giou_aux_2: 0.5812 (0.5812)  loss_vfl_aux_3: 0.4659 (0.4659)  loss_bbox_aux_3: 0.1831 (0.1831)  loss_giou_aux_3: 0.5658 (0.5658)  loss_vfl_aux_4: 0.4714 (0.4714)  loss_bbox_aux_4: 0.1784 (0.1784)  loss_giou_aux_4: 0.5519 (0.5519)  loss_vfl_dn_0: 0.4853 (0.4853)  loss_bbox_dn_0: 0.1638 (0.1638)  loss_giou_dn_0: 0.5454 (0.5454)  loss_vfl_dn_1: 0.4244 (0.4244)  loss_bbox_dn_1: 0.1436 (0.1436)  loss_giou_dn_1: 0.4968 (0.4968)  loss_vfl_dn_2: 0.4023 (0.4023)  loss_bbox_dn_2: 0.1321 (0.1321)  loss_giou_dn_2: 0.4701 (0.4701)  loss_vfl_dn_3: 0.3953 (0.3953)  loss_bbox_dn_3: 0.1291 (0.1291)  loss_giou_dn_3: 0.4648 (0.4648)  loss_vfl_dn_4: 0.3953 (0.3953)  loss_bbox_dn_4: 0.1284 (0.1284)  loss_giou_dn_4: 0.4606 (0.4606)  loss_vfl_dn_5: 0.3956 (0.3956)  loss_bbox_dn_5: 0.1284 (0.1284)  loss_giou_dn_5: 0.4589 (0.4589)  loss_vfl_enc_0: 0.8471 (0.8471)  loss_bbox_enc_0: 0.2471 (0.2471)  loss_giou_enc_0: 0.6951 (0.6951)  time: 2.2520  data: 1.6847  max mem: 16811\n",
            "Epoch: [123]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.4912 (14.8764)  loss_vfl: 0.4486 (0.4535)  loss_bbox: 0.1391 (0.1487)  loss_giou: 0.4752 (0.4835)  loss_vfl_aux_0: 0.9788 (0.9800)  loss_bbox_aux_0: 0.1549 (0.1684)  loss_giou_aux_0: 0.4894 (0.5048)  loss_vfl_aux_1: 0.6029 (0.6049)  loss_bbox_aux_1: 0.1639 (0.1721)  loss_giou_aux_1: 0.4992 (0.5175)  loss_vfl_aux_2: 0.4741 (0.4761)  loss_bbox_aux_2: 0.1486 (0.1604)  loss_giou_aux_2: 0.4881 (0.5052)  loss_vfl_aux_3: 0.4495 (0.4542)  loss_bbox_aux_3: 0.1431 (0.1525)  loss_giou_aux_3: 0.4845 (0.4948)  loss_vfl_aux_4: 0.4485 (0.4545)  loss_bbox_aux_4: 0.1388 (0.1497)  loss_giou_aux_4: 0.4804 (0.4862)  loss_vfl_dn_0: 0.4832 (0.4793)  loss_bbox_dn_0: 0.1475 (0.1506)  loss_giou_dn_0: 0.4979 (0.5044)  loss_vfl_dn_1: 0.4147 (0.4158)  loss_bbox_dn_1: 0.1251 (0.1295)  loss_giou_dn_1: 0.4393 (0.4476)  loss_vfl_dn_2: 0.3894 (0.3947)  loss_bbox_dn_2: 0.1158 (0.1214)  loss_giou_dn_2: 0.4154 (0.4269)  loss_vfl_dn_3: 0.3833 (0.3871)  loss_bbox_dn_3: 0.1140 (0.1196)  loss_giou_dn_3: 0.4107 (0.4228)  loss_vfl_dn_4: 0.3837 (0.3873)  loss_bbox_dn_4: 0.1129 (0.1189)  loss_giou_dn_4: 0.4066 (0.4206)  loss_vfl_dn_5: 0.3842 (0.3869)  loss_bbox_dn_5: 0.1127 (0.1188)  loss_giou_dn_5: 0.4058 (0.4191)  loss_vfl_enc_0: 0.8775 (0.8797)  loss_bbox_enc_0: 0.1846 (0.1917)  loss_giou_enc_0: 0.5651 (0.5867)  time: 0.7449  data: 0.2273  max mem: 16811\n",
            "Epoch: [123] Total time: 0:00:06 (0.7517 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.4912 (14.8764)  loss_vfl: 0.4486 (0.4535)  loss_bbox: 0.1391 (0.1487)  loss_giou: 0.4752 (0.4835)  loss_vfl_aux_0: 0.9788 (0.9800)  loss_bbox_aux_0: 0.1549 (0.1684)  loss_giou_aux_0: 0.4894 (0.5048)  loss_vfl_aux_1: 0.6029 (0.6049)  loss_bbox_aux_1: 0.1639 (0.1721)  loss_giou_aux_1: 0.4992 (0.5175)  loss_vfl_aux_2: 0.4741 (0.4761)  loss_bbox_aux_2: 0.1486 (0.1604)  loss_giou_aux_2: 0.4881 (0.5052)  loss_vfl_aux_3: 0.4495 (0.4542)  loss_bbox_aux_3: 0.1431 (0.1525)  loss_giou_aux_3: 0.4845 (0.4948)  loss_vfl_aux_4: 0.4485 (0.4545)  loss_bbox_aux_4: 0.1388 (0.1497)  loss_giou_aux_4: 0.4804 (0.4862)  loss_vfl_dn_0: 0.4832 (0.4793)  loss_bbox_dn_0: 0.1475 (0.1506)  loss_giou_dn_0: 0.4979 (0.5044)  loss_vfl_dn_1: 0.4147 (0.4158)  loss_bbox_dn_1: 0.1251 (0.1295)  loss_giou_dn_1: 0.4393 (0.4476)  loss_vfl_dn_2: 0.3894 (0.3947)  loss_bbox_dn_2: 0.1158 (0.1214)  loss_giou_dn_2: 0.4154 (0.4269)  loss_vfl_dn_3: 0.3833 (0.3871)  loss_bbox_dn_3: 0.1140 (0.1196)  loss_giou_dn_3: 0.4107 (0.4228)  loss_vfl_dn_4: 0.3837 (0.3873)  loss_bbox_dn_4: 0.1129 (0.1189)  loss_giou_dn_4: 0.4066 (0.4206)  loss_vfl_dn_5: 0.3842 (0.3869)  loss_bbox_dn_5: 0.1127 (0.1188)  loss_giou_dn_5: 0.4058 (0.4191)  loss_vfl_enc_0: 0.8775 (0.8797)  loss_bbox_enc_0: 0.1846 (0.1917)  loss_giou_enc_0: 0.5651 (0.5867)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.8277  data: 4.4358  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1413  data: 2.2349  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1789 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [124]  [0/8]  eta: 0:00:22  lr: 0.000005  loss: 14.6322 (14.6322)  loss_vfl: 0.4359 (0.4359)  loss_bbox: 0.1510 (0.1510)  loss_giou: 0.4806 (0.4806)  loss_vfl_aux_0: 0.9439 (0.9439)  loss_bbox_aux_0: 0.1547 (0.1547)  loss_giou_aux_0: 0.4794 (0.4794)  loss_vfl_aux_1: 0.6286 (0.6286)  loss_bbox_aux_1: 0.1622 (0.1622)  loss_giou_aux_1: 0.4953 (0.4953)  loss_vfl_aux_2: 0.4722 (0.4722)  loss_bbox_aux_2: 0.1688 (0.1688)  loss_giou_aux_2: 0.5002 (0.5002)  loss_vfl_aux_3: 0.4446 (0.4446)  loss_bbox_aux_3: 0.1556 (0.1556)  loss_giou_aux_3: 0.4848 (0.4848)  loss_vfl_aux_4: 0.4465 (0.4465)  loss_bbox_aux_4: 0.1484 (0.1484)  loss_giou_aux_4: 0.4707 (0.4707)  loss_vfl_dn_0: 0.4787 (0.4787)  loss_bbox_dn_0: 0.1509 (0.1509)  loss_giou_dn_0: 0.5045 (0.5045)  loss_vfl_dn_1: 0.4200 (0.4200)  loss_bbox_dn_1: 0.1260 (0.1260)  loss_giou_dn_1: 0.4423 (0.4423)  loss_vfl_dn_2: 0.3965 (0.3965)  loss_bbox_dn_2: 0.1184 (0.1184)  loss_giou_dn_2: 0.4201 (0.4201)  loss_vfl_dn_3: 0.3889 (0.3889)  loss_bbox_dn_3: 0.1158 (0.1158)  loss_giou_dn_3: 0.4131 (0.4131)  loss_vfl_dn_4: 0.3870 (0.3870)  loss_bbox_dn_4: 0.1162 (0.1162)  loss_giou_dn_4: 0.4140 (0.4140)  loss_vfl_dn_5: 0.3864 (0.3864)  loss_bbox_dn_5: 0.1157 (0.1157)  loss_giou_dn_5: 0.4111 (0.4111)  loss_vfl_enc_0: 0.8950 (0.8950)  loss_bbox_enc_0: 0.1702 (0.1702)  loss_giou_enc_0: 0.5381 (0.5381)  time: 2.8201  data: 2.2398  max mem: 16811\n",
            "Epoch: [124]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.6322 (14.7515)  loss_vfl: 0.4403 (0.4467)  loss_bbox: 0.1456 (0.1453)  loss_giou: 0.4710 (0.4771)  loss_vfl_aux_0: 0.9459 (0.9490)  loss_bbox_aux_0: 0.1666 (0.1659)  loss_giou_aux_0: 0.4885 (0.5031)  loss_vfl_aux_1: 0.6175 (0.6086)  loss_bbox_aux_1: 0.1643 (0.1722)  loss_giou_aux_1: 0.5052 (0.5161)  loss_vfl_aux_2: 0.4722 (0.4750)  loss_bbox_aux_2: 0.1565 (0.1575)  loss_giou_aux_2: 0.4967 (0.5002)  loss_vfl_aux_3: 0.4446 (0.4490)  loss_bbox_aux_3: 0.1513 (0.1512)  loss_giou_aux_3: 0.4848 (0.4907)  loss_vfl_aux_4: 0.4465 (0.4531)  loss_bbox_aux_4: 0.1465 (0.1456)  loss_giou_aux_4: 0.4702 (0.4769)  loss_vfl_dn_0: 0.4766 (0.4764)  loss_bbox_dn_0: 0.1509 (0.1510)  loss_giou_dn_0: 0.5045 (0.5056)  loss_vfl_dn_1: 0.4170 (0.4146)  loss_bbox_dn_1: 0.1260 (0.1290)  loss_giou_dn_1: 0.4497 (0.4457)  loss_vfl_dn_2: 0.3914 (0.3927)  loss_bbox_dn_2: 0.1184 (0.1195)  loss_giou_dn_2: 0.4264 (0.4224)  loss_vfl_dn_3: 0.3862 (0.3863)  loss_bbox_dn_3: 0.1158 (0.1185)  loss_giou_dn_3: 0.4245 (0.4199)  loss_vfl_dn_4: 0.3864 (0.3853)  loss_bbox_dn_4: 0.1161 (0.1176)  loss_giou_dn_4: 0.4215 (0.4172)  loss_vfl_dn_5: 0.3851 (0.3836)  loss_bbox_dn_5: 0.1157 (0.1174)  loss_giou_dn_5: 0.4211 (0.4161)  loss_vfl_enc_0: 0.8726 (0.8749)  loss_bbox_enc_0: 0.1927 (0.1917)  loss_giou_enc_0: 0.5712 (0.5830)  time: 0.8234  data: 0.3064  max mem: 16811\n",
            "Epoch: [124] Total time: 0:00:06 (0.8329 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.6322 (14.7515)  loss_vfl: 0.4403 (0.4467)  loss_bbox: 0.1456 (0.1453)  loss_giou: 0.4710 (0.4771)  loss_vfl_aux_0: 0.9459 (0.9490)  loss_bbox_aux_0: 0.1666 (0.1659)  loss_giou_aux_0: 0.4885 (0.5031)  loss_vfl_aux_1: 0.6175 (0.6086)  loss_bbox_aux_1: 0.1643 (0.1722)  loss_giou_aux_1: 0.5052 (0.5161)  loss_vfl_aux_2: 0.4722 (0.4750)  loss_bbox_aux_2: 0.1565 (0.1575)  loss_giou_aux_2: 0.4967 (0.5002)  loss_vfl_aux_3: 0.4446 (0.4490)  loss_bbox_aux_3: 0.1513 (0.1512)  loss_giou_aux_3: 0.4848 (0.4907)  loss_vfl_aux_4: 0.4465 (0.4531)  loss_bbox_aux_4: 0.1465 (0.1456)  loss_giou_aux_4: 0.4702 (0.4769)  loss_vfl_dn_0: 0.4766 (0.4764)  loss_bbox_dn_0: 0.1509 (0.1510)  loss_giou_dn_0: 0.5045 (0.5056)  loss_vfl_dn_1: 0.4170 (0.4146)  loss_bbox_dn_1: 0.1260 (0.1290)  loss_giou_dn_1: 0.4497 (0.4457)  loss_vfl_dn_2: 0.3914 (0.3927)  loss_bbox_dn_2: 0.1184 (0.1195)  loss_giou_dn_2: 0.4264 (0.4224)  loss_vfl_dn_3: 0.3862 (0.3863)  loss_bbox_dn_3: 0.1158 (0.1185)  loss_giou_dn_3: 0.4245 (0.4199)  loss_vfl_dn_4: 0.3864 (0.3853)  loss_bbox_dn_4: 0.1161 (0.1176)  loss_giou_dn_4: 0.4215 (0.4172)  loss_vfl_dn_5: 0.3851 (0.3836)  loss_bbox_dn_5: 0.1157 (0.1174)  loss_giou_dn_5: 0.4211 (0.4161)  loss_vfl_enc_0: 0.8726 (0.8749)  loss_bbox_enc_0: 0.1927 (0.1917)  loss_giou_enc_0: 0.5712 (0.5830)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3608  data: 1.2856  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4064  data: 0.6594  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4312 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [125]  [0/8]  eta: 0:00:27  lr: 0.000005  loss: 15.4140 (15.4140)  loss_vfl: 0.4743 (0.4743)  loss_bbox: 0.1658 (0.1658)  loss_giou: 0.5146 (0.5146)  loss_vfl_aux_0: 0.9460 (0.9460)  loss_bbox_aux_0: 0.1816 (0.1816)  loss_giou_aux_0: 0.5438 (0.5438)  loss_vfl_aux_1: 0.6011 (0.6011)  loss_bbox_aux_1: 0.1856 (0.1856)  loss_giou_aux_1: 0.5429 (0.5429)  loss_vfl_aux_2: 0.5045 (0.5045)  loss_bbox_aux_2: 0.1782 (0.1782)  loss_giou_aux_2: 0.5270 (0.5270)  loss_vfl_aux_3: 0.4766 (0.4766)  loss_bbox_aux_3: 0.1819 (0.1819)  loss_giou_aux_3: 0.5210 (0.5210)  loss_vfl_aux_4: 0.4858 (0.4858)  loss_bbox_aux_4: 0.1677 (0.1677)  loss_giou_aux_4: 0.5136 (0.5136)  loss_vfl_dn_0: 0.4704 (0.4704)  loss_bbox_dn_0: 0.1536 (0.1536)  loss_giou_dn_0: 0.5323 (0.5323)  loss_vfl_dn_1: 0.4054 (0.4054)  loss_bbox_dn_1: 0.1364 (0.1364)  loss_giou_dn_1: 0.4817 (0.4817)  loss_vfl_dn_2: 0.3892 (0.3892)  loss_bbox_dn_2: 0.1248 (0.1248)  loss_giou_dn_2: 0.4497 (0.4497)  loss_vfl_dn_3: 0.3836 (0.3836)  loss_bbox_dn_3: 0.1229 (0.1229)  loss_giou_dn_3: 0.4457 (0.4457)  loss_vfl_dn_4: 0.3858 (0.3858)  loss_bbox_dn_4: 0.1229 (0.1229)  loss_giou_dn_4: 0.4439 (0.4439)  loss_vfl_dn_5: 0.3831 (0.3831)  loss_bbox_dn_5: 0.1226 (0.1226)  loss_giou_dn_5: 0.4435 (0.4435)  loss_vfl_enc_0: 0.8559 (0.8559)  loss_bbox_enc_0: 0.2070 (0.2070)  loss_giou_enc_0: 0.6415 (0.6415)  time: 3.4708  data: 2.8965  max mem: 16811\n",
            "Epoch: [125]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.3688 (14.5548)  loss_vfl: 0.4276 (0.4419)  loss_bbox: 0.1398 (0.1427)  loss_giou: 0.4658 (0.4699)  loss_vfl_aux_0: 0.9585 (0.9567)  loss_bbox_aux_0: 0.1582 (0.1637)  loss_giou_aux_0: 0.4801 (0.4919)  loss_vfl_aux_1: 0.5917 (0.5870)  loss_bbox_aux_1: 0.1605 (0.1659)  loss_giou_aux_1: 0.4858 (0.5026)  loss_vfl_aux_2: 0.4600 (0.4708)  loss_bbox_aux_2: 0.1513 (0.1545)  loss_giou_aux_2: 0.4807 (0.4876)  loss_vfl_aux_3: 0.4406 (0.4465)  loss_bbox_aux_3: 0.1438 (0.1484)  loss_giou_aux_3: 0.4708 (0.4783)  loss_vfl_aux_4: 0.4457 (0.4487)  loss_bbox_aux_4: 0.1399 (0.1422)  loss_giou_aux_4: 0.4642 (0.4705)  loss_vfl_dn_0: 0.4721 (0.4743)  loss_bbox_dn_0: 0.1459 (0.1475)  loss_giou_dn_0: 0.4872 (0.4974)  loss_vfl_dn_1: 0.4048 (0.4082)  loss_bbox_dn_1: 0.1226 (0.1248)  loss_giou_dn_1: 0.4319 (0.4375)  loss_vfl_dn_2: 0.3892 (0.3909)  loss_bbox_dn_2: 0.1151 (0.1170)  loss_giou_dn_2: 0.4204 (0.4179)  loss_vfl_dn_3: 0.3836 (0.3839)  loss_bbox_dn_3: 0.1119 (0.1150)  loss_giou_dn_3: 0.4169 (0.4132)  loss_vfl_dn_4: 0.3858 (0.3838)  loss_bbox_dn_4: 0.1123 (0.1147)  loss_giou_dn_4: 0.4148 (0.4109)  loss_vfl_dn_5: 0.3831 (0.3821)  loss_bbox_dn_5: 0.1121 (0.1144)  loss_giou_dn_5: 0.4127 (0.4096)  loss_vfl_enc_0: 0.8608 (0.8673)  loss_bbox_enc_0: 0.1923 (0.1914)  loss_giou_enc_0: 0.5714 (0.5833)  time: 0.9538  data: 0.3936  max mem: 16811\n",
            "Epoch: [125] Total time: 0:00:07 (0.9604 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.3688 (14.5548)  loss_vfl: 0.4276 (0.4419)  loss_bbox: 0.1398 (0.1427)  loss_giou: 0.4658 (0.4699)  loss_vfl_aux_0: 0.9585 (0.9567)  loss_bbox_aux_0: 0.1582 (0.1637)  loss_giou_aux_0: 0.4801 (0.4919)  loss_vfl_aux_1: 0.5917 (0.5870)  loss_bbox_aux_1: 0.1605 (0.1659)  loss_giou_aux_1: 0.4858 (0.5026)  loss_vfl_aux_2: 0.4600 (0.4708)  loss_bbox_aux_2: 0.1513 (0.1545)  loss_giou_aux_2: 0.4807 (0.4876)  loss_vfl_aux_3: 0.4406 (0.4465)  loss_bbox_aux_3: 0.1438 (0.1484)  loss_giou_aux_3: 0.4708 (0.4783)  loss_vfl_aux_4: 0.4457 (0.4487)  loss_bbox_aux_4: 0.1399 (0.1422)  loss_giou_aux_4: 0.4642 (0.4705)  loss_vfl_dn_0: 0.4721 (0.4743)  loss_bbox_dn_0: 0.1459 (0.1475)  loss_giou_dn_0: 0.4872 (0.4974)  loss_vfl_dn_1: 0.4048 (0.4082)  loss_bbox_dn_1: 0.1226 (0.1248)  loss_giou_dn_1: 0.4319 (0.4375)  loss_vfl_dn_2: 0.3892 (0.3909)  loss_bbox_dn_2: 0.1151 (0.1170)  loss_giou_dn_2: 0.4204 (0.4179)  loss_vfl_dn_3: 0.3836 (0.3839)  loss_bbox_dn_3: 0.1119 (0.1150)  loss_giou_dn_3: 0.4169 (0.4132)  loss_vfl_dn_4: 0.3858 (0.3838)  loss_bbox_dn_4: 0.1123 (0.1147)  loss_giou_dn_4: 0.4148 (0.4109)  loss_vfl_dn_5: 0.3831 (0.3821)  loss_bbox_dn_5: 0.1121 (0.1144)  loss_giou_dn_5: 0.4127 (0.4096)  loss_vfl_enc_0: 0.8608 (0.8673)  loss_bbox_enc_0: 0.1923 (0.1914)  loss_giou_enc_0: 0.5714 (0.5833)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.1248  data: 4.0594  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7952  data: 2.0466  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8201 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [126]  [0/8]  eta: 0:00:13  lr: 0.000005  loss: 14.6517 (14.6517)  loss_vfl: 0.4237 (0.4237)  loss_bbox: 0.1463 (0.1463)  loss_giou: 0.4689 (0.4689)  loss_vfl_aux_0: 0.9188 (0.9188)  loss_bbox_aux_0: 0.1852 (0.1852)  loss_giou_aux_0: 0.5251 (0.5251)  loss_vfl_aux_1: 0.5772 (0.5772)  loss_bbox_aux_1: 0.1884 (0.1884)  loss_giou_aux_1: 0.5294 (0.5294)  loss_vfl_aux_2: 0.4623 (0.4623)  loss_bbox_aux_2: 0.1639 (0.1639)  loss_giou_aux_2: 0.5008 (0.5008)  loss_vfl_aux_3: 0.4290 (0.4290)  loss_bbox_aux_3: 0.1506 (0.1506)  loss_giou_aux_3: 0.4877 (0.4877)  loss_vfl_aux_4: 0.4308 (0.4308)  loss_bbox_aux_4: 0.1460 (0.1460)  loss_giou_aux_4: 0.4712 (0.4712)  loss_vfl_dn_0: 0.4712 (0.4712)  loss_bbox_dn_0: 0.1519 (0.1519)  loss_giou_dn_0: 0.5008 (0.5008)  loss_vfl_dn_1: 0.4086 (0.4086)  loss_bbox_dn_1: 0.1279 (0.1279)  loss_giou_dn_1: 0.4432 (0.4432)  loss_vfl_dn_2: 0.3886 (0.3886)  loss_bbox_dn_2: 0.1226 (0.1226)  loss_giou_dn_2: 0.4267 (0.4267)  loss_vfl_dn_3: 0.3784 (0.3784)  loss_bbox_dn_3: 0.1206 (0.1206)  loss_giou_dn_3: 0.4221 (0.4221)  loss_vfl_dn_4: 0.3783 (0.3783)  loss_bbox_dn_4: 0.1197 (0.1197)  loss_giou_dn_4: 0.4175 (0.4175)  loss_vfl_dn_5: 0.3777 (0.3777)  loss_bbox_dn_5: 0.1195 (0.1195)  loss_giou_dn_5: 0.4162 (0.4162)  loss_vfl_enc_0: 0.8462 (0.8462)  loss_bbox_enc_0: 0.2120 (0.2120)  loss_giou_enc_0: 0.5969 (0.5969)  time: 1.6535  data: 1.0734  max mem: 16811\n",
            "Epoch: [126]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.6517 (14.7489)  loss_vfl: 0.4578 (0.4663)  loss_bbox: 0.1352 (0.1422)  loss_giou: 0.4608 (0.4658)  loss_vfl_aux_0: 0.9729 (0.9742)  loss_bbox_aux_0: 0.1648 (0.1682)  loss_giou_aux_0: 0.4983 (0.4990)  loss_vfl_aux_1: 0.6238 (0.6238)  loss_bbox_aux_1: 0.1710 (0.1725)  loss_giou_aux_1: 0.5080 (0.5093)  loss_vfl_aux_2: 0.4684 (0.4867)  loss_bbox_aux_2: 0.1457 (0.1533)  loss_giou_aux_2: 0.4777 (0.4882)  loss_vfl_aux_3: 0.4609 (0.4716)  loss_bbox_aux_3: 0.1429 (0.1476)  loss_giou_aux_3: 0.4708 (0.4768)  loss_vfl_aux_4: 0.4568 (0.4649)  loss_bbox_aux_4: 0.1352 (0.1433)  loss_giou_aux_4: 0.4620 (0.4670)  loss_vfl_dn_0: 0.4712 (0.4725)  loss_bbox_dn_0: 0.1495 (0.1502)  loss_giou_dn_0: 0.5005 (0.4994)  loss_vfl_dn_1: 0.4090 (0.4103)  loss_bbox_dn_1: 0.1256 (0.1274)  loss_giou_dn_1: 0.4376 (0.4396)  loss_vfl_dn_2: 0.3880 (0.3891)  loss_bbox_dn_2: 0.1159 (0.1194)  loss_giou_dn_2: 0.4183 (0.4202)  loss_vfl_dn_3: 0.3787 (0.3831)  loss_bbox_dn_3: 0.1135 (0.1175)  loss_giou_dn_3: 0.4141 (0.4158)  loss_vfl_dn_4: 0.3789 (0.3822)  loss_bbox_dn_4: 0.1130 (0.1172)  loss_giou_dn_4: 0.4104 (0.4132)  loss_vfl_dn_5: 0.3783 (0.3820)  loss_bbox_dn_5: 0.1127 (0.1169)  loss_giou_dn_5: 0.4088 (0.4116)  loss_vfl_enc_0: 0.8666 (0.8770)  loss_bbox_enc_0: 0.1980 (0.1972)  loss_giou_enc_0: 0.5924 (0.5864)  time: 0.6665  data: 0.1526  max mem: 16811\n",
            "Epoch: [126] Total time: 0:00:05 (0.6726 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.6517 (14.7489)  loss_vfl: 0.4578 (0.4663)  loss_bbox: 0.1352 (0.1422)  loss_giou: 0.4608 (0.4658)  loss_vfl_aux_0: 0.9729 (0.9742)  loss_bbox_aux_0: 0.1648 (0.1682)  loss_giou_aux_0: 0.4983 (0.4990)  loss_vfl_aux_1: 0.6238 (0.6238)  loss_bbox_aux_1: 0.1710 (0.1725)  loss_giou_aux_1: 0.5080 (0.5093)  loss_vfl_aux_2: 0.4684 (0.4867)  loss_bbox_aux_2: 0.1457 (0.1533)  loss_giou_aux_2: 0.4777 (0.4882)  loss_vfl_aux_3: 0.4609 (0.4716)  loss_bbox_aux_3: 0.1429 (0.1476)  loss_giou_aux_3: 0.4708 (0.4768)  loss_vfl_aux_4: 0.4568 (0.4649)  loss_bbox_aux_4: 0.1352 (0.1433)  loss_giou_aux_4: 0.4620 (0.4670)  loss_vfl_dn_0: 0.4712 (0.4725)  loss_bbox_dn_0: 0.1495 (0.1502)  loss_giou_dn_0: 0.5005 (0.4994)  loss_vfl_dn_1: 0.4090 (0.4103)  loss_bbox_dn_1: 0.1256 (0.1274)  loss_giou_dn_1: 0.4376 (0.4396)  loss_vfl_dn_2: 0.3880 (0.3891)  loss_bbox_dn_2: 0.1159 (0.1194)  loss_giou_dn_2: 0.4183 (0.4202)  loss_vfl_dn_3: 0.3787 (0.3831)  loss_bbox_dn_3: 0.1135 (0.1175)  loss_giou_dn_3: 0.4141 (0.4158)  loss_vfl_dn_4: 0.3789 (0.3822)  loss_bbox_dn_4: 0.1130 (0.1172)  loss_giou_dn_4: 0.4104 (0.4132)  loss_vfl_dn_5: 0.3783 (0.3820)  loss_bbox_dn_5: 0.1127 (0.1169)  loss_giou_dn_5: 0.4088 (0.4116)  loss_vfl_enc_0: 0.8666 (0.8770)  loss_bbox_enc_0: 0.1980 (0.1972)  loss_giou_enc_0: 0.5924 (0.5864)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.7557  data: 3.6830  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7722  data: 1.8577  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.8014 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [127]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 15.4014 (15.4014)  loss_vfl: 0.4520 (0.4520)  loss_bbox: 0.1630 (0.1630)  loss_giou: 0.5110 (0.5110)  loss_vfl_aux_0: 0.9418 (0.9418)  loss_bbox_aux_0: 0.2116 (0.2116)  loss_giou_aux_0: 0.5658 (0.5658)  loss_vfl_aux_1: 0.5881 (0.5881)  loss_bbox_aux_1: 0.1927 (0.1927)  loss_giou_aux_1: 0.5732 (0.5732)  loss_vfl_aux_2: 0.4721 (0.4721)  loss_bbox_aux_2: 0.1747 (0.1747)  loss_giou_aux_2: 0.5421 (0.5421)  loss_vfl_aux_3: 0.4590 (0.4590)  loss_bbox_aux_3: 0.1679 (0.1679)  loss_giou_aux_3: 0.5226 (0.5226)  loss_vfl_aux_4: 0.4550 (0.4550)  loss_bbox_aux_4: 0.1634 (0.1634)  loss_giou_aux_4: 0.5124 (0.5124)  loss_vfl_dn_0: 0.4726 (0.4726)  loss_bbox_dn_0: 0.1590 (0.1590)  loss_giou_dn_0: 0.5184 (0.5184)  loss_vfl_dn_1: 0.4142 (0.4142)  loss_bbox_dn_1: 0.1335 (0.1335)  loss_giou_dn_1: 0.4586 (0.4586)  loss_vfl_dn_2: 0.3955 (0.3955)  loss_bbox_dn_2: 0.1273 (0.1273)  loss_giou_dn_2: 0.4417 (0.4417)  loss_vfl_dn_3: 0.3953 (0.3953)  loss_bbox_dn_3: 0.1248 (0.1248)  loss_giou_dn_3: 0.4369 (0.4369)  loss_vfl_dn_4: 0.3923 (0.3923)  loss_bbox_dn_4: 0.1250 (0.1250)  loss_giou_dn_4: 0.4362 (0.4362)  loss_vfl_dn_5: 0.3892 (0.3892)  loss_bbox_dn_5: 0.1247 (0.1247)  loss_giou_dn_5: 0.4334 (0.4334)  loss_vfl_enc_0: 0.8593 (0.8593)  loss_bbox_enc_0: 0.2411 (0.2411)  loss_giou_enc_0: 0.6539 (0.6539)  time: 1.4569  data: 0.8938  max mem: 16811\n",
            "Epoch: [127]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.4213 (14.6193)  loss_vfl: 0.4393 (0.4459)  loss_bbox: 0.1392 (0.1400)  loss_giou: 0.4542 (0.4701)  loss_vfl_aux_0: 0.9471 (0.9651)  loss_bbox_aux_0: 0.1589 (0.1637)  loss_giou_aux_0: 0.4748 (0.4932)  loss_vfl_aux_1: 0.5878 (0.5906)  loss_bbox_aux_1: 0.1600 (0.1623)  loss_giou_aux_1: 0.4832 (0.5053)  loss_vfl_aux_2: 0.4664 (0.4711)  loss_bbox_aux_2: 0.1392 (0.1476)  loss_giou_aux_2: 0.4661 (0.4912)  loss_vfl_aux_3: 0.4502 (0.4542)  loss_bbox_aux_3: 0.1356 (0.1443)  loss_giou_aux_3: 0.4576 (0.4810)  loss_vfl_aux_4: 0.4397 (0.4498)  loss_bbox_aux_4: 0.1361 (0.1405)  loss_giou_aux_4: 0.4541 (0.4722)  loss_vfl_dn_0: 0.4744 (0.4739)  loss_bbox_dn_0: 0.1514 (0.1518)  loss_giou_dn_0: 0.4996 (0.5047)  loss_vfl_dn_1: 0.4142 (0.4109)  loss_bbox_dn_1: 0.1306 (0.1269)  loss_giou_dn_1: 0.4374 (0.4406)  loss_vfl_dn_2: 0.3909 (0.3896)  loss_bbox_dn_2: 0.1220 (0.1190)  loss_giou_dn_2: 0.4142 (0.4222)  loss_vfl_dn_3: 0.3880 (0.3851)  loss_bbox_dn_3: 0.1198 (0.1177)  loss_giou_dn_3: 0.4121 (0.4183)  loss_vfl_dn_4: 0.3859 (0.3843)  loss_bbox_dn_4: 0.1191 (0.1171)  loss_giou_dn_4: 0.4110 (0.4162)  loss_vfl_dn_5: 0.3825 (0.3825)  loss_bbox_dn_5: 0.1188 (0.1169)  loss_giou_dn_5: 0.4088 (0.4145)  loss_vfl_enc_0: 0.8593 (0.8650)  loss_bbox_enc_0: 0.1832 (0.1922)  loss_giou_enc_0: 0.5577 (0.5819)  time: 0.6602  data: 0.1442  max mem: 16811\n",
            "Epoch: [127] Total time: 0:00:05 (0.6659 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.4213 (14.6193)  loss_vfl: 0.4393 (0.4459)  loss_bbox: 0.1392 (0.1400)  loss_giou: 0.4542 (0.4701)  loss_vfl_aux_0: 0.9471 (0.9651)  loss_bbox_aux_0: 0.1589 (0.1637)  loss_giou_aux_0: 0.4748 (0.4932)  loss_vfl_aux_1: 0.5878 (0.5906)  loss_bbox_aux_1: 0.1600 (0.1623)  loss_giou_aux_1: 0.4832 (0.5053)  loss_vfl_aux_2: 0.4664 (0.4711)  loss_bbox_aux_2: 0.1392 (0.1476)  loss_giou_aux_2: 0.4661 (0.4912)  loss_vfl_aux_3: 0.4502 (0.4542)  loss_bbox_aux_3: 0.1356 (0.1443)  loss_giou_aux_3: 0.4576 (0.4810)  loss_vfl_aux_4: 0.4397 (0.4498)  loss_bbox_aux_4: 0.1361 (0.1405)  loss_giou_aux_4: 0.4541 (0.4722)  loss_vfl_dn_0: 0.4744 (0.4739)  loss_bbox_dn_0: 0.1514 (0.1518)  loss_giou_dn_0: 0.4996 (0.5047)  loss_vfl_dn_1: 0.4142 (0.4109)  loss_bbox_dn_1: 0.1306 (0.1269)  loss_giou_dn_1: 0.4374 (0.4406)  loss_vfl_dn_2: 0.3909 (0.3896)  loss_bbox_dn_2: 0.1220 (0.1190)  loss_giou_dn_2: 0.4142 (0.4222)  loss_vfl_dn_3: 0.3880 (0.3851)  loss_bbox_dn_3: 0.1198 (0.1177)  loss_giou_dn_3: 0.4121 (0.4183)  loss_vfl_dn_4: 0.3859 (0.3843)  loss_bbox_dn_4: 0.1191 (0.1171)  loss_giou_dn_4: 0.4110 (0.4162)  loss_vfl_dn_5: 0.3825 (0.3825)  loss_bbox_dn_5: 0.1188 (0.1169)  loss_giou_dn_5: 0.4088 (0.4145)  loss_vfl_enc_0: 0.8593 (0.8650)  loss_bbox_enc_0: 0.1832 (0.1922)  loss_giou_enc_0: 0.5577 (0.5819)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.9657  data: 3.8933  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7088  data: 1.9631  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.7373 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [128]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.6899 (14.6899)  loss_vfl: 0.4482 (0.4482)  loss_bbox: 0.1455 (0.1455)  loss_giou: 0.4648 (0.4648)  loss_vfl_aux_0: 0.9597 (0.9597)  loss_bbox_aux_0: 0.1711 (0.1711)  loss_giou_aux_0: 0.5040 (0.5040)  loss_vfl_aux_1: 0.6067 (0.6067)  loss_bbox_aux_1: 0.1667 (0.1667)  loss_giou_aux_1: 0.4943 (0.4943)  loss_vfl_aux_2: 0.4815 (0.4815)  loss_bbox_aux_2: 0.1589 (0.1589)  loss_giou_aux_2: 0.4869 (0.4869)  loss_vfl_aux_3: 0.4571 (0.4571)  loss_bbox_aux_3: 0.1588 (0.1588)  loss_giou_aux_3: 0.4775 (0.4775)  loss_vfl_aux_4: 0.4526 (0.4526)  loss_bbox_aux_4: 0.1423 (0.1423)  loss_giou_aux_4: 0.4633 (0.4633)  loss_vfl_dn_0: 0.4673 (0.4673)  loss_bbox_dn_0: 0.1577 (0.1577)  loss_giou_dn_0: 0.5029 (0.5029)  loss_vfl_dn_1: 0.4102 (0.4102)  loss_bbox_dn_1: 0.1351 (0.1351)  loss_giou_dn_1: 0.4381 (0.4381)  loss_vfl_dn_2: 0.3929 (0.3929)  loss_bbox_dn_2: 0.1260 (0.1260)  loss_giou_dn_2: 0.4165 (0.4165)  loss_vfl_dn_3: 0.3862 (0.3862)  loss_bbox_dn_3: 0.1244 (0.1244)  loss_giou_dn_3: 0.4099 (0.4099)  loss_vfl_dn_4: 0.3857 (0.3857)  loss_bbox_dn_4: 0.1248 (0.1248)  loss_giou_dn_4: 0.4098 (0.4098)  loss_vfl_dn_5: 0.3833 (0.3833)  loss_bbox_dn_5: 0.1245 (0.1245)  loss_giou_dn_5: 0.4087 (0.4087)  loss_vfl_enc_0: 0.8530 (0.8530)  loss_bbox_enc_0: 0.2047 (0.2047)  loss_giou_enc_0: 0.5883 (0.5883)  time: 1.4684  data: 0.9037  max mem: 16811\n",
            "Epoch: [128]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.5362 (14.5892)  loss_vfl: 0.4482 (0.4482)  loss_bbox: 0.1401 (0.1432)  loss_giou: 0.4739 (0.4697)  loss_vfl_aux_0: 0.9597 (0.9591)  loss_bbox_aux_0: 0.1592 (0.1642)  loss_giou_aux_0: 0.5006 (0.4976)  loss_vfl_aux_1: 0.5829 (0.5912)  loss_bbox_aux_1: 0.1639 (0.1633)  loss_giou_aux_1: 0.5080 (0.5029)  loss_vfl_aux_2: 0.4781 (0.4784)  loss_bbox_aux_2: 0.1469 (0.1534)  loss_giou_aux_2: 0.4889 (0.4890)  loss_vfl_aux_3: 0.4534 (0.4573)  loss_bbox_aux_3: 0.1422 (0.1484)  loss_giou_aux_3: 0.4779 (0.4785)  loss_vfl_aux_4: 0.4522 (0.4524)  loss_bbox_aux_4: 0.1384 (0.1429)  loss_giou_aux_4: 0.4710 (0.4689)  loss_vfl_dn_0: 0.4673 (0.4727)  loss_bbox_dn_0: 0.1494 (0.1478)  loss_giou_dn_0: 0.4923 (0.4959)  loss_vfl_dn_1: 0.4068 (0.4097)  loss_bbox_dn_1: 0.1263 (0.1265)  loss_giou_dn_1: 0.4352 (0.4365)  loss_vfl_dn_2: 0.3895 (0.3906)  loss_bbox_dn_2: 0.1155 (0.1183)  loss_giou_dn_2: 0.4165 (0.4159)  loss_vfl_dn_3: 0.3806 (0.3831)  loss_bbox_dn_3: 0.1137 (0.1166)  loss_giou_dn_3: 0.4099 (0.4117)  loss_vfl_dn_4: 0.3798 (0.3825)  loss_bbox_dn_4: 0.1126 (0.1164)  loss_giou_dn_4: 0.4098 (0.4103)  loss_vfl_dn_5: 0.3787 (0.3818)  loss_bbox_dn_5: 0.1125 (0.1161)  loss_giou_dn_5: 0.4087 (0.4087)  loss_vfl_enc_0: 0.8622 (0.8641)  loss_bbox_enc_0: 0.1941 (0.1915)  loss_giou_enc_0: 0.5883 (0.5841)  time: 0.6543  data: 0.1410  max mem: 16811\n",
            "Epoch: [128] Total time: 0:00:05 (0.6622 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.5362 (14.5892)  loss_vfl: 0.4482 (0.4482)  loss_bbox: 0.1401 (0.1432)  loss_giou: 0.4739 (0.4697)  loss_vfl_aux_0: 0.9597 (0.9591)  loss_bbox_aux_0: 0.1592 (0.1642)  loss_giou_aux_0: 0.5006 (0.4976)  loss_vfl_aux_1: 0.5829 (0.5912)  loss_bbox_aux_1: 0.1639 (0.1633)  loss_giou_aux_1: 0.5080 (0.5029)  loss_vfl_aux_2: 0.4781 (0.4784)  loss_bbox_aux_2: 0.1469 (0.1534)  loss_giou_aux_2: 0.4889 (0.4890)  loss_vfl_aux_3: 0.4534 (0.4573)  loss_bbox_aux_3: 0.1422 (0.1484)  loss_giou_aux_3: 0.4779 (0.4785)  loss_vfl_aux_4: 0.4522 (0.4524)  loss_bbox_aux_4: 0.1384 (0.1429)  loss_giou_aux_4: 0.4710 (0.4689)  loss_vfl_dn_0: 0.4673 (0.4727)  loss_bbox_dn_0: 0.1494 (0.1478)  loss_giou_dn_0: 0.4923 (0.4959)  loss_vfl_dn_1: 0.4068 (0.4097)  loss_bbox_dn_1: 0.1263 (0.1265)  loss_giou_dn_1: 0.4352 (0.4365)  loss_vfl_dn_2: 0.3895 (0.3906)  loss_bbox_dn_2: 0.1155 (0.1183)  loss_giou_dn_2: 0.4165 (0.4159)  loss_vfl_dn_3: 0.3806 (0.3831)  loss_bbox_dn_3: 0.1137 (0.1166)  loss_giou_dn_3: 0.4099 (0.4117)  loss_vfl_dn_4: 0.3798 (0.3825)  loss_bbox_dn_4: 0.1126 (0.1164)  loss_giou_dn_4: 0.4098 (0.4103)  loss_vfl_dn_5: 0.3787 (0.3818)  loss_bbox_dn_5: 0.1125 (0.1161)  loss_giou_dn_5: 0.4087 (0.4087)  loss_vfl_enc_0: 0.8622 (0.8641)  loss_bbox_enc_0: 0.1941 (0.1915)  loss_giou_enc_0: 0.5883 (0.5841)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4145  data: 1.3584  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6033  data: 0.6954  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6328 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [129]  [0/8]  eta: 0:00:23  lr: 0.000005  loss: 14.1450 (14.1450)  loss_vfl: 0.4807 (0.4807)  loss_bbox: 0.1186 (0.1186)  loss_giou: 0.4369 (0.4369)  loss_vfl_aux_0: 0.9684 (0.9684)  loss_bbox_aux_0: 0.1383 (0.1383)  loss_giou_aux_0: 0.4689 (0.4689)  loss_vfl_aux_1: 0.6054 (0.6054)  loss_bbox_aux_1: 0.1355 (0.1355)  loss_giou_aux_1: 0.4720 (0.4720)  loss_vfl_aux_2: 0.5043 (0.5043)  loss_bbox_aux_2: 0.1265 (0.1265)  loss_giou_aux_2: 0.4513 (0.4513)  loss_vfl_aux_3: 0.4902 (0.4902)  loss_bbox_aux_3: 0.1228 (0.1228)  loss_giou_aux_3: 0.4448 (0.4448)  loss_vfl_aux_4: 0.4806 (0.4806)  loss_bbox_aux_4: 0.1206 (0.1206)  loss_giou_aux_4: 0.4415 (0.4415)  loss_vfl_dn_0: 0.4679 (0.4679)  loss_bbox_dn_0: 0.1370 (0.1370)  loss_giou_dn_0: 0.4839 (0.4839)  loss_vfl_dn_1: 0.4004 (0.4004)  loss_bbox_dn_1: 0.1147 (0.1147)  loss_giou_dn_1: 0.4221 (0.4221)  loss_vfl_dn_2: 0.3855 (0.3855)  loss_bbox_dn_2: 0.1075 (0.1075)  loss_giou_dn_2: 0.4002 (0.4002)  loss_vfl_dn_3: 0.3765 (0.3765)  loss_bbox_dn_3: 0.1056 (0.1056)  loss_giou_dn_3: 0.3940 (0.3940)  loss_vfl_dn_4: 0.3758 (0.3758)  loss_bbox_dn_4: 0.1045 (0.1045)  loss_giou_dn_4: 0.3902 (0.3902)  loss_vfl_dn_5: 0.3763 (0.3763)  loss_bbox_dn_5: 0.1043 (0.1043)  loss_giou_dn_5: 0.3897 (0.3897)  loss_vfl_enc_0: 0.8654 (0.8654)  loss_bbox_enc_0: 0.1645 (0.1645)  loss_giou_enc_0: 0.5717 (0.5717)  time: 2.9995  data: 2.4649  max mem: 16811\n",
            "Epoch: [129]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.4369 (14.5999)  loss_vfl: 0.4450 (0.4523)  loss_bbox: 0.1504 (0.1429)  loss_giou: 0.4584 (0.4680)  loss_vfl_aux_0: 0.9540 (0.9525)  loss_bbox_aux_0: 0.1682 (0.1645)  loss_giou_aux_0: 0.4845 (0.4934)  loss_vfl_aux_1: 0.5937 (0.5884)  loss_bbox_aux_1: 0.1727 (0.1632)  loss_giou_aux_1: 0.5031 (0.5041)  loss_vfl_aux_2: 0.4720 (0.4754)  loss_bbox_aux_2: 0.1544 (0.1535)  loss_giou_aux_2: 0.4713 (0.4898)  loss_vfl_aux_3: 0.4579 (0.4554)  loss_bbox_aux_3: 0.1490 (0.1473)  loss_giou_aux_3: 0.4679 (0.4821)  loss_vfl_aux_4: 0.4575 (0.4569)  loss_bbox_aux_4: 0.1468 (0.1432)  loss_giou_aux_4: 0.4640 (0.4701)  loss_vfl_dn_0: 0.4662 (0.4693)  loss_bbox_dn_0: 0.1412 (0.1478)  loss_giou_dn_0: 0.4839 (0.4952)  loss_vfl_dn_1: 0.4018 (0.4088)  loss_bbox_dn_1: 0.1213 (0.1265)  loss_giou_dn_1: 0.4221 (0.4390)  loss_vfl_dn_2: 0.3854 (0.3902)  loss_bbox_dn_2: 0.1137 (0.1186)  loss_giou_dn_2: 0.4027 (0.4187)  loss_vfl_dn_3: 0.3782 (0.3839)  loss_bbox_dn_3: 0.1118 (0.1175)  loss_giou_dn_3: 0.4019 (0.4157)  loss_vfl_dn_4: 0.3778 (0.3830)  loss_bbox_dn_4: 0.1109 (0.1165)  loss_giou_dn_4: 0.3997 (0.4123)  loss_vfl_dn_5: 0.3768 (0.3822)  loss_bbox_dn_5: 0.1107 (0.1162)  loss_giou_dn_5: 0.3992 (0.4120)  loss_vfl_enc_0: 0.8666 (0.8685)  loss_bbox_enc_0: 0.2016 (0.1920)  loss_giou_enc_0: 0.5822 (0.5828)  time: 0.8478  data: 0.3366  max mem: 16811\n",
            "Epoch: [129] Total time: 0:00:06 (0.8543 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.4369 (14.5999)  loss_vfl: 0.4450 (0.4523)  loss_bbox: 0.1504 (0.1429)  loss_giou: 0.4584 (0.4680)  loss_vfl_aux_0: 0.9540 (0.9525)  loss_bbox_aux_0: 0.1682 (0.1645)  loss_giou_aux_0: 0.4845 (0.4934)  loss_vfl_aux_1: 0.5937 (0.5884)  loss_bbox_aux_1: 0.1727 (0.1632)  loss_giou_aux_1: 0.5031 (0.5041)  loss_vfl_aux_2: 0.4720 (0.4754)  loss_bbox_aux_2: 0.1544 (0.1535)  loss_giou_aux_2: 0.4713 (0.4898)  loss_vfl_aux_3: 0.4579 (0.4554)  loss_bbox_aux_3: 0.1490 (0.1473)  loss_giou_aux_3: 0.4679 (0.4821)  loss_vfl_aux_4: 0.4575 (0.4569)  loss_bbox_aux_4: 0.1468 (0.1432)  loss_giou_aux_4: 0.4640 (0.4701)  loss_vfl_dn_0: 0.4662 (0.4693)  loss_bbox_dn_0: 0.1412 (0.1478)  loss_giou_dn_0: 0.4839 (0.4952)  loss_vfl_dn_1: 0.4018 (0.4088)  loss_bbox_dn_1: 0.1213 (0.1265)  loss_giou_dn_1: 0.4221 (0.4390)  loss_vfl_dn_2: 0.3854 (0.3902)  loss_bbox_dn_2: 0.1137 (0.1186)  loss_giou_dn_2: 0.4027 (0.4187)  loss_vfl_dn_3: 0.3782 (0.3839)  loss_bbox_dn_3: 0.1118 (0.1175)  loss_giou_dn_3: 0.4019 (0.4157)  loss_vfl_dn_4: 0.3778 (0.3830)  loss_bbox_dn_4: 0.1109 (0.1165)  loss_giou_dn_4: 0.3997 (0.4123)  loss_vfl_dn_5: 0.3768 (0.3822)  loss_bbox_dn_5: 0.1107 (0.1162)  loss_giou_dn_5: 0.3992 (0.4120)  loss_vfl_enc_0: 0.8666 (0.8685)  loss_bbox_enc_0: 0.2016 (0.1920)  loss_giou_enc_0: 0.5822 (0.5828)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5177  data: 4.3701  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9845  data: 2.2012  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.0059 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [130]  [0/8]  eta: 0:00:10  lr: 0.000005  loss: 13.6774 (13.6774)  loss_vfl: 0.4352 (0.4352)  loss_bbox: 0.1156 (0.1156)  loss_giou: 0.4242 (0.4242)  loss_vfl_aux_0: 0.9468 (0.9468)  loss_bbox_aux_0: 0.1197 (0.1197)  loss_giou_aux_0: 0.4237 (0.4237)  loss_vfl_aux_1: 0.5792 (0.5792)  loss_bbox_aux_1: 0.1300 (0.1300)  loss_giou_aux_1: 0.4357 (0.4357)  loss_vfl_aux_2: 0.4673 (0.4673)  loss_bbox_aux_2: 0.1197 (0.1197)  loss_giou_aux_2: 0.4297 (0.4297)  loss_vfl_aux_3: 0.4448 (0.4448)  loss_bbox_aux_3: 0.1166 (0.1166)  loss_giou_aux_3: 0.4304 (0.4304)  loss_vfl_aux_4: 0.4403 (0.4403)  loss_bbox_aux_4: 0.1164 (0.1164)  loss_giou_aux_4: 0.4271 (0.4271)  loss_vfl_dn_0: 0.4816 (0.4816)  loss_bbox_dn_0: 0.1313 (0.1313)  loss_giou_dn_0: 0.4688 (0.4688)  loss_vfl_dn_1: 0.4142 (0.4142)  loss_bbox_dn_1: 0.1086 (0.1086)  loss_giou_dn_1: 0.4102 (0.4102)  loss_vfl_dn_2: 0.3967 (0.3967)  loss_bbox_dn_2: 0.1013 (0.1013)  loss_giou_dn_2: 0.3980 (0.3980)  loss_vfl_dn_3: 0.3911 (0.3911)  loss_bbox_dn_3: 0.0987 (0.0987)  loss_giou_dn_3: 0.3921 (0.3921)  loss_vfl_dn_4: 0.3890 (0.3890)  loss_bbox_dn_4: 0.0983 (0.0983)  loss_giou_dn_4: 0.3888 (0.3888)  loss_vfl_dn_5: 0.3858 (0.3858)  loss_bbox_dn_5: 0.0983 (0.0983)  loss_giou_dn_5: 0.3892 (0.3892)  loss_vfl_enc_0: 0.8573 (0.8573)  loss_bbox_enc_0: 0.1544 (0.1544)  loss_giou_enc_0: 0.5214 (0.5214)  time: 1.3535  data: 0.8182  max mem: 16811\n",
            "Epoch: [130]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.2068 (14.3725)  loss_vfl: 0.4352 (0.4414)  loss_bbox: 0.1366 (0.1392)  loss_giou: 0.4442 (0.4575)  loss_vfl_aux_0: 0.9360 (0.9310)  loss_bbox_aux_0: 0.1600 (0.1663)  loss_giou_aux_0: 0.4761 (0.4894)  loss_vfl_aux_1: 0.5774 (0.5838)  loss_bbox_aux_1: 0.1644 (0.1696)  loss_giou_aux_1: 0.4869 (0.5000)  loss_vfl_aux_2: 0.4673 (0.4638)  loss_bbox_aux_2: 0.1481 (0.1485)  loss_giou_aux_2: 0.4740 (0.4792)  loss_vfl_aux_3: 0.4448 (0.4488)  loss_bbox_aux_3: 0.1478 (0.1438)  loss_giou_aux_3: 0.4551 (0.4678)  loss_vfl_aux_4: 0.4403 (0.4456)  loss_bbox_aux_4: 0.1399 (0.1401)  loss_giou_aux_4: 0.4491 (0.4607)  loss_vfl_dn_0: 0.4653 (0.4671)  loss_bbox_dn_0: 0.1435 (0.1459)  loss_giou_dn_0: 0.4772 (0.4862)  loss_vfl_dn_1: 0.4077 (0.4075)  loss_bbox_dn_1: 0.1230 (0.1246)  loss_giou_dn_1: 0.4230 (0.4296)  loss_vfl_dn_2: 0.3856 (0.3871)  loss_bbox_dn_2: 0.1147 (0.1169)  loss_giou_dn_2: 0.4016 (0.4104)  loss_vfl_dn_3: 0.3815 (0.3806)  loss_bbox_dn_3: 0.1124 (0.1153)  loss_giou_dn_3: 0.3988 (0.4061)  loss_vfl_dn_4: 0.3808 (0.3798)  loss_bbox_dn_4: 0.1115 (0.1148)  loss_giou_dn_4: 0.3959 (0.4036)  loss_vfl_dn_5: 0.3787 (0.3783)  loss_bbox_dn_5: 0.1111 (0.1146)  loss_giou_dn_5: 0.3930 (0.4021)  loss_vfl_enc_0: 0.8573 (0.8572)  loss_bbox_enc_0: 0.1860 (0.1938)  loss_giou_enc_0: 0.5615 (0.5744)  time: 0.6445  data: 0.1334  max mem: 16811\n",
            "Epoch: [130] Total time: 0:00:05 (0.6494 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.2068 (14.3725)  loss_vfl: 0.4352 (0.4414)  loss_bbox: 0.1366 (0.1392)  loss_giou: 0.4442 (0.4575)  loss_vfl_aux_0: 0.9360 (0.9310)  loss_bbox_aux_0: 0.1600 (0.1663)  loss_giou_aux_0: 0.4761 (0.4894)  loss_vfl_aux_1: 0.5774 (0.5838)  loss_bbox_aux_1: 0.1644 (0.1696)  loss_giou_aux_1: 0.4869 (0.5000)  loss_vfl_aux_2: 0.4673 (0.4638)  loss_bbox_aux_2: 0.1481 (0.1485)  loss_giou_aux_2: 0.4740 (0.4792)  loss_vfl_aux_3: 0.4448 (0.4488)  loss_bbox_aux_3: 0.1478 (0.1438)  loss_giou_aux_3: 0.4551 (0.4678)  loss_vfl_aux_4: 0.4403 (0.4456)  loss_bbox_aux_4: 0.1399 (0.1401)  loss_giou_aux_4: 0.4491 (0.4607)  loss_vfl_dn_0: 0.4653 (0.4671)  loss_bbox_dn_0: 0.1435 (0.1459)  loss_giou_dn_0: 0.4772 (0.4862)  loss_vfl_dn_1: 0.4077 (0.4075)  loss_bbox_dn_1: 0.1230 (0.1246)  loss_giou_dn_1: 0.4230 (0.4296)  loss_vfl_dn_2: 0.3856 (0.3871)  loss_bbox_dn_2: 0.1147 (0.1169)  loss_giou_dn_2: 0.4016 (0.4104)  loss_vfl_dn_3: 0.3815 (0.3806)  loss_bbox_dn_3: 0.1124 (0.1153)  loss_giou_dn_3: 0.3988 (0.4061)  loss_vfl_dn_4: 0.3808 (0.3798)  loss_bbox_dn_4: 0.1115 (0.1148)  loss_giou_dn_4: 0.3959 (0.4036)  loss_vfl_dn_5: 0.3787 (0.3783)  loss_bbox_dn_5: 0.1111 (0.1146)  loss_giou_dn_5: 0.3930 (0.4021)  loss_vfl_enc_0: 0.8573 (0.8572)  loss_bbox_enc_0: 0.1860 (0.1938)  loss_giou_enc_0: 0.5615 (0.5744)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.2338  data: 2.8260  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3464  data: 1.4303  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3751 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [131]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.2182 (14.2182)  loss_vfl: 0.4557 (0.4557)  loss_bbox: 0.1309 (0.1309)  loss_giou: 0.4395 (0.4395)  loss_vfl_aux_0: 0.9733 (0.9733)  loss_bbox_aux_0: 0.1481 (0.1481)  loss_giou_aux_0: 0.4456 (0.4456)  loss_vfl_aux_1: 0.5956 (0.5956)  loss_bbox_aux_1: 0.1498 (0.1498)  loss_giou_aux_1: 0.4705 (0.4705)  loss_vfl_aux_2: 0.4743 (0.4743)  loss_bbox_aux_2: 0.1395 (0.1395)  loss_giou_aux_2: 0.4574 (0.4574)  loss_vfl_aux_3: 0.4678 (0.4678)  loss_bbox_aux_3: 0.1300 (0.1300)  loss_giou_aux_3: 0.4399 (0.4399)  loss_vfl_aux_4: 0.4616 (0.4616)  loss_bbox_aux_4: 0.1312 (0.1312)  loss_giou_aux_4: 0.4390 (0.4390)  loss_vfl_dn_0: 0.4783 (0.4783)  loss_bbox_dn_0: 0.1493 (0.1493)  loss_giou_dn_0: 0.4831 (0.4831)  loss_vfl_dn_1: 0.4197 (0.4197)  loss_bbox_dn_1: 0.1258 (0.1258)  loss_giou_dn_1: 0.4201 (0.4201)  loss_vfl_dn_2: 0.3998 (0.3998)  loss_bbox_dn_2: 0.1155 (0.1155)  loss_giou_dn_2: 0.3972 (0.3972)  loss_vfl_dn_3: 0.3912 (0.3912)  loss_bbox_dn_3: 0.1133 (0.1133)  loss_giou_dn_3: 0.3926 (0.3926)  loss_vfl_dn_4: 0.3941 (0.3941)  loss_bbox_dn_4: 0.1132 (0.1132)  loss_giou_dn_4: 0.3884 (0.3884)  loss_vfl_dn_5: 0.3924 (0.3924)  loss_bbox_dn_5: 0.1130 (0.1130)  loss_giou_dn_5: 0.3883 (0.3883)  loss_vfl_enc_0: 0.8943 (0.8943)  loss_bbox_enc_0: 0.1678 (0.1678)  loss_giou_enc_0: 0.5310 (0.5310)  time: 1.4143  data: 0.8629  max mem: 16811\n",
            "Epoch: [131]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.3466 (14.3303)  loss_vfl: 0.4407 (0.4437)  loss_bbox: 0.1347 (0.1396)  loss_giou: 0.4488 (0.4531)  loss_vfl_aux_0: 0.9469 (0.9516)  loss_bbox_aux_0: 0.1632 (0.1631)  loss_giou_aux_0: 0.4787 (0.4821)  loss_vfl_aux_1: 0.5745 (0.5831)  loss_bbox_aux_1: 0.1584 (0.1678)  loss_giou_aux_1: 0.4887 (0.4925)  loss_vfl_aux_2: 0.4734 (0.4741)  loss_bbox_aux_2: 0.1503 (0.1483)  loss_giou_aux_2: 0.4574 (0.4715)  loss_vfl_aux_3: 0.4506 (0.4548)  loss_bbox_aux_3: 0.1345 (0.1416)  loss_giou_aux_3: 0.4568 (0.4627)  loss_vfl_aux_4: 0.4480 (0.4504)  loss_bbox_aux_4: 0.1341 (0.1380)  loss_giou_aux_4: 0.4474 (0.4520)  loss_vfl_dn_0: 0.4687 (0.4682)  loss_bbox_dn_0: 0.1484 (0.1468)  loss_giou_dn_0: 0.4831 (0.4870)  loss_vfl_dn_1: 0.3990 (0.4024)  loss_bbox_dn_1: 0.1204 (0.1242)  loss_giou_dn_1: 0.4255 (0.4272)  loss_vfl_dn_2: 0.3802 (0.3847)  loss_bbox_dn_2: 0.1115 (0.1161)  loss_giou_dn_2: 0.4064 (0.4082)  loss_vfl_dn_3: 0.3773 (0.3783)  loss_bbox_dn_3: 0.1088 (0.1139)  loss_giou_dn_3: 0.4027 (0.4030)  loss_vfl_dn_4: 0.3776 (0.3784)  loss_bbox_dn_4: 0.1084 (0.1137)  loss_giou_dn_4: 0.4001 (0.4014)  loss_vfl_dn_5: 0.3755 (0.3779)  loss_bbox_dn_5: 0.1085 (0.1135)  loss_giou_dn_5: 0.4009 (0.4009)  loss_vfl_enc_0: 0.8508 (0.8598)  loss_bbox_enc_0: 0.1768 (0.1871)  loss_giou_enc_0: 0.5657 (0.5674)  time: 0.6576  data: 0.1419  max mem: 16811\n",
            "Epoch: [131] Total time: 0:00:05 (0.6647 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.3466 (14.3303)  loss_vfl: 0.4407 (0.4437)  loss_bbox: 0.1347 (0.1396)  loss_giou: 0.4488 (0.4531)  loss_vfl_aux_0: 0.9469 (0.9516)  loss_bbox_aux_0: 0.1632 (0.1631)  loss_giou_aux_0: 0.4787 (0.4821)  loss_vfl_aux_1: 0.5745 (0.5831)  loss_bbox_aux_1: 0.1584 (0.1678)  loss_giou_aux_1: 0.4887 (0.4925)  loss_vfl_aux_2: 0.4734 (0.4741)  loss_bbox_aux_2: 0.1503 (0.1483)  loss_giou_aux_2: 0.4574 (0.4715)  loss_vfl_aux_3: 0.4506 (0.4548)  loss_bbox_aux_3: 0.1345 (0.1416)  loss_giou_aux_3: 0.4568 (0.4627)  loss_vfl_aux_4: 0.4480 (0.4504)  loss_bbox_aux_4: 0.1341 (0.1380)  loss_giou_aux_4: 0.4474 (0.4520)  loss_vfl_dn_0: 0.4687 (0.4682)  loss_bbox_dn_0: 0.1484 (0.1468)  loss_giou_dn_0: 0.4831 (0.4870)  loss_vfl_dn_1: 0.3990 (0.4024)  loss_bbox_dn_1: 0.1204 (0.1242)  loss_giou_dn_1: 0.4255 (0.4272)  loss_vfl_dn_2: 0.3802 (0.3847)  loss_bbox_dn_2: 0.1115 (0.1161)  loss_giou_dn_2: 0.4064 (0.4082)  loss_vfl_dn_3: 0.3773 (0.3783)  loss_bbox_dn_3: 0.1088 (0.1139)  loss_giou_dn_3: 0.4027 (0.4030)  loss_vfl_dn_4: 0.3776 (0.3784)  loss_bbox_dn_4: 0.1084 (0.1137)  loss_giou_dn_4: 0.4001 (0.4014)  loss_vfl_dn_5: 0.3755 (0.3779)  loss_bbox_dn_5: 0.1085 (0.1135)  loss_giou_dn_5: 0.4009 (0.4009)  loss_vfl_enc_0: 0.8508 (0.8598)  loss_bbox_enc_0: 0.1768 (0.1871)  loss_giou_enc_0: 0.5657 (0.5674)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.1166  data: 3.0540  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.2851  data: 1.5434  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3098 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [132]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 13.8126 (13.8126)  loss_vfl: 0.4218 (0.4218)  loss_bbox: 0.1350 (0.1350)  loss_giou: 0.4366 (0.4366)  loss_vfl_aux_0: 0.9842 (0.9842)  loss_bbox_aux_0: 0.1404 (0.1404)  loss_giou_aux_0: 0.4317 (0.4317)  loss_vfl_aux_1: 0.5770 (0.5770)  loss_bbox_aux_1: 0.1439 (0.1439)  loss_giou_aux_1: 0.4459 (0.4459)  loss_vfl_aux_2: 0.4531 (0.4531)  loss_bbox_aux_2: 0.1427 (0.1427)  loss_giou_aux_2: 0.4539 (0.4539)  loss_vfl_aux_3: 0.4351 (0.4351)  loss_bbox_aux_3: 0.1363 (0.1363)  loss_giou_aux_3: 0.4433 (0.4433)  loss_vfl_aux_4: 0.4299 (0.4299)  loss_bbox_aux_4: 0.1345 (0.1345)  loss_giou_aux_4: 0.4370 (0.4370)  loss_vfl_dn_0: 0.4654 (0.4654)  loss_bbox_dn_0: 0.1383 (0.1383)  loss_giou_dn_0: 0.4702 (0.4702)  loss_vfl_dn_1: 0.4011 (0.4011)  loss_bbox_dn_1: 0.1156 (0.1156)  loss_giou_dn_1: 0.4065 (0.4065)  loss_vfl_dn_2: 0.3810 (0.3810)  loss_bbox_dn_2: 0.1109 (0.1109)  loss_giou_dn_2: 0.3891 (0.3891)  loss_vfl_dn_3: 0.3750 (0.3750)  loss_bbox_dn_3: 0.1089 (0.1089)  loss_giou_dn_3: 0.3830 (0.3830)  loss_vfl_dn_4: 0.3723 (0.3723)  loss_bbox_dn_4: 0.1095 (0.1095)  loss_giou_dn_4: 0.3818 (0.3818)  loss_vfl_dn_5: 0.3717 (0.3717)  loss_bbox_dn_5: 0.1094 (0.1094)  loss_giou_dn_5: 0.3819 (0.3819)  loss_vfl_enc_0: 0.8888 (0.8888)  loss_bbox_enc_0: 0.1647 (0.1647)  loss_giou_enc_0: 0.5051 (0.5051)  time: 1.4044  data: 0.8409  max mem: 16811\n",
            "Epoch: [132]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.2487 (14.2510)  loss_vfl: 0.4311 (0.4407)  loss_bbox: 0.1354 (0.1342)  loss_giou: 0.4502 (0.4467)  loss_vfl_aux_0: 0.9230 (0.9446)  loss_bbox_aux_0: 0.1570 (0.1607)  loss_giou_aux_0: 0.4924 (0.4812)  loss_vfl_aux_1: 0.5770 (0.5864)  loss_bbox_aux_1: 0.1472 (0.1575)  loss_giou_aux_1: 0.4875 (0.4816)  loss_vfl_aux_2: 0.4726 (0.4695)  loss_bbox_aux_2: 0.1427 (0.1445)  loss_giou_aux_2: 0.4729 (0.4692)  loss_vfl_aux_3: 0.4511 (0.4543)  loss_bbox_aux_3: 0.1351 (0.1374)  loss_giou_aux_3: 0.4637 (0.4570)  loss_vfl_aux_4: 0.4366 (0.4479)  loss_bbox_aux_4: 0.1345 (0.1349)  loss_giou_aux_4: 0.4521 (0.4481)  loss_vfl_dn_0: 0.4645 (0.4683)  loss_bbox_dn_0: 0.1417 (0.1469)  loss_giou_dn_0: 0.4820 (0.4883)  loss_vfl_dn_1: 0.4040 (0.4057)  loss_bbox_dn_1: 0.1171 (0.1229)  loss_giou_dn_1: 0.4251 (0.4258)  loss_vfl_dn_2: 0.3816 (0.3855)  loss_bbox_dn_2: 0.1122 (0.1152)  loss_giou_dn_2: 0.4027 (0.4060)  loss_vfl_dn_3: 0.3781 (0.3794)  loss_bbox_dn_3: 0.1115 (0.1135)  loss_giou_dn_3: 0.4031 (0.4020)  loss_vfl_dn_4: 0.3750 (0.3769)  loss_bbox_dn_4: 0.1118 (0.1131)  loss_giou_dn_4: 0.3994 (0.3998)  loss_vfl_dn_5: 0.3750 (0.3766)  loss_bbox_dn_5: 0.1116 (0.1131)  loss_giou_dn_5: 0.4002 (0.3998)  loss_vfl_enc_0: 0.8565 (0.8575)  loss_bbox_enc_0: 0.1914 (0.1897)  loss_giou_enc_0: 0.5603 (0.5685)  time: 0.6486  data: 0.1342  max mem: 16811\n",
            "Epoch: [132] Total time: 0:00:05 (0.6558 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.2487 (14.2510)  loss_vfl: 0.4311 (0.4407)  loss_bbox: 0.1354 (0.1342)  loss_giou: 0.4502 (0.4467)  loss_vfl_aux_0: 0.9230 (0.9446)  loss_bbox_aux_0: 0.1570 (0.1607)  loss_giou_aux_0: 0.4924 (0.4812)  loss_vfl_aux_1: 0.5770 (0.5864)  loss_bbox_aux_1: 0.1472 (0.1575)  loss_giou_aux_1: 0.4875 (0.4816)  loss_vfl_aux_2: 0.4726 (0.4695)  loss_bbox_aux_2: 0.1427 (0.1445)  loss_giou_aux_2: 0.4729 (0.4692)  loss_vfl_aux_3: 0.4511 (0.4543)  loss_bbox_aux_3: 0.1351 (0.1374)  loss_giou_aux_3: 0.4637 (0.4570)  loss_vfl_aux_4: 0.4366 (0.4479)  loss_bbox_aux_4: 0.1345 (0.1349)  loss_giou_aux_4: 0.4521 (0.4481)  loss_vfl_dn_0: 0.4645 (0.4683)  loss_bbox_dn_0: 0.1417 (0.1469)  loss_giou_dn_0: 0.4820 (0.4883)  loss_vfl_dn_1: 0.4040 (0.4057)  loss_bbox_dn_1: 0.1171 (0.1229)  loss_giou_dn_1: 0.4251 (0.4258)  loss_vfl_dn_2: 0.3816 (0.3855)  loss_bbox_dn_2: 0.1122 (0.1152)  loss_giou_dn_2: 0.4027 (0.4060)  loss_vfl_dn_3: 0.3781 (0.3794)  loss_bbox_dn_3: 0.1115 (0.1135)  loss_giou_dn_3: 0.4031 (0.4020)  loss_vfl_dn_4: 0.3750 (0.3769)  loss_bbox_dn_4: 0.1118 (0.1131)  loss_giou_dn_4: 0.3994 (0.3998)  loss_vfl_dn_5: 0.3750 (0.3766)  loss_bbox_dn_5: 0.1116 (0.1131)  loss_giou_dn_5: 0.4002 (0.3998)  loss_vfl_enc_0: 0.8565 (0.8575)  loss_bbox_enc_0: 0.1914 (0.1897)  loss_giou_enc_0: 0.5603 (0.5685)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.7060  data: 1.2991  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.5809  data: 0.6666  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6098 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [133]  [0/8]  eta: 0:00:14  lr: 0.000005  loss: 13.9157 (13.9157)  loss_vfl: 0.4454 (0.4454)  loss_bbox: 0.1357 (0.1357)  loss_giou: 0.4269 (0.4269)  loss_vfl_aux_0: 0.9242 (0.9242)  loss_bbox_aux_0: 0.1554 (0.1554)  loss_giou_aux_0: 0.4531 (0.4531)  loss_vfl_aux_1: 0.5848 (0.5848)  loss_bbox_aux_1: 0.1452 (0.1452)  loss_giou_aux_1: 0.4466 (0.4466)  loss_vfl_aux_2: 0.4686 (0.4686)  loss_bbox_aux_2: 0.1381 (0.1381)  loss_giou_aux_2: 0.4482 (0.4482)  loss_vfl_aux_3: 0.4530 (0.4530)  loss_bbox_aux_3: 0.1384 (0.1384)  loss_giou_aux_3: 0.4403 (0.4403)  loss_vfl_aux_4: 0.4541 (0.4541)  loss_bbox_aux_4: 0.1361 (0.1361)  loss_giou_aux_4: 0.4288 (0.4288)  loss_vfl_dn_0: 0.4723 (0.4723)  loss_bbox_dn_0: 0.1394 (0.1394)  loss_giou_dn_0: 0.4601 (0.4601)  loss_vfl_dn_1: 0.4132 (0.4132)  loss_bbox_dn_1: 0.1192 (0.1192)  loss_giou_dn_1: 0.4025 (0.4025)  loss_vfl_dn_2: 0.3887 (0.3887)  loss_bbox_dn_2: 0.1133 (0.1133)  loss_giou_dn_2: 0.3864 (0.3864)  loss_vfl_dn_3: 0.3804 (0.3804)  loss_bbox_dn_3: 0.1130 (0.1130)  loss_giou_dn_3: 0.3856 (0.3856)  loss_vfl_dn_4: 0.3785 (0.3785)  loss_bbox_dn_4: 0.1125 (0.1125)  loss_giou_dn_4: 0.3836 (0.3836)  loss_vfl_dn_5: 0.3781 (0.3781)  loss_bbox_dn_5: 0.1126 (0.1126)  loss_giou_dn_5: 0.3832 (0.3832)  loss_vfl_enc_0: 0.8439 (0.8439)  loss_bbox_enc_0: 0.1842 (0.1842)  loss_giou_enc_0: 0.5420 (0.5420)  time: 1.7957  data: 1.2486  max mem: 16811\n",
            "Epoch: [133]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 13.9157 (14.0974)  loss_vfl: 0.4413 (0.4403)  loss_bbox: 0.1336 (0.1327)  loss_giou: 0.4410 (0.4409)  loss_vfl_aux_0: 0.9242 (0.9245)  loss_bbox_aux_0: 0.1554 (0.1561)  loss_giou_aux_0: 0.4779 (0.4779)  loss_vfl_aux_1: 0.5799 (0.5848)  loss_bbox_aux_1: 0.1454 (0.1573)  loss_giou_aux_1: 0.4748 (0.4753)  loss_vfl_aux_2: 0.4569 (0.4617)  loss_bbox_aux_2: 0.1381 (0.1407)  loss_giou_aux_2: 0.4601 (0.4642)  loss_vfl_aux_3: 0.4477 (0.4453)  loss_bbox_aux_3: 0.1338 (0.1349)  loss_giou_aux_3: 0.4511 (0.4533)  loss_vfl_aux_4: 0.4406 (0.4438)  loss_bbox_aux_4: 0.1328 (0.1324)  loss_giou_aux_4: 0.4457 (0.4437)  loss_vfl_dn_0: 0.4733 (0.4724)  loss_bbox_dn_0: 0.1394 (0.1416)  loss_giou_dn_0: 0.4756 (0.4800)  loss_vfl_dn_1: 0.4083 (0.4088)  loss_bbox_dn_1: 0.1192 (0.1206)  loss_giou_dn_1: 0.4136 (0.4202)  loss_vfl_dn_2: 0.3811 (0.3849)  loss_bbox_dn_2: 0.1133 (0.1125)  loss_giou_dn_2: 0.3982 (0.4020)  loss_vfl_dn_3: 0.3750 (0.3772)  loss_bbox_dn_3: 0.1116 (0.1107)  loss_giou_dn_3: 0.3960 (0.3971)  loss_vfl_dn_4: 0.3749 (0.3755)  loss_bbox_dn_4: 0.1112 (0.1107)  loss_giou_dn_4: 0.3956 (0.3957)  loss_vfl_dn_5: 0.3738 (0.3747)  loss_bbox_dn_5: 0.1111 (0.1105)  loss_giou_dn_5: 0.3942 (0.3949)  loss_vfl_enc_0: 0.8520 (0.8551)  loss_bbox_enc_0: 0.1799 (0.1818)  loss_giou_enc_0: 0.5576 (0.5608)  time: 0.6861  data: 0.1766  max mem: 16811\n",
            "Epoch: [133] Total time: 0:00:05 (0.6917 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 13.9157 (14.0974)  loss_vfl: 0.4413 (0.4403)  loss_bbox: 0.1336 (0.1327)  loss_giou: 0.4410 (0.4409)  loss_vfl_aux_0: 0.9242 (0.9245)  loss_bbox_aux_0: 0.1554 (0.1561)  loss_giou_aux_0: 0.4779 (0.4779)  loss_vfl_aux_1: 0.5799 (0.5848)  loss_bbox_aux_1: 0.1454 (0.1573)  loss_giou_aux_1: 0.4748 (0.4753)  loss_vfl_aux_2: 0.4569 (0.4617)  loss_bbox_aux_2: 0.1381 (0.1407)  loss_giou_aux_2: 0.4601 (0.4642)  loss_vfl_aux_3: 0.4477 (0.4453)  loss_bbox_aux_3: 0.1338 (0.1349)  loss_giou_aux_3: 0.4511 (0.4533)  loss_vfl_aux_4: 0.4406 (0.4438)  loss_bbox_aux_4: 0.1328 (0.1324)  loss_giou_aux_4: 0.4457 (0.4437)  loss_vfl_dn_0: 0.4733 (0.4724)  loss_bbox_dn_0: 0.1394 (0.1416)  loss_giou_dn_0: 0.4756 (0.4800)  loss_vfl_dn_1: 0.4083 (0.4088)  loss_bbox_dn_1: 0.1192 (0.1206)  loss_giou_dn_1: 0.4136 (0.4202)  loss_vfl_dn_2: 0.3811 (0.3849)  loss_bbox_dn_2: 0.1133 (0.1125)  loss_giou_dn_2: 0.3982 (0.4020)  loss_vfl_dn_3: 0.3750 (0.3772)  loss_bbox_dn_3: 0.1116 (0.1107)  loss_giou_dn_3: 0.3960 (0.3971)  loss_vfl_dn_4: 0.3749 (0.3755)  loss_bbox_dn_4: 0.1112 (0.1107)  loss_giou_dn_4: 0.3956 (0.3957)  loss_vfl_dn_5: 0.3738 (0.3747)  loss_bbox_dn_5: 0.1111 (0.1105)  loss_giou_dn_5: 0.3942 (0.3949)  loss_vfl_enc_0: 0.8520 (0.8551)  loss_bbox_enc_0: 0.1799 (0.1818)  loss_giou_enc_0: 0.5576 (0.5608)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.9123  data: 3.8437  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.6832  data: 1.9383  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.7003 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [134]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.0733 (14.0733)  loss_vfl: 0.4557 (0.4557)  loss_bbox: 0.1352 (0.1352)  loss_giou: 0.4327 (0.4327)  loss_vfl_aux_0: 0.9334 (0.9334)  loss_bbox_aux_0: 0.1461 (0.1461)  loss_giou_aux_0: 0.4573 (0.4573)  loss_vfl_aux_1: 0.5906 (0.5906)  loss_bbox_aux_1: 0.1529 (0.1529)  loss_giou_aux_1: 0.4696 (0.4696)  loss_vfl_aux_2: 0.4755 (0.4755)  loss_bbox_aux_2: 0.1414 (0.1414)  loss_giou_aux_2: 0.4490 (0.4490)  loss_vfl_aux_3: 0.4620 (0.4620)  loss_bbox_aux_3: 0.1357 (0.1357)  loss_giou_aux_3: 0.4384 (0.4384)  loss_vfl_aux_4: 0.4586 (0.4586)  loss_bbox_aux_4: 0.1330 (0.1330)  loss_giou_aux_4: 0.4311 (0.4311)  loss_vfl_dn_0: 0.4735 (0.4735)  loss_bbox_dn_0: 0.1458 (0.1458)  loss_giou_dn_0: 0.4855 (0.4855)  loss_vfl_dn_1: 0.4120 (0.4120)  loss_bbox_dn_1: 0.1249 (0.1249)  loss_giou_dn_1: 0.4224 (0.4224)  loss_vfl_dn_2: 0.3906 (0.3906)  loss_bbox_dn_2: 0.1158 (0.1158)  loss_giou_dn_2: 0.3950 (0.3950)  loss_vfl_dn_3: 0.3826 (0.3826)  loss_bbox_dn_3: 0.1142 (0.1142)  loss_giou_dn_3: 0.3923 (0.3923)  loss_vfl_dn_4: 0.3830 (0.3830)  loss_bbox_dn_4: 0.1141 (0.1141)  loss_giou_dn_4: 0.3902 (0.3902)  loss_vfl_dn_5: 0.3844 (0.3844)  loss_bbox_dn_5: 0.1140 (0.1140)  loss_giou_dn_5: 0.3923 (0.3923)  loss_vfl_enc_0: 0.8494 (0.8494)  loss_bbox_enc_0: 0.1617 (0.1617)  loss_giou_enc_0: 0.5316 (0.5316)  time: 1.4727  data: 0.8984  max mem: 16811\n",
            "Epoch: [134]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.0505 (14.0310)  loss_vfl: 0.4332 (0.4383)  loss_bbox: 0.1281 (0.1302)  loss_giou: 0.4264 (0.4339)  loss_vfl_aux_0: 0.9334 (0.9450)  loss_bbox_aux_0: 0.1461 (0.1568)  loss_giou_aux_0: 0.4573 (0.4688)  loss_vfl_aux_1: 0.5723 (0.5736)  loss_bbox_aux_1: 0.1522 (0.1548)  loss_giou_aux_1: 0.4696 (0.4656)  loss_vfl_aux_2: 0.4601 (0.4604)  loss_bbox_aux_2: 0.1402 (0.1412)  loss_giou_aux_2: 0.4490 (0.4534)  loss_vfl_aux_3: 0.4407 (0.4425)  loss_bbox_aux_3: 0.1339 (0.1343)  loss_giou_aux_3: 0.4384 (0.4438)  loss_vfl_aux_4: 0.4427 (0.4432)  loss_bbox_aux_4: 0.1284 (0.1310)  loss_giou_aux_4: 0.4278 (0.4371)  loss_vfl_dn_0: 0.4700 (0.4697)  loss_bbox_dn_0: 0.1400 (0.1416)  loss_giou_dn_0: 0.4765 (0.4795)  loss_vfl_dn_1: 0.4074 (0.4077)  loss_bbox_dn_1: 0.1189 (0.1191)  loss_giou_dn_1: 0.4131 (0.4170)  loss_vfl_dn_2: 0.3837 (0.3857)  loss_bbox_dn_2: 0.1137 (0.1123)  loss_giou_dn_2: 0.3950 (0.3999)  loss_vfl_dn_3: 0.3752 (0.3787)  loss_bbox_dn_3: 0.1124 (0.1108)  loss_giou_dn_3: 0.3923 (0.3951)  loss_vfl_dn_4: 0.3741 (0.3776)  loss_bbox_dn_4: 0.1118 (0.1103)  loss_giou_dn_4: 0.3902 (0.3925)  loss_vfl_dn_5: 0.3726 (0.3772)  loss_bbox_dn_5: 0.1121 (0.1102)  loss_giou_dn_5: 0.3908 (0.3918)  loss_vfl_enc_0: 0.8494 (0.8569)  loss_bbox_enc_0: 0.1778 (0.1854)  loss_giou_enc_0: 0.5316 (0.5581)  time: 0.6641  data: 0.1459  max mem: 16811\n",
            "Epoch: [134] Total time: 0:00:05 (0.6695 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.0505 (14.0310)  loss_vfl: 0.4332 (0.4383)  loss_bbox: 0.1281 (0.1302)  loss_giou: 0.4264 (0.4339)  loss_vfl_aux_0: 0.9334 (0.9450)  loss_bbox_aux_0: 0.1461 (0.1568)  loss_giou_aux_0: 0.4573 (0.4688)  loss_vfl_aux_1: 0.5723 (0.5736)  loss_bbox_aux_1: 0.1522 (0.1548)  loss_giou_aux_1: 0.4696 (0.4656)  loss_vfl_aux_2: 0.4601 (0.4604)  loss_bbox_aux_2: 0.1402 (0.1412)  loss_giou_aux_2: 0.4490 (0.4534)  loss_vfl_aux_3: 0.4407 (0.4425)  loss_bbox_aux_3: 0.1339 (0.1343)  loss_giou_aux_3: 0.4384 (0.4438)  loss_vfl_aux_4: 0.4427 (0.4432)  loss_bbox_aux_4: 0.1284 (0.1310)  loss_giou_aux_4: 0.4278 (0.4371)  loss_vfl_dn_0: 0.4700 (0.4697)  loss_bbox_dn_0: 0.1400 (0.1416)  loss_giou_dn_0: 0.4765 (0.4795)  loss_vfl_dn_1: 0.4074 (0.4077)  loss_bbox_dn_1: 0.1189 (0.1191)  loss_giou_dn_1: 0.4131 (0.4170)  loss_vfl_dn_2: 0.3837 (0.3857)  loss_bbox_dn_2: 0.1137 (0.1123)  loss_giou_dn_2: 0.3950 (0.3999)  loss_vfl_dn_3: 0.3752 (0.3787)  loss_bbox_dn_3: 0.1124 (0.1108)  loss_giou_dn_3: 0.3923 (0.3951)  loss_vfl_dn_4: 0.3741 (0.3776)  loss_bbox_dn_4: 0.1118 (0.1103)  loss_giou_dn_4: 0.3902 (0.3925)  loss_vfl_dn_5: 0.3726 (0.3772)  loss_bbox_dn_5: 0.1121 (0.1102)  loss_giou_dn_5: 0.3908 (0.3918)  loss_vfl_enc_0: 0.8494 (0.8569)  loss_bbox_enc_0: 0.1778 (0.1854)  loss_giou_enc_0: 0.5316 (0.5581)\n",
            "Test:  [0/2]  eta: 0:00:09    time: 4.8429  data: 3.4538  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.6490  data: 1.7438  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.6695 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [135]  [0/8]  eta: 0:00:13  lr: 0.000005  loss: 14.2475 (14.2475)  loss_vfl: 0.4437 (0.4437)  loss_bbox: 0.1409 (0.1409)  loss_giou: 0.4310 (0.4310)  loss_vfl_aux_0: 0.9351 (0.9351)  loss_bbox_aux_0: 0.1639 (0.1639)  loss_giou_aux_0: 0.4595 (0.4595)  loss_vfl_aux_1: 0.5836 (0.5836)  loss_bbox_aux_1: 0.1461 (0.1461)  loss_giou_aux_1: 0.4511 (0.4511)  loss_vfl_aux_2: 0.4806 (0.4806)  loss_bbox_aux_2: 0.1398 (0.1398)  loss_giou_aux_2: 0.4441 (0.4441)  loss_vfl_aux_3: 0.4570 (0.4570)  loss_bbox_aux_3: 0.1403 (0.1403)  loss_giou_aux_3: 0.4396 (0.4396)  loss_vfl_aux_4: 0.4449 (0.4449)  loss_bbox_aux_4: 0.1388 (0.1388)  loss_giou_aux_4: 0.4361 (0.4361)  loss_vfl_dn_0: 0.4672 (0.4672)  loss_bbox_dn_0: 0.1541 (0.1541)  loss_giou_dn_0: 0.4965 (0.4965)  loss_vfl_dn_1: 0.4139 (0.4139)  loss_bbox_dn_1: 0.1312 (0.1312)  loss_giou_dn_1: 0.4329 (0.4329)  loss_vfl_dn_2: 0.3956 (0.3956)  loss_bbox_dn_2: 0.1257 (0.1257)  loss_giou_dn_2: 0.4203 (0.4203)  loss_vfl_dn_3: 0.3906 (0.3906)  loss_bbox_dn_3: 0.1228 (0.1228)  loss_giou_dn_3: 0.4136 (0.4136)  loss_vfl_dn_4: 0.3871 (0.3871)  loss_bbox_dn_4: 0.1230 (0.1230)  loss_giou_dn_4: 0.4124 (0.4124)  loss_vfl_dn_5: 0.3882 (0.3882)  loss_bbox_dn_5: 0.1227 (0.1227)  loss_giou_dn_5: 0.4114 (0.4114)  loss_vfl_enc_0: 0.8252 (0.8252)  loss_bbox_enc_0: 0.1985 (0.1985)  loss_giou_enc_0: 0.5386 (0.5386)  time: 1.6487  data: 1.0760  max mem: 16811\n",
            "Epoch: [135]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 14.2374 (14.2290)  loss_vfl: 0.4417 (0.4408)  loss_bbox: 0.1314 (0.1320)  loss_giou: 0.4325 (0.4410)  loss_vfl_aux_0: 0.9351 (0.9415)  loss_bbox_aux_0: 0.1477 (0.1597)  loss_giou_aux_0: 0.4676 (0.4793)  loss_vfl_aux_1: 0.5728 (0.5728)  loss_bbox_aux_1: 0.1508 (0.1607)  loss_giou_aux_1: 0.4661 (0.4818)  loss_vfl_aux_2: 0.4664 (0.4677)  loss_bbox_aux_2: 0.1396 (0.1431)  loss_giou_aux_2: 0.4583 (0.4635)  loss_vfl_aux_3: 0.4451 (0.4486)  loss_bbox_aux_3: 0.1316 (0.1365)  loss_giou_aux_3: 0.4413 (0.4514)  loss_vfl_aux_4: 0.4362 (0.4439)  loss_bbox_aux_4: 0.1323 (0.1325)  loss_giou_aux_4: 0.4375 (0.4454)  loss_vfl_dn_0: 0.4672 (0.4673)  loss_bbox_dn_0: 0.1454 (0.1477)  loss_giou_dn_0: 0.4916 (0.4885)  loss_vfl_dn_1: 0.4085 (0.4067)  loss_bbox_dn_1: 0.1267 (0.1248)  loss_giou_dn_1: 0.4287 (0.4274)  loss_vfl_dn_2: 0.3865 (0.3864)  loss_bbox_dn_2: 0.1149 (0.1181)  loss_giou_dn_2: 0.4090 (0.4105)  loss_vfl_dn_3: 0.3808 (0.3805)  loss_bbox_dn_3: 0.1133 (0.1160)  loss_giou_dn_3: 0.4040 (0.4054)  loss_vfl_dn_4: 0.3806 (0.3795)  loss_bbox_dn_4: 0.1142 (0.1158)  loss_giou_dn_4: 0.4009 (0.4036)  loss_vfl_dn_5: 0.3797 (0.3783)  loss_bbox_dn_5: 0.1135 (0.1154)  loss_giou_dn_5: 0.3994 (0.4024)  loss_vfl_enc_0: 0.8296 (0.8455)  loss_bbox_enc_0: 0.1853 (0.1922)  loss_giou_enc_0: 0.5669 (0.5746)  time: 0.6633  data: 0.1506  max mem: 16811\n",
            "Epoch: [135] Total time: 0:00:05 (0.6702 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 14.2374 (14.2290)  loss_vfl: 0.4417 (0.4408)  loss_bbox: 0.1314 (0.1320)  loss_giou: 0.4325 (0.4410)  loss_vfl_aux_0: 0.9351 (0.9415)  loss_bbox_aux_0: 0.1477 (0.1597)  loss_giou_aux_0: 0.4676 (0.4793)  loss_vfl_aux_1: 0.5728 (0.5728)  loss_bbox_aux_1: 0.1508 (0.1607)  loss_giou_aux_1: 0.4661 (0.4818)  loss_vfl_aux_2: 0.4664 (0.4677)  loss_bbox_aux_2: 0.1396 (0.1431)  loss_giou_aux_2: 0.4583 (0.4635)  loss_vfl_aux_3: 0.4451 (0.4486)  loss_bbox_aux_3: 0.1316 (0.1365)  loss_giou_aux_3: 0.4413 (0.4514)  loss_vfl_aux_4: 0.4362 (0.4439)  loss_bbox_aux_4: 0.1323 (0.1325)  loss_giou_aux_4: 0.4375 (0.4454)  loss_vfl_dn_0: 0.4672 (0.4673)  loss_bbox_dn_0: 0.1454 (0.1477)  loss_giou_dn_0: 0.4916 (0.4885)  loss_vfl_dn_1: 0.4085 (0.4067)  loss_bbox_dn_1: 0.1267 (0.1248)  loss_giou_dn_1: 0.4287 (0.4274)  loss_vfl_dn_2: 0.3865 (0.3864)  loss_bbox_dn_2: 0.1149 (0.1181)  loss_giou_dn_2: 0.4090 (0.4105)  loss_vfl_dn_3: 0.3808 (0.3805)  loss_bbox_dn_3: 0.1133 (0.1160)  loss_giou_dn_3: 0.4040 (0.4054)  loss_vfl_dn_4: 0.3806 (0.3795)  loss_bbox_dn_4: 0.1142 (0.1158)  loss_giou_dn_4: 0.4009 (0.4036)  loss_vfl_dn_5: 0.3797 (0.3783)  loss_bbox_dn_5: 0.1135 (0.1154)  loss_giou_dn_5: 0.3994 (0.4024)  loss_vfl_enc_0: 0.8296 (0.8455)  loss_bbox_enc_0: 0.1853 (0.1922)  loss_giou_enc_0: 0.5669 (0.5746)\n",
            "Test:  [0/2]  eta: 0:00:05    time: 2.9791  data: 1.9145  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.7162  data: 0.9736  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.7416 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [136]  [0/8]  eta: 0:00:11  lr: 0.000005  loss: 14.2763 (14.2763)  loss_vfl: 0.4313 (0.4313)  loss_bbox: 0.1361 (0.1361)  loss_giou: 0.4691 (0.4691)  loss_vfl_aux_0: 0.9045 (0.9045)  loss_bbox_aux_0: 0.1858 (0.1858)  loss_giou_aux_0: 0.5323 (0.5323)  loss_vfl_aux_1: 0.5597 (0.5597)  loss_bbox_aux_1: 0.1676 (0.1676)  loss_giou_aux_1: 0.5192 (0.5192)  loss_vfl_aux_2: 0.4489 (0.4489)  loss_bbox_aux_2: 0.1593 (0.1593)  loss_giou_aux_2: 0.5113 (0.5113)  loss_vfl_aux_3: 0.4288 (0.4288)  loss_bbox_aux_3: 0.1427 (0.1427)  loss_giou_aux_3: 0.4832 (0.4832)  loss_vfl_aux_4: 0.4386 (0.4386)  loss_bbox_aux_4: 0.1361 (0.1361)  loss_giou_aux_4: 0.4662 (0.4662)  loss_vfl_dn_0: 0.4623 (0.4623)  loss_bbox_dn_0: 0.1383 (0.1383)  loss_giou_dn_0: 0.4738 (0.4738)  loss_vfl_dn_1: 0.4015 (0.4015)  loss_bbox_dn_1: 0.1173 (0.1173)  loss_giou_dn_1: 0.4167 (0.4167)  loss_vfl_dn_2: 0.3782 (0.3782)  loss_bbox_dn_2: 0.1111 (0.1111)  loss_giou_dn_2: 0.3997 (0.3997)  loss_vfl_dn_3: 0.3696 (0.3696)  loss_bbox_dn_3: 0.1098 (0.1098)  loss_giou_dn_3: 0.3956 (0.3956)  loss_vfl_dn_4: 0.3692 (0.3692)  loss_bbox_dn_4: 0.1091 (0.1091)  loss_giou_dn_4: 0.3934 (0.3934)  loss_vfl_dn_5: 0.3673 (0.3673)  loss_bbox_dn_5: 0.1089 (0.1089)  loss_giou_dn_5: 0.3911 (0.3911)  loss_vfl_enc_0: 0.8057 (0.8057)  loss_bbox_enc_0: 0.2189 (0.2189)  loss_giou_enc_0: 0.6182 (0.6182)  time: 1.4587  data: 0.9055  max mem: 16811\n",
            "Epoch: [136]  [7/8]  eta: 0:00:00  lr: 0.000005  loss: 13.9383 (13.9831)  loss_vfl: 0.4282 (0.4315)  loss_bbox: 0.1271 (0.1285)  loss_giou: 0.4373 (0.4386)  loss_vfl_aux_0: 0.9045 (0.9317)  loss_bbox_aux_0: 0.1522 (0.1568)  loss_giou_aux_0: 0.4625 (0.4722)  loss_vfl_aux_1: 0.5597 (0.5687)  loss_bbox_aux_1: 0.1575 (0.1542)  loss_giou_aux_1: 0.4605 (0.4762)  loss_vfl_aux_2: 0.4607 (0.4612)  loss_bbox_aux_2: 0.1345 (0.1386)  loss_giou_aux_2: 0.4498 (0.4583)  loss_vfl_aux_3: 0.4381 (0.4385)  loss_bbox_aux_3: 0.1272 (0.1318)  loss_giou_aux_3: 0.4395 (0.4457)  loss_vfl_aux_4: 0.4330 (0.4360)  loss_bbox_aux_4: 0.1283 (0.1291)  loss_giou_aux_4: 0.4356 (0.4389)  loss_vfl_dn_0: 0.4651 (0.4662)  loss_bbox_dn_0: 0.1383 (0.1430)  loss_giou_dn_0: 0.4771 (0.4812)  loss_vfl_dn_1: 0.4015 (0.4045)  loss_bbox_dn_1: 0.1173 (0.1192)  loss_giou_dn_1: 0.4173 (0.4183)  loss_vfl_dn_2: 0.3838 (0.3843)  loss_bbox_dn_2: 0.1111 (0.1126)  loss_giou_dn_2: 0.3961 (0.3987)  loss_vfl_dn_3: 0.3799 (0.3775)  loss_bbox_dn_3: 0.1098 (0.1104)  loss_giou_dn_3: 0.3927 (0.3944)  loss_vfl_dn_4: 0.3776 (0.3763)  loss_bbox_dn_4: 0.1091 (0.1097)  loss_giou_dn_4: 0.3892 (0.3913)  loss_vfl_dn_5: 0.3768 (0.3751)  loss_bbox_dn_5: 0.1089 (0.1095)  loss_giou_dn_5: 0.3873 (0.3906)  loss_vfl_enc_0: 0.8270 (0.8440)  loss_bbox_enc_0: 0.1781 (0.1820)  loss_giou_enc_0: 0.5526 (0.5579)  time: 0.6557  data: 0.1435  max mem: 16811\n",
            "Epoch: [136] Total time: 0:00:05 (0.6632 s / it)\n",
            "Averaged stats: lr: 0.000005  loss: 13.9383 (13.9831)  loss_vfl: 0.4282 (0.4315)  loss_bbox: 0.1271 (0.1285)  loss_giou: 0.4373 (0.4386)  loss_vfl_aux_0: 0.9045 (0.9317)  loss_bbox_aux_0: 0.1522 (0.1568)  loss_giou_aux_0: 0.4625 (0.4722)  loss_vfl_aux_1: 0.5597 (0.5687)  loss_bbox_aux_1: 0.1575 (0.1542)  loss_giou_aux_1: 0.4605 (0.4762)  loss_vfl_aux_2: 0.4607 (0.4612)  loss_bbox_aux_2: 0.1345 (0.1386)  loss_giou_aux_2: 0.4498 (0.4583)  loss_vfl_aux_3: 0.4381 (0.4385)  loss_bbox_aux_3: 0.1272 (0.1318)  loss_giou_aux_3: 0.4395 (0.4457)  loss_vfl_aux_4: 0.4330 (0.4360)  loss_bbox_aux_4: 0.1283 (0.1291)  loss_giou_aux_4: 0.4356 (0.4389)  loss_vfl_dn_0: 0.4651 (0.4662)  loss_bbox_dn_0: 0.1383 (0.1430)  loss_giou_dn_0: 0.4771 (0.4812)  loss_vfl_dn_1: 0.4015 (0.4045)  loss_bbox_dn_1: 0.1173 (0.1192)  loss_giou_dn_1: 0.4173 (0.4183)  loss_vfl_dn_2: 0.3838 (0.3843)  loss_bbox_dn_2: 0.1111 (0.1126)  loss_giou_dn_2: 0.3961 (0.3987)  loss_vfl_dn_3: 0.3799 (0.3775)  loss_bbox_dn_3: 0.1098 (0.1104)  loss_giou_dn_3: 0.3927 (0.3944)  loss_vfl_dn_4: 0.3776 (0.3763)  loss_bbox_dn_4: 0.1091 (0.1097)  loss_giou_dn_4: 0.3892 (0.3913)  loss_vfl_dn_5: 0.3768 (0.3751)  loss_bbox_dn_5: 0.1089 (0.1095)  loss_giou_dn_5: 0.3873 (0.3906)  loss_vfl_enc_0: 0.8270 (0.8440)  loss_bbox_enc_0: 0.1781 (0.1820)  loss_giou_enc_0: 0.5526 (0.5579)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3911  data: 1.3206  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4236  data: 0.6767  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.0905 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [137]  [0/8]  eta: 0:00:12  lr: 0.000005  loss: 14.1303 (14.1303)  loss_vfl: 0.4483 (0.4483)  loss_bbox: 0.1304 (0.1304)  loss_giou: 0.4210 (0.4210)  loss_vfl_aux_0: 0.9670 (0.9670)  loss_bbox_aux_0: 0.1472 (0.1472)  loss_giou_aux_0: 0.4683 (0.4683)  loss_vfl_aux_1: 0.6228 (0.6228)  loss_bbox_aux_1: 0.1590 (0.1590)  loss_giou_aux_1: 0.4583 (0.4583)  loss_vfl_aux_2: 0.4706 (0.4706)  loss_bbox_aux_2: 0.1375 (0.1375)  loss_giou_aux_2: 0.4377 (0.4377)  loss_vfl_aux_3: 0.4449 (0.4449)  loss_bbox_aux_3: 0.1357 (0.1357)  loss_giou_aux_3: 0.4342 (0.4342)  loss_vfl_aux_4: 0.4471 (0.4471)  loss_bbox_aux_4: 0.1312 (0.1312)  loss_giou_aux_4: 0.4228 (0.4228)  loss_vfl_dn_0: 0.4743 (0.4743)  loss_bbox_dn_0: 0.1544 (0.1544)  loss_giou_dn_0: 0.4913 (0.4913)  loss_vfl_dn_1: 0.4097 (0.4097)  loss_bbox_dn_1: 0.1291 (0.1291)  loss_giou_dn_1: 0.4273 (0.4273)  loss_vfl_dn_2: 0.3874 (0.3874)  loss_bbox_dn_2: 0.1199 (0.1199)  loss_giou_dn_2: 0.4020 (0.4020)  loss_vfl_dn_3: 0.3793 (0.3793)  loss_bbox_dn_3: 0.1182 (0.1182)  loss_giou_dn_3: 0.3966 (0.3966)  loss_vfl_dn_4: 0.3797 (0.3797)  loss_bbox_dn_4: 0.1169 (0.1169)  loss_giou_dn_4: 0.3921 (0.3921)  loss_vfl_dn_5: 0.3795 (0.3795)  loss_bbox_dn_5: 0.1168 (0.1168)  loss_giou_dn_5: 0.3918 (0.3918)  loss_vfl_enc_0: 0.8704 (0.8704)  loss_bbox_enc_0: 0.1704 (0.1704)  loss_giou_enc_0: 0.5391 (0.5391)  time: 1.5765  data: 0.9934  max mem: 16811\n",
            "Epoch: [137]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 14.1303 (13.9910)  loss_vfl: 0.4397 (0.4400)  loss_bbox: 0.1245 (0.1268)  loss_giou: 0.4217 (0.4293)  loss_vfl_aux_0: 0.9304 (0.9403)  loss_bbox_aux_0: 0.1533 (0.1548)  loss_giou_aux_0: 0.4610 (0.4698)  loss_vfl_aux_1: 0.5754 (0.5871)  loss_bbox_aux_1: 0.1610 (0.1592)  loss_giou_aux_1: 0.4645 (0.4715)  loss_vfl_aux_2: 0.4547 (0.4642)  loss_bbox_aux_2: 0.1373 (0.1387)  loss_giou_aux_2: 0.4408 (0.4489)  loss_vfl_aux_3: 0.4386 (0.4405)  loss_bbox_aux_3: 0.1307 (0.1321)  loss_giou_aux_3: 0.4342 (0.4414)  loss_vfl_aux_4: 0.4454 (0.4425)  loss_bbox_aux_4: 0.1256 (0.1269)  loss_giou_aux_4: 0.4256 (0.4321)  loss_vfl_dn_0: 0.4711 (0.4693)  loss_bbox_dn_0: 0.1394 (0.1420)  loss_giou_dn_0: 0.4665 (0.4751)  loss_vfl_dn_1: 0.4083 (0.4062)  loss_bbox_dn_1: 0.1192 (0.1201)  loss_giou_dn_1: 0.4056 (0.4158)  loss_vfl_dn_2: 0.3866 (0.3860)  loss_bbox_dn_2: 0.1133 (0.1124)  loss_giou_dn_2: 0.3845 (0.3960)  loss_vfl_dn_3: 0.3792 (0.3795)  loss_bbox_dn_3: 0.1131 (0.1106)  loss_giou_dn_3: 0.3824 (0.3910)  loss_vfl_dn_4: 0.3793 (0.3785)  loss_bbox_dn_4: 0.1137 (0.1101)  loss_giou_dn_4: 0.3821 (0.3886)  loss_vfl_dn_5: 0.3779 (0.3776)  loss_bbox_dn_5: 0.1135 (0.1098)  loss_giou_dn_5: 0.3823 (0.3874)  loss_vfl_enc_0: 0.8333 (0.8524)  loss_bbox_enc_0: 0.1794 (0.1830)  loss_giou_enc_0: 0.5391 (0.5534)  time: 0.6650  data: 0.1473  max mem: 16811\n",
            "Epoch: [137] Total time: 0:00:05 (0.6712 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 14.1303 (13.9910)  loss_vfl: 0.4397 (0.4400)  loss_bbox: 0.1245 (0.1268)  loss_giou: 0.4217 (0.4293)  loss_vfl_aux_0: 0.9304 (0.9403)  loss_bbox_aux_0: 0.1533 (0.1548)  loss_giou_aux_0: 0.4610 (0.4698)  loss_vfl_aux_1: 0.5754 (0.5871)  loss_bbox_aux_1: 0.1610 (0.1592)  loss_giou_aux_1: 0.4645 (0.4715)  loss_vfl_aux_2: 0.4547 (0.4642)  loss_bbox_aux_2: 0.1373 (0.1387)  loss_giou_aux_2: 0.4408 (0.4489)  loss_vfl_aux_3: 0.4386 (0.4405)  loss_bbox_aux_3: 0.1307 (0.1321)  loss_giou_aux_3: 0.4342 (0.4414)  loss_vfl_aux_4: 0.4454 (0.4425)  loss_bbox_aux_4: 0.1256 (0.1269)  loss_giou_aux_4: 0.4256 (0.4321)  loss_vfl_dn_0: 0.4711 (0.4693)  loss_bbox_dn_0: 0.1394 (0.1420)  loss_giou_dn_0: 0.4665 (0.4751)  loss_vfl_dn_1: 0.4083 (0.4062)  loss_bbox_dn_1: 0.1192 (0.1201)  loss_giou_dn_1: 0.4056 (0.4158)  loss_vfl_dn_2: 0.3866 (0.3860)  loss_bbox_dn_2: 0.1133 (0.1124)  loss_giou_dn_2: 0.3845 (0.3960)  loss_vfl_dn_3: 0.3792 (0.3795)  loss_bbox_dn_3: 0.1131 (0.1106)  loss_giou_dn_3: 0.3824 (0.3910)  loss_vfl_dn_4: 0.3793 (0.3785)  loss_bbox_dn_4: 0.1137 (0.1101)  loss_giou_dn_4: 0.3821 (0.3886)  loss_vfl_dn_5: 0.3779 (0.3776)  loss_bbox_dn_5: 0.1135 (0.1098)  loss_giou_dn_5: 0.3823 (0.3874)  loss_vfl_enc_0: 0.8333 (0.8524)  loss_bbox_enc_0: 0.1794 (0.1830)  loss_giou_enc_0: 0.5391 (0.5534)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.4231  data: 4.3533  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.9376  data: 2.1941  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.9620 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [138]  [0/8]  eta: 0:00:17  lr: 0.000006  loss: 13.5207 (13.5207)  loss_vfl: 0.4242 (0.4242)  loss_bbox: 0.1249 (0.1249)  loss_giou: 0.3913 (0.3913)  loss_vfl_aux_0: 0.9809 (0.9809)  loss_bbox_aux_0: 0.1423 (0.1423)  loss_giou_aux_0: 0.4299 (0.4299)  loss_vfl_aux_1: 0.5554 (0.5554)  loss_bbox_aux_1: 0.1457 (0.1457)  loss_giou_aux_1: 0.4325 (0.4325)  loss_vfl_aux_2: 0.4455 (0.4455)  loss_bbox_aux_2: 0.1300 (0.1300)  loss_giou_aux_2: 0.4139 (0.4139)  loss_vfl_aux_3: 0.4272 (0.4272)  loss_bbox_aux_3: 0.1252 (0.1252)  loss_giou_aux_3: 0.4019 (0.4019)  loss_vfl_aux_4: 0.4295 (0.4295)  loss_bbox_aux_4: 0.1236 (0.1236)  loss_giou_aux_4: 0.3940 (0.3940)  loss_vfl_dn_0: 0.4680 (0.4680)  loss_bbox_dn_0: 0.1441 (0.1441)  loss_giou_dn_0: 0.4553 (0.4553)  loss_vfl_dn_1: 0.4012 (0.4012)  loss_bbox_dn_1: 0.1219 (0.1219)  loss_giou_dn_1: 0.3987 (0.3987)  loss_vfl_dn_2: 0.3763 (0.3763)  loss_bbox_dn_2: 0.1148 (0.1148)  loss_giou_dn_2: 0.3791 (0.3791)  loss_vfl_dn_3: 0.3723 (0.3723)  loss_bbox_dn_3: 0.1133 (0.1133)  loss_giou_dn_3: 0.3770 (0.3770)  loss_vfl_dn_4: 0.3709 (0.3709)  loss_bbox_dn_4: 0.1123 (0.1123)  loss_giou_dn_4: 0.3737 (0.3737)  loss_vfl_dn_5: 0.3686 (0.3686)  loss_bbox_dn_5: 0.1120 (0.1120)  loss_giou_dn_5: 0.3721 (0.3721)  loss_vfl_enc_0: 0.8859 (0.8859)  loss_bbox_enc_0: 0.1725 (0.1725)  loss_giou_enc_0: 0.5130 (0.5130)  time: 2.1564  data: 1.5708  max mem: 16811\n",
            "Epoch: [138]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.6349 (13.9128)  loss_vfl: 0.4242 (0.4289)  loss_bbox: 0.1249 (0.1324)  loss_giou: 0.4239 (0.4395)  loss_vfl_aux_0: 0.9216 (0.9130)  loss_bbox_aux_0: 0.1479 (0.1557)  loss_giou_aux_0: 0.4667 (0.4732)  loss_vfl_aux_1: 0.5554 (0.5572)  loss_bbox_aux_1: 0.1539 (0.1536)  loss_giou_aux_1: 0.4621 (0.4769)  loss_vfl_aux_2: 0.4455 (0.4548)  loss_bbox_aux_2: 0.1300 (0.1405)  loss_giou_aux_2: 0.4420 (0.4604)  loss_vfl_aux_3: 0.4272 (0.4330)  loss_bbox_aux_3: 0.1268 (0.1351)  loss_giou_aux_3: 0.4309 (0.4487)  loss_vfl_aux_4: 0.4295 (0.4339)  loss_bbox_aux_4: 0.1236 (0.1328)  loss_giou_aux_4: 0.4254 (0.4414)  loss_vfl_dn_0: 0.4593 (0.4624)  loss_bbox_dn_0: 0.1354 (0.1409)  loss_giou_dn_0: 0.4553 (0.4699)  loss_vfl_dn_1: 0.4009 (0.4017)  loss_bbox_dn_1: 0.1157 (0.1194)  loss_giou_dn_1: 0.3989 (0.4120)  loss_vfl_dn_2: 0.3799 (0.3813)  loss_bbox_dn_2: 0.1084 (0.1115)  loss_giou_dn_2: 0.3862 (0.3949)  loss_vfl_dn_3: 0.3725 (0.3747)  loss_bbox_dn_3: 0.1084 (0.1098)  loss_giou_dn_3: 0.3829 (0.3904)  loss_vfl_dn_4: 0.3709 (0.3734)  loss_bbox_dn_4: 0.1071 (0.1092)  loss_giou_dn_4: 0.3790 (0.3882)  loss_vfl_dn_5: 0.3692 (0.3717)  loss_bbox_dn_5: 0.1068 (0.1090)  loss_giou_dn_5: 0.3786 (0.3869)  loss_vfl_enc_0: 0.8394 (0.8490)  loss_bbox_enc_0: 0.1742 (0.1838)  loss_giou_enc_0: 0.5593 (0.5615)  time: 0.7417  data: 0.2251  max mem: 16811\n",
            "Epoch: [138] Total time: 0:00:06 (0.7512 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.6349 (13.9128)  loss_vfl: 0.4242 (0.4289)  loss_bbox: 0.1249 (0.1324)  loss_giou: 0.4239 (0.4395)  loss_vfl_aux_0: 0.9216 (0.9130)  loss_bbox_aux_0: 0.1479 (0.1557)  loss_giou_aux_0: 0.4667 (0.4732)  loss_vfl_aux_1: 0.5554 (0.5572)  loss_bbox_aux_1: 0.1539 (0.1536)  loss_giou_aux_1: 0.4621 (0.4769)  loss_vfl_aux_2: 0.4455 (0.4548)  loss_bbox_aux_2: 0.1300 (0.1405)  loss_giou_aux_2: 0.4420 (0.4604)  loss_vfl_aux_3: 0.4272 (0.4330)  loss_bbox_aux_3: 0.1268 (0.1351)  loss_giou_aux_3: 0.4309 (0.4487)  loss_vfl_aux_4: 0.4295 (0.4339)  loss_bbox_aux_4: 0.1236 (0.1328)  loss_giou_aux_4: 0.4254 (0.4414)  loss_vfl_dn_0: 0.4593 (0.4624)  loss_bbox_dn_0: 0.1354 (0.1409)  loss_giou_dn_0: 0.4553 (0.4699)  loss_vfl_dn_1: 0.4009 (0.4017)  loss_bbox_dn_1: 0.1157 (0.1194)  loss_giou_dn_1: 0.3989 (0.4120)  loss_vfl_dn_2: 0.3799 (0.3813)  loss_bbox_dn_2: 0.1084 (0.1115)  loss_giou_dn_2: 0.3862 (0.3949)  loss_vfl_dn_3: 0.3725 (0.3747)  loss_bbox_dn_3: 0.1084 (0.1098)  loss_giou_dn_3: 0.3829 (0.3904)  loss_vfl_dn_4: 0.3709 (0.3734)  loss_bbox_dn_4: 0.1071 (0.1092)  loss_giou_dn_4: 0.3790 (0.3882)  loss_vfl_dn_5: 0.3692 (0.3717)  loss_bbox_dn_5: 0.1068 (0.1090)  loss_giou_dn_5: 0.3786 (0.3869)  loss_vfl_enc_0: 0.8394 (0.8490)  loss_bbox_enc_0: 0.1742 (0.1838)  loss_giou_enc_0: 0.5593 (0.5615)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.3970  data: 2.3370  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.9236  data: 1.1846  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.9441 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [139]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 14.0344 (14.0344)  loss_vfl: 0.4430 (0.4430)  loss_bbox: 0.1228 (0.1228)  loss_giou: 0.4309 (0.4309)  loss_vfl_aux_0: 0.9309 (0.9309)  loss_bbox_aux_0: 0.1549 (0.1549)  loss_giou_aux_0: 0.4632 (0.4632)  loss_vfl_aux_1: 0.5773 (0.5773)  loss_bbox_aux_1: 0.1486 (0.1486)  loss_giou_aux_1: 0.4687 (0.4687)  loss_vfl_aux_2: 0.4719 (0.4719)  loss_bbox_aux_2: 0.1324 (0.1324)  loss_giou_aux_2: 0.4508 (0.4508)  loss_vfl_aux_3: 0.4475 (0.4475)  loss_bbox_aux_3: 0.1301 (0.1301)  loss_giou_aux_3: 0.4417 (0.4417)  loss_vfl_aux_4: 0.4515 (0.4515)  loss_bbox_aux_4: 0.1231 (0.1231)  loss_giou_aux_4: 0.4321 (0.4321)  loss_vfl_dn_0: 0.4614 (0.4614)  loss_bbox_dn_0: 0.1400 (0.1400)  loss_giou_dn_0: 0.4866 (0.4866)  loss_vfl_dn_1: 0.4057 (0.4057)  loss_bbox_dn_1: 0.1189 (0.1189)  loss_giou_dn_1: 0.4293 (0.4293)  loss_vfl_dn_2: 0.3840 (0.3840)  loss_bbox_dn_2: 0.1110 (0.1110)  loss_giou_dn_2: 0.4088 (0.4088)  loss_vfl_dn_3: 0.3788 (0.3788)  loss_bbox_dn_3: 0.1106 (0.1106)  loss_giou_dn_3: 0.4070 (0.4070)  loss_vfl_dn_4: 0.3794 (0.3794)  loss_bbox_dn_4: 0.1088 (0.1088)  loss_giou_dn_4: 0.4027 (0.4027)  loss_vfl_dn_5: 0.3777 (0.3777)  loss_bbox_dn_5: 0.1087 (0.1087)  loss_giou_dn_5: 0.4027 (0.4027)  loss_vfl_enc_0: 0.8626 (0.8626)  loss_bbox_enc_0: 0.1806 (0.1806)  loss_giou_enc_0: 0.5476 (0.5476)  time: 1.5255  data: 0.8730  max mem: 16811\n",
            "Epoch: [139]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 14.0344 (13.9297)  loss_vfl: 0.4396 (0.4363)  loss_bbox: 0.1228 (0.1269)  loss_giou: 0.4309 (0.4328)  loss_vfl_aux_0: 0.9060 (0.9067)  loss_bbox_aux_0: 0.1521 (0.1523)  loss_giou_aux_0: 0.4739 (0.4636)  loss_vfl_aux_1: 0.5845 (0.5891)  loss_bbox_aux_1: 0.1566 (0.1561)  loss_giou_aux_1: 0.4687 (0.4666)  loss_vfl_aux_2: 0.4601 (0.4634)  loss_bbox_aux_2: 0.1343 (0.1369)  loss_giou_aux_2: 0.4508 (0.4521)  loss_vfl_aux_3: 0.4475 (0.4459)  loss_bbox_aux_3: 0.1301 (0.1318)  loss_giou_aux_3: 0.4417 (0.4425)  loss_vfl_aux_4: 0.4390 (0.4395)  loss_bbox_aux_4: 0.1231 (0.1274)  loss_giou_aux_4: 0.4321 (0.4329)  loss_vfl_dn_0: 0.4595 (0.4608)  loss_bbox_dn_0: 0.1404 (0.1417)  loss_giou_dn_0: 0.4799 (0.4771)  loss_vfl_dn_1: 0.4009 (0.4039)  loss_bbox_dn_1: 0.1189 (0.1205)  loss_giou_dn_1: 0.4235 (0.4189)  loss_vfl_dn_2: 0.3840 (0.3858)  loss_bbox_dn_2: 0.1110 (0.1127)  loss_giou_dn_2: 0.3994 (0.3980)  loss_vfl_dn_3: 0.3758 (0.3787)  loss_bbox_dn_3: 0.1106 (0.1110)  loss_giou_dn_3: 0.3951 (0.3935)  loss_vfl_dn_4: 0.3741 (0.3773)  loss_bbox_dn_4: 0.1088 (0.1114)  loss_giou_dn_4: 0.3920 (0.3924)  loss_vfl_dn_5: 0.3755 (0.3771)  loss_bbox_dn_5: 0.1087 (0.1112)  loss_giou_dn_5: 0.3921 (0.3919)  loss_vfl_enc_0: 0.8363 (0.8391)  loss_bbox_enc_0: 0.1735 (0.1765)  loss_giou_enc_0: 0.5476 (0.5476)  time: 0.6674  data: 0.1400  max mem: 16811\n",
            "Epoch: [139] Total time: 0:00:05 (0.6753 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 14.0344 (13.9297)  loss_vfl: 0.4396 (0.4363)  loss_bbox: 0.1228 (0.1269)  loss_giou: 0.4309 (0.4328)  loss_vfl_aux_0: 0.9060 (0.9067)  loss_bbox_aux_0: 0.1521 (0.1523)  loss_giou_aux_0: 0.4739 (0.4636)  loss_vfl_aux_1: 0.5845 (0.5891)  loss_bbox_aux_1: 0.1566 (0.1561)  loss_giou_aux_1: 0.4687 (0.4666)  loss_vfl_aux_2: 0.4601 (0.4634)  loss_bbox_aux_2: 0.1343 (0.1369)  loss_giou_aux_2: 0.4508 (0.4521)  loss_vfl_aux_3: 0.4475 (0.4459)  loss_bbox_aux_3: 0.1301 (0.1318)  loss_giou_aux_3: 0.4417 (0.4425)  loss_vfl_aux_4: 0.4390 (0.4395)  loss_bbox_aux_4: 0.1231 (0.1274)  loss_giou_aux_4: 0.4321 (0.4329)  loss_vfl_dn_0: 0.4595 (0.4608)  loss_bbox_dn_0: 0.1404 (0.1417)  loss_giou_dn_0: 0.4799 (0.4771)  loss_vfl_dn_1: 0.4009 (0.4039)  loss_bbox_dn_1: 0.1189 (0.1205)  loss_giou_dn_1: 0.4235 (0.4189)  loss_vfl_dn_2: 0.3840 (0.3858)  loss_bbox_dn_2: 0.1110 (0.1127)  loss_giou_dn_2: 0.3994 (0.3980)  loss_vfl_dn_3: 0.3758 (0.3787)  loss_bbox_dn_3: 0.1106 (0.1110)  loss_giou_dn_3: 0.3951 (0.3935)  loss_vfl_dn_4: 0.3741 (0.3773)  loss_bbox_dn_4: 0.1088 (0.1114)  loss_giou_dn_4: 0.3920 (0.3924)  loss_vfl_dn_5: 0.3755 (0.3771)  loss_bbox_dn_5: 0.1087 (0.1112)  loss_giou_dn_5: 0.3921 (0.3919)  loss_vfl_enc_0: 0.8363 (0.8391)  loss_bbox_enc_0: 0.1735 (0.1765)  loss_giou_enc_0: 0.5476 (0.5476)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.5174  data: 4.4394  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1638  data: 2.2382  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1949 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [140]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 14.0855 (14.0855)  loss_vfl: 0.4590 (0.4590)  loss_bbox: 0.1209 (0.1209)  loss_giou: 0.4274 (0.4274)  loss_vfl_aux_0: 0.9273 (0.9273)  loss_bbox_aux_0: 0.1518 (0.1518)  loss_giou_aux_0: 0.4606 (0.4606)  loss_vfl_aux_1: 0.6081 (0.6081)  loss_bbox_aux_1: 0.1541 (0.1541)  loss_giou_aux_1: 0.4597 (0.4597)  loss_vfl_aux_2: 0.4762 (0.4762)  loss_bbox_aux_2: 0.1305 (0.1305)  loss_giou_aux_2: 0.4505 (0.4505)  loss_vfl_aux_3: 0.4634 (0.4634)  loss_bbox_aux_3: 0.1262 (0.1262)  loss_giou_aux_3: 0.4442 (0.4442)  loss_vfl_aux_4: 0.4632 (0.4632)  loss_bbox_aux_4: 0.1209 (0.1209)  loss_giou_aux_4: 0.4294 (0.4294)  loss_vfl_dn_0: 0.4616 (0.4616)  loss_bbox_dn_0: 0.1442 (0.1442)  loss_giou_dn_0: 0.4792 (0.4792)  loss_vfl_dn_1: 0.4061 (0.4061)  loss_bbox_dn_1: 0.1265 (0.1265)  loss_giou_dn_1: 0.4259 (0.4259)  loss_vfl_dn_2: 0.3907 (0.3907)  loss_bbox_dn_2: 0.1191 (0.1191)  loss_giou_dn_2: 0.4055 (0.4055)  loss_vfl_dn_3: 0.3821 (0.3821)  loss_bbox_dn_3: 0.1177 (0.1177)  loss_giou_dn_3: 0.4004 (0.4004)  loss_vfl_dn_4: 0.3824 (0.3824)  loss_bbox_dn_4: 0.1183 (0.1183)  loss_giou_dn_4: 0.4003 (0.4003)  loss_vfl_dn_5: 0.3801 (0.3801)  loss_bbox_dn_5: 0.1179 (0.1179)  loss_giou_dn_5: 0.3985 (0.3985)  loss_vfl_enc_0: 0.8321 (0.8321)  loss_bbox_enc_0: 0.1820 (0.1820)  loss_giou_enc_0: 0.5415 (0.5415)  time: 1.5009  data: 0.9442  max mem: 16811\n",
            "Epoch: [140]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.6615 (13.6831)  loss_vfl: 0.4218 (0.4262)  loss_bbox: 0.1202 (0.1194)  loss_giou: 0.4274 (0.4183)  loss_vfl_aux_0: 0.9162 (0.9178)  loss_bbox_aux_0: 0.1459 (0.1490)  loss_giou_aux_0: 0.4606 (0.4602)  loss_vfl_aux_1: 0.5589 (0.5676)  loss_bbox_aux_1: 0.1436 (0.1484)  loss_giou_aux_1: 0.4597 (0.4536)  loss_vfl_aux_2: 0.4541 (0.4556)  loss_bbox_aux_2: 0.1305 (0.1319)  loss_giou_aux_2: 0.4438 (0.4383)  loss_vfl_aux_3: 0.4336 (0.4363)  loss_bbox_aux_3: 0.1237 (0.1260)  loss_giou_aux_3: 0.4371 (0.4282)  loss_vfl_aux_4: 0.4267 (0.4302)  loss_bbox_aux_4: 0.1202 (0.1200)  loss_giou_aux_4: 0.4294 (0.4197)  loss_vfl_dn_0: 0.4626 (0.4633)  loss_bbox_dn_0: 0.1387 (0.1381)  loss_giou_dn_0: 0.4743 (0.4728)  loss_vfl_dn_1: 0.4018 (0.4009)  loss_bbox_dn_1: 0.1186 (0.1168)  loss_giou_dn_1: 0.4102 (0.4111)  loss_vfl_dn_2: 0.3821 (0.3812)  loss_bbox_dn_2: 0.1088 (0.1087)  loss_giou_dn_2: 0.3912 (0.3914)  loss_vfl_dn_3: 0.3769 (0.3744)  loss_bbox_dn_3: 0.1070 (0.1070)  loss_giou_dn_3: 0.3856 (0.3868)  loss_vfl_dn_4: 0.3757 (0.3739)  loss_bbox_dn_4: 0.1052 (0.1062)  loss_giou_dn_4: 0.3822 (0.3842)  loss_vfl_dn_5: 0.3739 (0.3731)  loss_bbox_dn_5: 0.1053 (0.1061)  loss_giou_dn_5: 0.3830 (0.3842)  loss_vfl_enc_0: 0.8187 (0.8298)  loss_bbox_enc_0: 0.1735 (0.1779)  loss_giou_enc_0: 0.5415 (0.5486)  time: 0.6690  data: 0.1521  max mem: 16811\n",
            "Epoch: [140] Total time: 0:00:05 (0.6767 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.6615 (13.6831)  loss_vfl: 0.4218 (0.4262)  loss_bbox: 0.1202 (0.1194)  loss_giou: 0.4274 (0.4183)  loss_vfl_aux_0: 0.9162 (0.9178)  loss_bbox_aux_0: 0.1459 (0.1490)  loss_giou_aux_0: 0.4606 (0.4602)  loss_vfl_aux_1: 0.5589 (0.5676)  loss_bbox_aux_1: 0.1436 (0.1484)  loss_giou_aux_1: 0.4597 (0.4536)  loss_vfl_aux_2: 0.4541 (0.4556)  loss_bbox_aux_2: 0.1305 (0.1319)  loss_giou_aux_2: 0.4438 (0.4383)  loss_vfl_aux_3: 0.4336 (0.4363)  loss_bbox_aux_3: 0.1237 (0.1260)  loss_giou_aux_3: 0.4371 (0.4282)  loss_vfl_aux_4: 0.4267 (0.4302)  loss_bbox_aux_4: 0.1202 (0.1200)  loss_giou_aux_4: 0.4294 (0.4197)  loss_vfl_dn_0: 0.4626 (0.4633)  loss_bbox_dn_0: 0.1387 (0.1381)  loss_giou_dn_0: 0.4743 (0.4728)  loss_vfl_dn_1: 0.4018 (0.4009)  loss_bbox_dn_1: 0.1186 (0.1168)  loss_giou_dn_1: 0.4102 (0.4111)  loss_vfl_dn_2: 0.3821 (0.3812)  loss_bbox_dn_2: 0.1088 (0.1087)  loss_giou_dn_2: 0.3912 (0.3914)  loss_vfl_dn_3: 0.3769 (0.3744)  loss_bbox_dn_3: 0.1070 (0.1070)  loss_giou_dn_3: 0.3856 (0.3868)  loss_vfl_dn_4: 0.3757 (0.3739)  loss_bbox_dn_4: 0.1052 (0.1062)  loss_giou_dn_4: 0.3822 (0.3842)  loss_vfl_dn_5: 0.3739 (0.3731)  loss_bbox_dn_5: 0.1053 (0.1061)  loss_giou_dn_5: 0.3830 (0.3842)  loss_vfl_enc_0: 0.8187 (0.8298)  loss_bbox_enc_0: 0.1735 (0.1779)  loss_giou_enc_0: 0.5415 (0.5486)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4879  data: 1.3482  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4770  data: 0.6916  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4963 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [141]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 13.5396 (13.5396)  loss_vfl: 0.4197 (0.4197)  loss_bbox: 0.1191 (0.1191)  loss_giou: 0.4252 (0.4252)  loss_vfl_aux_0: 0.9492 (0.9492)  loss_bbox_aux_0: 0.1510 (0.1510)  loss_giou_aux_0: 0.4737 (0.4737)  loss_vfl_aux_1: 0.5282 (0.5282)  loss_bbox_aux_1: 0.1534 (0.1534)  loss_giou_aux_1: 0.4749 (0.4749)  loss_vfl_aux_2: 0.4617 (0.4617)  loss_bbox_aux_2: 0.1383 (0.1383)  loss_giou_aux_2: 0.4392 (0.4392)  loss_vfl_aux_3: 0.4381 (0.4381)  loss_bbox_aux_3: 0.1348 (0.1348)  loss_giou_aux_3: 0.4367 (0.4367)  loss_vfl_aux_4: 0.4310 (0.4310)  loss_bbox_aux_4: 0.1178 (0.1178)  loss_giou_aux_4: 0.4253 (0.4253)  loss_vfl_dn_0: 0.4604 (0.4604)  loss_bbox_dn_0: 0.1266 (0.1266)  loss_giou_dn_0: 0.4522 (0.4522)  loss_vfl_dn_1: 0.3933 (0.3933)  loss_bbox_dn_1: 0.1039 (0.1039)  loss_giou_dn_1: 0.3853 (0.3853)  loss_vfl_dn_2: 0.3673 (0.3673)  loss_bbox_dn_2: 0.0961 (0.0961)  loss_giou_dn_2: 0.3703 (0.3703)  loss_vfl_dn_3: 0.3650 (0.3650)  loss_bbox_dn_3: 0.0937 (0.0937)  loss_giou_dn_3: 0.3666 (0.3666)  loss_vfl_dn_4: 0.3640 (0.3640)  loss_bbox_dn_4: 0.0927 (0.0927)  loss_giou_dn_4: 0.3648 (0.3648)  loss_vfl_dn_5: 0.3625 (0.3625)  loss_bbox_dn_5: 0.0928 (0.0928)  loss_giou_dn_5: 0.3653 (0.3653)  loss_vfl_enc_0: 0.8472 (0.8472)  loss_bbox_enc_0: 0.1823 (0.1823)  loss_giou_enc_0: 0.5700 (0.5700)  time: 1.6013  data: 1.0519  max mem: 16811\n",
            "Epoch: [141]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.6339 (13.7473)  loss_vfl: 0.4244 (0.4289)  loss_bbox: 0.1203 (0.1254)  loss_giou: 0.4160 (0.4232)  loss_vfl_aux_0: 0.9366 (0.9351)  loss_bbox_aux_0: 0.1462 (0.1534)  loss_giou_aux_0: 0.4657 (0.4665)  loss_vfl_aux_1: 0.5478 (0.5514)  loss_bbox_aux_1: 0.1465 (0.1530)  loss_giou_aux_1: 0.4652 (0.4661)  loss_vfl_aux_2: 0.4438 (0.4469)  loss_bbox_aux_2: 0.1332 (0.1374)  loss_giou_aux_2: 0.4399 (0.4440)  loss_vfl_aux_3: 0.4381 (0.4369)  loss_bbox_aux_3: 0.1252 (0.1308)  loss_giou_aux_3: 0.4367 (0.4354)  loss_vfl_aux_4: 0.4310 (0.4327)  loss_bbox_aux_4: 0.1205 (0.1256)  loss_giou_aux_4: 0.4214 (0.4245)  loss_vfl_dn_0: 0.4620 (0.4621)  loss_bbox_dn_0: 0.1356 (0.1376)  loss_giou_dn_0: 0.4631 (0.4684)  loss_vfl_dn_1: 0.3983 (0.3997)  loss_bbox_dn_1: 0.1125 (0.1162)  loss_giou_dn_1: 0.4069 (0.4090)  loss_vfl_dn_2: 0.3786 (0.3794)  loss_bbox_dn_2: 0.1056 (0.1098)  loss_giou_dn_2: 0.3881 (0.3920)  loss_vfl_dn_3: 0.3733 (0.3737)  loss_bbox_dn_3: 0.1035 (0.1072)  loss_giou_dn_3: 0.3830 (0.3867)  loss_vfl_dn_4: 0.3716 (0.3711)  loss_bbox_dn_4: 0.1032 (0.1067)  loss_giou_dn_4: 0.3818 (0.3842)  loss_vfl_dn_5: 0.3693 (0.3705)  loss_bbox_dn_5: 0.1028 (0.1065)  loss_giou_dn_5: 0.3799 (0.3829)  loss_vfl_enc_0: 0.8333 (0.8305)  loss_bbox_enc_0: 0.1801 (0.1831)  loss_giou_enc_0: 0.5382 (0.5527)  time: 0.6643  data: 0.1484  max mem: 16811\n",
            "Epoch: [141] Total time: 0:00:05 (0.6708 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.6339 (13.7473)  loss_vfl: 0.4244 (0.4289)  loss_bbox: 0.1203 (0.1254)  loss_giou: 0.4160 (0.4232)  loss_vfl_aux_0: 0.9366 (0.9351)  loss_bbox_aux_0: 0.1462 (0.1534)  loss_giou_aux_0: 0.4657 (0.4665)  loss_vfl_aux_1: 0.5478 (0.5514)  loss_bbox_aux_1: 0.1465 (0.1530)  loss_giou_aux_1: 0.4652 (0.4661)  loss_vfl_aux_2: 0.4438 (0.4469)  loss_bbox_aux_2: 0.1332 (0.1374)  loss_giou_aux_2: 0.4399 (0.4440)  loss_vfl_aux_3: 0.4381 (0.4369)  loss_bbox_aux_3: 0.1252 (0.1308)  loss_giou_aux_3: 0.4367 (0.4354)  loss_vfl_aux_4: 0.4310 (0.4327)  loss_bbox_aux_4: 0.1205 (0.1256)  loss_giou_aux_4: 0.4214 (0.4245)  loss_vfl_dn_0: 0.4620 (0.4621)  loss_bbox_dn_0: 0.1356 (0.1376)  loss_giou_dn_0: 0.4631 (0.4684)  loss_vfl_dn_1: 0.3983 (0.3997)  loss_bbox_dn_1: 0.1125 (0.1162)  loss_giou_dn_1: 0.4069 (0.4090)  loss_vfl_dn_2: 0.3786 (0.3794)  loss_bbox_dn_2: 0.1056 (0.1098)  loss_giou_dn_2: 0.3881 (0.3920)  loss_vfl_dn_3: 0.3733 (0.3737)  loss_bbox_dn_3: 0.1035 (0.1072)  loss_giou_dn_3: 0.3830 (0.3867)  loss_vfl_dn_4: 0.3716 (0.3711)  loss_bbox_dn_4: 0.1032 (0.1067)  loss_giou_dn_4: 0.3818 (0.3842)  loss_vfl_dn_5: 0.3693 (0.3705)  loss_bbox_dn_5: 0.1028 (0.1065)  loss_giou_dn_5: 0.3799 (0.3829)  loss_vfl_enc_0: 0.8333 (0.8305)  loss_bbox_enc_0: 0.1801 (0.1831)  loss_giou_enc_0: 0.5382 (0.5527)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.7731  data: 4.3675  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1151  data: 2.2016  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1445 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [142]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 14.8263 (14.8263)  loss_vfl: 0.4325 (0.4325)  loss_bbox: 0.1557 (0.1557)  loss_giou: 0.4799 (0.4799)  loss_vfl_aux_0: 0.8810 (0.8810)  loss_bbox_aux_0: 0.1929 (0.1929)  loss_giou_aux_0: 0.5470 (0.5470)  loss_vfl_aux_1: 0.5598 (0.5598)  loss_bbox_aux_1: 0.1999 (0.1999)  loss_giou_aux_1: 0.5519 (0.5519)  loss_vfl_aux_2: 0.4332 (0.4332)  loss_bbox_aux_2: 0.1675 (0.1675)  loss_giou_aux_2: 0.5170 (0.5170)  loss_vfl_aux_3: 0.4358 (0.4358)  loss_bbox_aux_3: 0.1537 (0.1537)  loss_giou_aux_3: 0.4949 (0.4949)  loss_vfl_aux_4: 0.4273 (0.4273)  loss_bbox_aux_4: 0.1547 (0.1547)  loss_giou_aux_4: 0.4846 (0.4846)  loss_vfl_dn_0: 0.4628 (0.4628)  loss_bbox_dn_0: 0.1586 (0.1586)  loss_giou_dn_0: 0.5215 (0.5215)  loss_vfl_dn_1: 0.4074 (0.4074)  loss_bbox_dn_1: 0.1385 (0.1385)  loss_giou_dn_1: 0.4602 (0.4602)  loss_vfl_dn_2: 0.3907 (0.3907)  loss_bbox_dn_2: 0.1280 (0.1280)  loss_giou_dn_2: 0.4378 (0.4378)  loss_vfl_dn_3: 0.3901 (0.3901)  loss_bbox_dn_3: 0.1255 (0.1255)  loss_giou_dn_3: 0.4332 (0.4332)  loss_vfl_dn_4: 0.3886 (0.3886)  loss_bbox_dn_4: 0.1253 (0.1253)  loss_giou_dn_4: 0.4294 (0.4294)  loss_vfl_dn_5: 0.3904 (0.3904)  loss_bbox_dn_5: 0.1253 (0.1253)  loss_giou_dn_5: 0.4291 (0.4291)  loss_vfl_enc_0: 0.7921 (0.7921)  loss_bbox_enc_0: 0.2095 (0.2095)  loss_giou_enc_0: 0.6126 (0.6126)  time: 1.5315  data: 0.9289  max mem: 16811\n",
            "Epoch: [142]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.6792 (13.8157)  loss_vfl: 0.4325 (0.4404)  loss_bbox: 0.1167 (0.1244)  loss_giou: 0.4163 (0.4246)  loss_vfl_aux_0: 0.9062 (0.9145)  loss_bbox_aux_0: 0.1425 (0.1485)  loss_giou_aux_0: 0.4442 (0.4562)  loss_vfl_aux_1: 0.6180 (0.6132)  loss_bbox_aux_1: 0.1364 (0.1484)  loss_giou_aux_1: 0.4385 (0.4595)  loss_vfl_aux_2: 0.4433 (0.4599)  loss_bbox_aux_2: 0.1214 (0.1324)  loss_giou_aux_2: 0.4268 (0.4417)  loss_vfl_aux_3: 0.4358 (0.4465)  loss_bbox_aux_3: 0.1210 (0.1272)  loss_giou_aux_3: 0.4150 (0.4312)  loss_vfl_aux_4: 0.4331 (0.4402)  loss_bbox_aux_4: 0.1170 (0.1245)  loss_giou_aux_4: 0.4155 (0.4263)  loss_vfl_dn_0: 0.4600 (0.4623)  loss_bbox_dn_0: 0.1334 (0.1388)  loss_giou_dn_0: 0.4545 (0.4689)  loss_vfl_dn_1: 0.4018 (0.4036)  loss_bbox_dn_1: 0.1130 (0.1174)  loss_giou_dn_1: 0.3981 (0.4115)  loss_vfl_dn_2: 0.3811 (0.3825)  loss_bbox_dn_2: 0.1057 (0.1097)  loss_giou_dn_2: 0.3769 (0.3907)  loss_vfl_dn_3: 0.3746 (0.3774)  loss_bbox_dn_3: 0.1040 (0.1084)  loss_giou_dn_3: 0.3768 (0.3877)  loss_vfl_dn_4: 0.3718 (0.3749)  loss_bbox_dn_4: 0.1037 (0.1078)  loss_giou_dn_4: 0.3726 (0.3846)  loss_vfl_dn_5: 0.3721 (0.3754)  loss_bbox_dn_5: 0.1035 (0.1078)  loss_giou_dn_5: 0.3724 (0.3845)  loss_vfl_enc_0: 0.8461 (0.8485)  loss_bbox_enc_0: 0.1720 (0.1740)  loss_giou_enc_0: 0.5298 (0.5395)  time: 0.6664  data: 0.1454  max mem: 16811\n",
            "Epoch: [142] Total time: 0:00:05 (0.6736 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.6792 (13.8157)  loss_vfl: 0.4325 (0.4404)  loss_bbox: 0.1167 (0.1244)  loss_giou: 0.4163 (0.4246)  loss_vfl_aux_0: 0.9062 (0.9145)  loss_bbox_aux_0: 0.1425 (0.1485)  loss_giou_aux_0: 0.4442 (0.4562)  loss_vfl_aux_1: 0.6180 (0.6132)  loss_bbox_aux_1: 0.1364 (0.1484)  loss_giou_aux_1: 0.4385 (0.4595)  loss_vfl_aux_2: 0.4433 (0.4599)  loss_bbox_aux_2: 0.1214 (0.1324)  loss_giou_aux_2: 0.4268 (0.4417)  loss_vfl_aux_3: 0.4358 (0.4465)  loss_bbox_aux_3: 0.1210 (0.1272)  loss_giou_aux_3: 0.4150 (0.4312)  loss_vfl_aux_4: 0.4331 (0.4402)  loss_bbox_aux_4: 0.1170 (0.1245)  loss_giou_aux_4: 0.4155 (0.4263)  loss_vfl_dn_0: 0.4600 (0.4623)  loss_bbox_dn_0: 0.1334 (0.1388)  loss_giou_dn_0: 0.4545 (0.4689)  loss_vfl_dn_1: 0.4018 (0.4036)  loss_bbox_dn_1: 0.1130 (0.1174)  loss_giou_dn_1: 0.3981 (0.4115)  loss_vfl_dn_2: 0.3811 (0.3825)  loss_bbox_dn_2: 0.1057 (0.1097)  loss_giou_dn_2: 0.3769 (0.3907)  loss_vfl_dn_3: 0.3746 (0.3774)  loss_bbox_dn_3: 0.1040 (0.1084)  loss_giou_dn_3: 0.3768 (0.3877)  loss_vfl_dn_4: 0.3718 (0.3749)  loss_bbox_dn_4: 0.1037 (0.1078)  loss_giou_dn_4: 0.3726 (0.3846)  loss_vfl_dn_5: 0.3721 (0.3754)  loss_bbox_dn_5: 0.1035 (0.1078)  loss_giou_dn_5: 0.3724 (0.3845)  loss_vfl_enc_0: 0.8461 (0.8485)  loss_bbox_enc_0: 0.1720 (0.1740)  loss_giou_enc_0: 0.5298 (0.5395)\n",
            "Test:  [0/2]  eta: 0:00:06    time: 3.1423  data: 2.0681  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.7975  data: 1.0510  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.8159 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [143]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 13.8620 (13.8620)  loss_vfl: 0.4458 (0.4458)  loss_bbox: 0.1258 (0.1258)  loss_giou: 0.4165 (0.4165)  loss_vfl_aux_0: 0.8941 (0.8941)  loss_bbox_aux_0: 0.1417 (0.1417)  loss_giou_aux_0: 0.4451 (0.4451)  loss_vfl_aux_1: 0.5862 (0.5862)  loss_bbox_aux_1: 0.1459 (0.1459)  loss_giou_aux_1: 0.4592 (0.4592)  loss_vfl_aux_2: 0.4671 (0.4671)  loss_bbox_aux_2: 0.1344 (0.1344)  loss_giou_aux_2: 0.4360 (0.4360)  loss_vfl_aux_3: 0.4550 (0.4550)  loss_bbox_aux_3: 0.1282 (0.1282)  loss_giou_aux_3: 0.4230 (0.4230)  loss_vfl_aux_4: 0.4513 (0.4513)  loss_bbox_aux_4: 0.1258 (0.1258)  loss_giou_aux_4: 0.4160 (0.4160)  loss_vfl_dn_0: 0.4789 (0.4789)  loss_bbox_dn_0: 0.1448 (0.1448)  loss_giou_dn_0: 0.4798 (0.4798)  loss_vfl_dn_1: 0.4174 (0.4174)  loss_bbox_dn_1: 0.1216 (0.1216)  loss_giou_dn_1: 0.4194 (0.4194)  loss_vfl_dn_2: 0.3993 (0.3993)  loss_bbox_dn_2: 0.1143 (0.1143)  loss_giou_dn_2: 0.3949 (0.3949)  loss_vfl_dn_3: 0.3931 (0.3931)  loss_bbox_dn_3: 0.1125 (0.1125)  loss_giou_dn_3: 0.3888 (0.3888)  loss_vfl_dn_4: 0.3878 (0.3878)  loss_bbox_dn_4: 0.1126 (0.1126)  loss_giou_dn_4: 0.3859 (0.3859)  loss_vfl_dn_5: 0.3857 (0.3857)  loss_bbox_dn_5: 0.1126 (0.1126)  loss_giou_dn_5: 0.3853 (0.3853)  loss_vfl_enc_0: 0.8197 (0.8197)  loss_bbox_enc_0: 0.1640 (0.1640)  loss_giou_enc_0: 0.5464 (0.5464)  time: 1.5687  data: 0.9927  max mem: 16811\n",
            "Epoch: [143]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.5725 (13.5668)  loss_vfl: 0.4215 (0.4258)  loss_bbox: 0.1220 (0.1215)  loss_giou: 0.4061 (0.4161)  loss_vfl_aux_0: 0.8909 (0.8970)  loss_bbox_aux_0: 0.1362 (0.1478)  loss_giou_aux_0: 0.4383 (0.4561)  loss_vfl_aux_1: 0.5453 (0.5535)  loss_bbox_aux_1: 0.1414 (0.1450)  loss_giou_aux_1: 0.4288 (0.4532)  loss_vfl_aux_2: 0.4441 (0.4512)  loss_bbox_aux_2: 0.1294 (0.1323)  loss_giou_aux_2: 0.4127 (0.4375)  loss_vfl_aux_3: 0.4259 (0.4304)  loss_bbox_aux_3: 0.1282 (0.1262)  loss_giou_aux_3: 0.4104 (0.4261)  loss_vfl_aux_4: 0.4265 (0.4314)  loss_bbox_aux_4: 0.1258 (0.1229)  loss_giou_aux_4: 0.4101 (0.4181)  loss_vfl_dn_0: 0.4630 (0.4642)  loss_bbox_dn_0: 0.1369 (0.1372)  loss_giou_dn_0: 0.4648 (0.4650)  loss_vfl_dn_1: 0.4010 (0.4027)  loss_bbox_dn_1: 0.1154 (0.1140)  loss_giou_dn_1: 0.3948 (0.4023)  loss_vfl_dn_2: 0.3819 (0.3832)  loss_bbox_dn_2: 0.1101 (0.1075)  loss_giou_dn_2: 0.3771 (0.3838)  loss_vfl_dn_3: 0.3737 (0.3755)  loss_bbox_dn_3: 0.1077 (0.1050)  loss_giou_dn_3: 0.3726 (0.3779)  loss_vfl_dn_4: 0.3725 (0.3741)  loss_bbox_dn_4: 0.1073 (0.1049)  loss_giou_dn_4: 0.3722 (0.3762)  loss_vfl_dn_5: 0.3715 (0.3727)  loss_bbox_dn_5: 0.1068 (0.1047)  loss_giou_dn_5: 0.3716 (0.3752)  loss_vfl_enc_0: 0.8197 (0.8312)  loss_bbox_enc_0: 0.1640 (0.1747)  loss_giou_enc_0: 0.5107 (0.5424)  time: 0.6651  data: 0.1490  max mem: 16811\n",
            "Epoch: [143] Total time: 0:00:05 (0.6711 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.5725 (13.5668)  loss_vfl: 0.4215 (0.4258)  loss_bbox: 0.1220 (0.1215)  loss_giou: 0.4061 (0.4161)  loss_vfl_aux_0: 0.8909 (0.8970)  loss_bbox_aux_0: 0.1362 (0.1478)  loss_giou_aux_0: 0.4383 (0.4561)  loss_vfl_aux_1: 0.5453 (0.5535)  loss_bbox_aux_1: 0.1414 (0.1450)  loss_giou_aux_1: 0.4288 (0.4532)  loss_vfl_aux_2: 0.4441 (0.4512)  loss_bbox_aux_2: 0.1294 (0.1323)  loss_giou_aux_2: 0.4127 (0.4375)  loss_vfl_aux_3: 0.4259 (0.4304)  loss_bbox_aux_3: 0.1282 (0.1262)  loss_giou_aux_3: 0.4104 (0.4261)  loss_vfl_aux_4: 0.4265 (0.4314)  loss_bbox_aux_4: 0.1258 (0.1229)  loss_giou_aux_4: 0.4101 (0.4181)  loss_vfl_dn_0: 0.4630 (0.4642)  loss_bbox_dn_0: 0.1369 (0.1372)  loss_giou_dn_0: 0.4648 (0.4650)  loss_vfl_dn_1: 0.4010 (0.4027)  loss_bbox_dn_1: 0.1154 (0.1140)  loss_giou_dn_1: 0.3948 (0.4023)  loss_vfl_dn_2: 0.3819 (0.3832)  loss_bbox_dn_2: 0.1101 (0.1075)  loss_giou_dn_2: 0.3771 (0.3838)  loss_vfl_dn_3: 0.3737 (0.3755)  loss_bbox_dn_3: 0.1077 (0.1050)  loss_giou_dn_3: 0.3726 (0.3779)  loss_vfl_dn_4: 0.3725 (0.3741)  loss_bbox_dn_4: 0.1073 (0.1049)  loss_giou_dn_4: 0.3722 (0.3762)  loss_vfl_dn_5: 0.3715 (0.3727)  loss_bbox_dn_5: 0.1068 (0.1047)  loss_giou_dn_5: 0.3716 (0.3752)  loss_vfl_enc_0: 0.8197 (0.8312)  loss_bbox_enc_0: 0.1640 (0.1747)  loss_giou_enc_0: 0.5107 (0.5424)\n",
            "Test:  [0/2]  eta: 0:00:11    time: 5.7783  data: 4.3871  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:03    time: 3.1162  data: 2.2097  max mem: 16811\n",
            "Test: Total time: 0:00:06 (3.1373 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [144]  [0/8]  eta: 0:00:11  lr: 0.000006  loss: 13.0621 (13.0621)  loss_vfl: 0.4065 (0.4065)  loss_bbox: 0.1080 (0.1080)  loss_giou: 0.4083 (0.4083)  loss_vfl_aux_0: 0.8974 (0.8974)  loss_bbox_aux_0: 0.1271 (0.1271)  loss_giou_aux_0: 0.4317 (0.4317)  loss_vfl_aux_1: 0.5217 (0.5217)  loss_bbox_aux_1: 0.1258 (0.1258)  loss_giou_aux_1: 0.4456 (0.4456)  loss_vfl_aux_2: 0.4398 (0.4398)  loss_bbox_aux_2: 0.1131 (0.1131)  loss_giou_aux_2: 0.4250 (0.4250)  loss_vfl_aux_3: 0.4128 (0.4128)  loss_bbox_aux_3: 0.1105 (0.1105)  loss_giou_aux_3: 0.4211 (0.4211)  loss_vfl_aux_4: 0.4167 (0.4167)  loss_bbox_aux_4: 0.1086 (0.1086)  loss_giou_aux_4: 0.4090 (0.4090)  loss_vfl_dn_0: 0.4550 (0.4550)  loss_bbox_dn_0: 0.1211 (0.1211)  loss_giou_dn_0: 0.4568 (0.4568)  loss_vfl_dn_1: 0.3841 (0.3841)  loss_bbox_dn_1: 0.1001 (0.1001)  loss_giou_dn_1: 0.3927 (0.3927)  loss_vfl_dn_2: 0.3643 (0.3643)  loss_bbox_dn_2: 0.0954 (0.0954)  loss_giou_dn_2: 0.3758 (0.3758)  loss_vfl_dn_3: 0.3568 (0.3568)  loss_bbox_dn_3: 0.0936 (0.0936)  loss_giou_dn_3: 0.3701 (0.3701)  loss_vfl_dn_4: 0.3558 (0.3558)  loss_bbox_dn_4: 0.0922 (0.0922)  loss_giou_dn_4: 0.3663 (0.3663)  loss_vfl_dn_5: 0.3550 (0.3550)  loss_bbox_dn_5: 0.0921 (0.0921)  loss_giou_dn_5: 0.3661 (0.3661)  loss_vfl_enc_0: 0.8200 (0.8200)  loss_bbox_enc_0: 0.1611 (0.1611)  loss_giou_enc_0: 0.5592 (0.5592)  time: 1.4528  data: 0.8960  max mem: 16811\n",
            "Epoch: [144]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.5012 (13.6409)  loss_vfl: 0.4345 (0.4330)  loss_bbox: 0.1202 (0.1213)  loss_giou: 0.4094 (0.4176)  loss_vfl_aux_0: 0.8785 (0.8827)  loss_bbox_aux_0: 0.1418 (0.1492)  loss_giou_aux_0: 0.4433 (0.4534)  loss_vfl_aux_1: 0.5495 (0.5604)  loss_bbox_aux_1: 0.1427 (0.1436)  loss_giou_aux_1: 0.4572 (0.4572)  loss_vfl_aux_2: 0.4530 (0.4589)  loss_bbox_aux_2: 0.1235 (0.1289)  loss_giou_aux_2: 0.4250 (0.4389)  loss_vfl_aux_3: 0.4272 (0.4329)  loss_bbox_aux_3: 0.1227 (0.1240)  loss_giou_aux_3: 0.4211 (0.4287)  loss_vfl_aux_4: 0.4325 (0.4354)  loss_bbox_aux_4: 0.1210 (0.1214)  loss_giou_aux_4: 0.4099 (0.4189)  loss_vfl_dn_0: 0.4557 (0.4603)  loss_bbox_dn_0: 0.1356 (0.1382)  loss_giou_dn_0: 0.4568 (0.4706)  loss_vfl_dn_1: 0.4031 (0.4015)  loss_bbox_dn_1: 0.1144 (0.1170)  loss_giou_dn_1: 0.4036 (0.4117)  loss_vfl_dn_2: 0.3815 (0.3827)  loss_bbox_dn_2: 0.1077 (0.1093)  loss_giou_dn_2: 0.3845 (0.3909)  loss_vfl_dn_3: 0.3762 (0.3760)  loss_bbox_dn_3: 0.1049 (0.1071)  loss_giou_dn_3: 0.3806 (0.3860)  loss_vfl_dn_4: 0.3746 (0.3740)  loss_bbox_dn_4: 0.1052 (0.1066)  loss_giou_dn_4: 0.3786 (0.3829)  loss_vfl_dn_5: 0.3750 (0.3733)  loss_bbox_dn_5: 0.1050 (0.1065)  loss_giou_dn_5: 0.3780 (0.3830)  loss_vfl_enc_0: 0.8269 (0.8278)  loss_bbox_enc_0: 0.1679 (0.1808)  loss_giou_enc_0: 0.5417 (0.5483)  time: 0.6613  data: 0.1490  max mem: 16811\n",
            "Epoch: [144] Total time: 0:00:05 (0.6675 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.5012 (13.6409)  loss_vfl: 0.4345 (0.4330)  loss_bbox: 0.1202 (0.1213)  loss_giou: 0.4094 (0.4176)  loss_vfl_aux_0: 0.8785 (0.8827)  loss_bbox_aux_0: 0.1418 (0.1492)  loss_giou_aux_0: 0.4433 (0.4534)  loss_vfl_aux_1: 0.5495 (0.5604)  loss_bbox_aux_1: 0.1427 (0.1436)  loss_giou_aux_1: 0.4572 (0.4572)  loss_vfl_aux_2: 0.4530 (0.4589)  loss_bbox_aux_2: 0.1235 (0.1289)  loss_giou_aux_2: 0.4250 (0.4389)  loss_vfl_aux_3: 0.4272 (0.4329)  loss_bbox_aux_3: 0.1227 (0.1240)  loss_giou_aux_3: 0.4211 (0.4287)  loss_vfl_aux_4: 0.4325 (0.4354)  loss_bbox_aux_4: 0.1210 (0.1214)  loss_giou_aux_4: 0.4099 (0.4189)  loss_vfl_dn_0: 0.4557 (0.4603)  loss_bbox_dn_0: 0.1356 (0.1382)  loss_giou_dn_0: 0.4568 (0.4706)  loss_vfl_dn_1: 0.4031 (0.4015)  loss_bbox_dn_1: 0.1144 (0.1170)  loss_giou_dn_1: 0.4036 (0.4117)  loss_vfl_dn_2: 0.3815 (0.3827)  loss_bbox_dn_2: 0.1077 (0.1093)  loss_giou_dn_2: 0.3845 (0.3909)  loss_vfl_dn_3: 0.3762 (0.3760)  loss_bbox_dn_3: 0.1049 (0.1071)  loss_giou_dn_3: 0.3806 (0.3860)  loss_vfl_dn_4: 0.3746 (0.3740)  loss_bbox_dn_4: 0.1052 (0.1066)  loss_giou_dn_4: 0.3786 (0.3829)  loss_vfl_dn_5: 0.3750 (0.3733)  loss_bbox_dn_5: 0.1050 (0.1065)  loss_giou_dn_5: 0.3780 (0.3830)  loss_vfl_enc_0: 0.8269 (0.8278)  loss_bbox_enc_0: 0.1679 (0.1808)  loss_giou_enc_0: 0.5417 (0.5483)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.3730  data: 1.3138  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.4151  data: 0.6740  max mem: 16811\n",
            "Test: Total time: 0:00:02 (1.4332 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [145]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 12.8590 (12.8590)  loss_vfl: 0.4099 (0.4099)  loss_bbox: 0.1017 (0.1017)  loss_giou: 0.3848 (0.3848)  loss_vfl_aux_0: 0.8962 (0.8962)  loss_bbox_aux_0: 0.1160 (0.1160)  loss_giou_aux_0: 0.4157 (0.4157)  loss_vfl_aux_1: 0.6045 (0.6045)  loss_bbox_aux_1: 0.1157 (0.1157)  loss_giou_aux_1: 0.4145 (0.4145)  loss_vfl_aux_2: 0.4472 (0.4472)  loss_bbox_aux_2: 0.1094 (0.1094)  loss_giou_aux_2: 0.3974 (0.3974)  loss_vfl_aux_3: 0.4069 (0.4069)  loss_bbox_aux_3: 0.1084 (0.1084)  loss_giou_aux_3: 0.3937 (0.3937)  loss_vfl_aux_4: 0.4134 (0.4134)  loss_bbox_aux_4: 0.1034 (0.1034)  loss_giou_aux_4: 0.3847 (0.3847)  loss_vfl_dn_0: 0.4475 (0.4475)  loss_bbox_dn_0: 0.1216 (0.1216)  loss_giou_dn_0: 0.4450 (0.4450)  loss_vfl_dn_1: 0.3930 (0.3930)  loss_bbox_dn_1: 0.1006 (0.1006)  loss_giou_dn_1: 0.3847 (0.3847)  loss_vfl_dn_2: 0.3692 (0.3692)  loss_bbox_dn_2: 0.0945 (0.0945)  loss_giou_dn_2: 0.3661 (0.3661)  loss_vfl_dn_3: 0.3609 (0.3609)  loss_bbox_dn_3: 0.0925 (0.0925)  loss_giou_dn_3: 0.3611 (0.3611)  loss_vfl_dn_4: 0.3609 (0.3609)  loss_bbox_dn_4: 0.0911 (0.0911)  loss_giou_dn_4: 0.3566 (0.3566)  loss_vfl_dn_5: 0.3610 (0.3610)  loss_bbox_dn_5: 0.0909 (0.0909)  loss_giou_dn_5: 0.3569 (0.3569)  loss_vfl_enc_0: 0.8215 (0.8215)  loss_bbox_enc_0: 0.1550 (0.1550)  loss_giou_enc_0: 0.5051 (0.5051)  time: 1.5664  data: 1.0133  max mem: 16811\n",
            "Epoch: [145]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.2198 (13.3847)  loss_vfl: 0.4151 (0.4191)  loss_bbox: 0.1170 (0.1190)  loss_giou: 0.4127 (0.4139)  loss_vfl_aux_0: 0.8962 (0.8917)  loss_bbox_aux_0: 0.1390 (0.1454)  loss_giou_aux_0: 0.4250 (0.4470)  loss_vfl_aux_1: 0.5564 (0.5610)  loss_bbox_aux_1: 0.1403 (0.1425)  loss_giou_aux_1: 0.4474 (0.4494)  loss_vfl_aux_2: 0.4505 (0.4525)  loss_bbox_aux_2: 0.1225 (0.1265)  loss_giou_aux_2: 0.4090 (0.4306)  loss_vfl_aux_3: 0.4166 (0.4226)  loss_bbox_aux_3: 0.1193 (0.1231)  loss_giou_aux_3: 0.4132 (0.4228)  loss_vfl_aux_4: 0.4176 (0.4232)  loss_bbox_aux_4: 0.1183 (0.1192)  loss_giou_aux_4: 0.4129 (0.4149)  loss_vfl_dn_0: 0.4573 (0.4593)  loss_bbox_dn_0: 0.1283 (0.1330)  loss_giou_dn_0: 0.4450 (0.4560)  loss_vfl_dn_1: 0.3958 (0.3977)  loss_bbox_dn_1: 0.1090 (0.1117)  loss_giou_dn_1: 0.3847 (0.3942)  loss_vfl_dn_2: 0.3755 (0.3778)  loss_bbox_dn_2: 0.1026 (0.1045)  loss_giou_dn_2: 0.3661 (0.3764)  loss_vfl_dn_3: 0.3679 (0.3715)  loss_bbox_dn_3: 0.1006 (0.1028)  loss_giou_dn_3: 0.3611 (0.3713)  loss_vfl_dn_4: 0.3671 (0.3699)  loss_bbox_dn_4: 0.1013 (0.1019)  loss_giou_dn_4: 0.3567 (0.3687)  loss_vfl_dn_5: 0.3659 (0.3689)  loss_bbox_dn_5: 0.1007 (0.1016)  loss_giou_dn_5: 0.3569 (0.3674)  loss_vfl_enc_0: 0.8126 (0.8124)  loss_bbox_enc_0: 0.1729 (0.1766)  loss_giou_enc_0: 0.5270 (0.5366)  time: 0.6614  data: 0.1464  max mem: 16811\n",
            "Epoch: [145] Total time: 0:00:05 (0.6692 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.2198 (13.3847)  loss_vfl: 0.4151 (0.4191)  loss_bbox: 0.1170 (0.1190)  loss_giou: 0.4127 (0.4139)  loss_vfl_aux_0: 0.8962 (0.8917)  loss_bbox_aux_0: 0.1390 (0.1454)  loss_giou_aux_0: 0.4250 (0.4470)  loss_vfl_aux_1: 0.5564 (0.5610)  loss_bbox_aux_1: 0.1403 (0.1425)  loss_giou_aux_1: 0.4474 (0.4494)  loss_vfl_aux_2: 0.4505 (0.4525)  loss_bbox_aux_2: 0.1225 (0.1265)  loss_giou_aux_2: 0.4090 (0.4306)  loss_vfl_aux_3: 0.4166 (0.4226)  loss_bbox_aux_3: 0.1193 (0.1231)  loss_giou_aux_3: 0.4132 (0.4228)  loss_vfl_aux_4: 0.4176 (0.4232)  loss_bbox_aux_4: 0.1183 (0.1192)  loss_giou_aux_4: 0.4129 (0.4149)  loss_vfl_dn_0: 0.4573 (0.4593)  loss_bbox_dn_0: 0.1283 (0.1330)  loss_giou_dn_0: 0.4450 (0.4560)  loss_vfl_dn_1: 0.3958 (0.3977)  loss_bbox_dn_1: 0.1090 (0.1117)  loss_giou_dn_1: 0.3847 (0.3942)  loss_vfl_dn_2: 0.3755 (0.3778)  loss_bbox_dn_2: 0.1026 (0.1045)  loss_giou_dn_2: 0.3661 (0.3764)  loss_vfl_dn_3: 0.3679 (0.3715)  loss_bbox_dn_3: 0.1006 (0.1028)  loss_giou_dn_3: 0.3611 (0.3713)  loss_vfl_dn_4: 0.3671 (0.3699)  loss_bbox_dn_4: 0.1013 (0.1019)  loss_giou_dn_4: 0.3567 (0.3687)  loss_vfl_dn_5: 0.3659 (0.3689)  loss_bbox_dn_5: 0.1007 (0.1016)  loss_giou_dn_5: 0.3569 (0.3674)  loss_vfl_enc_0: 0.8126 (0.8124)  loss_bbox_enc_0: 0.1729 (0.1766)  loss_giou_enc_0: 0.5270 (0.5366)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.2429  data: 2.8574  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3463  data: 1.4456  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3765 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [146]  [0/8]  eta: 0:00:11  lr: 0.000006  loss: 13.7178 (13.7178)  loss_vfl: 0.4115 (0.4115)  loss_bbox: 0.1236 (0.1236)  loss_giou: 0.4365 (0.4365)  loss_vfl_aux_0: 0.8610 (0.8610)  loss_bbox_aux_0: 0.1780 (0.1780)  loss_giou_aux_0: 0.4987 (0.4987)  loss_vfl_aux_1: 0.5336 (0.5336)  loss_bbox_aux_1: 0.1597 (0.1597)  loss_giou_aux_1: 0.4666 (0.4666)  loss_vfl_aux_2: 0.4381 (0.4381)  loss_bbox_aux_2: 0.1285 (0.1285)  loss_giou_aux_2: 0.4474 (0.4474)  loss_vfl_aux_3: 0.4161 (0.4161)  loss_bbox_aux_3: 0.1330 (0.1330)  loss_giou_aux_3: 0.4487 (0.4487)  loss_vfl_aux_4: 0.4144 (0.4144)  loss_bbox_aux_4: 0.1246 (0.1246)  loss_giou_aux_4: 0.4375 (0.4375)  loss_vfl_dn_0: 0.4603 (0.4603)  loss_bbox_dn_0: 0.1341 (0.1341)  loss_giou_dn_0: 0.4745 (0.4745)  loss_vfl_dn_1: 0.4019 (0.4019)  loss_bbox_dn_1: 0.1143 (0.1143)  loss_giou_dn_1: 0.4186 (0.4186)  loss_vfl_dn_2: 0.3860 (0.3860)  loss_bbox_dn_2: 0.1048 (0.1048)  loss_giou_dn_2: 0.3950 (0.3950)  loss_vfl_dn_3: 0.3813 (0.3813)  loss_bbox_dn_3: 0.1034 (0.1034)  loss_giou_dn_3: 0.3886 (0.3886)  loss_vfl_dn_4: 0.3803 (0.3803)  loss_bbox_dn_4: 0.1026 (0.1026)  loss_giou_dn_4: 0.3861 (0.3861)  loss_vfl_dn_5: 0.3784 (0.3784)  loss_bbox_dn_5: 0.1025 (0.1025)  loss_giou_dn_5: 0.3856 (0.3856)  loss_vfl_enc_0: 0.7716 (0.7716)  loss_bbox_enc_0: 0.2066 (0.2066)  loss_giou_enc_0: 0.5838 (0.5838)  time: 1.3881  data: 0.8514  max mem: 16811\n",
            "Epoch: [146]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.3953 (13.3659)  loss_vfl: 0.4131 (0.4152)  loss_bbox: 0.1195 (0.1195)  loss_giou: 0.4037 (0.4132)  loss_vfl_aux_0: 0.8911 (0.8915)  loss_bbox_aux_0: 0.1461 (0.1446)  loss_giou_aux_0: 0.4427 (0.4498)  loss_vfl_aux_1: 0.5428 (0.5408)  loss_bbox_aux_1: 0.1437 (0.1428)  loss_giou_aux_1: 0.4392 (0.4444)  loss_vfl_aux_2: 0.4409 (0.4414)  loss_bbox_aux_2: 0.1285 (0.1292)  loss_giou_aux_2: 0.4255 (0.4292)  loss_vfl_aux_3: 0.4161 (0.4196)  loss_bbox_aux_3: 0.1206 (0.1241)  loss_giou_aux_3: 0.4149 (0.4213)  loss_vfl_aux_4: 0.4160 (0.4179)  loss_bbox_aux_4: 0.1193 (0.1217)  loss_giou_aux_4: 0.4071 (0.4167)  loss_vfl_dn_0: 0.4603 (0.4592)  loss_bbox_dn_0: 0.1340 (0.1350)  loss_giou_dn_0: 0.4594 (0.4580)  loss_vfl_dn_1: 0.3958 (0.3967)  loss_bbox_dn_1: 0.1089 (0.1111)  loss_giou_dn_1: 0.3886 (0.3963)  loss_vfl_dn_2: 0.3755 (0.3755)  loss_bbox_dn_2: 0.1048 (0.1050)  loss_giou_dn_2: 0.3787 (0.3798)  loss_vfl_dn_3: 0.3682 (0.3703)  loss_bbox_dn_3: 0.1020 (0.1032)  loss_giou_dn_3: 0.3730 (0.3744)  loss_vfl_dn_4: 0.3699 (0.3694)  loss_bbox_dn_4: 0.1026 (0.1027)  loss_giou_dn_4: 0.3715 (0.3723)  loss_vfl_dn_5: 0.3680 (0.3677)  loss_bbox_dn_5: 0.1024 (0.1024)  loss_giou_dn_5: 0.3700 (0.3712)  loss_vfl_enc_0: 0.8052 (0.8162)  loss_bbox_enc_0: 0.1705 (0.1756)  loss_giou_enc_0: 0.5331 (0.5406)  time: 0.6551  data: 0.1413  max mem: 16811\n",
            "Epoch: [146] Total time: 0:00:05 (0.6641 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.3953 (13.3659)  loss_vfl: 0.4131 (0.4152)  loss_bbox: 0.1195 (0.1195)  loss_giou: 0.4037 (0.4132)  loss_vfl_aux_0: 0.8911 (0.8915)  loss_bbox_aux_0: 0.1461 (0.1446)  loss_giou_aux_0: 0.4427 (0.4498)  loss_vfl_aux_1: 0.5428 (0.5408)  loss_bbox_aux_1: 0.1437 (0.1428)  loss_giou_aux_1: 0.4392 (0.4444)  loss_vfl_aux_2: 0.4409 (0.4414)  loss_bbox_aux_2: 0.1285 (0.1292)  loss_giou_aux_2: 0.4255 (0.4292)  loss_vfl_aux_3: 0.4161 (0.4196)  loss_bbox_aux_3: 0.1206 (0.1241)  loss_giou_aux_3: 0.4149 (0.4213)  loss_vfl_aux_4: 0.4160 (0.4179)  loss_bbox_aux_4: 0.1193 (0.1217)  loss_giou_aux_4: 0.4071 (0.4167)  loss_vfl_dn_0: 0.4603 (0.4592)  loss_bbox_dn_0: 0.1340 (0.1350)  loss_giou_dn_0: 0.4594 (0.4580)  loss_vfl_dn_1: 0.3958 (0.3967)  loss_bbox_dn_1: 0.1089 (0.1111)  loss_giou_dn_1: 0.3886 (0.3963)  loss_vfl_dn_2: 0.3755 (0.3755)  loss_bbox_dn_2: 0.1048 (0.1050)  loss_giou_dn_2: 0.3787 (0.3798)  loss_vfl_dn_3: 0.3682 (0.3703)  loss_bbox_dn_3: 0.1020 (0.1032)  loss_giou_dn_3: 0.3730 (0.3744)  loss_vfl_dn_4: 0.3699 (0.3694)  loss_bbox_dn_4: 0.1026 (0.1027)  loss_giou_dn_4: 0.3715 (0.3723)  loss_vfl_dn_5: 0.3680 (0.3677)  loss_bbox_dn_5: 0.1024 (0.1024)  loss_giou_dn_5: 0.3700 (0.3712)  loss_vfl_enc_0: 0.8052 (0.8162)  loss_bbox_enc_0: 0.1705 (0.1756)  loss_giou_enc_0: 0.5331 (0.5406)\n",
            "Test:  [0/2]  eta: 0:00:10    time: 5.0742  data: 4.0042  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.7637  data: 2.0191  max mem: 16811\n",
            "Test: Total time: 0:00:05 (2.7888 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [147]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 12.9157 (12.9157)  loss_vfl: 0.4077 (0.4077)  loss_bbox: 0.1087 (0.1087)  loss_giou: 0.3828 (0.3828)  loss_vfl_aux_0: 0.9363 (0.9363)  loss_bbox_aux_0: 0.1382 (0.1382)  loss_giou_aux_0: 0.4027 (0.4027)  loss_vfl_aux_1: 0.5679 (0.5679)  loss_bbox_aux_1: 0.1183 (0.1183)  loss_giou_aux_1: 0.3946 (0.3946)  loss_vfl_aux_2: 0.4294 (0.4294)  loss_bbox_aux_2: 0.1173 (0.1173)  loss_giou_aux_2: 0.4012 (0.4012)  loss_vfl_aux_3: 0.4043 (0.4043)  loss_bbox_aux_3: 0.1134 (0.1134)  loss_giou_aux_3: 0.3926 (0.3926)  loss_vfl_aux_4: 0.4116 (0.4116)  loss_bbox_aux_4: 0.1084 (0.1084)  loss_giou_aux_4: 0.3804 (0.3804)  loss_vfl_dn_0: 0.4554 (0.4554)  loss_bbox_dn_0: 0.1327 (0.1327)  loss_giou_dn_0: 0.4304 (0.4304)  loss_vfl_dn_1: 0.3859 (0.3859)  loss_bbox_dn_1: 0.1143 (0.1143)  loss_giou_dn_1: 0.3804 (0.3804)  loss_vfl_dn_2: 0.3645 (0.3645)  loss_bbox_dn_2: 0.1052 (0.1052)  loss_giou_dn_2: 0.3607 (0.3607)  loss_vfl_dn_3: 0.3607 (0.3607)  loss_bbox_dn_3: 0.1046 (0.1046)  loss_giou_dn_3: 0.3580 (0.3580)  loss_vfl_dn_4: 0.3596 (0.3596)  loss_bbox_dn_4: 0.1028 (0.1028)  loss_giou_dn_4: 0.3537 (0.3537)  loss_vfl_dn_5: 0.3598 (0.3598)  loss_bbox_dn_5: 0.1028 (0.1028)  loss_giou_dn_5: 0.3530 (0.3530)  loss_vfl_enc_0: 0.8501 (0.8501)  loss_bbox_enc_0: 0.1662 (0.1662)  loss_giou_enc_0: 0.4988 (0.4988)  time: 1.5362  data: 0.9987  max mem: 16811\n",
            "Epoch: [147]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.2047 (13.2532)  loss_vfl: 0.4190 (0.4200)  loss_bbox: 0.1123 (0.1152)  loss_giou: 0.3894 (0.3999)  loss_vfl_aux_0: 0.8737 (0.8856)  loss_bbox_aux_0: 0.1402 (0.1412)  loss_giou_aux_0: 0.4336 (0.4391)  loss_vfl_aux_1: 0.5502 (0.5514)  loss_bbox_aux_1: 0.1388 (0.1352)  loss_giou_aux_1: 0.4272 (0.4333)  loss_vfl_aux_2: 0.4432 (0.4436)  loss_bbox_aux_2: 0.1213 (0.1248)  loss_giou_aux_2: 0.4053 (0.4189)  loss_vfl_aux_3: 0.4257 (0.4244)  loss_bbox_aux_3: 0.1208 (0.1209)  loss_giou_aux_3: 0.4035 (0.4106)  loss_vfl_aux_4: 0.4246 (0.4242)  loss_bbox_aux_4: 0.1139 (0.1155)  loss_giou_aux_4: 0.3911 (0.4016)  loss_vfl_dn_0: 0.4577 (0.4580)  loss_bbox_dn_0: 0.1327 (0.1349)  loss_giou_dn_0: 0.4422 (0.4531)  loss_vfl_dn_1: 0.3959 (0.3947)  loss_bbox_dn_1: 0.1107 (0.1124)  loss_giou_dn_1: 0.3804 (0.3916)  loss_vfl_dn_2: 0.3723 (0.3739)  loss_bbox_dn_2: 0.1052 (0.1059)  loss_giou_dn_2: 0.3652 (0.3738)  loss_vfl_dn_3: 0.3664 (0.3693)  loss_bbox_dn_3: 0.1039 (0.1045)  loss_giou_dn_3: 0.3628 (0.3700)  loss_vfl_dn_4: 0.3672 (0.3683)  loss_bbox_dn_4: 0.1028 (0.1040)  loss_giou_dn_4: 0.3598 (0.3672)  loss_vfl_dn_5: 0.3666 (0.3683)  loss_bbox_dn_5: 0.1028 (0.1038)  loss_giou_dn_5: 0.3595 (0.3665)  loss_vfl_enc_0: 0.8085 (0.8225)  loss_bbox_enc_0: 0.1682 (0.1716)  loss_giou_enc_0: 0.5214 (0.5336)  time: 0.6578  data: 0.1459  max mem: 16811\n",
            "Epoch: [147] Total time: 0:00:05 (0.6657 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.2047 (13.2532)  loss_vfl: 0.4190 (0.4200)  loss_bbox: 0.1123 (0.1152)  loss_giou: 0.3894 (0.3999)  loss_vfl_aux_0: 0.8737 (0.8856)  loss_bbox_aux_0: 0.1402 (0.1412)  loss_giou_aux_0: 0.4336 (0.4391)  loss_vfl_aux_1: 0.5502 (0.5514)  loss_bbox_aux_1: 0.1388 (0.1352)  loss_giou_aux_1: 0.4272 (0.4333)  loss_vfl_aux_2: 0.4432 (0.4436)  loss_bbox_aux_2: 0.1213 (0.1248)  loss_giou_aux_2: 0.4053 (0.4189)  loss_vfl_aux_3: 0.4257 (0.4244)  loss_bbox_aux_3: 0.1208 (0.1209)  loss_giou_aux_3: 0.4035 (0.4106)  loss_vfl_aux_4: 0.4246 (0.4242)  loss_bbox_aux_4: 0.1139 (0.1155)  loss_giou_aux_4: 0.3911 (0.4016)  loss_vfl_dn_0: 0.4577 (0.4580)  loss_bbox_dn_0: 0.1327 (0.1349)  loss_giou_dn_0: 0.4422 (0.4531)  loss_vfl_dn_1: 0.3959 (0.3947)  loss_bbox_dn_1: 0.1107 (0.1124)  loss_giou_dn_1: 0.3804 (0.3916)  loss_vfl_dn_2: 0.3723 (0.3739)  loss_bbox_dn_2: 0.1052 (0.1059)  loss_giou_dn_2: 0.3652 (0.3738)  loss_vfl_dn_3: 0.3664 (0.3693)  loss_bbox_dn_3: 0.1039 (0.1045)  loss_giou_dn_3: 0.3628 (0.3700)  loss_vfl_dn_4: 0.3672 (0.3683)  loss_bbox_dn_4: 0.1028 (0.1040)  loss_giou_dn_4: 0.3598 (0.3672)  loss_vfl_dn_5: 0.3666 (0.3683)  loss_bbox_dn_5: 0.1028 (0.1038)  loss_giou_dn_5: 0.3595 (0.3665)  loss_vfl_enc_0: 0.8085 (0.8225)  loss_bbox_enc_0: 0.1682 (0.1716)  loss_giou_enc_0: 0.5214 (0.5336)\n",
            "Test:  [0/2]  eta: 0:00:08    time: 4.2487  data: 3.1822  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.3490  data: 1.6072  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.3673 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.645\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [148]  [0/8]  eta: 0:00:12  lr: 0.000006  loss: 13.6795 (13.6795)  loss_vfl: 0.4154 (0.4154)  loss_bbox: 0.1252 (0.1252)  loss_giou: 0.4112 (0.4112)  loss_vfl_aux_0: 0.8764 (0.8764)  loss_bbox_aux_0: 0.1532 (0.1532)  loss_giou_aux_0: 0.4517 (0.4517)  loss_vfl_aux_1: 0.5473 (0.5473)  loss_bbox_aux_1: 0.1562 (0.1562)  loss_giou_aux_1: 0.4492 (0.4492)  loss_vfl_aux_2: 0.4547 (0.4547)  loss_bbox_aux_2: 0.1335 (0.1335)  loss_giou_aux_2: 0.4272 (0.4272)  loss_vfl_aux_3: 0.4274 (0.4274)  loss_bbox_aux_3: 0.1297 (0.1297)  loss_giou_aux_3: 0.4242 (0.4242)  loss_vfl_aux_4: 0.4245 (0.4245)  loss_bbox_aux_4: 0.1243 (0.1243)  loss_giou_aux_4: 0.4104 (0.4104)  loss_vfl_dn_0: 0.4714 (0.4714)  loss_bbox_dn_0: 0.1495 (0.1495)  loss_giou_dn_0: 0.4780 (0.4780)  loss_vfl_dn_1: 0.4137 (0.4137)  loss_bbox_dn_1: 0.1230 (0.1230)  loss_giou_dn_1: 0.4146 (0.4146)  loss_vfl_dn_2: 0.3866 (0.3866)  loss_bbox_dn_2: 0.1166 (0.1166)  loss_giou_dn_2: 0.3973 (0.3973)  loss_vfl_dn_3: 0.3817 (0.3817)  loss_bbox_dn_3: 0.1151 (0.1151)  loss_giou_dn_3: 0.3931 (0.3931)  loss_vfl_dn_4: 0.3774 (0.3774)  loss_bbox_dn_4: 0.1145 (0.1145)  loss_giou_dn_4: 0.3902 (0.3902)  loss_vfl_dn_5: 0.3764 (0.3764)  loss_bbox_dn_5: 0.1143 (0.1143)  loss_giou_dn_5: 0.3889 (0.3889)  loss_vfl_enc_0: 0.8252 (0.8252)  loss_bbox_enc_0: 0.1760 (0.1760)  loss_giou_enc_0: 0.5344 (0.5344)  time: 1.5711  data: 0.9879  max mem: 16811\n",
            "Epoch: [148]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 12.9448 (13.3190)  loss_vfl: 0.4139 (0.4228)  loss_bbox: 0.1139 (0.1184)  loss_giou: 0.3908 (0.4057)  loss_vfl_aux_0: 0.8773 (0.8827)  loss_bbox_aux_0: 0.1452 (0.1434)  loss_giou_aux_0: 0.4276 (0.4459)  loss_vfl_aux_1: 0.5258 (0.5332)  loss_bbox_aux_1: 0.1378 (0.1383)  loss_giou_aux_1: 0.4208 (0.4391)  loss_vfl_aux_2: 0.4349 (0.4418)  loss_bbox_aux_2: 0.1278 (0.1275)  loss_giou_aux_2: 0.4117 (0.4270)  loss_vfl_aux_3: 0.4230 (0.4266)  loss_bbox_aux_3: 0.1216 (0.1224)  loss_giou_aux_3: 0.4089 (0.4181)  loss_vfl_aux_4: 0.4200 (0.4268)  loss_bbox_aux_4: 0.1166 (0.1200)  loss_giou_aux_4: 0.3973 (0.4109)  loss_vfl_dn_0: 0.4548 (0.4589)  loss_bbox_dn_0: 0.1294 (0.1322)  loss_giou_dn_0: 0.4416 (0.4546)  loss_vfl_dn_1: 0.3908 (0.3966)  loss_bbox_dn_1: 0.1086 (0.1111)  loss_giou_dn_1: 0.3837 (0.3978)  loss_vfl_dn_2: 0.3683 (0.3747)  loss_bbox_dn_2: 0.1026 (0.1052)  loss_giou_dn_2: 0.3640 (0.3807)  loss_vfl_dn_3: 0.3635 (0.3692)  loss_bbox_dn_3: 0.1008 (0.1034)  loss_giou_dn_3: 0.3609 (0.3761)  loss_vfl_dn_4: 0.3615 (0.3670)  loss_bbox_dn_4: 0.1005 (0.1032)  loss_giou_dn_4: 0.3572 (0.3742)  loss_vfl_dn_5: 0.3594 (0.3655)  loss_bbox_dn_5: 0.1005 (0.1029)  loss_giou_dn_5: 0.3559 (0.3733)  loss_vfl_enc_0: 0.8119 (0.8101)  loss_bbox_enc_0: 0.1723 (0.1718)  loss_giou_enc_0: 0.5344 (0.5400)  time: 0.6648  data: 0.1474  max mem: 16811\n",
            "Epoch: [148] Total time: 0:00:05 (0.6712 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 12.9448 (13.3190)  loss_vfl: 0.4139 (0.4228)  loss_bbox: 0.1139 (0.1184)  loss_giou: 0.3908 (0.4057)  loss_vfl_aux_0: 0.8773 (0.8827)  loss_bbox_aux_0: 0.1452 (0.1434)  loss_giou_aux_0: 0.4276 (0.4459)  loss_vfl_aux_1: 0.5258 (0.5332)  loss_bbox_aux_1: 0.1378 (0.1383)  loss_giou_aux_1: 0.4208 (0.4391)  loss_vfl_aux_2: 0.4349 (0.4418)  loss_bbox_aux_2: 0.1278 (0.1275)  loss_giou_aux_2: 0.4117 (0.4270)  loss_vfl_aux_3: 0.4230 (0.4266)  loss_bbox_aux_3: 0.1216 (0.1224)  loss_giou_aux_3: 0.4089 (0.4181)  loss_vfl_aux_4: 0.4200 (0.4268)  loss_bbox_aux_4: 0.1166 (0.1200)  loss_giou_aux_4: 0.3973 (0.4109)  loss_vfl_dn_0: 0.4548 (0.4589)  loss_bbox_dn_0: 0.1294 (0.1322)  loss_giou_dn_0: 0.4416 (0.4546)  loss_vfl_dn_1: 0.3908 (0.3966)  loss_bbox_dn_1: 0.1086 (0.1111)  loss_giou_dn_1: 0.3837 (0.3978)  loss_vfl_dn_2: 0.3683 (0.3747)  loss_bbox_dn_2: 0.1026 (0.1052)  loss_giou_dn_2: 0.3640 (0.3807)  loss_vfl_dn_3: 0.3635 (0.3692)  loss_bbox_dn_3: 0.1008 (0.1034)  loss_giou_dn_3: 0.3609 (0.3761)  loss_vfl_dn_4: 0.3615 (0.3670)  loss_bbox_dn_4: 0.1005 (0.1032)  loss_giou_dn_4: 0.3572 (0.3742)  loss_vfl_dn_5: 0.3594 (0.3655)  loss_bbox_dn_5: 0.1005 (0.1029)  loss_giou_dn_5: 0.3559 (0.3733)  loss_vfl_enc_0: 0.8119 (0.8101)  loss_bbox_enc_0: 0.1723 (0.1718)  loss_giou_enc_0: 0.5344 (0.5400)\n",
            "Test:  [0/2]  eta: 0:00:04    time: 2.4455  data: 1.3787  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:01    time: 1.6249  data: 0.7059  max mem: 16811\n",
            "Test: Total time: 0:00:03 (1.6468 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Epoch: [149]  [0/8]  eta: 0:00:11  lr: 0.000006  loss: 13.5094 (13.5094)  loss_vfl: 0.3976 (0.3976)  loss_bbox: 0.1223 (0.1223)  loss_giou: 0.4256 (0.4256)  loss_vfl_aux_0: 0.8830 (0.8830)  loss_bbox_aux_0: 0.1489 (0.1489)  loss_giou_aux_0: 0.4663 (0.4663)  loss_vfl_aux_1: 0.4949 (0.4949)  loss_bbox_aux_1: 0.1534 (0.1534)  loss_giou_aux_1: 0.4738 (0.4738)  loss_vfl_aux_2: 0.4095 (0.4095)  loss_bbox_aux_2: 0.1324 (0.1324)  loss_giou_aux_2: 0.4492 (0.4492)  loss_vfl_aux_3: 0.3968 (0.3968)  loss_bbox_aux_3: 0.1287 (0.1287)  loss_giou_aux_3: 0.4381 (0.4381)  loss_vfl_aux_4: 0.4003 (0.4003)  loss_bbox_aux_4: 0.1276 (0.1276)  loss_giou_aux_4: 0.4291 (0.4291)  loss_vfl_dn_0: 0.4692 (0.4692)  loss_bbox_dn_0: 0.1330 (0.1330)  loss_giou_dn_0: 0.4587 (0.4587)  loss_vfl_dn_1: 0.4084 (0.4084)  loss_bbox_dn_1: 0.1178 (0.1178)  loss_giou_dn_1: 0.4100 (0.4100)  loss_vfl_dn_2: 0.3826 (0.3826)  loss_bbox_dn_2: 0.1128 (0.1128)  loss_giou_dn_2: 0.3980 (0.3980)  loss_vfl_dn_3: 0.3758 (0.3758)  loss_bbox_dn_3: 0.1119 (0.1119)  loss_giou_dn_3: 0.3933 (0.3933)  loss_vfl_dn_4: 0.3744 (0.3744)  loss_bbox_dn_4: 0.1114 (0.1114)  loss_giou_dn_4: 0.3905 (0.3905)  loss_vfl_dn_5: 0.3741 (0.3741)  loss_bbox_dn_5: 0.1109 (0.1109)  loss_giou_dn_5: 0.3877 (0.3877)  loss_vfl_enc_0: 0.8102 (0.8102)  loss_bbox_enc_0: 0.1652 (0.1652)  loss_giou_enc_0: 0.5358 (0.5358)  time: 1.4837  data: 0.9166  max mem: 16811\n",
            "Epoch: [149]  [7/8]  eta: 0:00:00  lr: 0.000006  loss: 13.0990 (13.2024)  loss_vfl: 0.4022 (0.4101)  loss_bbox: 0.1070 (0.1157)  loss_giou: 0.3914 (0.4026)  loss_vfl_aux_0: 0.8720 (0.8679)  loss_bbox_aux_0: 0.1381 (0.1446)  loss_giou_aux_0: 0.4364 (0.4491)  loss_vfl_aux_1: 0.5385 (0.5360)  loss_bbox_aux_1: 0.1370 (0.1428)  loss_giou_aux_1: 0.4357 (0.4434)  loss_vfl_aux_2: 0.4346 (0.4397)  loss_bbox_aux_2: 0.1183 (0.1254)  loss_giou_aux_2: 0.4097 (0.4243)  loss_vfl_aux_3: 0.4118 (0.4203)  loss_bbox_aux_3: 0.1107 (0.1188)  loss_giou_aux_3: 0.4083 (0.4121)  loss_vfl_aux_4: 0.4035 (0.4153)  loss_bbox_aux_4: 0.1081 (0.1166)  loss_giou_aux_4: 0.3928 (0.4037)  loss_vfl_dn_0: 0.4656 (0.4604)  loss_bbox_dn_0: 0.1281 (0.1291)  loss_giou_dn_0: 0.4397 (0.4488)  loss_vfl_dn_1: 0.4048 (0.4004)  loss_bbox_dn_1: 0.1068 (0.1093)  loss_giou_dn_1: 0.3850 (0.3903)  loss_vfl_dn_2: 0.3794 (0.3760)  loss_bbox_dn_2: 0.0987 (0.1028)  loss_giou_dn_2: 0.3670 (0.3733)  loss_vfl_dn_3: 0.3722 (0.3697)  loss_bbox_dn_3: 0.0961 (0.1006)  loss_giou_dn_3: 0.3606 (0.3679)  loss_vfl_dn_4: 0.3708 (0.3679)  loss_bbox_dn_4: 0.0954 (0.0999)  loss_giou_dn_4: 0.3573 (0.3652)  loss_vfl_dn_5: 0.3685 (0.3668)  loss_bbox_dn_5: 0.0951 (0.0996)  loss_giou_dn_5: 0.3560 (0.3636)  loss_vfl_enc_0: 0.8095 (0.8102)  loss_bbox_enc_0: 0.1652 (0.1745)  loss_giou_enc_0: 0.5277 (0.5374)  time: 0.6642  data: 0.1432  max mem: 16811\n",
            "Epoch: [149] Total time: 0:00:05 (0.6716 s / it)\n",
            "Averaged stats: lr: 0.000006  loss: 13.0990 (13.2024)  loss_vfl: 0.4022 (0.4101)  loss_bbox: 0.1070 (0.1157)  loss_giou: 0.3914 (0.4026)  loss_vfl_aux_0: 0.8720 (0.8679)  loss_bbox_aux_0: 0.1381 (0.1446)  loss_giou_aux_0: 0.4364 (0.4491)  loss_vfl_aux_1: 0.5385 (0.5360)  loss_bbox_aux_1: 0.1370 (0.1428)  loss_giou_aux_1: 0.4357 (0.4434)  loss_vfl_aux_2: 0.4346 (0.4397)  loss_bbox_aux_2: 0.1183 (0.1254)  loss_giou_aux_2: 0.4097 (0.4243)  loss_vfl_aux_3: 0.4118 (0.4203)  loss_bbox_aux_3: 0.1107 (0.1188)  loss_giou_aux_3: 0.4083 (0.4121)  loss_vfl_aux_4: 0.4035 (0.4153)  loss_bbox_aux_4: 0.1081 (0.1166)  loss_giou_aux_4: 0.3928 (0.4037)  loss_vfl_dn_0: 0.4656 (0.4604)  loss_bbox_dn_0: 0.1281 (0.1291)  loss_giou_dn_0: 0.4397 (0.4488)  loss_vfl_dn_1: 0.4048 (0.4004)  loss_bbox_dn_1: 0.1068 (0.1093)  loss_giou_dn_1: 0.3850 (0.3903)  loss_vfl_dn_2: 0.3794 (0.3760)  loss_bbox_dn_2: 0.0987 (0.1028)  loss_giou_dn_2: 0.3670 (0.3733)  loss_vfl_dn_3: 0.3722 (0.3697)  loss_bbox_dn_3: 0.0961 (0.1006)  loss_giou_dn_3: 0.3606 (0.3679)  loss_vfl_dn_4: 0.3708 (0.3679)  loss_bbox_dn_4: 0.0954 (0.0999)  loss_giou_dn_4: 0.3573 (0.3652)  loss_vfl_dn_5: 0.3685 (0.3668)  loss_bbox_dn_5: 0.0951 (0.0996)  loss_giou_dn_5: 0.3560 (0.3636)  loss_vfl_enc_0: 0.8095 (0.8102)  loss_bbox_enc_0: 0.1652 (0.1745)  loss_giou_enc_0: 0.5277 (0.5374)\n",
            "Test:  [0/2]  eta: 0:00:07    time: 3.8376  data: 2.7660  max mem: 16811\n",
            "Test:  [1/2]  eta: 0:00:02    time: 2.1474  data: 1.4000  max mem: 16811\n",
            "Test: Total time: 0:00:04 (2.1706 s / it)\n",
            "Averaged stats: \n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.631\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            "best_stat: {'epoch': 123, 'coco_eval_bbox': 0.3206248663277214}\n",
            "Training time 0:37:44\n"
          ]
        }
      ]
    }
  ]
}